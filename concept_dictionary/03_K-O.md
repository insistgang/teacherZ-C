# 计算机视觉概念词典 - K-O

## K-means (K均值)

**定义**: 经典的无监督聚类算法，将数据划分到K个簇，使簇内误差最小。

**详细解释**: K-means迭代执行两步：分配步将每个点分配到最近的簇中心，更新步重新计算簇中心（均值）。初始化方法影响收敛，K-means++通过概率选择初始中心改善。对球状簇效果好，对非凸簇效果差。变体包括Kernel K-means、Mini-batch K-means。广泛应用于向量量化、颜色量化、超像素分割。

**数学公式**:
$$\min_{C} \sum_{k=1}^K \sum_{x_i \in C_k} \|x_i - \mu_k\|^2$$

**相关概念**: Clustering, K-means++, Vector Quantization, Superpixel

**代表论文**: Lloyd, S. (1982). Least squares quantization in PCM. IEEE Trans. Inf. Theory.

**代码示例**:
```python
def kmeans(X, K, max_iters=100):
    """K-means聚类"""
    # 随机初始化中心
    idx = np.random.choice(len(X), K, replace=False)
    centers = X[idx]
    
    for _ in range(max_iters):
        # 分配步：计算距离并分配
        distances = np.sqrt(((X[:, None] - centers) ** 2).sum(axis=2))
        labels = np.argmin(distances, axis=1)
        
        # 更新步：重新计算中心
        new_centers = np.array([X[labels == k].mean(axis=0) for k in range(K)])
        
        # 检查收敛
        if np.allclose(centers, new_centers):
            break
        centers = new_centers
    
    return labels, centers

def kmeans_plus_plus_init(X, K):
    """K-means++初始化"""
    centers = [X[np.random.randint(len(X))]]
    
    for _ in range(1, K):
        # 计算每个点到最近中心的距离
        distances = np.min([np.sum((X - c)**2, axis=1) for c in centers], axis=0)
        
        # 概率选择新中心
        probs = distances / distances.sum()
        idx = np.random.choice(len(X), p=probs)
        centers.append(X[idx])
    
    return np.array(centers)
```

---

## K-nearest Neighbors (K近邻)

**定义**: 基于实例的学习算法，通过K个最近邻样本进行分类或回归。

**详细解释**: KNN是懒惰学习，训练阶段只存储数据，预测时计算到所有训练样本的距离，选择最近的K个进行投票（分类）或平均（回归）。距离度量常用欧氏距离、曼哈顿距离。K的选择影响结果：K小易过拟合，K大易欠拟合。计算复杂度高O(Nd)，可通过KD树、Ball树加速。

**数学公式**:
分类: $\hat{y} = \arg\max_c \sum_{i \in N_K(x)} I(y_i = c)$

**相关概念**: Instance-based Learning, Distance Metric, KD-tree

**代表论文**: Fix, E., & Hodges, J. L. (1951). Discriminatory analysis. USAF School of Aviation Medicine.

**代码示例**:
```python
from collections import Counter

class KNN:
    def __init__(self, k=5):
        self.k = k
    
    def fit(self, X, y):
        self.X_train = X
        self.y_train = y
    
    def predict(self, X):
        predictions = []
        for x in X:
            # 计算到所有训练样本的距离
            distances = np.sqrt(np.sum((self.X_train - x)**2, axis=1))
            
            # 选择K个最近邻
            k_indices = np.argsort(distances)[:self.k]
            k_labels = self.y_train[k_indices]
            
            # 多数投票
            most_common = Counter(k_labels).most_common(1)
            predictions.append(most_common[0][0])
        
        return np.array(predictions)
```

---

## KKT Conditions (KKT条件)

**定义**: 带约束优化问题的最优解必须满足的必要条件，是拉格朗日乘子法的推广。

**详细解释**: KKT条件将无约束优化的梯度为零条件推广到约束优化。包括：1)平稳性：拉格朗日函数梯度为零，2)原始可行性：满足约束，3)对偶可行性：不等式乘子非负，4)互补松弛：不等式约束与乘子乘积为零。对于凸问题，KKT条件是充分必要条件。是理解和支持向量机等算法的基础。

**数学公式**:
$$\nabla f(x^*) + \sum_i \lambda_i \nabla g_i(x^*) + \sum_j \mu_j \nabla h_j(x^*) = 0$$
$$\lambda_i \geq 0, \quad \lambda_i g_i(x^*) = 0$$

**相关概念**: Lagrangian Multiplier, Constrained Optimization, SVM

**代表论文**: Karush, W. (1939). Minima of functions of several variables. Master's thesis.

---

## Kernel Method (核方法)

**定义**: 将数据映射到高维特征空间的技巧，通过核函数隐式计算高维内积。

**详细解释**: 核方法避免显式计算高维映射，直接通过核函数K(x,y)=φ(x)·φ(y)计算内积。常用核包括：线性核、多项式核、高斯核(RBF)。核技巧使线性方法能够处理非线性问题，如SVM、核PCA、核K-means。Mercer定理保证核函数的有效性。核方法在深度学习前是机器学习的主流方法。

**数学公式**:
$$K(x, y) = \langle \phi(x), \phi(y) \rangle$$

RBF核: $K(x, y) = \exp(-\gamma \|x-y\|^2)$

**相关概念**: SVM, Kernel PCA, Mercer's Theorem, RBF

**代表论文**: Schölkopf, B., & Smola, A. J. (2002). Learning with Kernels. MIT Press.

**代码示例**:
```python
def linear_kernel(X, Y):
    """线性核"""
    return X @ Y.T

def rbf_kernel(X, Y, gamma=1.0):
    """RBF核（高斯核）"""
    X_norm = np.sum(X**2, axis=1).reshape(-1, 1)
    Y_norm = np.sum(Y**2, axis=1).reshape(1, -1)
    distances = X_norm + Y_norm - 2 * X @ Y.T
    return np.exp(-gamma * distances)

def polynomial_kernel(X, Y, degree=3, coef0=1):
    """多项式核"""
    return (X @ Y.T + coef0) ** degree
```

---

## Keyframe Extraction (关键帧提取)

**定义**: 从视频序列中选择最具代表性帧的技术，用于视频摘要和检索。

**详细解释**: 关键帧提取基于视觉内容变化选择代表性帧。方法包括：基于镜头边界检测、基于运动分析、基于聚类、基于深度学习。评估标准包括覆盖度、冗余度、代表性。关键帧用于视频摘要、缩略图生成、视频检索等应用。挑战在于平衡代表性和压缩率。

**数学公式**:
优化目标: $\max \sum_{i} R(f_i) - \lambda \sum_{i,j} Sim(f_i, f_j)$

**相关概念**: Video Summarization, Shot Detection, Video Retrieval

**代表论文**: de Avila, S. E. F., et al. (2011). VSUMM: A mechanism. TCSVT.

---

## Label Smoothing (标签平滑)

**定义**: 正则化技术，将one-hot标签软化，防止模型过度自信。

**详细解释**: 标签平滑将硬标签y=[0,0,1,0]转换为软标签y'=[ε/K, ε/K, 1-ε+ε/K, ε/K]，其中ε是小常数（如0.1）。这防止模型对训练标签过于自信，提高泛化能力。在图像分类中广泛使用，特别是在知识蒸馏中作为教师网络的输出。标签平滑本质上添加了正则化，鼓励模型学习更平滑的决策边界。

**数学公式**:
$$y'_k = (1-\varepsilon) y_k + \frac{\varepsilon}{K}$$

**相关概念**: Regularization, Cross-Entropy Loss, Knowledge Distillation

**代表论文**: Szegedy, C., et al. (2016). Rethinking the inception architecture. CVPR.

**代码示例**:
```python
def label_smoothing(labels, num_classes, epsilon=0.1):
    """标签平滑"""
    smooth_labels = torch.zeros(labels.size(0), num_classes)
    smooth_labels.fill_(epsilon / (num_classes - 1))
    smooth_labels.scatter_(1, labels.unsqueeze(1), 1 - epsilon)
    return smooth_labels

def smooth_cross_entropy(predictions, targets, epsilon=0.1):
    """带标签平滑的交叉熵"""
    num_classes = predictions.size(1)
    log_probs = F.log_softmax(predictions, dim=1)
    
    # 平滑标签
    smooth_targets = torch.zeros_like(log_probs)
    smooth_targets.fill_(epsilon / (num_classes - 1))
    smooth_targets.scatter_(1, targets.unsqueeze(1), 1 - epsilon)
    
    loss = -torch.sum(smooth_targets * log_probs, dim=1)
    return loss.mean()
```

---

## LBP (局部二值模式)

**定义**: 描述局部纹理特征的算子，通过比较中心像素与邻域像素的灰度值编码。

**详细解释**: LBP对每个像素，比较其与周围8邻域像素的灰度值，大于中心置1否则置0，得到8位二进制编码。LBP对单调灰度变换具有不变性。变体包括：均匀LBP（减少模式数）、旋转不变LBP、多尺度LBP。广泛应用于人脸识别、纹理分类等任务，是经典的纹理描述子。

**数学公式**:
$$LBP_{P,R} = \sum_{p=0}^{P-1} s(g_p - g_c) 2^p, \quad s(x) = \begin{cases} 1 & x \geq 0 \\ 0 & x < 0 \end{cases}$$

**相关概念**: Texture Descriptor, Face Recognition, Uniform LBP

**代表论文**: Ojala, T., Pietikäinen, M., & Harwood, D. (1996). A comparative study of texture measures. Pattern Recognition.

**代码示例**:
```python
def lbp(image, P=8, R=1):
    """局部二值模式"""
    h, w = image.shape
    lbp_image = np.zeros_like(image)
    
    for i in range(R, h-R):
        for j in range(R, w-R):
            center = image[i, j]
            binary = 0
            for p in range(P):
                angle = 2 * np.pi * p / P
                x = int(i + R * np.sin(angle))
                y = int(j + R * np.cos(angle))
                if image[x, y] >= center:
                    binary |= (1 << p)
            lbp_image[i, j] = binary
    
    return lbp_image
```

---

## Learning Rate (学习率)

**定义**: 控制参数更新步长的超参数，是深度学习训练中最关键的超参数之一。

**详细解释**: 学习率决定每次参数更新的幅度。过大导致训练发散或震荡，过小导致收敛缓慢或陷入局部最优。学习率调度策略包括：步长衰减、余弦退火、周期性调度、自适应方法（Adam）。Warmup策略在训练初期使用小学习率稳定训练。学习率的选择对模型性能影响巨大。

**数学公式**:
$$\theta_{t+1} = \theta_t - \eta \nabla_\theta \mathcal{L}$$

**相关概念**: Optimization, Learning Rate Schedule, Warmup, Adam

**代表论文**: Smith, L. N. (2017). Cyclical learning rates. WACV.

**代码示例**:
```python
class CosineAnnealingLR:
    """余弦退火学习率调度"""
    def __init__(self, initial_lr, T_max, eta_min=0):
        self.initial_lr = initial_lr
        self.T_max = T_max
        self.eta_min = eta_min
    
    def get_lr(self, epoch):
        return self.eta_min + (self.initial_lr - self.eta_min) * \
               (1 + np.cos(np.pi * epoch / self.T_max)) / 2

class WarmupCosineSchedule:
    """带Warmup的余弦调度"""
    def __init__(self, optimizer, warmup_steps, total_steps, base_lr):
        self.optimizer = optimizer
        self.warmup_steps = warmup_steps
        self.total_steps = total_steps
        self.base_lr = base_lr
    
    def step(self, step):
        if step < self.warmup_steps:
            lr = self.base_lr * step / self.warmup_steps
        else:
            progress = (step - self.warmup_steps) / (self.total_steps - self.warmup_steps)
            lr = self.base_lr * 0.5 * (1 + np.cos(np.pi * progress))
        
        for param_group in self.optimizer.param_groups:
            param_group['lr'] = lr
```

---

## Level Set (水平集)

**定义**: 隐式表示曲线/曲面的方法，将曲线作为高维函数的零水平集。

**详细解释**: 水平集方法将曲线C表示为函数φ的零水平集{φ=0}。曲线演化通过更新φ实现，φ按照偏微分方程演化。优势在于自动处理拓扑变化（合并、分裂），数值稳定。Chan-Vese模型、测地活动轮廓(GAC)都是水平集方法的应用。缺点是计算量较大，需要重新初始化保持φ为距离函数。

**数学公式**:
曲线演化: $$\frac{\partial \phi}{\partial t} + v|\nabla \phi| = 0$$

**相关概念**: Chan-Vese Model, Active Contour, Implicit Surface

**代表论文**: Osher, S., & Sethian, J. A. (1988). Fronts propagating with curvature-dependent speed. JCP.

**代码示例**:
```python
def level_set_evolution(phi, velocity_func, dt=0.1, max_iter=100):
    """水平集演化"""
    for _ in range(max_iter):
        # 计算速度场
        v = velocity_func(phi)
        
        # 计算梯度和曲率
        phi_x = np.gradient(phi, axis=1)
        phi_y = np.gradient(phi, axis=0)
        phi_norm = np.sqrt(phi_x**2 + phi_y**2 + 1e-10)
        
        # 更新水平集函数
        phi = phi + dt * v * phi_norm
        
        # 重新初始化（保持为距离函数）
        if _ % 10 == 0:
            phi = reinitialize_distance_function(phi)
    
    return phi

def reinitialize_distance_function(phi, iterations=5):
    """重新初始化为符号距离函数"""
    for _ in range(iterations):
        phi_x = np.gradient(phi, axis=1)
        phi_y = np.gradient(phi, axis=0)
        s = phi / np.sqrt(phi**2 + phi_x**2 + phi_y**2 + 1e-10)
        phi = phi - 0.5 * (phi_x**2 + phi_y**2 - 1) * s
    return phi
```

---

## Local Binary Patterns (见LBP)

---

## LoRA (低秩适应)

**定义**: 大模型的参数高效微调方法，通过低秩分解减少可训练参数。

**详细解释**: LoRA冻结预训练权重W₀，添加低秩分解W=BA来适应下游任务。A和B的秩r远小于原始维度，参数量减少数千倍。训练时只更新A和B，推理时可将BA合并回W₀，无额外开销。LoRA在保持性能的同时大幅降低微调成本，是PEFT的主流方法，广泛应用于Stable Diffusion、LLM微调。

**数学公式**:
$$W = W_0 + \Delta W = W_0 + BA$$

其中 $B \in \mathbb{R}^{d \times r}$, $A \in \mathbb{R}^{r \times k}$, $r \ll \min(d, k)$

**相关概念**: PEFT, Fine-tuning, Low-Rank Decomposition, Stable Diffusion

**代表论文**: Hu, E. J., et al. (2022). LoRA: Low-Rank Adaptation of Large Language Models. ICLR.

**代码示例**:
```python
class LoRALinear(nn.Module):
    def __init__(self, in_features, out_features, rank=8, alpha=16):
        super().__init__()
        self.original = nn.Linear(in_features, out_features, bias=False)
        self.original.weight.requires_grad = False
        
        self.lora_A = nn.Parameter(torch.zeros(rank, in_features))
        self.lora_B = nn.Parameter(torch.zeros(out_features, rank))
        self.scaling = alpha / rank
        
        # 初始化
        nn.init.kaiming_uniform_(self.lora_A, a=np.sqrt(5))
        nn.init.zeros_(self.lora_B)
    
    def forward(self, x):
        result = self.original(x)
        lora_output = (x @ self.lora_A.T @ self.lora_B.T) * self.scaling
        return result + lora_output
    
    def merge_weights(self):
        """合并LoRA权重到原始权重"""
        self.original.weight.data += (self.lora_B @ self.lora_A) * self.scaling
```

---

## Loss Function (损失函数)

**定义**: 衡量模型预测与真实值之间差异的函数，是优化的目标。

**详细解释**: 损失函数定义了学习的目标。回归任务常用MSE、MAE、Huber损失；分类任务常用交叉熵、Focal Loss；分割任务常用Dice Loss、IoU Loss；检测任务常用IoU Loss、CIoU Loss。损失函数设计影响模型性能，如带权重的损失处理类别不平衡。正则化项可加入损失函数防止过拟合。

**数学公式**:
MSE: $\mathcal{L}_{MSE} = \frac{1}{n}\sum_{i=1}^n (y_i - \hat{y}_i)^2$

交叉熵: $\mathcal{L}_{CE} = -\sum_{i} y_i \log(\hat{y}_i)$

**相关概念**: Cross-Entropy, MSE, Dice Loss, IoU Loss

**代表论文**: Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep Learning. MIT Press.

---

## LSTM (长短期记忆网络)

**定义**: 能够学习长期依赖的循环神经网络，通过门控机制控制信息流。

**详细解释**: LSTM通过三个门（遗忘门、输入门、输出门）控制细胞状态。遗忘门决定丢弃哪些信息，输入门决定存储哪些新信息，输出门决定输出哪些信息。细胞状态作为信息传送带，跨越长距离传递信息。LSTM解决了普通RNN的梯度消失问题，广泛应用于序列建模。变体包括GRU、Peephole LSTM。

**数学公式**:
$$\begin{aligned} f_t &= \sigma(W_f \cdot [h_{t-1}, x_t] + b_f) \\ i_t &= \sigma(W_i \cdot [h_{t-1}, x_t] + b_i) \\ o_t &= \sigma(W_o \cdot [h_{t-1}, x_t] + b_o) \\ C_t &= f_t \odot C_{t-1} + i_t \odot \tilde{C}_t \\ h_t &= o_t \odot \tanh(C_t) \end{aligned}$$

**相关概念**: RNN, GRU, Sequence Modeling, Gating Mechanism

**代表论文**: Hochreiter, S., & Schmidhuber, J. (1997). Long short-term memory. Neural Computation.

**代码示例**:
```python
class LSTMCell(nn.Module):
    def __init__(self, input_size, hidden_size):
        super().__init__()
        self.hidden_size = hidden_size
        self.W_f = nn.Linear(input_size + hidden_size, hidden_size)
        self.W_i = nn.Linear(input_size + hidden_size, hidden_size)
        self.W_c = nn.Linear(input_size + hidden_size, hidden_size)
        self.W_o = nn.Linear(input_size + hidden_size, hidden_size)
    
    def forward(self, x, state):
        h_prev, c_prev = state
        combined = torch.cat([h_prev, x], dim=1)
        
        f = torch.sigmoid(self.W_f(combined))
        i = torch.sigmoid(self.W_i(combined))
        c_tilde = torch.tanh(self.W_c(combined))
        o = torch.sigmoid(self.W_o(combined))
        
        c = f * c_prev + i * c_tilde
        h = o * torch.tanh(c)
        
        return h, (h, c)
```

---

## Mamba (状态空间模型)

**定义**: 基于选择性状态空间的序列建模范式，具有线性复杂度和全局感受野。

**详细解释**: Mamba是SSM（State Space Model）的最新进展，通过选择性机制使模型能够过滤或保留信息。相比Transformer的O(n²)复杂度，Mamba的复杂度为O(n)，适合处理长序列。选择性SSM根据输入动态调整参数，增强了表达能力。在语言建模、图像处理（Vim、VMamba）等任务展现出与Transformer相当的性能。

**数学公式**:
$$h'(t) = Ah(t) + Bx(t), \quad y(t) = Ch(t) + Dx(t)$$

离散化: $h_t = \bar{A}h_{t-1} + \bar{B}x_t$

**相关概念**: State Space Model, Selective Mechanism, Efficient Attention

**代表论文**: Gu, A., & Dao, T. (2023). Mamba: Linear-Time Sequence Modeling with Selective State Spaces. arXiv.

**代码示例**:
```python
class MambaBlock(nn.Module):
    def __init__(self, d_model, d_state=16, d_conv=4, expand=2):
        super().__init__()
        self.d_model = d_model
        self.d_state = d_state
        self.d_inner = d_model * expand
        
        self.proj = nn.Linear(d_model, self.d_inner * 2, bias=False)
        self.conv = nn.Conv1d(self.d_inner, self.d_inner, d_conv, padding=d_conv-1, groups=self.d_inner)
        
        # SSM参数
        self.A = nn.Parameter(torch.randn(self.d_inner, d_state))
        self.B = nn.Parameter(torch.randn(self.d_inner, d_state))
        self.C = nn.Parameter(torch.randn(self.d_state, self.d_inner))
        self.D = nn.Parameter(torch.ones(self.d_inner))
    
    def forward(self, x):
        batch, seq_len, _ = x.shape
        
        # 投影和分块
        xz = self.proj(x)
        x, z = xz.chunk(2, dim=-1)
        
        # 卷积
        x = self.conv(x.transpose(1, 2)).transpose(1, 2)[:, :seq_len]
        
        # SSM（简化版）
        # 实际实现需要高效的并行扫描
        h = torch.zeros(batch, self.d_inner, self.d_state, device=x.device)
        outputs = []
        for t in range(seq_len):
            h = h * torch.softmax(self.A, dim=-1) + x[:, t:t+1].unsqueeze(-1) * self.B
            y = (h * self.C).sum(dim=-1) + x[:, t] * self.D
            outputs.append(y)
        
        y = torch.stack(outputs, dim=1)
        return y * F.silu(z)
```

---

## Mask R-CNN (掩码R-CNN)

**定义**: 扩展Faster R-CNN实现实例分割的框架，在检测框基础上预测分割掩码。

**详细解释**: Mask R-CNN在Faster R-CNN的检测分支外增加掩码分支。RoI对齐取代RoI池化解决量化误差。掩码分支对每个RoI预测m×m的分割掩码，与类别无关（每类一个通道）。训练时多任务损失=Lcls+Lbox+Lmask。Mask R-CNN是实例分割的基准方法，易于扩展到关键点检测等任务。

**数学公式**:
$$\mathcal{L} = \mathcal{L}_{cls} + \mathcal{L}_{box} + \mathcal{L}_{mask}$$

**相关概念**: Instance Segmentation, Faster R-CNN, RoI Align

**代表论文**: He, K., et al. (2017). Mask R-CNN. ICCV.

**代码示例**:
```python
class MaskRCNN(nn.Module):
    def __init__(self, backbone, num_classes):
        super().__init__()
        self.backbone = backbone
        self.rpn = RegionProposalNetwork()
        self.roi_heads = RoIHeads(num_classes)
        self.mask_head = MaskHead(num_classes)
    
    def forward(self, images, targets=None):
        features = self.backbone(images)
        
        # RPN生成候选框
        proposals, rpn_loss = self.rpn(features, targets)
        
        # RoI分类和回归
        detections, roi_loss = self.roi_heads(features, proposals, targets)
        
        # 掩码预测
        masks = self.mask_head(features, detections)
        
        return detections, masks
```

---

## Matrix Factorization (矩阵分解)

**定义**: 将矩阵分解为多个低秩矩阵乘积的技术，用于降维、推荐、压缩等。

**详细解释**: 矩阵分解将大矩阵分解为小矩阵乘积，捕获数据的潜在结构。常用方法包括：SVD（奇异值分解）是最优低秩近似，NMF（非负矩阵分解）保证非负性，PMF（概率矩阵分解）引入概率框架。在推荐系统中，用户-物品矩阵分解捕获用户偏好和物品特征。正则化防止过拟合。

**数学公式**:
$$X \approx UV^T$$

SVD: $X = U\Sigma V^T$

**相关概念**: SVD, NMF, Low-Rank Approximation, Recommender System

**代表论文**: Koren, Y., Bell, R., & Volinsky, C. (2009). Matrix factorization techniques for recommender systems. Computer.

**代码示例**:
```python
def svd_decomposition(X, k):
    """截断SVD"""
    U, S, Vt = np.linalg.svd(X, full_matrices=False)
    return U[:, :k], np.diag(S[:k]), Vt[:k, :]

def nmf(X, k, max_iter=100, tol=1e-4):
    """非负矩阵分解（乘法更新）"""
    m, n = X.shape
    W = np.random.rand(m, k)
    H = np.random.rand(k, n)
    
    for _ in range(max_iter):
        # 乘法更新规则
        H = H * (W.T @ X) / (W.T @ W @ H + 1e-10)
        W = W * (X @ H.T) / (W @ H @ H.T + 1e-10)
        
        # 检查收敛
        if np.linalg.norm(X - W @ H) < tol:
            break
    
    return W, H
```

---

## MCMC (马尔可夫链蒙特卡洛)

**定义**: 通过构建马尔可夫链从复杂分布采样的方法，用于后验推断。

**详细解释**: MCMC通过构建一个平稳分布为目标分布的马尔可夫链来采样。常用算法包括：Metropolis-Hastings通过提议-接受机制采样，Gibbs采样每次更新一个变量，Hamiltonian Monte Carlo利用梯度信息加速探索。MCMC在贝叶斯推断中用于计算后验期望，是概率建模的核心工具。

**数学公式**:
Metropolis接受率: $\alpha = \min(1, \frac{p(x')q(x|x')}{p(x)q(x'|x)})$

**相关概念**: Bayesian Inference, Gibbs Sampling, HMC, Posterior Sampling

**代表论文**: Hastings, W. K. (1970). Monte Carlo sampling methods. Biometrika.

**代码示例**:
```python
def metropolis_hastings(target_pdf, proposal_sample, x0, n_samples):
    """Metropolis-Hastings采样"""
    samples = [x0]
    x = x0
    
    for _ in range(n_samples):
        # 提议新样本
        x_proposed = proposal_sample(x)
        
        # 计算接受率
        acceptance = target_pdf(x_proposed) / target_pdf(x)
        
        # 接受或拒绝
        if np.random.rand() < acceptance:
            x = x_proposed
        
        samples.append(x)
    
    return np.array(samples)

def gibbs_sampling(joint_pdf, conditionals, x0, n_samples):
    """Gibbs采样"""
    samples = [x0]
    x = x0.copy()
    
    for _ in range(n_samples):
        for i in range(len(x)):
            # 从条件分布采样
            x[i] = conditionals[i](x)
        samples.append(x.copy())
    
    return np.array(samples)
```

---

## Metric Learning (度量学习)

**定义**: 学习样本间相似度或距离的机器学习方法，学习嵌入空间使相似样本接近。

**详细解释**: 度量学习将样本映射到嵌入空间，在空间中距离反映语义相似性。经典方法包括：对比损失拉近正样本对、推远负样本对，三元组损失使锚点-正样本距离小于锚点-负样本距离加margin。深度度量学习广泛应用于人脸识别、图像检索、Few-shot学习。难样本挖掘是关键技巧。

**数学公式**:
对比损失: $\mathcal{L} = (1-y)d^2 + y\max(0, m-d)^2$

三元组损失: $\mathcal{L} = \max(0, d(a,p) - d(a,n) + m)$

**相关概念**: Contrastive Loss, Triplet Loss, Face Recognition, Few-shot Learning

**代表论文**: Schroff, F., Kalenichenko, D., & Philbin, J. (2015). FaceNet: A unified embedding. CVPR.

**代码示例**:
```python
def contrastive_loss(embed1, embed2, label, margin=1.0):
    """对比损失"""
    dist = F.pairwise_distance(embed1, embed2)
    loss = (1 - label) * dist.pow(2) + label * F.relu(margin - dist).pow(2)
    return loss.mean()

def triplet_loss(anchor, positive, negative, margin=0.2):
    """三元组损失"""
    pos_dist = F.pairwise_distance(anchor, positive)
    neg_dist = F.pairwise_distance(anchor, negative)
    loss = F.relu(pos_dist - neg_dist + margin)
    return loss.mean()

def hard_triplet_mining(embeddings, labels, margin=0.2):
    """在线难样本挖掘"""
    dist_matrix = torch.cdist(embeddings, embeddings)
    
    # 找最难正样本
    pos_mask = labels.unsqueeze(1) == labels.unsqueeze(0)
    pos_dist = dist_matrix * pos_mask.float()
    hardest_pos = pos_dist.max(dim=1)[0]
    
    # 找最难负样本
    neg_mask = ~pos_mask
    neg_dist = dist_matrix + pos_mask.float() * 1e9
    hardest_neg = neg_dist.min(dim=1)[0]
    
    loss = F.relu(hardest_pos - hardest_neg + margin)
    return loss.mean()
```

---

## Mixture of Experts (混合专家)

**定义**: 由多个专家网络和门控网络组成的架构，根据输入动态选择专家组合。

**详细解释**: MoE包含多个专家网络（通常是FFN）和一个门控网络。门控网络输出权重决定每个专家的贡献。稀疏MoE只激活top-k专家，降低计算成本。MoE增加了模型容量而不成比例增加计算。在NLP（Switch Transformer、Mixtral）和CV（V-MoE）中有应用。挑战包括负载均衡和训练稳定性。

**数学公式**:
$$y = \sum_{i=1}^n G(x)_i E_i(x)$$

稀疏: $G(x) = \text{softmax}(\text{topk}(H(x), k))$

**相关概念**: Sparse Activation, Gating Network, Scalable Architecture

**代表论文**: Shazeer, N., et al. (2017). Outrageously large neural networks. ICLR.

**代码示例**:
```python
class MoE(nn.Module):
    def __init__(self, d_model, d_ff, num_experts, top_k=2):
        super().__init__()
        self.num_experts = num_experts
        self.top_k = top_k
        
        self.experts = nn.ModuleList([
            nn.Sequential(nn.Linear(d_model, d_ff), nn.ReLU(), nn.Linear(d_ff, d_model))
            for _ in range(num_experts)
        ])
        self.gate = nn.Linear(d_model, num_experts)
    
    def forward(self, x):
        batch_size, seq_len, d_model = x.shape
        x_flat = x.view(-1, d_model)
        
        # 门控权重
        gate_logits = self.gate(x_flat)
        gate_weights, indices = torch.topk(gate_logits, self.top_k, dim=-1)
        gate_weights = F.softmax(gate_weights, dim=-1)
        
        # 稀疏计算
        output = torch.zeros_like(x_flat)
        for i in range(self.top_k):
            expert_idx = indices[:, i]
            weight = gate_weights[:, i]
            
            for e in range(self.num_experts):
                mask = (expert_idx == e)
                if mask.any():
                    expert_output = self.experts[e](x_flat[mask])
                    output[mask] += weight[mask].unsqueeze(-1) * expert_output
        
        return output.view(batch_size, seq_len, d_model)
```

---

## MLP (多层感知机)

**定义**: 最基本的神经网络结构，由多个全连接层和非线性激活函数堆叠而成。

**详细解释**: MLP是深度学习的基础构建块。每层执行线性变换和非线性激活。理论上，有足够宽度的单隐藏层MLP可以逼近任何连续函数（万能逼近定理）。现代视觉模型中，MLP用于：CNN的分类头、Transformer的FFN层、MLP-Mixer的混合层。简单的结构在大量数据和深度下表现强大。

**数学公式**:
$$h = \sigma(W_1 x + b_1), \quad y = W_2 h + b_2$$

**相关概念**: Feedforward Network, Universal Approximation, FFN

**代表论文**: Hornik, K. (1991). Approximation capabilities of multilayer feedforward networks. Neural Networks.

**代码示例**:
```python
class MLP(nn.Module):
    def __init__(self, input_dim, hidden_dims, output_dim, activation='relu'):
        super().__init__()
        layers = []
        prev_dim = input_dim
        
        for hidden_dim in hidden_dims:
            layers.append(nn.Linear(prev_dim, hidden_dim))
            if activation == 'relu':
                layers.append(nn.ReLU())
            elif activation == 'gelu':
                layers.append(nn.GELU())
            layers.append(nn.Dropout(0.1))
            prev_dim = hidden_dim
        
        layers.append(nn.Linear(prev_dim, output_dim))
        self.mlp = nn.Sequential(*layers)
    
    def forward(self, x):
        return self.mlp(x)
```

---

## Morphological Operations (形态学操作)

**定义**: 基于形状的图像处理操作，使用结构元素进行腐蚀、膨胀等操作。

**详细解释**: 形态学操作基于集合论，主要用于二值图像处理。腐蚀收缩前景区域，膨胀扩张前景区域。开运算（先腐蚀后膨胀）去除小物体，闭运算（先膨胀后腐蚀）填充小孔。形态学梯度（膨胀-腐蚀）提取边缘。可扩展到灰度图像。广泛应用于图像预处理、分割后处理。

**数学公式**:
腐蚀: $A \ominus B = \{z | B_z \subseteq A\}$

膨胀: $A \oplus B = \{z | (\hat{B})_z \cap A \neq \emptyset\}$

**相关概念**: Erosion, Dilation, Opening, Closing, Structure Element

**代表论文**: Serra, J. (1982). Image Analysis and Mathematical Morphology. Academic Press.

**代码示例**:
```python
def erode(image, kernel):
    """形态学腐蚀"""
    h, w = image.shape
    kh, kw = kernel.shape
    pad_h, pad_w = kh // 2, kw // 2
    
    padded = np.pad(image, ((pad_h, pad_h), (pad_w, pad_w)), mode='constant', constant_values=0)
    result = np.zeros_like(image)
    
    for i in range(h):
        for j in range(w):
            region = padded[i:i+kh, j:j+kw]
            if kernel.sum() == (region * kernel).sum():
                result[i, j] = 1
    
    return result

def dilate(image, kernel):
    """形态学膨胀"""
    h, w = image.shape
    kh, kw = kernel.shape
    pad_h, pad_w = kh // 2, kw // 2
    
    padded = np.pad(image, ((pad_h, pad_h), (pad_w, pad_w)), mode='constant', constant_values=0)
    result = np.zeros_like(image)
    
    for i in range(h):
        for j in range(w):
            region = padded[i:i+kh, j:j+kw]
            if (region * kernel).sum() > 0:
                result[i, j] = 1
    
    return result

def opening(image, kernel):
    """开运算：先腐蚀后膨胀"""
    return dilate(erode(image, kernel), kernel)

def closing(image, kernel):
    """闭运算：先膨胀后腐蚀"""
    return erode(dilate(image, kernel), kernel)
```

---

## Mumford-Shah Functional (Mumford-Shah泛函)

**定义**: 经典的图像分割能量函数，同时优化分割边界和区域平滑性。

**详细解释**: MS泛函是变分分割的理论基础。它包含三项：边界长度（正则化边界），区域内数据拟合（分割后区域接近原图），区域平滑（区域内部平滑）。最小化MS泛函是一个困难的问题，有近似方法如Chan-Vese模型（假设区域内恒定）、水平集方法、离散方法。MS泛函是数学图像处理的经典框架。

**数学公式**:
$$E(u, C) = \mu \cdot \text{Length}(C) + \lambda \int_{\Omega \setminus C} |u - f|^2 dx + \nu \int_{\Omega \setminus C} |\nabla u|^2 dx$$

**相关概念**: Chan-Vese Model, Variational Segmentation, Level Set, SaT

**代表论文**: Mumford, D., & Shah, J. (1989). Optimal approximations by piecewise smooth functions. CPAM.

---

## NMS (非极大值抑制)

**定义**: 目标检测后处理步骤，移除重叠检测框，只保留最高置信度的框。

**详细解释**: NMS按置信度排序检测框，从最高分开始，移除与其IoU超过阈值的所有其他框，迭代直到处理完所有框。NMS的问题：密集目标可能被错误抑制。改进方法包括：Soft-NMS降低而非移除重叠框的分数，DIoU-NMS使用DIoU代替IoU，自适应NMS根据密度调整阈值。NMS是检测流程的标准组件。

**数学公式**:
$$s_i = \begin{cases} s_i & \text{IoU}(M, b_i) < N_t \\ 0 & \text{IoU}(M, b_i) \geq N_t \end{cases}$$

**相关概念**: Object Detection, IoU, Soft-NMS

**代表论文**: Neubeck, A., & Van Gool, L. (2006). Efficient non-maximum suppression. ICPR.

**代码示例**:
```python
def nms(boxes, scores, iou_threshold=0.5):
    """非极大值抑制"""
    x1, y1, x2, y2 = boxes[:, 0], boxes[:, 1], boxes[:, 2], boxes[:, 3]
    areas = (x2 - x1) * (y2 - y1)
    
    order = scores.argsort()[::-1]
    keep = []
    
    while order.size > 0:
        i = order[0]
        keep.append(i)
        
        # 计算IoU
        xx1 = np.maximum(x1[i], x1[order[1:]])
        yy1 = np.maximum(y1[i], y1[order[1:]])
        xx2 = np.minimum(x2[i], x2[order[1:]])
        yy2 = np.minimum(y2[i], y2[order[1:]])
        
        w = np.maximum(0, xx2 - xx1)
        h = np.maximum(0, yy2 - yy1)
        inter = w * h
        
        iou = inter / (areas[i] + areas[order[1:]] - inter)
        
        # 保留IoU小于阈值的框
        inds = np.where(iou <= iou_threshold)[0]
        order = order[inds + 1]
    
    return keep

def soft_nms(boxes, scores, iou_threshold=0.5, sigma=0.5, method='gaussian'):
    """Soft-NMS"""
    N = len(boxes)
    indexes = np.arange(N)
    
    for i in range(N):
        max_score_idx = np.argmax(scores[i:]) + i
        
        # 交换
        boxes[i], boxes[max_score_idx] = boxes[max_score_idx].copy(), boxes[i].copy()
        scores[i], scores[max_score_idx] = scores[max_score_idx], scores[i]
        indexes[i], indexes[max_score_idx] = indexes[max_score_idx], indexes[i]
        
        # 计算IoU并衰减分数
        ious = compute_iou_batch(boxes[i:i+1], boxes[i+1:]).flatten()
        
        if method == 'linear':
            scores[i+1][ious >= iou_threshold] *= (1 - ious[ious >= iou_threshold])
        elif method == 'gaussian':
            scores[i+1:] *= np.exp(-(ious ** 2) / sigma)
    
    keep = indexes[scores > 0.01]
    return keep
```

---

## Neural Architecture Search (神经架构搜索)

**定义**: 自动搜索最优神经网络架构的技术，减少人工设计。

**详细解释**: NAS包括三个组件：搜索空间定义候选架构，搜索策略探索搜索空间，性能评估估计架构性能。搜索策略包括：强化学习（控制器生成架构描述）、进化算法、可微分方法（DARTS）、One-shot方法（训练超网）。NAS搜索出的架构（如EfficientNet）在许多任务上超越人工设计。挑战是搜索成本高。

**数学公式**:
DARTS: $\min_{\alpha} \mathcal{L}_{val}(w^*(\alpha), \alpha)$

其中 $w^*(\alpha) = \arg\min_w \mathcal{L}_{train}(w, \alpha)$

**相关概念**: AutoML, DARTS, EfficientNet, Differentiable Search

**代表论文**: Zoph, B., & Le, Q. V. (2017). Neural architecture search with reinforcement learning. ICLR.

---

## Neural Tangent Kernel (神经切核)

**定义**: 描述无限宽神经网络训练动态的理论框架，将神经网络等价为核方法。

**详细解释**: NTK研究无限宽网络在梯度下降训练时的行为。在无限宽极限下，NTK在训练过程中保持常量，网络等价于使用该核的核回归。NTK提供了理解深度学习的理论工具，可以分析收敛性、泛化能力。虽然实际网络宽度有限，但NTK的理论洞察仍然有价值。

**数学公式**:
$$\Theta(x, x') = \nabla_\theta f(x; \theta) \cdot \nabla_\theta f(x'; \theta)$$

**相关概念**: Kernel Method, Infinite-Width Network, Neural Network Theory

**代表论文**: Jacot, A., Gabriel, F., & Hongler, C. (2018). Neural tangent kernel: Convergence and generalization. NeurIPS.

---

## Normalization (归一化)

**定义**: 将数据缩放到特定范围或分布的技术，加速训练并提高稳定性。

**详细解释**: 归一化是深度学习的关键技术。常见方法包括：批归一化(BN)在batch维度归一化，层归一化(LN)在特征维度归一化，实例归一化(IN)在每个样本内归一化，组归一化(GN)分组归一化。归一化减少内部协变量偏移，允许更大学习率，有正则化效果。不同任务选择不同归一化方法。

**数学公式**:
$$\hat{x} = \frac{x - \mu}{\sqrt{\sigma^2 + \epsilon}}, \quad y = \gamma \hat{x} + \beta$$

**相关概念**: Batch Normalization, Layer Normalization, Instance Normalization

**代表论文**: Ioffe, S., & Szegedy, C. (2015). Batch normalization. ICML.

---

## Object Detection (目标检测)

**定义**: 定位图像中所有目标并识别其类别的视觉任务，输出边界框和类别标签。

**详细解释**: 目标检测需要同时解决定位（在哪里）和分类（是什么）。主流方法：两阶段检测器（R-CNN系列）先生成候选框再分类，单阶段检测器（YOLO、SSD、RetinaNet）直接预测框和类别，Anchor-free检测器（FCOS、CenterNet）不依赖锚框。评估指标包括mAP。检测是自动驾驶、安防等应用的核心技术。

**数学公式**:
$$\mathcal{L} = \mathcal{L}_{cls} + \lambda_{box}\mathcal{L}_{box} + \lambda_{obj}\mathcal{L}_{obj}$$

**相关概念**: Bounding Box, NMS, Faster R-CNN, YOLO, RetinaNet

**代表论文**: Girshick, R. (2015). Fast R-CNN. ICCV.

**代码示例**:
```python
class SimpleDetector(nn.Module):
    def __init__(self, backbone, num_classes, num_anchors=9):
        super().__init__()
        self.backbone = backbone
        self.cls_head = nn.Conv2d(256, num_anchors * num_classes, 3, padding=1)
        self.reg_head = nn.Conv2d(256, num_anchors * 4, 3, padding=1)
    
    def forward(self, x):
        features = self.backbone(x)
        
        # 分类分支
        cls_pred = self.cls_head(features)
        cls_pred = cls_pred.permute(0, 2, 3, 1).contiguous()
        cls_pred = cls_pred.view(x.size(0), -1, num_classes)
        
        # 回归分支
        reg_pred = self.reg_head(features)
        reg_pred = reg_pred.permute(0, 2, 3, 1).contiguous()
        reg_pred = reg_pred.view(x.size(0), -1, 4)
        
        return cls_pred, reg_pred
```

---

## OCR (光学字符识别)

**定义**: 从图像中识别和提取文本的技术，包括文本检测和文本识别。

**详细解释**: OCR系统通常包含：文本检测定位文本区域，文本识别将文本图像转为字符序列。检测方法：CTPN、EAST、DBNet。识别方法：CRNN（CNN+RNN+CTC）、基于注意力机制的方法。端到端方法同时检测和识别。OCR应用于文档数字化、车牌识别、票据处理等场景。

**数学公式**:
CTC损失: $\mathcal{L}_{CTC} = -\log P(\pi^*|x)$

**相关概念**: Text Detection, Text Recognition, CTC, CRNN

**代表论文**: Shi, B., Bai, X., & Yao, C. (2016). An end-to-end trainning neural network for scene text detection. PAMI.

---

## One-shot Learning (单样本学习)

**定义**: 每类仅用单个样本学习新类别的机器学习范式。

**详细解释**: 单样本学习是小样本学习的极端情况（1-shot）。方法包括：度量学习方法学习可迁移的距离度量，数据增强方法生成更多样本，基于模型的方法设计能快速适应的架构。测试时通过比较查询样本与支持集样本的相似度进行分类。人脸识别是典型应用场景。

**数学公式**:
$$P(y=c|x, S) = \frac{\exp(-d(f(x), f(x_c)))}{\sum_{c'}\exp(-d(f(x), f(x_{c'})))}$$

**相关概念**: Few-shot Learning, Metric Learning, Siamese Network

**代表论文**: Koch, G., Zemel, R., & Salakhutdinov, R. (2015). Siamese neural networks for one-shot image recognition. ICML Workshop.

---

## Online Algorithm (在线算法)

**定义**: 数据流式处理的算法，每次处理一个样本或小批量，不存储全部数据。

**详细解释**: 在线算法适用于数据流或大数据场景，无法或不需要存储全部数据。特点：低内存占用、实时处理、可适应数据分布变化。在线学习每次根据新样本更新模型。经典算法包括：在线梯度下降、在线EM、Follow the Regularized Leader。在推荐系统、广告点击预测等场景广泛使用。

**数学公式**:
在线梯度下降: $w_{t+1} = w_t - \eta_t \nabla \ell(w_t, x_t)$

**相关概念**: Streaming Data, Incremental Learning, Online Learning

**代表论文**: Cesa-Bianchi, N., & Lugosi, G. (2006). Prediction, Learning, and Games. Cambridge University Press.

**代码示例**:
```python
class OnlineSGD:
    def __init__(self, model, lr=0.01):
        self.model = model
        self.lr = lr
    
    def update(self, x, y):
        """在线更新"""
        self.model.zero_grad()
        output = self.model(x)
        loss = F.cross_entropy(output, y)
        loss.backward()
        
        with torch.no_grad():
            for param in self.model.parameters():
                param -= self.lr * param.grad
        
        return loss.item()
```

---

## Optical Flow (光流)

**定义**: 描述像素在连续帧间运动的向量场，是运动估计的基础。

**详细解释**: 光流假设像素亮度在短时间内不变（亮度恒定假设）。经典方法：Lucas-Kanade方法假设局部光流一致，Horn-Schunck方法引入全局平滑约束。深度学习方法（FlowNet、RAFT）学习端到端的光流预测。光流应用于视频稳像、动作识别、视频插帧等。挑战包括大位移、遮挡、光照变化。

**数学公式**:
$$\frac{\partial I}{\partial x}u + \frac{\partial I}{\partial y}v + \frac{\partial I}{\partial t} = 0$$

**相关概念**: Motion Estimation, Video Analysis, Lucas-Kanade, RAFT

**代表论文**: Horn, B. K., & Schunck, B. G. (1981). Determining optical flow. Artificial Intelligence.

**代码示例**:
```python
def lucas_kanade(img1, img2, window_size=15):
    """Lucas-Kanade光流"""
    # 计算时空梯度
    Ix = np.gradient(img1, axis=1)
    Iy = np.gradient(img1, axis=0)
    It = img2 - img1
    
    h, w = img1.shape
    u = np.zeros((h, w))
    v = np.zeros((h, w))
    
    half_win = window_size // 2
    
    for i in range(half_win, h - half_win):
        for j in range(half_win, w - half_win):
            # 提取窗口内梯度
            Ix_win = Ix[i-half_win:i+half_win+1, j-half_win:j+half_win+1].flatten()
            Iy_win = Iy[i-half_win:i+half_win+1, j-half_win:j+half_win+1].flatten()
            It_win = It[i-half_win:i+half_win+1, j-half_win:j+half_win+1].flatten()
            
            # 最小二乘求解
            A = np.stack([Ix_win, Iy_win], axis=1)
            b = -It_win
            
            if np.linalg.det(A.T @ A) > 1e-6:
                flow = np.linalg.lstsq(A, b, rcond=None)[0]
                u[i, j], v[i, j] = flow
    
    return u, v
```

---

## Optimization (优化)

**定义**: 寻找使目标函数最小化（或最大化）的参数的数学方法。

**详细解释**: 优化是机器学习的核心。一阶方法（SGD、Adam、Adagrad）使用梯度信息，二阶方法（牛顿法、拟牛顿法）使用海森矩阵信息。凸优化有全局最优保证，非凸优化只能保证局部最优。深度学习优化常用Adam及其变体。优化技巧包括学习率调度、梯度裁剪、权重衰减等。

**数学公式**:
梯度下降: $\theta_{t+1} = \theta_t - \eta \nabla f(\theta_t)$

Adam: $m_t = \beta_1 m_{t-1} + (1-\beta_1)g_t$, $v_t = \beta_2 v_{t-1} + (1-\beta_2)g_t^2$

**相关概念**: Gradient Descent, Adam, Convex Optimization

**代表论文**: Kingma, D. P., & Ba, J. (2015). Adam: A method for stochastic optimization. ICLR.

**代码示例**:
```python
class Adam:
    def __init__(self, params, lr=0.001, betas=(0.9, 0.999), eps=1e-8):
        self.params = list(params)
        self.lr = lr
        self.beta1, self.beta2 = betas
        self.eps = eps
        self.m = [torch.zeros_like(p) for p in self.params]
        self.v = [torch.zeros_like(p) for p in self.params]
        self.t = 0
    
    def step(self):
        self.t += 1
        for i, param in enumerate(self.params):
            if param.grad is None:
                continue
            
            grad = param.grad
            self.m[i] = self.beta1 * self.m[i] + (1 - self.beta1) * grad
            self.v[i] = self.beta2 * self.v[i] + (1 - self.beta2) * grad ** 2
            
            m_hat = self.m[i] / (1 - self.beta1 ** self.t)
            v_hat = self.v[i] / (1 - self.beta2 ** self.t)
            
            param.data -= self.lr * m_hat / (torch.sqrt(v_hat) + self.eps)
```
