# 计算机视觉概念词典 - F-J

## Face Recognition (人脸识别)

**定义**: 识别或验证图像/视频中人脸身份的技术，包括人脸检测、特征提取和匹配。

**详细解释**: 人脸识别系统通常包括：人脸检测定位人脸，人脸对齐校正姿态，特征提取将人脸映射到紧凑向量，特征匹配计算相似度。深度学习方法（DeepFace、FaceNet、ArcFace）将人脸映射到高维空间，使用三元组损失或角度损失学习判别性特征。广泛应用于安防、支付、身份验证等场景。

**数学公式**:
ArcFace损失: $$\mathcal{L} = -\log \frac{e^{s(\cos(\theta_{y_i}+m))}}{e^{s(\cos(\theta_{y_i}+m))} + \sum_{j\neq y_i} e^{s\cos\theta_j}}$$

**相关概念**: Face Detection, Face Alignment, Metric Learning, ArcFace

**代表论文**: Deng, J., et al. (2019). ArcFace: Additive angular margin loss. CVPR.

**代码示例**:
```python
class ArcFace(nn.Module):
    def __init__(self, in_features, out_features, s=30.0, m=0.5):
        super().__init__()
        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))
        self.s = s
        self.m = m
    
    def forward(self, features, labels):
        cosine = F.linear(F.normalize(features), F.normalize(self.weight))
        theta = torch.acos(cosine)
        one_hot = torch.zeros_like(cosine)
        one_hot.scatter_(1, labels.view(-1, 1), 1)
        output = cosine + one_hot * (torch.cos(theta + self.m) - cosine)
        return self.s * output
```

---

## Few-shot Learning (小样本学习)

**定义**: 从少量样本中学习新类别的机器学习范式，模拟人类快速学习新概念的能力。

**详细解释**: 小样本学习解决深度学习需要大量标注数据的问题。设定通常是N-way K-shot：每类K个样本，共N类。方法包括：基于优化的方法（MAML）学习好的初始化，基于度量学习的方法（原型网络、关系网络）学习比较样本相似度，基于数据增强的方法生成伪样本。元学习框架是主流范式。

**数学公式**:
原型网络: $$p_\phi(y=k|x) = \frac{\exp(-d(f_\phi(x), c_k))}{\sum_j \exp(-d(f_\phi(x), c_j))}$$

**相关概念**: Meta-Learning, Zero-shot Learning, Prototypical Network, MAML

**代表论文**: Snell, J., Swersky, K., & Zemel, R. (2017). Prototypical networks for few-shot learning. NeurIPS.

**代码示例**:
```python
class PrototypicalNetwork(nn.Module):
    def __init__(self, encoder):
        super().__init__()
        self.encoder = encoder
    
    def forward(self, support, query):
        # 计算原型
        support_embed = self.encoder(support)
        prototypes = support_embed.mean(dim=1)  # [N_way, embed_dim]
        
        # 计算查询样本到原型的距离
        query_embed = self.encoder(query)
        dists = torch.cdist(query_embed, prototypes)
        
        return -dists  # 返回负距离作为logits
```

---

## Focal Loss (焦点损失)

**定义**: 解决类别不平衡的损失函数，降低易分样本权重，聚焦难分样本。

**详细解释**: 在目标检测中，正负样本极其不平衡（背景远多于目标）。标准交叉熵损失被大量易分负样本主导，模型难以学习。Focal Loss通过调制因子$(1-p_t)^\gamma$降低易分样本的损失权重，$\gamma$越大抑制越强。配合RetinaNet，Focal Loss实现了单阶段检测器与两阶段检测器性能相当。

**数学公式**:
$$\mathcal{L}_{fl} = -\alpha_t (1 - p_t)^\gamma \log(p_t)$$

其中 $p_t = p$ (正类) 或 $1-p$ (负类)。

**相关概念**: Class Imbalance, RetinaNet, Object Detection, Cross-Entropy Loss

**代表论文**: Lin, T. Y., et al. (2017). Focal loss for dense object detection. ICCV.

**代码示例**:
```python
class FocalLoss(nn.Module):
    def __init__(self, alpha=0.25, gamma=2.0):
        super().__init__()
        self.alpha = alpha
        self.gamma = gamma
    
    def forward(self, predictions, targets):
        bce = F.binary_cross_entropy_with_logits(predictions, targets, reduction='none')
        pt = torch.exp(-bce)
        focal_loss = self.alpha * (1 - pt) ** self.gamma * bce
        return focal_loss.mean()
```

---

## Framelet (框架小波)

**定义**: 小波的过完备表示，提供冗余的多尺度信号分解。

**详细解释**: 框架小波是正交小波的推广，使用更多的基函数提供冗余表示。冗余性带来更好的平移不变性和对噪声的鲁棒性。框架小波分解通过滤波器组实现，满足完全重构条件。在图像处理中，框架小波用于去噪、修复、压缩等任务，特别是Bregman迭代算法中。

**数学公式**:
完全重构: $$\sum_{i} H_i^* H_i = I$$

分解: $c_i = H_i f$, 重构: $f = \sum_i H_i^* c_i$

**相关概念**: Wavelet, Multi-scale Analysis, Image Restoration, Bregman Iteration

**代表论文**: Cai, J. F., Osher, S., & Shen, Z. (2009). Split Bregman methods and frame based image restoration. Multiscale Modeling & Simulation.

---

## Functional (泛函)

**定义**: 函数空间到实数的映射，在变分方法中作为优化的目标。

**详细解释**: 泛函将函数作为输入，输出一个标量。在图像处理中，能量泛函衡量图像的质量或拟合程度。经典泛函包括：TV泛函衡量图像的总变分，Mumford-Shah泛函用于分割，Dirichlet能量衡量平滑度。变分方法通过最小化能量泛函求解逆问题，是数学图像处理的核心工具。

**数学公式**:
TV泛函: $$TV(u) = \int_\Omega |\nabla u| dx$$

**相关概念**: Variational Method, Energy Minimization, Euler-Lagrange Equation

**代表论文**: Aubert, G., & Kornprobst, P. (2006). Mathematical Problems in Image Processing. Springer.

---

## GAN (生成对抗网络)

**定义**: 由生成器和判别器组成的对抗训练框架，通过博弈学习数据分布。

**详细解释**: GAN包含生成器G和判别器D。G从噪声生成假样本，D区分真假样本，两者对抗训练。训练目标是纳什均衡：G生成的样本足以欺骗D，D无法区分真假。GAN变体包括DCGAN（卷积GAN）、WGAN（Wasserstein GAN）、StyleGAN（高质量人脸生成）。GAN训练不稳定，需要技巧如谱归一化、渐进训练。

**数学公式**:
$$\min_G \max_D V(D,G) = E_{x\sim p_{data}}[\log D(x)] + E_{z\sim p_z}[\log(1-D(G(z)))]$$

**相关概念**: Generative Model, Adversarial Training, StyleGAN, Diffusion Model

**代表论文**: Goodfellow, I., et al. (2014). Generative adversarial nets. NeurIPS.

**代码示例**:
```python
class Generator(nn.Module):
    def __init__(self, latent_dim, img_shape):
        super().__init__()
        self.model = nn.Sequential(
            nn.Linear(latent_dim, 128),
            nn.LeakyReLU(0.2),
            nn.Linear(128, 256),
            nn.BatchNorm1d(256),
            nn.LeakyReLU(0.2),
            nn.Linear(256, int(np.prod(img_shape))),
            nn.Tanh()
        )
    
    def forward(self, z):
        img = self.model(z)
        return img.view(img.size(0), *img_shape)

class Discriminator(nn.Module):
    def __init__(self, img_shape):
        super().__init__()
        self.model = nn.Sequential(
            nn.Linear(int(np.prod(img_shape)), 512),
            nn.LeakyReLU(0.2),
            nn.Linear(512, 256),
            nn.LeakyReLU(0.2),
            nn.Linear(256, 1),
            nn.Sigmoid()
        )
    
    def forward(self, img):
        return self.model(img.view(img.size(0), -1))
```

---

## Gated Convolution (门控卷积)

**定义**: 带有门控机制的卷积层，通过学习的选择性门控控制信息流。

**详细解释**: 门控卷积将卷积输出分成两部分，一部分经过sigmoid作为门控，另一部分与门控相乘。这使网络能够学习选择性地传递信息，对于图像修复等任务特别有效。相比标准卷积，门控卷积在处理不规则掩码和背景时更加灵活，在DeepFill等图像修复方法中使用。

**数学公式**:
$$O = \phi(W_f * X + b_f) \odot \sigma(W_g * X + b_g)$$

其中 $\phi$ 是激活函数，$\sigma$ 是sigmoid。

**相关概念**: Gating Mechanism, Image Inpainting, DeepFill

**代表论文**: Yu, J., et al. (2019). Free-form image inpainting with gated convolution. ICCV.

**代码示例**:
```python
class GatedConv2d(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, **kwargs):
        super().__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, **kwargs)
        self.gate_conv = nn.Conv2d(in_channels, out_channels, kernel_size, **kwargs)
    
    def forward(self, x):
        features = F.elu(self.conv(x))
        gate = torch.sigmoid(self.gate_conv(x))
        return features * gate
```

---

## Gaussian Filter (高斯滤波)

**定义**: 使用高斯函数作为卷积核的平滑滤波器，是线性低通滤波的标准方法。

**详细解释**: 高斯滤波器的权重由二维高斯函数采样得到，中心权重大、边缘权重小。高斯函数可分离为两个一维高斯的乘积，可将O(n²)复杂度降到O(n)。高斯滤波是尺度空间理论的基础，也是LoG、DoG等边缘检测算子的组成部分。$\sigma$参数控制平滑程度。

**数学公式**:
$$G(x,y) = \frac{1}{2\pi\sigma^2} e^{-\frac{x^2+y^2}{2\sigma^2}}$$

**相关概念**: Smoothing, Scale Space, LoG, Bilateral Filter

**代表论文**: Lindeberg, T. (1994). Scale-space theory: A basic tool for analysing structures. Kluwer Academic.

**代码示例**:
```python
def gaussian_kernel(size, sigma):
    """生成高斯核"""
    x = np.arange(size) - size // 2
    kernel_1d = np.exp(-x**2 / (2 * sigma**2))
    kernel_2d = np.outer(kernel_1d, kernel_1d)
    return kernel_2d / kernel_2d.sum()

def gaussian_blur(image, sigma=1.0):
    """高斯模糊"""
    size = int(6 * sigma + 1)
    kernel = gaussian_kernel(size, sigma)
    return convolve2d(image, kernel, mode='same')
```

---

## GNN (图神经网络)

**定义**: 处理图结构数据的神经网络，通过消息传递在节点间聚合信息。

**详细解释**: GNN将图数据（如社交网络、分子结构）映射到嵌入空间。核心操作是消息传递：每个节点从邻居接收消息，更新自身表示。主要类型包括：GCN（图卷积网络）使用归一化聚合，GAT（图注意力网络）使用注意力加权，GraphSAGE使用采样聚合。在点云处理、场景图生成等视觉任务中有应用。

**数学公式**:
GCN: $$H^{(l+1)} = \sigma(\tilde{D}^{-\frac{1}{2}}\tilde{A}\tilde{D}^{-\frac{1}{2}}H^{(l)}W^{(l)})$$

**相关概念**: Message Passing, Graph Convolution, GCN, GAT

**代表论文**: Kipf, T. N., & Welling, M. (2017). Semi-supervised classification with graph convolutional networks. ICLR.

**代码示例**:
```python
class GCNConv(nn.Module):
    def __init__(self, in_features, out_features):
        super().__init__()
        self.linear = nn.Linear(in_features, out_features)
    
    def forward(self, x, adj):
        # x: [N, in_features], adj: [N, N]
        # 归一化邻接矩阵
        degree = adj.sum(dim=1, keepdim=True).clamp(min=1)
        norm_adj = adj / degree.sqrt() / degree.sqrt().t()
        
        # 图卷积
        x = self.linear(x)
        x = torch.matmul(norm_adj, x)
        return x
```

---

## Gradient Descent (梯度下降)

**定义**: 沿负梯度方向迭代更新参数以最小化损失函数的优化算法。

**详细解释**: 梯度下降是最基本的优化算法。批量梯度下降使用全部数据计算梯度，随机梯度下降(SGD)使用单个样本，小批量梯度下降使用mini-batch。学习率是关键超参数，过大导致震荡，过小收敛慢。动量、Adam等优化器在SGD基础上改进。是深度学习训练的基础。

**数学公式**:
$$\theta_{t+1} = \theta_t - \eta \nabla_\theta \mathcal{L}(\theta_t)$$

**相关概念**: SGD, Momentum, Adam, Optimization

**代表论文**: Robbins, H., & Monro, S. (1951). A stochastic approximation method. Annals of Mathematical Statistics.

**代码示例**:
```python
def sgd_update(params, grads, lr, momentum=0.9):
    """带动量的SGD更新"""
    velocities = [torch.zeros_like(p) for p in params]
    
    for i, (param, grad) in enumerate(zip(params, grads)):
        velocities[i] = momentum * velocities[i] - lr * grad
        param += velocities[i]
    
    return params
```

---

## Graph Cut (图割)

**定义**: 基于图论的能量优化方法，将图像分割转化为图的最小割问题。

**详细解释**: 图割将图像像素表示为图的节点，相邻像素间有边，边的权重反映像素相似度。增加源点和汇点分别代表前景和背景，图割找到最小代价的割将图分成两部分。能量函数包括数据项（像素属于前景/背景的代价）和平滑项（相邻像素标签不一致的代价）。可通过最大流算法高效求解。

**数学公式**:
$$E(L) = \sum_{p} D_p(L_p) + \lambda \sum_{(p,q)\in N} V_{p,q}(L_p, L_q)$$

**相关概念**: Mincut/Maxflow, Energy Minimization, Segmentation, GrabCut

**代表论文**: Boykov, Y., & Kolmogorov, V. (2004). An experimental comparison of min-cut/max-flow algorithms. PAMI.

**代码示例**:
```python
import maxflow

def graph_cut_segmentation(image, seeds_foreground, seeds_background):
    """基于图割的交互式分割"""
    g = maxflow.Graph[float]()
    nodeids = g.add_grid_nodes(image.shape[:2])
    
    # 添加n-links（相邻像素边）
    for y in range(image.shape[0]-1):
        for x in range(image.shape[1]-1):
            # 根据颜色差异设置边权重
            pass
    
    # 添加t-links（源/汇边）
    for (y, x) in seeds_foreground:
        g.add_tedge(nodeids[y, x], float('inf'), 0)
    for (y, x) in seeds_background:
        g.add_tedge(nodeids[y, x], 0, float('inf'))
    
    g.maxflow()
    segmentation = g.get_grid_segments(nodeids)
    return segmentation
```

---

## Group Normalization (组归一化)

**定义**: 将通道分组进行归一化的方法，解决批归一化对小批量敏感的问题。

**详细解释**: 组归一化将通道分成若干组，每组内计算均值和方差进行归一化。与批归一化不同，GN的计算不依赖批量大小，在小批量甚至批量=1时也能稳定工作。GN介于层归一化和实例归一化之间，在目标检测、分割等需要高分辨率特征的任务中表现优异。

**数学公式**:
$$\hat{x} = \frac{x - \mu_g}{\sqrt{\sigma_g^2 + \epsilon}}, \quad y = \gamma\hat{x} + \beta$$

其中 $\mu_g$, $\sigma_g$ 在每组内计算。

**相关概念**: Batch Normalization, Layer Normalization, Instance Normalization

**代表论文**: Wu, Y., & He, K. (2018). Group normalization. ECCV.

**代码示例**:
```python
class GroupNorm(nn.Module):
    def __init__(self, num_groups, num_channels, eps=1e-5):
        super().__init__()
        self.num_groups = num_groups
        self.gamma = nn.Parameter(torch.ones(num_channels))
        self.beta = nn.Parameter(torch.zeros(num_channels))
        self.eps = eps
    
    def forward(self, x):
        N, C, H, W = x.shape
        G = self.num_groups
        
        # 重塑为 [N, G, C//G, H, W]
        x = x.view(N, G, C//G, H, W)
        
        # 每组内归一化
        mean = x.mean(dim=(2, 3, 4), keepdim=True)
        var = x.var(dim=(2, 3, 4), keepdim=True)
        x = (x - mean) / torch.sqrt(var + self.eps)
        
        # 恢复形状并应用仿射变换
        x = x.view(N, C, H, W)
        return self.gamma.view(1, C, 1, 1) * x + self.beta.view(1, C, 1, 1)
```

---

## Harris Corner (Harris角点)

**定义**: 基于局部自相关函数的角点检测算子，检测图像中具有丰富梯度信息的点。

**详细解释**: Harris角点检测通过计算图像在每个像素处的结构张量（梯度二阶矩矩阵），判断该点是否为角点。角点在两个方向上都有较大梯度变化，特征值都大；边缘一个方向大；平坦区域都小。Harris响应函数R = det(M) - k*trace(M)²用于阈值化。具有旋转不变性和部分仿射不变性。

**数学公式**:
$$R = \det(M) - k \cdot \text{tr}(M)^2 = \lambda_1\lambda_2 - k(\lambda_1+\lambda_2)^2$$

其中 $M = \sum_{x,y} w(x,y) \begin{bmatrix} I_x^2 & I_x I_y \\ I_x I_y & I_y^2 \end{bmatrix}$

**相关概念**: Feature Detection, SIFT, Corner Detection, Structure Tensor

**代表论文**: Harris, C., & Stephens, M. (1988). A combined corner and edge detector. Alvey Vision Conference.

**代码示例**:
```python
def harris_corner(image, k=0.04, threshold=0.01):
    """Harris角点检测"""
    # 计算梯度
    Ix = np.gradient(image, axis=1)
    Iy = np.gradient(image, axis=0)
    
    # 结构张量元素
    Ixx = gaussian_filter(Ix**2, sigma=1)
    Iyy = gaussian_filter(Iy**2, sigma=1)
    Ixy = gaussian_filter(Ix*Iy, sigma=1)
    
    # Harris响应
    det = Ixx * Iyy - Ixy**2
    trace = Ixx + Iyy
    R = det - k * trace**2
    
    # 非极大值抑制和阈值化
    corners = (R > threshold * R.max())
    return corners
```

---

## HOG (方向梯度直方图)

**定义**: 描述局部梯度方向分布的特征描述子，广泛应用于目标检测。

**详细解释**: HOG将图像分成小cell，每个cell内计算梯度方向直方图。多个cell组成block，block内归一化提高鲁棒性。所有block的直方图拼接成最终特征。HOG对光照变化和形变具有鲁棒性，是传统行人检测的标准特征。计算过程：梯度计算→cell直方图→block归一化→特征拼接。

**数学公式**:
$$h(\theta) = \sum_{p \in cell} |\nabla I(p)| \cdot \delta(\theta_p = \theta)$$

**相关概念**: SIFT, Feature Descriptor, Object Detection, SVM

**代表论文**: Dalal, N., & Triggs, B. (2005). Histograms of oriented gradients for human detection. CVPR.

**代码示例**:
```python
def compute_hog(image, cell_size=8, block_size=2, num_bins=9):
    """计算HOG特征"""
    # 计算梯度
    gx = np.gradient(image, axis=1)
    gy = np.gradient(image, axis=0)
    magnitude = np.sqrt(gx**2 + gy**2)
    orientation = np.arctan2(gy, gx) * 180 / np.pi % 180
    
    h, w = image.shape
    cells_h, cells_w = h // cell_size, w // cell_size
    
    # 计算cell直方图
    histograms = []
    for i in range(cells_h):
        for j in range(cells_w):
            cell_mag = magnitude[i*cell_size:(i+1)*cell_size, j*cell_size:(j+1)*cell_size]
            cell_ori = orientation[i*cell_size:(i+1)*cell_size, j*cell_size:(j+1)*cell_size]
            hist, _ = np.histogram(cell_ori, bins=num_bins, range=(0, 180), weights=cell_mag)
            histograms.append(hist)
    
    # Block归一化
    histograms = np.array(histograms).reshape(cells_h, cells_w, num_bins)
    features = []
    for i in range(cells_h - block_size + 1):
        for j in range(cells_w - block_size + 1):
            block = histograms[i:i+block_size, j:j+block_size].flatten()
            block = block / (np.linalg.norm(block) + 1e-6)
            features.extend(block)
    
    return np.array(features)
```

---

## HITS (超链接诱导主题搜索)

**定义**: 一种网页排序算法，将网页分为枢纽(hub)和权威(authority)两类，相互增强评分。

**详细解释**: HITS算法假设好的hub指向好的authority，好的authority被好的hub指向。算法迭代更新：authority得分等于指向它的hub得分之和，hub得分等于它指向的authority得分之和。虽然主要用于网页排序，但其思想可应用于图像检索、推荐系统等需要区分两类对象的场景。

**数学公式**:
$$a_p = \sum_{q \to p} h_q, \quad h_p = \sum_{p \to q} a_q$$

**相关概念**: PageRank, Link Analysis, Hub and Authority

**代表论文**: Kleinberg, J. M. (1999). Authoritative sources in a hyperlinked environment. JACM.

**代码示例**:
```python
def hits_algorithm(adj_matrix, max_iter=100, tol=1e-6):
    """HITS算法"""
    n = adj_matrix.shape[0]
    hubs = np.ones(n)
    authorities = np.ones(n)
    
    for _ in range(max_iter):
        # 更新authority得分
        new_auth = adj_matrix.T @ hubs
        # 更新hub得分
        new_hubs = adj_matrix @ new_auth
        
        # 归一化
        new_auth = new_auth / np.linalg.norm(new_auth)
        new_hubs = new_hubs / np.linalg.norm(new_hubs)
        
        # 检查收敛
        if np.linalg.norm(new_auth - authorities) < tol:
            break
        
        authorities = new_auth
        hubs = new_hubs
    
    return hubs, authorities
```

---

## HOOI (高阶正交迭代)

**定义**: Tucker张量分解的迭代算法，交替优化各模态的因子矩阵。

**详细解释**: HOOI通过交替最小二乘求解Tucker分解。每次迭代固定其他模态的因子矩阵，优化当前模态的因子矩阵（通过SVD）。算法迭代直到收敛，收敛到局部最优。HOOI是高阶SVD(HOSVD)的改进版本，通过迭代优化获得更好的压缩效果。广泛应用于张量补全、推荐系统。

**数学公式**:
Tucker分解: $\mathcal{X} \approx \mathcal{G} \times_1 U^{(1)} \times_2 U^{(2)} \times_3 U^{(3)}$

**相关概念**: Tucker Decomposition, Tensor Factorization, HOSVD, CP Decomposition

**代表论文**: Lathauwer, L. D., Moor, B. D., & Vandewalle, J. (2000). A multilinear singular value decomposition. SIMAX.

**代码示例**:
```python
def hooi(tensor, ranks, max_iter=50):
    """高阶正交迭代"""
    order = tensor.ndim
    factors = [None] * order
    
    # 初始化：使用HOSVD
    for i in range(order):
        unfolded = np.moveaxis(tensor, i, 0).reshape(tensor.shape[i], -1)
        U, _, _ = np.linalg.svd(unfolded, full_matrices=False)
        factors[i] = U[:, :ranks[i]]
    
    # 迭代优化
    for _ in range(max_iter):
        for i in range(order):
            # 计算模态i的展开
            temp = tensor
            for j in range(order):
                if j != i:
                    temp = np.tensordot(temp, factors[j].T, axes=([0], [0]))
            
            # SVD更新因子矩阵
            U, _, _ = np.linalg.svd(temp.reshape(ranks[i], -1), full_matrices=False)
            factors[i] = U[:, :ranks[i]]
    
    # 计算核心张量
    core = tensor
    for i, factor in enumerate(factors):
        core = np.tensordot(core, factor.T, axes=([0], [0]))
    
    return core, factors
```

---

## Hypergraph (超图)

**定义**: 边可以连接任意数量顶点的图推广，能够建模多对多关系。

**详细解释**: 普通图的边连接两个顶点，超图的超边可以连接多个顶点。超边用子集表示，可以建模更复杂的关系。超图学习包括超图划分、超图匹配、超图神经网络等。在图像检索、推荐系统、社交网络分析中，超图能更好地捕获群体关系。

**数学公式**:
超图 $H = (V, E)$，其中超边 $e \in E$ 是顶点子集 $e \subseteq V$

**相关概念**: Graph Neural Network, Hypergraph Neural Network, Multi-way Relation

**代表论文**: Zhou, D., Huang, J., & Schölkopf, B. (2007). Learning with hypergraphs. ICML.

---

## Image Enhancement (图像增强)

**定义**: 改善图像视觉效果或为后续处理准备图像的技术，包括对比度增强、去噪、锐化等。

**详细解释**: 图像增强通过调整图像的亮度、对比度、颜色等属性提高视觉质量。方法包括：直方图均衡化增强对比度，去噪滤波减少噪声，锐化增强边缘。深度学习方法学习端到端的增强映射，如Zero-DCE进行零样本低光增强。增强是图像处理的基本步骤。

**数学公式**:
直方图均衡化: $s_k = (L-1) \sum_{j=0}^k p_r(r_j)$

**相关概念**: Histogram Equalization, Denoising, Sharpening, Retinex

**代表论文**: Pizer, S. M., et al. (1987). Adaptive histogram equalization. Medical Physics.

**代码示例**:
```python
def histogram_equalization(image):
    """直方图均衡化"""
    hist, bins = np.histogram(image.flatten(), bins=256, range=(0, 256))
    cdf = hist.cumsum()
    cdf_normalized = (cdf - cdf.min()) * 255 / (cdf.max() - cdf.min())
    
    equalized = np.interp(image.flatten(), bins[:-1], cdf_normalized)
    return equalized.reshape(image.shape).astype(np.uint8)
```

---

## Image Inpainting (图像修复)

**定义**: 填充图像中缺失或损坏区域的技术，使修复结果自然连贯。

**详细解释**: 图像修复根据周围已知信息推断缺失区域内容。传统方法包括：基于扩散的方法将周围信息扩散到缺失区域，基于patch的方法从图像其他部分复制相似patch。深度学习方法（Context Encoder、DeepFill、LaMa）通过学习大规模数据生成合理的修复内容。应用于老照片修复、目标移除等。

**数学公式**:
$$\min_u \int_\Omega |\nabla u|^2 dx, \quad u|_{\partial\Omega} = u_0$$

**相关概念**: Image Completion, Diffusion-based Inpainting, DeepFill

**代表论文**: Bertalmio, M., et al. (2000). Image inpainting. SIGGRAPH.

**代码示例**:
```python
def patchmatch_inpaint(image, mask, patch_size=7, iterations=10):
    """基于PatchMatch的图像修复"""
    result = image.copy()
    
    for _ in range(iterations):
        # 对于每个缺失像素，找到最佳匹配patch
        for y in range(patch_size//2, image.shape[0]-patch_size//2):
            for x in range(patch_size//2, image.shape[1]-patch_size//2):
                if mask[y, x]:
                    # 搜索最佳匹配
                    best_patch = find_best_match(image, mask, y, x, patch_size)
                    result[y, x] = best_patch[patch_size//2, patch_size//2]
    
    return result
```

---

## Instance Segmentation (实例分割)

**定义**: 同时检测目标并分割每个实例的像素级任务，区分同一类的不同实例。

**详细解释**: 实例分割结合目标检测和语义分割，需要：1)检测每个目标实例，2)分割每个实例的像素。主流方法：Mask R-CNN在检测框内预测分割mask，YOLACT实时生成原型mask并组合，SOLOv2直接预测网格内的实例mask。评估指标包括Mask AP。实例分割是视觉理解的进阶任务。

**数学公式**:
Mask R-CNN损失: $\mathcal{L} = \mathcal{L}_{cls} + \mathcal{L}_{box} + \mathcal{L}_{mask}$

**相关概念**: Mask R-CNN, Semantic Segmentation, Panoptic Segmentation

**代表论文**: He, K., et al. (2017). Mask R-CNN. ICCV.

---

## IoU (交并比)

**定义**: 衡量两个边界框或分割区域重叠度的指标，是目标检测和分割的核心评估指标。

**详细解释**: IoU计算预测区域与真实区域的交集面积除以并集面积。IoU∈[0,1]，越大表示匹配越好。在检测中，IoU>0.5通常认为正确检测。IoU作为损失函数（IoU Loss、GIoU、DIoU、CIoU）直接优化评估指标，比坐标回归更有效。在NMS中用于抑制重叠检测。

**数学公式**:
$$IoU = \frac{|A \cap B|}{|A \cup B|} = \frac{|A \cap B|}{|A| + |B| - |A \cap B|}$$

**相关概念**: Bounding Box, Object Detection, NMS, GIoU

**代表论文**: Everingham, M., et al. (2010). The Pascal Visual Object Classes Challenge. IJCV.

**代码示例**:
```python
def compute_iou(box1, box2):
    """计算两个边界框的IoU"""
    # box: [x1, y1, x2, y2]
    x1 = max(box1[0], box2[0])
    y1 = max(box1[1], box2[1])
    x2 = min(box1[2], box2[2])
    y2 = min(box1[3], box2[3])
    
    intersection = max(0, x2 - x1) * max(0, y2 - y1)
    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])
    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])
    union = area1 + area2 - intersection
    
    return intersection / (union + 1e-6)
```

---

## Jaccard Index (Jaccard指数)

**定义**: 衡量两个集合相似度的指标，等于交集与并集的比值，IoU在集合上的推广。

**详细解释**: Jaccard指数用于衡量集合、分割区域的相似度。在语义分割中，Jaccard指数也称为mIoU（mean IoU），是分割任务的主要评估指标。Jaccard距离=1-Jaccard指数，是度量距离。在聚类评估、推荐系统中也广泛应用。

**数学公式**:
$$J(A, B) = \frac{|A \cap B|}{|A \cup B|}$$

**相关概念**: IoU, Semantic Segmentation, Similarity Metric

**代表论文**: Jaccard, P. (1912). The distribution of the flora in the alpine zone. New Phytologist.

---

## JPEG Compression (JPEG压缩)

**定义**: 广泛使用的有损图像压缩标准，基于离散余弦变换(DCT)和量化。

**详细解释**: JPEG压缩流程：1)颜色空间转换RGB→YCbCr，2)色度下采样，3)8×8块DCT变换，4)量化（主要信息损失点），5)熵编码（Huffman）。解压缩是逆过程。量化表控制压缩率和质量的平衡。JPEG在高压缩率下产生块效应，是图像处理中常见的退化类型。

**数学公式**:
DCT: $$F(u,v) = \frac{1}{4}C(u)C(v)\sum_{x=0}^7\sum_{y=0}^7 f(x,y)\cos\frac{(2x+1)u\pi}{16}\cos\frac{(2y+1)v\pi}{16}$$

**相关概念**: DCT, Image Compression, Quantization, Block Artifact

**代表论文**: Wallace, G. K. (1991). The JPEG still picture compression standard. CACM.

**代码示例**:
```python
def jpeg_compress_block(block, quality=50):
    """简化的JPEG压缩"""
    # DCT变换
    dct_block = dct(dct(block, axis=0), axis=1)
    
    # 量化表（简化）
    qtable = np.ones((8, 8)) * quality
    quantized = np.round(dct_block / qtable)
    
    return quantized

def jpeg_decompress_block(quantized, quality=50):
    """简化的JPEG解压缩"""
    qtable = np.ones((8, 8)) * quality
    dct_block = quantized * qtable
    
    # IDCT变换
    block = idct(idct(dct_block, axis=0), axis=1)
    
    return block
```
