# 计算机视觉概念词典 - A-E

## Active Contour (活动轮廓)

**定义**: 一种基于能量最小化的图像分割方法，通过曲线演化逼近目标边界。

**详细解释**: 活动轮廓模型（也称为Snake模型）将图像分割问题转化为能量泛函的最小化问题。轮廓曲线在内外力的作用下变形，内力保持曲线光滑性，外力（通常来自图像梯度）吸引曲线向目标边界移动。该方法的优点是能产生光滑闭合的轮廓，缺点是对初始位置敏感且难以处理拓扑变化。

**数学公式**:
$$E_{snake} = \int_0^1 \left[ \alpha |v'(s)|^2 + \beta |v''(s)|^2 + E_{ext}(v(s)) \right] ds$$

**相关概念**: Level Set, Chan-Vese Model, Mumford-Shah Functional

**代表论文**: Kass, M., Witkin, A., & Terzopoulos, D. (1988). Snakes: Active contour models. IJCV.

**代码示例**:
```python
import numpy as np
from skimage import draw

def active_contour(image, snake, alpha=0.01, beta=0.1, gamma=0.01):
    """简化的活动轮廓实现"""
    # 计算图像梯度作为外力
    grad_x = np.gradient(image, axis=1)
    grad_y = np.gradient(image, axis=0)
    
    for _ in range(100):
        # 内力: 弹性力和刚性力
        # 更新snake位置
        pass
    return snake
```

---

## ADMM (交替方向乘子法)

**定义**: 一种求解带约束优化问题的分裂算法，通过交替优化分解原问题。

**详细解释**: ADMM将复杂优化问题分解为若干简单子问题交替求解。它结合了对偶上升法的可分解性和增广拉格朗日方法的鲁棒性。特别适合处理目标函数可分离的凸优化问题，在信号处理、机器学习和统计推断中有广泛应用。收敛速度为O(1/k)，可以分布式实现。

**数学公式**:
$$\begin{aligned} x^{k+1} &= \arg\min_x L_\rho(x, y^k, \lambda^k) \\ y^{k+1} &= \arg\min_y L_\rho(x^{k+1}, y, \lambda^k) \\ \lambda^{k+1} &= \lambda^k + \rho(Ax^{k+1} + By^{k+1} - c) \end{aligned}$$

其中 $L_\rho$ 是增广拉格朗日函数。

**相关概念**: Proximal Operator, Primal-Dual, Convex Relaxation

**代表论文**: Boyd, S., et al. (2011). Distributed optimization and statistical learning via the alternating direction method of multipliers. Foundations and Trends in Machine Learning.

**代码示例**:
```python
def admm_solver(f, g, A, B, c, rho=1.0, max_iter=1000):
    """ADMM求解器框架"""
    x, y, lam = np.zeros(n), np.zeros(m), np.zeros(p)
    
    for k in range(max_iter):
        # x-更新
        x = prox_f(A.T @ (rho * (B @ y + c) - lam))
        # y-更新
        y = prox_g(B.T @ (rho * (A @ x - c) + lam))
        # 对偶变量更新
        lam = lam + rho * (A @ x + B @ y - c)
    
    return x, y
```

---

## Anisotropic Diffusion (各向异性扩散)

**定义**: 一种边缘保持的图像平滑方法，沿边缘方向扩散强于垂直边缘方向。

**详细解释**: Perona-Malik各向异性扩散通过调整扩散系数来保护边缘。在图像平坦区域，扩散系数大，平滑效果强；在边缘附近，扩散系数小，边缘得以保留。这克服了高斯滤波边缘模糊的问题。扩散系数通常基于图像梯度设计，如$\exp(-|\nabla I|^2/K^2)$。

**数学公式**:
$$\frac{\partial I}{\partial t} = \text{div}(c(|\nabla I|)\nabla I)$$

其中 $c(\cdot)$ 是扩散系数函数。

**相关概念**: Total Variation, ROF Model, Diffusion Model

**代表论文**: Perona, P., & Malik, J. (1990). Scale-space and edge detection using anisotropic diffusion. PAMI.

**代码示例**:
```python
def anisotropic_diffusion(image, n_iter=100, kappa=50, gamma=0.1):
    """Perona-Malik各向异性扩散"""
    img = image.copy()
    
    for _ in range(n_iter):
        # 计算四个方向的梯度
        deltaN = np.roll(img, -1, axis=0) - img
        deltaS = np.roll(img, 1, axis=0) - img
        deltaE = np.roll(img, -1, axis=1) - img
        deltaW = np.roll(img, 1, axis=1) - img
        
        # 计算扩散系数
        cN = np.exp(-(deltaN/kappa)**2)
        cS = np.exp(-(deltaS/kappa)**2)
        cE = np.exp(-(deltaE/kappa)**2)
        cW = np.exp(-(deltaW/kappa)**2)
        
        # 更新图像
        img += gamma * (cN*deltaN + cS*deltaS + cE*deltaE + cW*deltaW)
    
    return img
```

---

## Attention Mechanism (注意力机制)

**定义**: 一种让模型动态关注输入相关部分的技术，通过权重分配实现选择性信息处理。

**详细解释**: 注意力机制模拟人类视觉的选择性注意，通过计算查询与键的相似度得到注意力权重，再对值进行加权求和。常见类型包括加性注意力、点积注意力和多头注意力。Transformer架构完全基于注意力机制，摒弃了循环结构，实现了并行化训练和长程依赖建模。

**数学公式**:
$$\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V$$

**相关概念**: Transformer, Self-Attention, Vision Transformer

**代表论文**: Vaswani, A., et al. (2017). Attention is all you need. NeurIPS.

**代码示例**:
```python
import torch
import torch.nn.functional as F

def scaled_dot_product_attention(Q, K, V, mask=None):
    """缩放点积注意力"""
    d_k = Q.size(-1)
    scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(d_k)
    
    if mask is not None:
        scores = scores.masked_fill(mask == 0, -1e9)
    
    attn_weights = F.softmax(scores, dim=-1)
    output = torch.matmul(attn_weights, V)
    
    return output, attn_weights
```

---

## Autoencoder (自编码器)

**定义**: 一种无监督学习的神经网络架构，通过编码-解码结构学习数据的压缩表示。

**详细解释**: 自编码器由编码器和解码器组成，目标是使重构输出尽可能接近输入。编码器将高维输入映射到低维隐空间（瓶颈层），解码器从隐表示重构原始输入。变体包括去噪自编码器、变分自编码器(VAE)和稀疏自编码器。广泛应用于降维、特征学习和生成模型。

**数学公式**:
$$\mathcal{L} = \|x - D(E(x))\|^2 + \lambda \mathcal{R}(z)$$

其中 $E$ 是编码器，$D$ 是解码器，$\mathcal{R}$ 是正则项。

**相关概念**: VAE, Denoising Autoencoder, Representation Learning

**代表论文**: Hinton, G. E., & Salakhutdinov, R. R. (2006). Reducing the dimensionality of data with neural networks. Science.

---

## Backpropagation (反向传播)

**定义**: 神经网络中计算梯度的核心算法，通过链式法则从输出层向输入层传递误差。

**详细解释**: 反向传播利用动态规划思想高效计算损失函数对各参数的梯度。前向传播计算各层输出，反向传播从损失函数开始，逐层计算梯度并传递。通过缓存中间结果避免重复计算，将梯度计算复杂度从O(n²)降到O(n)。是深度学习训练的基础算法。

**数学公式**:
$$\frac{\partial L}{\partial w_{ij}^{(l)}} = \frac{\partial L}{\partial a_j^{(l)}} \cdot \frac{\partial a_j^{(l)}}{\partial w_{ij}^{(l)}} = \delta_j^{(l)} \cdot a_i^{(l-1)}$$

**相关概念**: Gradient Descent, Chain Rule, Deep Learning

**代表论文**: Rumelhart, D. E., Hinton, G. E., & Williams, R. J. (1986). Learning representations by back-propagating errors. Nature.

---

## Batch Normalization (批归一化)

**定义**: 一种加速深度网络训练的技术，通过标准化每层的输入分布来缓解内部协变量偏移。

**详细解释**: 批归一化在每个 mini-batch 上计算均值和方差，对激活值进行标准化，再通过可学习的缩放和偏移参数恢复表达能力。它允许使用更大的学习率，减少对初始化的敏感度，并有正则化效果。在训练和推理时行为不同，推理时使用全局统计量。

**数学公式**:
$$\hat{x} = \frac{x - \mu_B}{\sqrt{\sigma_B^2 + \epsilon}}, \quad y = \gamma\hat{x} + \beta$$

**相关概念**: Layer Normalization, Group Normalization, Deep Learning

**代表论文**: Ioffe, S., & Szegedy, C. (2015). Batch normalization: Accelerating deep network training. ICML.

**代码示例**:
```python
class BatchNorm2d(nn.Module):
    def __init__(self, num_features, eps=1e-5, momentum=0.1):
        super().__init__()
        self.gamma = nn.Parameter(torch.ones(num_features))
        self.beta = nn.Parameter(torch.zeros(num_features))
        self.eps = eps
        self.momentum = momentum
        self.register_buffer('running_mean', torch.zeros(num_features))
        self.register_buffer('running_var', torch.ones(num_features))
    
    def forward(self, x):
        if self.training:
            mean = x.mean(dim=(0, 2, 3))
            var = x.var(dim=(0, 2, 3), unbiased=False)
            self.running_mean = (1-self.momentum)*self.running_mean + self.momentum*mean
            self.running_var = (1-self.momentum)*self.running_var + self.momentum*var
        else:
            mean, var = self.running_mean, self.running_var
        
        x_norm = (x - mean[None,:,None,None]) / torch.sqrt(var[None,:,None,None] + self.eps)
        return self.gamma[None,:,None,None] * x_norm + self.beta[None,:,None,None]
```

---

## Bilevel Optimization (双层优化)

**定义**: 包含上下两层嵌套的优化问题，上层问题的约束或参数依赖于下层问题的解。

**详细解释**: 双层优化广泛应用于超参数优化、元学习和神经架构搜索。上层问题优化主目标，下层问题优化嵌套目标。求解方法包括隐微分法（通过KKT条件）、迭代微分法和梯度估计法。双层优化的挑战在于下层问题的精确求解和梯度的有效回传。

**数学公式**:
$$\begin{aligned} \min_{x,y} \quad & F(x, y^*(x)) \\ \text{s.t.} \quad & y^*(x) = \arg\min_y G(x, y) \end{aligned}$$

**相关概念**: Meta-learning, Hyperparameter Optimization, Neural Architecture Search

**代表论文**: Colson, B., Marcotte, P., & Savard, G. (2007). An overview of bilevel optimization. Annals of Operations Research.

---

## Bilateral Filter (双边滤波)

**定义**: 一种保边平滑滤波器，同时考虑空间距离和像素值差异进行加权平均。

**详细解释**: 双边滤波的权重由空间高斯和值域高斯的乘积决定。空间高斯保证邻近像素权重大，值域高斯保证相似像素权重大。这使双边滤波在平滑噪声的同时能够保持边缘。缺点是计算复杂度高O(N²)，但已有快速近似算法如Permutohedral Lattice。

**数学公式**:
$$BF[I]_p = \frac{1}{W_p} \sum_{q \in \Omega} G_{\sigma_s}(\|p-q\|) G_{\sigma_r}(|I_p - I_q|) I_q$$

**相关概念**: Guided Filter, Edge-preserving Smoothing, Anisotropic Diffusion

**代表论文**: Tomasi, C., & Manduchi, R. (1998). Bilateral filtering for gray and color images. ICCV.

**代码示例**:
```python
def bilateral_filter(image, sigma_s=3, sigma_r=0.1):
    """简化的双边滤波实现"""
    h, w = image.shape
    pad = int(3 * sigma_s)
    padded = np.pad(image, pad, mode='reflect')
    output = np.zeros_like(image)
    
    for i in range(h):
        for j in range(w):
            # 窗口内加权平均
            window = padded[i:i+2*pad+1, j:j+2*pad+1]
            spatial_weight = gaussian_kernel(2*pad+1, sigma_s)
            range_weight = np.exp(-0.5 * ((window - image[i,j]) / sigma_r)**2)
            weight = spatial_weight * range_weight
            output[i,j] = np.sum(weight * window) / np.sum(weight)
    
    return output
```

---

## Bounding Box (边界框)

**定义**: 包围目标物体的矩形框，由左上角和右下角坐标定义，用于目标检测和定位。

**详细解释**: 边界框是目标检测中最基本的标注和预测形式。常用表示方式有(x_min, y_min, x_max, y_max)或(x_center, y_center, width, height)。IoU（交并比）是评估边界框匹配度的标准指标。现代检测器如YOLO、Faster R-CNN都基于边界框预测。

**数学公式**:
$$\text{IoU} = \frac{|B_p \cap B_{gt}|}{|B_p \cup B_{gt}|}$$

**相关概念**: IoU, Object Detection, Anchor Box, Non-maximum Suppression

**代表论文**: Girshick, R., et al. (2014). Rich feature hierarchies for accurate object detection. CVPR.

---

## CAM (类激活图)

**定义**: 一种可视化卷积神经网络决策依据的技术，显示图像中对分类贡献最大的区域。

**详细解释**: 类激活图通过全局平均池化层(GAP)的权重与特征图加权求和得到。它揭示了CNN关注的图像区域，提供模型可解释性。Grad-CAM是其扩展版本，通过梯度加权适用于任意CNN架构，无需修改网络结构。广泛应用于模型诊断和弱监督定位。

**数学公式**:
$$L_{CAM}^c = \sum_k w_k^c A^k$$

其中 $w_k^c$ 是类别c对特征图k的权重，$A^k$ 是第k个特征图。

**相关概念**: Grad-CAM, Explainable AI, Weakly Supervised Localization

**代表论文**: Zhou, B., et al. (2016). Learning deep features for discriminative localization. CVPR.

**代码示例**:
```python
def compute_cam(feature_maps, weights, class_idx):
    """计算类激活图"""
    # feature_maps: [C, H, W]
    # weights: [num_classes, C]
    cam = np.zeros(feature_maps.shape[1:])
    
    for i, w in enumerate(weights[class_idx]):
        cam += w * feature_maps[i]
    
    cam = np.maximum(cam, 0)  # ReLU
    cam = (cam - cam.min()) / (cam.max() - cam.min() + 1e-8)
    return cam
```

---

## Chan-Vese Model (Chan-Vese模型)

**定义**: 基于水平集的图像分割模型，不依赖边缘梯度，适合分割弱边界目标。

**详细解释**: Chan-Vese模型是Mumford-Shah泛函的简化特例，假设图像由两个区域（前景和背景）组成，每个区域内部具有恒定灰度值。它最小化区域内外灰度方差之和，而非依赖边缘梯度。这使得模型能够分割没有明显边缘的目标，对噪声更鲁棒。

**数学公式**:
$$E(c_1, c_2, C) = \mu|C| + \lambda_1 \int_{inside(C)}(I-c_1)^2 dA + \lambda_2 \int_{outside(C)}(I-c_2)^2 dA$$

**相关概念**: Level Set, Mumford-Shah Functional, Active Contour, SaT

**代表论文**: Chan, T. F., & Vese, L. A. (2001). Active contours without edges. PAMI.

**代码示例**:
```python
def chan_vese(image, mu=0.25, lambda1=1, lambda2=1, max_iter=200):
    """Chan-Vese水平集分割"""
    phi = np.ones_like(image)  # 初始化水平集
    phi[image < image.mean()] = -1
    
    for _ in range(max_iter):
        # 计算内外均值
        c1 = image[phi > 0].mean()
        c2 = image[phi < 0].mean()
        
        # 更新水平集
        # ... (略去详细实现)
    
    return phi > 0
```

---

## Chambolle's Algorithm (Chambolle算法)

**定义**: 求解ROF去噪模型对偶问题的投影梯度算法，具有理论保证的收敛性。

**详细解释**: Chambolle算法将ROF模型的原始问题转化为对偶问题求解。原始变量是去噪图像，对偶变量是梯度场。算法通过迭代投影到约束球上来更新对偶变量，然后从对偶变量恢复原始变量。该方法避免了正则化参数的选择困难，是TV去噪的经典方法。

**数学公式**:
$$p^{n+1} = \frac{p^n + \tau(\nabla(\text{div}(p^n) - f/\lambda))}{1 + \tau|\nabla(\text{div}(p^n) - f/\lambda)|}$$

**相关概念**: ROF Model, Total Variation, Primal-Dual, Proximal Operator

**代表论文**: Chambolle, A. (2004). An algorithm for total variation minimization and applications. JMIV.

**代码示例**:
```python
def chambolle_denoise(image, lambda_tv=0.1, tau=0.25, max_iter=100):
    """Chambolle TV去噪算法"""
    h, w = image.shape
    px, py = np.zeros_like(image), np.zeros_like(image)
    
    for _ in range(max_iter):
        # 计算div(p)
        div_p = np.roll(px, -1, axis=1) - px + np.roll(py, -1, axis=0) - py
        # 更新梯度
        grad_x = np.roll(div_p - image/lambda_tv, 1, axis=1) - (div_p - image/lambda_tv)
        grad_y = np.roll(div_p - image/lambda_tv, 1, axis=0) - (div_p - image/lambda_tv)
        
        # 投影
        denom = 1 + tau * np.sqrt(grad_x**2 + grad_y**2)
        px = (px + tau * grad_x) / denom
        py = (py + tau * grad_y) / denom
    
    return image - lambda_tv * (np.roll(px, -1, axis=1) - px + np.roll(py, -1, axis=0) - py)
```

---

## Classification (分类)

**定义**: 计算机视觉的基本任务之一，将图像分配到预定义类别中的一个或多个。

**详细解释**: 图像分类是视觉任务的基础，从简单的二分类到ImageNet的1000类分类。传统方法依赖手工特征（SIFT, HOG）和分类器（SVM, 随机森林），深度学习时代端到端学习特征。评估指标包括准确率、Top-1/Top-5准确率、F1分数等。是目标检测、分割等任务的基础。

**数学公式**:
$$\hat{y} = \arg\max_c P(y=c|x) = \arg\max_c f_c(x; \theta)$$

**相关概念**: Softmax, Cross-Entropy Loss, ImageNet, Transfer Learning

**代表论文**: Krizhevsky, A., Sutskever, I., & Hinton, G. E. (2012). ImageNet classification with deep CNNs. NeurIPS.

---

## CNN (卷积神经网络)

**定义**: 一种专门处理网格结构数据的神经网络，通过卷积操作提取局部特征。

**详细解释**: CNN的核心组件包括卷积层、池化层和全连接层。卷积层通过共享权重的滤波器提取局部特征，池化层降采样增加平移不变性。相比全连接网络，CNN参数更少、更适合处理图像。经典架构包括LeNet、AlexNet、VGG、ResNet等，是现代计算机视觉的基石。

**数学公式**:
$$(f * g)[n] = \sum_{m=-\infty}^{\infty} f[m] g[n-m]$$

**相关概念**: Convolution, Pooling, ResNet, VGG, Feature Extraction

**代表论文**: LeCun, Y., et al. (1998). Gradient-based learning applied to document recognition. Proceedings of the IEEE.

**代码示例**:
```python
class SimpleCNN(nn.Module):
    def __init__(self, num_classes=10):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)
        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)
        self.pool = nn.MaxPool2d(2, 2)
        self.fc = nn.Linear(64 * 8 * 8, num_classes)
    
    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(x.size(0), -1)
        x = self.fc(x)
        return x
```

---

## Contrastive Learning (对比学习)

**定义**: 一种自监督学习方法，通过拉近相似样本、推远不相似样本学习表示。

**详细解释**: 对比学习构造正负样本对，训练编码器使正样本在隐空间中接近，负样本远离。关键设计包括数据增强策略（SimCLR）、记忆库（MoCo）、负样本采样。SimCLR使用大批量负样本，MoCo用队列维护一致性。对比学习无需标签即可学到有意义的视觉表示，可用于下游任务微调。

**数学公式**:
$$\mathcal{L}_{contrast} = -\log \frac{\exp(\text{sim}(z_i, z_j)/\tau)}{\sum_{k=1}^{2N} \mathbb{1}_{[k \neq i]} \exp(\text{sim}(z_i, z_k)/\tau)}$$

**相关概念**: Self-Supervised Learning, SimCLR, MoCo, Representation Learning

**代表论文**: Chen, T., et al. (2020). A simple framework for contrastive learning of visual representations. ICML.

**代码示例**:
```python
def contrastive_loss(z1, z2, temperature=0.5):
    """NT-Xent对比损失"""
    batch_size = z1.shape[0]
    z = torch.cat([z1, z2], dim=0)
    
    # 计算相似度矩阵
    sim = F.cosine_similarity(z.unsqueeze(1), z.unsqueeze(0), dim=2)
    
    # 构建正负样本mask
    pos_mask = torch.zeros(2*batch_size, 2*batch_size)
    for i in range(batch_size):
        pos_mask[i, batch_size+i] = 1
        pos_mask[batch_size+i, i] = 1
    
    # 计算损失
    sim = sim / temperature
    pos = torch.sum(sim * pos_mask, dim=1)
    neg = torch.logsumexp(sim * (1 - pos_mask), dim=1)
    loss = -pos + neg
    return loss.mean()
```

---

## Convex Relaxation (凸松弛)

**定义**: 将非凸优化问题转化为凸优化问题的技术，通过放松约束或修改目标函数。

**详细解释**: 许多视觉问题（如图割、压缩感知）原本是非凸的，难以找到全局最优解。凸松弛通过放宽整数约束或用凸函数近似非凸项，使问题可求解。常用方法包括：半定规划松弛（SDP）、L1范数代替L0范数、连续松弛。虽然可能引入近似误差，但凸松弛保证了全局最优性和高效求解。

**数学公式**:
原问题: $\min_x \|x\|_0$ s.t. $Ax=b$ → 松弛: $\min_x \|x\|_1$ s.t. $Ax=b$

**相关概念**: Compressed Sensing, Graph Cut, Semi-Definite Programming

**代表论文**: Candès, E. J., Romberg, J., & Tao, T. (2006). Robust uncertainty principles: Exact signal reconstruction. IEEE Trans. Inf. Theory.

---

## Convolution (卷积)

**定义**: 一种数学运算，将滤波器与输入进行滑动点积，提取局部特征。

**详细解释**: 卷积是CNN的核心操作。二维卷积将滤波器在图像上滑动，每个位置计算点积。关键参数包括步长（stride）、填充（padding）、膨胀（dilation）。深度可分离卷积将空间卷积和通道卷积分解，大幅减少参数。转置卷积用于上采样。卷积的平移等变性使其特别适合处理图像。

**数学公式**:
$$(I * K)(i,j) = \sum_m \sum_n I(i+m, j+n) K(m, n)$$

**相关概念**: CNN, Feature Map, Kernel, Transposed Convolution

**代表论文**: Fukushima, K. (1980). Neocognitron: A self-organizing neural network model. Biological Cybernetics.

**代码示例**:
```python
def conv2d(image, kernel, stride=1, padding=0):
    """手动实现2D卷积"""
    if padding > 0:
        image = np.pad(image, padding, mode='constant')
    
    h, w = image.shape
    kh, kw = kernel.shape
    oh, ow = (h - kh) // stride + 1, (w - kw) // stride + 1
    output = np.zeros((oh, ow))
    
    for i in range(oh):
        for j in range(ow):
            region = image[i*stride:i*stride+kh, j*stride:j*stride+kw]
            output[i, j] = np.sum(region * kernel)
    
    return output
```

---

## Cross-Entropy Loss (交叉熵损失)

**定义**: 分类任务的标准损失函数，衡量预测分布与真实分布之间的差异。

**详细解释**: 交叉熵损失来源于信息论，衡量两个概率分布的相似性。在分类中，真实标签是one-hot向量，预测是softmax输出。交叉熵损失对错误分类惩罚大，梯度清晰。与MSE相比，交叉熵更适合分类任务，避免了sigmoid/softmax饱和时的梯度消失问题。

**数学公式**:
$$\mathcal{L}_{CE} = -\sum_{c=1}^C y_c \log(\hat{y}_c) = -\log(\hat{y}_{y_{true}})$$

**相关概念**: Softmax, KL Divergence, Classification, Focal Loss

**代表论文**: Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep Learning. MIT Press.

**代码示例**:
```python
def cross_entropy_loss(predictions, targets):
    """交叉熵损失"""
    # predictions: [N, C], targets: [N]
    batch_size = predictions.shape[0]
    log_probs = F.log_softmax(predictions, dim=1)
    loss = -log_probs[range(batch_size), targets].mean()
    return loss
```

---

## CUR Decomposition (CUR分解)

**定义**: 矩阵的行列采样分解方法，选择原始矩阵的列和行构成近似。

**详细解释**: CUR分解选择矩阵的实际列和行（而非SVD的抽象基），使分解结果更易解释。列和行的选择基于统计杠杆分数（leverage score），重要列/行被选中的概率更大。相比SVD，CUR保持稀疏性和非负性，适用于推荐系统、文档分析和图像处理。

**数学公式**:
$$A \approx CUR$$

其中C是A的列子集，R是A的行子集，U是连接矩阵。

**相关概念**: SVD, Matrix Factorization, Low-Rank Approximation

**代表论文**: Mahoney, M. W., & Drineas, P. (2009). CUR matrix decompositions for improved data analysis. PNAS.

---

## Data Augmentation (数据增强)

**定义**: 通过对训练数据应用变换来增加数据多样性的技术，提升模型泛化能力。

**详细解释**: 数据增强是防止过拟合的有效手段。图像增强包括几何变换（翻转、旋转、裁剪）、颜色变换（亮度、对比度、色调）、高级变换（Mixup、CutMix、AutoAugment）。增强策略需要针对任务设计，如分类可大量增强，检测需同步变换标注。是现代深度学习训练的标准流程。

**数学公式**:
$$\tilde{x} = T(x, \theta), \quad \theta \sim p(\theta)$$

**相关概念**: Regularization, Generalization, Mixup, AutoAugment

**代表论文**: Zhang, H., et al. (2018). mixup: Beyond empirical risk minimization. ICLR.

**代码示例**:
```python
from torchvision import transforms

transform = transforms.Compose([
    transforms.RandomResizedCrop(224),
    transforms.RandomHorizontalFlip(),
    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

def mixup_data(x, y, alpha=0.2):
    """Mixup数据增强"""
    lam = np.random.beta(alpha, alpha)
    index = torch.randperm(x.size(0))
    mixed_x = lam * x + (1 - lam) * x[index]
    y_a, y_b = y, y[index]
    return mixed_x, y_a, y_b, lam
```

---

## Deep Learning (深度学习)

**定义**: 使用多层神经网络自动学习数据层次特征表示的机器学习方法。

**详细解释**: 深度学习通过堆叠多个非线性变换层，自动学习从低级到高级的特征表示。相比传统方法依赖手工特征，深度学习端到端学习特征和分类器。关键技术包括反向传播、GPU加速、批量归一化、残差连接等。在图像分类、目标检测、语音识别等领域取得突破性进展。

**数学公式**:
$$f(x; \theta) = f_L(f_{L-1}(...f_1(x)...))$$

**相关概念**: Neural Network, CNN, RNN, Transformer, Backpropagation

**代表论文**: LeCun, Y., Bengio, Y., & Hinton, G. (2015). Deep learning. Nature.

---

## DeepLab (深度标签)

**定义**: Google提出的语义分割模型系列，使用空洞卷积扩大感受野。

**详细解释**: DeepLab系列是语义分割的里程碑。DeepLabv1引入空洞卷积保持分辨率，DeepLabv2加入ASPP（空洞空间金字塔池化）捕获多尺度信息，DeepLabv3改进ASPP并加入图像级特征，DeepLabv3+使用编码器-解码器结构恢复细节。空洞卷积在不增加参数的情况下扩大感受野。

**数学公式**:
空洞卷积: $$(f *_r g)(x) = \sum_k f[k] \cdot g[x + r \cdot k]$$

其中r是空洞率。

**相关概念**: Semantic Segmentation, Atrous Convolution, ASPP, Encoder-Decoder

**代表论文**: Chen, L. C., et al. (2018). Encoder-decoder with atrous separable convolution. ECCV.

**代码示例**:
```python
class ASPP(nn.Module):
    def __init__(self, in_channels, out_channels, rates=[6, 12, 18]):
        super().__init__()
        self.conv1 = nn.Conv2d(in_channels, out_channels, 1)
        self.aspp_blocks = nn.ModuleList([
            nn.Conv2d(in_channels, out_channels, 3, padding=r, dilation=r)
            for r in rates
        ])
        self.global_pool = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Conv2d(in_channels, out_channels, 1)
        )
    
    def forward(self, x):
        size = x.shape[2:]
        feats = [self.conv1(x)]
        for block in self.aspp_blocks:
            feats.append(block(x))
        feats.append(F.interpolate(self.global_pool(x), size=size, mode='bilinear'))
        return torch.cat(feats, dim=1)
```

---

## Diffusion Model (扩散模型)

**定义**: 基于随机微分方程的生成模型，通过逐步去噪学习数据分布。

**详细解释**: 扩散模型包括前向扩散（逐步加噪）和反向去噪（学习去噪网络）。训练时预测添加的噪声，推理时从随机噪声逐步去噪生成图像。相比GAN训练更稳定，生成质量更高。DDPM、DDIM、Stable Diffusion是该领域的代表工作。扩散模型在图像生成、修复、编辑等任务表现优异。

**数学公式**:
前向: $q(x_t|x_{t-1}) = \mathcal{N}(x_t; \sqrt{1-\beta_t}x_{t-1}, \beta_t I)$

反向: $p_\theta(x_{t-1}|x_t) = \mathcal{N}(x_{t-1}; \mu_\theta(x_t, t), \sigma_t^2 I)$

**相关概念**: Score Matching, Denoising, Stable Diffusion, DDPM

**代表论文**: Ho, J., Jain, A., & Abbeel, P. (2020). Denoising diffusion probabilistic models. NeurIPS.

**代码示例**:
```python
class DiffusionModel(nn.Module):
    def __init__(self, model, timesteps=1000, beta_start=1e-4, beta_end=0.02):
        super().__init__()
        self.model = model
        self.timesteps = timesteps
        self.betas = torch.linspace(beta_start, beta_end, timesteps)
        self.alphas = 1 - self.betas
        self.alphas_cumprod = torch.cumprod(self.alphas, dim=0)
    
    def forward_diffusion(self, x0, t):
        """前向扩散：添加噪声"""
        noise = torch.randn_like(x0)
        alpha_t = self.alphas_cumprod[t]
        xt = torch.sqrt(alpha_t) * x0 + torch.sqrt(1 - alpha_t) * noise
        return xt, noise
    
    def reverse_diffusion(self, xt, t):
        """反向去噪"""
        predicted_noise = self.model(xt, t)
        return predicted_noise
```

---

## Domain Adaptation (域适应)

**定义**: 将源域学习到的知识迁移到目标域的技术，解决分布偏移问题。

**详细解释**: 域适应解决训练和测试数据分布不同的问题。方法包括：基于差异的方法（MMD、CORAL）最小化域间距离，基于对抗的方法（DANN）学习域不变特征，基于重构的方法使用自编码器。根据目标域是否有标签，分为有监督、半监督和无监督域适应。

**数学公式**:
$$\mathcal{L} = \mathcal{L}_{cls}(x_s, y_s) + \lambda \mathcal{L}_{adv}(x_s, x_t)$$

**相关概念**: Transfer Learning, Domain Generalization, MMD, DANN

**代表论文**: Ganin, Y., & Lempitsky, V. (2015). Unsupervised domain adaptation by backpropagation. ICML.

**代码示例**:
```python
class DomainAdversarialNetwork(nn.Module):
    def __init__(self, feature_extractor, classifier, domain_classifier):
        super().__init__()
        self.feature = feature_extractor
        self.classifier = classifier
        self.domain = domain_classifier
    
    def forward(self, x, alpha=1.0):
        features = self.feature(x)
        
        # 分类任务
        class_output = self.classifier(features)
        
        # 域分类（带梯度反转）
        reverse_features = GradientReversalFunction.apply(features, alpha)
        domain_output = self.domain(reverse_features)
        
        return class_output, domain_output
```

---

## Dropout (丢弃)

**定义**: 训练时随机丢弃神经元以防止过拟合的正则化技术。

**详细解释**: Dropout在前向传播时以概率p随机将神经元输出置零，训练多个子网络的集成。推理时使用全部神经元但输出乘以(1-p)以保持期望一致。Dropout有效防止神经元共适应，提供模型正则化。变体包括DropConnect、Spatial Dropout、DropBlock等。是深度学习训练的标准技术。

**数学公式**:
训练: $\tilde{h} = r \odot h$, 其中 $r_i \sim \text{Bernoulli}(p)$

推理: $\hat{h} = (1-p) \cdot h$

**相关概念**: Regularization, Batch Normalization, Ensemble Learning

**代表论文**: Srivastava, N., et al. (2014). Dropout: A simple way to prevent neural networks from overfitting. JMLR.

**代码示例**:
```python
class Dropout(nn.Module):
    def __init__(self, p=0.5):
        super().__init__()
        self.p = p
    
    def forward(self, x):
        if self.training:
            mask = torch.bernoulli(torch.ones_like(x) * (1 - self.p))
            return x * mask / (1 - self.p)
        return x
```

---

## Edge Detection (边缘检测)

**定义**: 识别图像中亮度、颜色或纹理发生显著变化的位置的技术。

**详细解释**: 边缘是图像的基本特征，反映了物体边界和场景结构。传统方法包括一阶导数算子（Sobel、Prewitt）、二阶导数算子（Laplacian）、最优算子（Canny）。深度学习方法通过学习边缘特征提高检测质量。边缘检测是图像分割、目标检测等任务的基础步骤。

**数学公式**:
Sobel算子: $$G_x = \begin{bmatrix} -1 & 0 & 1 \\ -2 & 0 & 2 \\ -1 & 0 & 1 \end{bmatrix}, G_y = \begin{bmatrix} -1 & -2 & -1 \\ 0 & 0 & 0 \\ 1 & 2 & 1 \end{bmatrix}$$

**相关概念**: Canny Edge Detector, Sobel Operator, Image Gradient

**代表论文**: Canny, J. (1986). A computational approach to edge detection. PAMI.

**代码示例**:
```python
def sobel_edge_detection(image):
    """Sobel边缘检测"""
    sobel_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])
    sobel_y = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])
    
    gx = convolve2d(image, sobel_x, mode='same')
    gy = convolve2d(image, sobel_y, mode='same')
    
    magnitude = np.sqrt(gx**2 + gy**2)
    direction = np.arctan2(gy, gx)
    
    return magnitude, direction
```

---

## ELM (极端学习机)

**定义**: 一种单隐含层前馈神经网络，隐含层参数随机初始化且固定，只需训练输出权重。

**详细解释**: ELM随机初始化输入权重和偏置，隐含层参数训练时固定不变，仅通过最小二乘或伪逆求解输出权重。训练速度比传统神经网络快几个数量级，但泛化性能可能不如深度网络。ELM的变体包括核ELM、在线序贯ELM等，在实时应用中有一定价值。

**数学公式**:
$$\beta = H^\dagger T$$

其中 $H$ 是隐含层输出矩阵，$T$ 是目标矩阵，$H^\dagger$ 是Moore-Penrose伪逆。

**相关概念**: Random Projection, Single-Layer Network, Fast Training

**代表论文**: Huang, G. B., Zhu, Q. Y., & Siew, C. K. (2006). Extreme learning machine: Theory and applications. Neurocomputing.

---

## EM Algorithm (EM算法)

**定义**: 期望最大化算法，用于含有隐变量的概率模型参数估计的迭代方法。

**详细解释**: EM算法交替执行E步（计算隐变量的后验期望）和M步（最大化期望对数似然）。每次迭代保证似然不减，最终收敛到局部最优。广泛应用于高斯混合模型、隐马尔可夫模型、因子分析等。缺点是收敛速度慢且可能陷入局部最优。

**数学公式**:
E步: $Q(\theta|\theta^{(t)}) = E_{Z|X,\theta^{(t)}}[\log P(X,Z|\theta)]$

M步: $\theta^{(t+1)} = \arg\max_\theta Q(\theta|\theta^{(t)})$

**相关概念**: Gaussian Mixture Model, Hidden Markov Model, Latent Variable Model

**代表论文**: Dempster, A. P., Laird, N. M., & Rubin, D. B. (1977). Maximum likelihood from incomplete data. J. Royal Statistical Society.

**代码示例**:
```python
def em_gmm(X, K, max_iter=100):
    """EM算法求解高斯混合模型"""
    N, D = X.shape
    
    # 初始化
    pi = np.ones(K) / K
    mu = X[np.random.choice(N, K)]
    sigma = np.array([np.eye(D) for _ in range(K)])
    
    for _ in range(max_iter):
        # E步：计算后验概率
        gamma = np.zeros((N, K))
        for k in range(K):
            gamma[:, k] = pi[k] * multivariate_normal.pdf(X, mu[k], sigma[k])
        gamma /= gamma.sum(axis=1, keepdims=True)
        
        # M步：更新参数
        Nk = gamma.sum(axis=0)
        pi = Nk / N
        mu = gamma.T @ X / Nk[:, None]
        for k in range(K):
            diff = X - mu[k]
            sigma[k] = (gamma[:, k:k+1] * diff).T @ diff / Nk[k]
    
    return pi, mu, sigma
```

---

## Energy-Based Model (基于能量的模型)

**定义**: 通过能量函数定义数据概率分布的生成模型，低能量对应高概率。

**详细解释**: 能量模型定义能量函数E(x)，概率分布为$p(x) = e^{-E(x)}/Z$，其中Z是配分函数。训练目标是使真实数据能量低、假数据能量高。由于配分函数难计算，常用对比散度、分数匹配等方法训练。能量模型灵活但训练困难，近年来通过分数匹配和扩散模型复兴。

**数学公式**:
$$p_\theta(x) = \frac{e^{-E_\theta(x)}}{Z(\theta)}, \quad Z(\theta) = \int e^{-E_\theta(x)} dx$$

**相关概念**: Boltzmann Machine, Score Matching, Diffusion Model

**代表论文**: LeCun, Y., et al. (2006). A tutorial on energy-based learning. Predicting Structured Data.

---

## Ensemble Learning (集成学习)

**定义**: 结合多个学习器以获得比单一学习器更好性能的技术。

**详细解释**: 集成学习通过组合多个模型降低方差和偏差。主要方法包括：Bagging（随机森林）并行训练多个模型取平均，Boosting（AdaBoost、GBDT）串行训练并加权组合，Stacking用元模型组合基模型。深度学习中常用模型平均、知识蒸馏实现集成效果。集成是竞赛中提升性能的标准方法。

**数学公式**:
$$\hat{y} = \sum_{m=1}^M w_m h_m(x)$$

**相关概念**: Random Forest, Boosting, Bagging, Stacking

**代表论文**: Zhou, Z. H. (2012). Ensemble Methods: Foundations and Algorithms. CRC Press.

**代码示例**:
```python
class EnsembleClassifier:
    def __init__(self, models, weights=None):
        self.models = models
        self.weights = weights or [1/len(models)] * len(models)
    
    def predict(self, x):
        predictions = [model.predict(x) for model in self.models]
        weighted_pred = np.average(predictions, axis=0, weights=self.weights)
        return weighted_pred
```
