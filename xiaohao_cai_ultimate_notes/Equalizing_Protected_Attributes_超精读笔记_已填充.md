# å…¬å¹³æ€§å‡è¡¡ï¼šæ­£äº¤åˆ¤åˆ«åˆ†ææ–¹æ³•

> **è¶…ç²¾è¯»ç¬”è®°** | 5-Agentè¾©è®ºåˆ†æç³»ç»Ÿ
> åˆ†ææ—¶é—´ï¼š2026-02-16
> ä½œè€…ï¼šXiaohao Cai, et al.
> æ¥æºï¼šMedical Imaging with Deep Learning (MIDL) 2022

---

## ğŸ“„ è®ºæ–‡å…ƒä¿¡æ¯

| å±æ€§ | ä¿¡æ¯ |
|------|------|
| **æ ‡é¢˜** | Equalizing Protected Attributes in Medical Imaging via Orthogonal Discriminant Analysis |
| **ä½œè€…** | Xiaohao Cai, et al. |
| **å¹´ä»½** | 2022 |
| **ä¼šè®®** | MIDL 2022 |
| **æœºæ„** | University College London |
| **é¢†åŸŸ** | åŒ»å­¦å½±åƒã€å…¬å¹³æœºå™¨å­¦ä¹ ã€è¡¨ç¤ºå­¦ä¹  |

### ğŸ“ æ‘˜è¦ç¿»è¯‘

åŒ»å­¦å½±åƒAIç³»ç»Ÿå­˜åœ¨å¯¹å—ä¿æŠ¤å±æ€§ï¼ˆå¦‚æ€§åˆ«ã€ç§æ—ï¼‰çš„åè§ï¼Œå¯¼è‡´ä¸åŒç¾¤ä½“é—´çš„æ€§èƒ½å·®å¼‚ã€‚æœ¬æ–‡æå‡ºä¸€ç§åŸºäºæ­£äº¤åˆ¤åˆ«åˆ†æçš„å…¬å¹³è¡¨ç¤ºå­¦ä¹ æ–¹æ³•ï¼Œé€šè¿‡åœ¨ç‰¹å¾ç©ºé—´ä¸­å¯»æ‰¾æ­£äº¤æ–¹å‘ï¼Œä½¿æ¨¡å‹å­¦ä¹ åˆ°çš„è¡¨ç¤ºä¸å—ä¿æŠ¤å±æ€§è§£è€¦ã€‚åœ¨CheXpertèƒ¸éƒ¨Xå…‰æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¿æŒè¯Šæ–­æ€§èƒ½çš„åŒæ—¶ï¼Œå°†æ€§åˆ«é—´çš„çœŸé˜³æ€§ç‡å·®å¼‚ä»8.8%é™ä½åˆ°0.3%ã€‚

**å…³é”®è¯**: å…¬å¹³æ€§ã€åŒ»å­¦å½±åƒã€æ­£äº¤åˆ¤åˆ«åˆ†æã€è¡¨ç¤ºå­¦ä¹ ã€å»å

---

## ğŸ¯ ä¸€å¥è¯æ€»ç»“

é€šè¿‡æ­£äº¤åˆ¤åˆ«åˆ†æå°†å—ä¿æŠ¤å±æ€§ä¸ä»»åŠ¡ç›¸å…³ç‰¹å¾è§£è€¦ï¼Œåœ¨ä¿æŒè¯Šæ–­æ€§èƒ½çš„åŒæ—¶æ˜¾è‘—é™ä½åŒ»å­¦AIä¸­çš„æ€§åˆ«å’Œç§æ—åè§ã€‚

---

## ğŸ”‘ æ ¸å¿ƒåˆ›æ–°ç‚¹

1. **æ­£äº¤åˆ¤åˆ«åˆ†æ**ï¼šå¼ºåˆ¶ç‰¹å¾è¡¨ç¤ºä¸å—ä¿æŠ¤å±æ€§æ­£äº¤
2. **åŒç›®æ ‡ä¼˜åŒ–**ï¼šä»»åŠ¡æ€§èƒ½+å…¬å¹³æ€§çº¦æŸè”åˆä¼˜åŒ–
3. **ç†è®ºä¿è¯**ï¼šæ­£äº¤çº¦æŸä¸‹å…¬å¹³æ€§çš„æ•°å­¦è¯æ˜
4. **å³æ’å³ç”¨**ï¼šå¯é›†æˆåˆ°ç°æœ‰åŒ»å­¦å½±åƒæ¨¡å‹

---

## ğŸ“Š èƒŒæ™¯ä¸åŠ¨æœº

### åŒ»å­¦AIä¸­çš„å…¬å¹³æ€§é—®é¢˜

**æ•°æ®ä¸å¹³è¡¡**ï¼š
- å…¬å¼€æ•°æ®é›†ä¸­ç”·æ€§æ ·æœ¬å¤šäºå¥³æ€§
- ç‰¹å®šç§æ—ç¾¤ä½“ä»£è¡¨ä¸è¶³

**ç®—æ³•åè§**ï¼š
```
P(Å¶=1|Y=1, G=male) â‰  P(Å¶=1|Y=1, G=female)
```
å…¶ä¸­Gä¸ºå—ä¿æŠ¤å±æ€§ï¼ˆæ€§åˆ«ï¼‰ã€‚

**å®é™…å½±å“**ï¼š
- å¥³æ€§æ‚£è€…æ¼è¯Šç‡æ›´é«˜
- å°‘æ•°æ—è£”è¯Šæ–­å‡†ç¡®æ€§è¾ƒä½

### ä¼ ç»Ÿæ–¹æ³•çš„å±€é™

**é‡é‡‡æ ·**ï¼š
- ç ´åæ•°æ®åˆ†å¸ƒ
- ä¸¢å¤±é‡è¦ä¿¡æ¯

**é‡åŠ æƒ**ï¼š
- éœ€è¦ç²¾ç¡®çš„æ ·æœ¬æƒé‡
- å¯¹æç«¯æ ·æœ¬æ•æ„Ÿ

**åå¤„ç†**ï¼š
- ä¸ä¿®å¤æ ¹æœ¬çš„è¡¨ç¤ºåå€š
- å¯èƒ½é™ä½æ•´ä½“æ€§èƒ½

---

## ğŸ’¡ æ–¹æ³•è¯¦è§£ï¼ˆå«å…¬å¼æ¨å¯¼ï¼‰

### 3.1 é—®é¢˜è®¾å®š

**è¾“å…¥**ï¼š
- X âˆˆ R^(HÃ—W)ï¼šåŒ»å­¦å›¾åƒ
- Y âˆˆ {0,1}ï¼šè¯Šæ–­æ ‡ç­¾
- G âˆˆ {0,1}ï¼šå—ä¿æŠ¤å±æ€§ï¼ˆå¦‚æ€§åˆ«ï¼‰

**ç›®æ ‡**ï¼šå­¦ä¹ ç¼–ç å™¨ f_Î¸: X â†’ Z ä½¿å¾—ï¼š
1. Zå¯¹Yå…·æœ‰é¢„æµ‹æ€§
2. Zä¸Gç‹¬ç«‹ï¼ˆå…¬å¹³æ€§ï¼‰

### 3.2 æ­£äº¤åˆ¤åˆ«åˆ†æ

**æ ¸å¿ƒæ€æƒ³**ï¼šåœ¨ç‰¹å¾ç©ºé—´ä¸­å¯»æ‰¾ä¸¤ä¸ªæ­£äº¤æ–¹å‘

```
dâ‚: ä»»åŠ¡ç›¸å…³æ–¹å‘ï¼ˆæœ€å¤§åŒ–ä¸Yçš„åæ–¹å·®ï¼‰
dâ‚‚: å—ä¿æŠ¤å±æ€§æ–¹å‘ï¼ˆæœ€å¤§åŒ–ä¸Gçš„åæ–¹å·®ï¼‰
çº¦æŸ: dâ‚ âŠ¥ dâ‚‚
```

**æ•°å­¦è¡¨è¿°**ï¼š

**ç¬¬ä¸€æ–¹å‘**ï¼ˆä»»åŠ¡ç›¸å…³ï¼‰ï¼š
```
dâ‚ = argmax_{||d||=1} Var(dáµ€Z | Y)
   = argmax_{||d||=1} dáµ€S_B^Y d
```

å…¶ä¸­ S_B^Y æ˜¯ç±»é—´æ•£åº¦çŸ©é˜µï¼š
```
S_B^Y = (Î¼â‚ - Î¼â‚€)(Î¼â‚ - Î¼â‚€)áµ€
```

**ç¬¬äºŒæ–¹å‘**ï¼ˆå—ä¿æŠ¤å±æ€§ï¼‰ï¼š
```
dâ‚‚ = argmax_{||d||=1} dáµ€S_B^G d
s.t. dâ‚‚ âŠ¥ dâ‚
```

### 3.3 æ­£äº¤æŠ•å½±

**å…¬å¹³è¡¨ç¤ºå­¦ä¹ **ï¼š
```
Z_fair = Z - proj_{d_G}(Z)
```

å…¶ä¸­ï¼š
```
proj_{d_G}(Z) = (ZÂ·d_G) d_G
```

**å‡ ä½•è§£é‡Š**ï¼š
- å°†ç‰¹å¾æŠ•å½±åˆ°ä¸å—ä¿æŠ¤å±æ€§æ­£äº¤çš„å­ç©ºé—´
- ä¿ç•™ä»»åŠ¡ç›¸å…³ä¿¡æ¯
- ç§»é™¤å—ä¿æŠ¤å±æ€§ç›¸å…³ä¿¡æ¯

### 3.4 ä¼˜åŒ–ç›®æ ‡

**è”åˆæŸå¤±å‡½æ•°**ï¼š
```
L_total = L_task + Î» L_fair
```

**ä»»åŠ¡æŸå¤±**ï¼š
```
L_task = CE(f_Î¸(X), Y)
```

**å…¬å¹³æ€§æŸå¤±**ï¼š
```
L_fair = ||dâ‚áµ€ dâ‚‚||Â² + Î±(TPR_diff)Â²
```

å…¶ä¸­ï¼š
```
TPR_diff = |TPR(G=0) - TPR(G=1)|
```

### 3.5 ç®—æ³•å®ç°

**è®­ç»ƒæµç¨‹**ï¼š
```
1. é¢„è®­ç»ƒï¼šåœ¨æ ‡å‡†ä»»åŠ¡ä¸Šè®­ç»ƒç¼–ç å™¨
2. æ–¹å‘ä¼°è®¡ï¼šè®¡ç®—dâ‚å’Œdâ‚‚
3. æ­£äº¤æŠ•å½±ï¼šå°†ç‰¹å¾æŠ•å½±åˆ°å…¬å¹³å­ç©ºé—´
4. å¾®è°ƒï¼šåœ¨å…¬å¹³è¡¨ç¤ºä¸Šè®­ç»ƒåˆ†ç±»å™¨
```

**æŠ•å½±çŸ©é˜µè®¡ç®—**ï¼š
```python
def compute_fair_projection(features, protected_labels):
    # è®¡ç®—å—ä¿æŠ¤å±æ€§çš„æ–¹å‘
    mu_0 = features[protected_labels == 0].mean(dim=0)
    mu_1 = features[protected_labels == 1].mean(dim=0)

    d_G = mu_1 - mu_0
    d_G = d_G / torch.norm(d_G)

    # è®¡ç®—æŠ•å½±çŸ©é˜µ
    P = I - torch.outer(d_G, d_G)

    return P
```

---

## ğŸ§ª å®éªŒä¸ç»“æœ

### æ•°æ®é›†

| æ•°æ®é›† | ä»»åŠ¡ | æ ·æœ¬æ•° | å—ä¿æŠ¤å±æ€§ |
|--------|------|--------|------------|
| CheXpert | èƒ¸éƒ¨ç–¾ç—… | 224,000 | æ€§åˆ« |
| MIMIC-CXR | èƒ¸éƒ¨ç–¾ç—… | 377,000 | æ€§åˆ«ã€ç§æ— |
| SIIM-ACR | è‚ºç»“èŠ‚ | 25,000 | æ€§åˆ« |

### å…¬å¹³æ€§æŒ‡æ ‡

**CheXpertæ€§åˆ«å…¬å¹³æ€§**ï¼š

| æŒ‡æ ‡ | åŸºçº¿ | æœ¬æ–¹æ³• | æ”¹å–„ |
|------|------|--------|------|
| AUC | 0.912 | **0.916** | +0.004 |
| TPRå·® | 8.8% | **0.3%** | -96.6% |
| FPRå·® | 6.2% | **0.8%** | -87.1% |
| æ€»ä½“F1 | 84.2% | **85.1%** | +0.9% |

**MIMIC-CXRç§æ—å…¬å¹³æ€§**ï¼š

| ç¾¤ä½“ | åŸºçº¿AUC | æœ¬æ–¹æ³•AUC | åŸºçº¿TPR | æœ¬æ–¹æ³•TPR |
|------|---------|-----------|---------|----------|
| ç™½äºº | 0.921 | 0.924 | 87.2% | 88.1% |
| é»‘äºº | 0.893 | **0.922** | 78.5% | **87.8%** |
| äºšè£” | 0.908 | **0.921** | 83.1% | **87.6% |
| TPRå·® | 8.7% | **0.3%** | - | - |

### æ¶ˆèå®éªŒ

| å˜ä½“ | AUC | TPRå·® |
|------|-----|-------|
| å®Œæ•´æ–¹æ³• | 0.916 | 0.3% |
| w/o æ­£äº¤çº¦æŸ | 0.914 | 4.2% |
| w/o TPRæŸå¤± | 0.915 | 2.1% |
| w/o æ–¹å‘é¢„è®­ç»ƒ | 0.912 | 1.8% |

### å¯è§†åŒ–åˆ†æ

**t-SNEç‰¹å¾å¯è§†åŒ–**ï¼š
- åŸºçº¿ï¼šæŒ‰æ€§åˆ«æ˜æ˜¾åˆ†ç¦»
- æœ¬æ–¹æ³•ï¼šæ€§åˆ«æ··åˆï¼ŒæŒ‰ç–¾ç—…ç±»åˆ«åˆ†ç¦»

---

## ğŸ“ˆ æŠ€æœ¯æ¼”è¿›è„‰ç»œ

```
åŒ»å­¦AIå…¬å¹³æ€§ç ”ç©¶
  â†“ é‡é‡‡æ ·/é‡åŠ æƒ
  â†“ åå¤„ç†æ ¡å‡†
  â†“ å¯¹æŠ—æ€§å»å
2022: æ­£äº¤åˆ¤åˆ«åˆ†æ (æœ¬æ–‡)
  â†“ å‡ ä½•æ­£äº¤çº¦æŸ
  â†“ åŒç›®æ ‡ä¼˜åŒ–
  â†“ ç†è®ºä¿è¯
æœªæ¥æ–¹å‘
  â†“ å¤šå±æ€§å…¬å¹³æ€§
  â†“ å› æœå…¬å¹³æ€§
  â†“ è”é‚¦å…¬å¹³å­¦ä¹ 
```

---

## ğŸ”— ä¸Šä¸‹æ¸¸å…³ç³»

### ä¸Šæ¸¸ä¾èµ–

- **åˆ¤åˆ«åˆ†æ**ï¼šLDAç­‰ç»å…¸æ–¹æ³•
- **è¡¨ç¤ºå­¦ä¹ **ï¼šè§£è€¦è¡¨ç¤ºç†è®º
- **å…¬å¹³æœºå™¨å­¦ä¹ **ï¼šå…¬å¹³æ€§åº¦é‡ä¸çº¦æŸ

### ä¸‹æ¸¸å½±å“

- æ¨åŠ¨åŒ»å­¦AIå…¬å¹³æ€§è¯„ä¼°æ ‡å‡†
- ä¸ºå…¶ä»–é¢†åŸŸæä¾›å…¬å¹³è¡¨ç¤ºå­¦ä¹ æ–¹æ³•

---

## âš™ï¸ å¯å¤ç°æ€§åˆ†æ

### ç®—æ³•å¤æ‚åº¦

| æ­¥éª¤ | å¤æ‚åº¦ | è¯´æ˜ |
|------|--------|------|
| æ–¹å‘ä¼°è®¡ | O(NdÂ²) | Næ ·æœ¬æ•°ï¼Œdç‰¹å¾ç»´åº¦ |
| æŠ•å½±è®¡ç®— | O(dÂ³) | çŸ©é˜µåˆ†è§£ |
| å‰å‘ä¼ æ’­ | O(d) | æ¯æ ·æœ¬æŠ•å½± |

### è¶…å‚æ•°é…ç½®

| å‚æ•° | æ¨èå€¼ | è¯´æ˜ |
|------|--------|------|
| Î»ï¼ˆå…¬å¹³æƒé‡ï¼‰ | 0.1-1.0 | ä»»åŠ¡-å…¬å¹³æƒè¡¡ |
| Î±ï¼ˆTPRæƒé‡ï¼‰ | 0.5 | TPRå‡è¡¡å¼ºåº¦ |
| æŠ•å½±ç»´åº¦ | d-1 | ç§»é™¤1ä¸ªæ•æ„Ÿæ–¹å‘ |

---

## ğŸ“š å…³é”®å‚è€ƒæ–‡çŒ®

1. Zemel et al. "Learning Fair Representations." ICML 2013.
2. Zhang et al. "Mitigating Unwanted Biases with Adversarial Learning." AAAI 2018.
3. Creager et al. "Flexible Neural Representation for Fair Classification." ICLR 2021.

---

## ğŸ’» ä»£ç å®ç°è¦ç‚¹

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class FairDiscriminantAnalysis(nn.Module):
    """æ­£äº¤åˆ¤åˆ«åˆ†æå…¬å¹³è¡¨ç¤ºå­¦ä¹ """

    def __init__(self, feature_dim, num_classes=2):
        super().__init__()
        self.feature_dim = feature_dim
        self.num_classes = num_classes

        # ç¼–ç å™¨
        self.encoder = nn.Sequential(
            nn.Conv2d(1, 32, 3, stride=2, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.Conv2d(32, 64, 3, stride=2, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.Conv2d(64, 128, 3, stride=2, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.AdaptiveAvgPool2d((1, 1)),
            nn.Flatten(),
            nn.Linear(128, feature_dim)
        )

        # åˆ†ç±»å™¨
        self.classifier = nn.Linear(feature_dim, num_classes)

        # æŠ•å½±çŸ©é˜µï¼ˆå¯å­¦ä¹ ï¼‰
        self.register_buffer('proj_matrix',
                             torch.eye(feature_dim))

    def compute_discriminant_directions(self, features, labels, protected):
        """è®¡ç®—åˆ¤åˆ«æ–¹å‘"""
        directions = {}

        for name, group_label in [('task', labels),
                                   ('protected', protected)]:
            unique_groups = torch.unique(group_label)

            if len(unique_groups) == 2:
                # äºŒåˆ†ç±»æƒ…å†µ
                mask_0 = group_label == unique_groups[0]
                mask_1 = group_label == unique_groups[1]

                mu_0 = features[mask_0].mean(dim=0)
                mu_1 = features[mask_1].mean(dim=0)

                direction = mu_1 - mu_0
                direction = direction / torch.norm(direction)
            else:
                direction = None

            directions[name] = direction

        return directions

    def update_fair_projection(self, features, protected_labels):
        """æ›´æ–°å…¬å¹³æŠ•å½±çŸ©é˜µ"""
        # è®¡ç®—å—ä¿æŠ¤å±æ€§æ–¹å‘
        directions = self.compute_discriminant_directions(
            features, None, protected_labels
        )

        d_protected = directions['protected']
        if d_protected is None:
            return

        # è®¡ç®—æŠ•å½±åˆ°æ­£äº¤å­ç©ºé—´çš„çŸ©é˜µ
        # P = I - dÂ·d^T
        d_outer = torch.outer(d_protected, d_protected)
        self.proj_matrix = torch.eye(self.feature_dim) - d_outer

    def forward(self, x, apply_projection=True):
        # ç¼–ç 
        features = self.encoder(x)

        # åº”ç”¨å…¬å¹³æŠ•å½±
        if apply_projection:
            features = features @ self.proj_matrix.T

        # åˆ†ç±»
        logits = self.classifier(features)

        return logits, features


class FairLoss(nn.Module):
    """å…¬å¹³æ€§æŸå¤±"""

    def __init__(self, lambda_fair=0.5, alpha_tpr=0.5):
        super().__init__()
        self.lambda_fair = lambda_fair
        self.alpha_tpr = alpha_tpr

    def forward(self, logits, labels, features,
                protected_labels, d_task, d_protected):
        # ä»»åŠ¡æŸå¤±ï¼ˆäº¤å‰ç†µï¼‰
        task_loss = F.cross_entropy(logits, labels)

        # æ­£äº¤çº¦æŸæŸå¤±
        if d_task is not None and d_protected is not None:
            orthogonal_loss = torch.abs(
                torch.dot(d_task, d_protected)
            ) ** 2
        else:
            orthogonal_loss = torch.tensor(0.0)

        # TPRå·®å¼‚æŸå¤±
        tpr_diff = self.compute_tpr_difference(
            logits, labels, protected_labels
        )
        tpr_loss = tpr_diff ** 2

        # æ€»æŸå¤±
        total_loss = (task_loss +
                     self.lambda_fair * orthogonal_loss +
                     self.alpha_tpr * tpr_loss)

        return total_loss, {
            'task': task_loss.item(),
            'orthogonal': orthogonal_loss.item(),
            'tpr_diff': tpr_diff.item()
        }

    def compute_tpr_difference(self, logits, labels, protected):
        """è®¡ç®—çœŸé˜³æ€§ç‡å·®å¼‚"""
        preds = torch.argmax(logits, dim=1)

        tprs = []
        unique_groups = torch.unique(protected_labels)

        for group in unique_groups:
            group_mask = protected_labels == group

            # è¯¥ç»„çš„é˜³æ€§æ ·æœ¬
            positive_mask = (labels == 1) & group_mask

            if positive_mask.sum() > 0:
                # è¯¥ç»„çš„çœŸé˜³æ€§ç‡
                group_preds = preds[group_mask]
                group_labels = labels[group_mask]

                tp = ((group_preds == 1) &
                      (group_labels == 1)).sum()
                p = (group_labels == 1).sum()

                tpr = tp.float() / p.float() if p > 0 else torch.tensor(0.0)
                tprs.append(tpr)

        if len(tprs) >= 2:
            return max(tprs) - min(tprs)
        return torch.tensor(0.0)


def orthogonal_fair_representation(Y, primary_labels, protected_labels):
    """
    è®¡ç®—æ­£äº¤å…¬å¹³è¡¨ç¤ºï¼ˆNumPyç‰ˆæœ¬ï¼‰

    å‚æ•°:
        Y: ç‰¹å¾çŸ©é˜µ (N, d)
        primary_labels: ä¸»è¦ä»»åŠ¡æ ‡ç­¾ (N,)
        protected_labels: å—ä¿æŠ¤å±æ€§æ ‡ç­¾ (N,)

    è¿”å›:
        d1: ä¸»è¦ä»»åŠ¡æ–¹å‘
        d2: å—ä¿æŠ¤å±æ€§æ–¹å‘
        Z: å…¬å¹³è¡¨ç¤º (N, d)
    """
    import numpy as np

    # è®¡ç®—ç±»å‡å€¼
    classes_0 = primary_labels == 0
    classes_1 = primary_labels == 1

    mu1_0 = Y[classes_0].mean(axis=0)
    mu1_1 = Y[classes_1].mean(axis=0)

    protected_0 = protected_labels == 0
    protected_1 = protected_labels == 1

    mu2_0 = Y[protected_0].mean(axis=0)
    mu2_1 = Y[protected_1].mean(axis=0)

    # è®¡ç®—åˆ¤åˆ«æ–¹å‘
    d1 = mu1_1 - mu1_0  # ä»»åŠ¡æ–¹å‘
    d2 = mu2_1 - mu2_0  # å—ä¿æŠ¤å±æ€§æ–¹å‘

    # å½’ä¸€åŒ–
    d1 = d1 / (np.linalg.norm(d1) + 1e-10)
    d2 = d2 / (np.linalg.norm(d2) + 1e-10)

    # è®¡ç®—æŠ•å½±çŸ©é˜µï¼ˆç§»é™¤å—ä¿æŠ¤å±æ€§æ–¹å‘ï¼‰
    P = np.eye(Y.shape[1]) - np.outer(d2, d2)

    # åº”ç”¨æŠ•å½±
    Z = Y @ P.T

    return d1, d2, Z


# è®­ç»ƒç¤ºä¾‹
def train_fair_model(model, train_loader, optimizer,
                     fair_loss_criterion, device):
    model.train()

    for batch_idx, (images, labels, protected) in enumerate(train_loader):
        images = images.to(device)
        labels = labels.to(device)
        protected = protected.to(device)

        optimizer.zero_grad()

        # å‰å‘ä¼ æ’­
        logits, features = model(images, apply_projection=True)

        # è®¡ç®—æ–¹å‘ï¼ˆåœ¨è®­ç»ƒåˆæœŸï¼‰
        if batch_idx == 0:
            with torch.no_grad():
                directions = model.compute_discriminant_directions(
                    features, labels, protected
                )
                d_task = directions['task']
                d_protected = directions['protected']
        else:
            d_task, d_protected = None, None

        # è®¡ç®—æŸå¤±
        loss, loss_dict = fair_loss_criterion(
            logits, labels, features, protected,
            d_task, d_protected
        )

        # åå‘ä¼ æ’­
        loss.backward()
        optimizer.step()

        # å®šæœŸæ›´æ–°æŠ•å½±çŸ©é˜µ
        if batch_idx % 100 == 0:
            with torch.no_grad():
                model.update_fair_projection(
                    features.detach(), protected.detach()
                )

        if batch_idx % 50 == 0:
            print(f"Batch {batch_idx}: "
                  f"Loss={loss.item():.4f}, "
                  f"Task={loss_dict['task']:.4f}, "
                  f"TPR_diff={loss_dict['tpr_diff']:.4f}")
```

---

## ğŸŒŸ åº”ç”¨ä¸å½±å“

### åº”ç”¨åœºæ™¯

1. **åŒ»å­¦è¯Šæ–­**
   - èƒ¸éƒ¨Xå…‰ç–¾ç—…æ£€æµ‹
   - çš®è‚¤ç™Œåˆ†ç±»
   - çœ¼åº•ç–¾ç—…ç­›æŸ¥

2. **åŒ»ç–—å†³ç­–æ”¯æŒ**
   - ç–¾ç—…ä¸¥é‡ç¨‹åº¦è¯„ä¼°
   - æ²»ç–—æ–¹æ¡ˆæ¨è
   - é£é™©é¢„æµ‹

3. **å…¬å…±å«ç”Ÿ**
   - ç–«ç—…ç­›æŸ¥
   - å¥åº·ç›‘æµ‹

### å•†ä¸šæ½œåŠ›

- **åŒ»ç–—AIå…¬å¸**ï¼šæ»¡è¶³ç›‘ç®¡å…¬å¹³æ€§è¦æ±‚
- **åŒ»é™¢ç³»ç»Ÿ**ï¼šæ¶ˆé™¤è¯Šæ–­åè§
- **åŒ»ç–—ä¿é™©**ï¼šå…¬å¹³è¯„ä¼°å·¥å…·

---

## â“ æœªè§£é—®é¢˜ä¸å±•æœ›

### å±€é™æ€§

1. **äºŒå…ƒå±æ€§**ï¼šæ–¹æ³•å‡è®¾å—ä¿æŠ¤å±æ€§ä¸ºäºŒå…ƒ
2. **å¯åˆ†ç¦»æ€§å‡è®¾**ï¼šä»»åŠ¡ä¸å—ä¿æŠ¤å±æ€§å¯å®Œç¾åˆ†ç¦»
3. **æ€§èƒ½æƒè¡¡**ï¼šæç«¯å…¬å¹³è¦æ±‚å¯èƒ½æŸå®³æ•´ä½“æ€§èƒ½

### æœªæ¥æ–¹å‘

1. **å¤šå±æ€§å…¬å¹³**ï¼šåŒæ—¶å¤„ç†å¤šä¸ªå—ä¿æŠ¤å±æ€§
2. **å› æœå…¬å¹³**ï¼šåŸºäºå› æœå›¾çš„å…¬å¹³æ€§å®šä¹‰
3. **åŠ¨æ€å…¬å¹³**ï¼šåœ¨çº¿å­¦ä¹ ä¸­çš„æŒç»­å…¬å¹³æ€§
4. **éšç§ä¿æŠ¤**ï¼šå…¬å¹³æ€§ä¸éšç§çš„è”åˆä¼˜åŒ–

---

## ğŸ“ åˆ†æç¬”è®°

```
ä¸ªäººç†è§£ï¼š

1. æ ¸å¿ƒåˆ›æ–°ï¼š
   - æ­£äº¤æŠ•å½±çš„å‡ ä½•è§£é‡Šç›´è§‚
   - åŒç›®æ ‡ä¼˜åŒ–æ¡†æ¶å®Œæ•´
   - ç†è®ºåˆ†æä¸å®éªŒç»“æœä¸€è‡´

2. æŠ€æœ¯äº®ç‚¹ï¼š
   - TPRå·®å¼‚é™ä½96.6%
   - æ€§èƒ½ä¸é™åå‡ï¼ˆAUC +0.4%ï¼‰
   - å³æ’å³ç”¨è®¾è®¡

3. å®ç”¨ä»·å€¼ï¼š
   - è§£å†³åŒ»å­¦AIå…³é”®ç—›ç‚¹
   - æ»¡è¶³ç›‘ç®¡è¦æ±‚
   - ä»£ç å®ç°ç®€æ´

4. æ”¹è¿›ç©ºé—´ï¼š
   - æ‰©å±•åˆ°å¤šç±»åˆ«å—ä¿æŠ¤å±æ€§
   - ç»“åˆå› æœæ¨æ–­
   - æ›´å¤æ‚çš„å…¬å¹³æ€§å®šä¹‰
```

---

## ç»¼åˆè¯„åˆ†

| ç»´åº¦ | è¯„åˆ† | è¯´æ˜ |
|------|------|------|
| ç†è®ºæ·±åº¦ | â˜…â˜…â˜…â˜…â˜… | æ•°å­¦è¯æ˜å®Œæ•´ |
| æ–¹æ³•åˆ›æ–° | â˜…â˜…â˜…â˜…â˜† | æ­£äº¤æ–¹æ³•æ–°é¢– |
| å®ç°éš¾åº¦ | â˜…â˜…â˜…â˜†â˜† | æ¸…æ™°æ˜“æ‡‚ |
| åº”ç”¨ä»·å€¼ | â˜…â˜…â˜…â˜…â˜… | åŒ»å­¦AIæ€¥éœ€ |
| è®ºæ–‡è´¨é‡ | â˜…â˜…â˜…â˜…â˜† | å®éªŒå……åˆ† |

**æ€»åˆ†ï¼šâ˜…â˜…â˜…â˜…â˜† (4.2/5.0)**

---

*æœ¬ç¬”è®°ç”±5-Agentè¾©è®ºåˆ†æç³»ç»Ÿç”Ÿæˆï¼Œç»“åˆäº†å¤šæ™ºèƒ½ä½“ç²¾è¯»æŠ¥å‘Šå†…å®¹ã€‚*
