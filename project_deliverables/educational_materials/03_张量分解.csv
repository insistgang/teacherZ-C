张量分解,张量分解,标签
什么是张量?,"多维数组<br>0阶: 标量<br>1阶: 向量<br>2阶: 矩阵<br>3阶+: 张量",张量分解::概念
张量的阶(order)和模态(mode)是什么?,"阶: 维度数量 (N-way)<br>模态: 第n个维度<br>例: 3阶张量有3个模态<br>视频: (高×宽×时间)",张量分解::概念
CP分解是什么?,"CANDECOMP/PARAFAC<br>T ≈ Σᵣ aᵣ ∘ bᵣ ∘ cᵣ<br>和秩-1张量<br>唯一性条件宽松",张量分解::方法
Tucker分解是什么?,"T ≈ G ×₁ A ×₂ B ×₃ C<br>G: 核心张量<br>A,B,C: 因子矩阵<br>高阶SVD",张量分解::方法
CP与Tucker的区别是什么?,"CP: 对角核心，秩-R<br>Tucker: 一般核心，(R₁,R₂,R₃)<br>CP更紧凑<br>Tucker更灵活",张量分解::对比
什么是张量秩?,"CP秩: 最小R使T可分解<br>秩计算是NP-hard<br>可能无闭式解<br>与矩阵秩不同",张量分解::概念
什么是n-模乘积?,"张量与矩阵在第n模态相乘<br>Y = T ×ₙ M<br>改变第n维度大小<br>Tucker分解核心操作",张量分解::公式
张量的矩阵化是什么?,"Matricization/Unfolding<br>将张量展开为矩阵<br>沿某模态排列<br>T(n): 第n模态展开",张量分解::概念
什么是Khatri-Rao积?,"列式Kronecker积<br>A ⊙ B = [a₁⊗b₁, a₂⊗b₂, ...]<br>CP分解的关键运算<br>用于展开公式",张量分解::公式
HOSVD是什么?,"Higher-Order SVD<br>每个模态做SVD<br>核心张量压缩<br>Tucker的特殊形式",张量分解::方法
HOSVD的计算复杂度是多少?,"O(I₁³ + I₂³ + ... + I_N³)<br>各模态SVD的代价<br>随维度立方增长<br>需要截断加速",张量分解::概念
ALS算法是什么?,"Alternating Least Squares<br>固定其他因子，优化一个<br>迭代收敛<br>CP分解标准方法",张量分解::方法
ALS的收敛性如何?,"目标函数单调下降<br>可能收敛到局部最优<br>依赖初始化<br>多随机重启",张量分解::概念
什么是张量补全?,"从部分观测恢复完整张量<br>利用低秩结构<br>矩阵补全的推广<br>推荐系统应用",张量分解::应用
张量补全的目标函数是什么?,"min rank(T) s.t. T_Ω = M_Ω<br>Ω: 观测索引集<br>rank非凸，用核范式松弛<br>优化困难",张量分解::公式
张量核范数是什么?,"张量SVD的核范数<br>多个矩阵核范式组合<br>凸松弛<br>不同定义版本",张量分解::概念
什么是TT分解?,"Tensor Train分解<br>T(i₁,...,i_N) = G₁(i₁)G₂(i₂)...G_N(i_N)<br>线性复杂度<br>避免维度灾难",张量分解::方法
TT秩是什么?,"TT分解的连接矩阵秩<br>r₀, r₁, ..., r_N<br>r₀=r_N=1<br>控制复杂度",张量分解::概念
什么是TR分解?,"Tensor Ring分解<br>TT的环形版本<br>首尾相连<br>更强表达能力",张量分解::方法
什么是HT分解?,"Hierarchical Tucker<br>树形层次结构<br>递归二分<br>适合张量网络",张量分解::方法
张量网络是什么?,"张量分解的图形表示<br>节点: 张量<br>边: 缩并指标<br>量子物理起源",张量分解::概念
张量列车与矩阵链乘法的联系?,"TT形如矩阵链<br>G_k是r_k×I_k×r_k+1<br>乘积得到元素<br>高效存储",张量分解::概念
什么是张量回归?,"Y = <T, X> + ε<br>高维特征映射<br>低秩约束<br>减少参数",张量分解::应用
张量PCA是什么?,"主成分分析的张量扩展<br>提取主要变化方向<br>降维<br>高阶相关性",张量分解::方法
张量在推荐系统中的应用?,"用户×物品×上下文<br>捕获三方交互<br>个性化推荐<br>时间动态",张量分解::应用
张量去噪的原理是什么?,"低秩假设<br>噪声破坏低秩结构<br>分解过滤噪声<br>重建干净张量",张量分解::应用
什么是张量卷积?,"高维卷积运算<br>张量核<br>时空特征提取<br>3D CNN基础",张量分解::应用
张量分解的并行算法?,"1. 分布式ALS<br>2. 随机梯度<br>3. 块坐标下降<br>4. ADMM",张量分解::方法
随机张量分解是什么?,"随机投影加速<br>近似SVD<br>可扩展性强<br>大规模数据",张量分解::方法
增量张量分解是什么?,"在线更新<br>流式数据<br>滑动窗口<br>时间序列",张量分解::方法
什么是非负张量分解?,"所有因子非负<br>NMF的张量扩展<br>可加性<br>部件学习",张量分解::方法
非负约束的优化方法?,"1. 乘法更新<br>2. 投影梯度<br>3. ADMM<br>4. 活跃集法",张量分解::方法
稀疏张量分解是什么?,"因子矩阵稀疏<br>L1正则化<br>可解释性强<br>高维数据",张量分解::方法
贝叶斯张量分解是什么?,"概率模型<br>自动确定秩<br>不确定性量化<br>GP先验",张量分解::方法
张量分解的初始化方法?,"1. 随机<br>2. SVD<br>3. HOSVD<br>4. 增量",张量分解::方法
如何选择张量秩?,"1. 交叉验证<br>2. 核一致性<br>3. AIC/BIC<br>4. 贝叶斯",张量分解::方法
什么是核心一致性?,"CORCONDIA<br>衡量CP拟合质量<br>高值(>80%)好<br>帮助选择R",张量分解::概念
张量分解的欠定问题是什么?,"多解情况<br>秩不唯一<br>退化<br>需要约束",张量分解::概念
旋转不确定性是什么?,"CP分解的排列和缩放自由度<br>A→AP, B→BP', C→CP''<br>PPP'=I<br>归一化处理",张量分解::概念
张量分解的唯一性条件是什么?,"k-rank条件<br>Kruskal定理<br>Σk_A ≥ 2R + (N-1)<br>比矩阵分解强",张量分解::概念
什么是Kruskal秩(k-rank)?,"k_A: 最大k使任意k列线性无关<br>唯一性的关键<br>比列秩更强<br>CP分解理论工具",张量分解::概念
张量在图像修复中的应用?,"图像块×行×列<br>低秩先验<br>填充缺失像素<br>非局部相似性",张量分解::应用
视频可以用什么张量表示?,"高×宽×时间×通道<br>4阶张量<br>时空相关性<br>压缩和去噪",张量分解::应用
张量在神经网络的压缩应用?,"全连接层: 矩阵→张量分解<br>卷积层: 4D核分解<br>减少参数<br>TT层",张量分解::应用
什么是TT层?,"Tensor Train Layer<br>权重用TT格式<br>参数O(NR²) vs O(N²)<br>巨幅压缩",张量分解::应用
张量分解在MRI的应用?,"动态MRI: x×y×t<br>低秩+稀疏<br>加速采集<br>压缩感知",张量分解::应用
张量在EEG分析中的应用?,"通道×时间×频率×受试者<br>脑电模式提取<br>BCI分类<br>时频分析",张量分解::应用
张量分解的计算软件?,"1. TensorLab (MATLAB)<br>2. Tensorly (Python)<br>3. TT-Toolbox<br>4. scikit-tensor",张量分解::工具
Tensorly的主要功能?,"Python库<br>CP, Tucker, TT<br>GPU支持<br>后端灵活",张量分解::工具
什么是张量环分解?,"Tensor Ring (TR)<br>循环连接<br>比TT更灵活<br>更低秩",张量分解::方法
张量分解的GPU加速?,"1. cuTensor<br>2. cuBLAS集成<br>3. 大矩阵乘法<br>4. 批处理操作",张量分解::方法