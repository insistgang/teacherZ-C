正面,背面,标签
什么是全变分(Total Variation)?,"TV(u) = ∫|∇u|dx = ∫√(∂u/∂x)² + (∂u/∂y)² dx<br>- 度量图像的""总变化量""<br>- 约束图像分段光滑<br>- 边缘保持能力强<br>示例: ROF去噪使用TV作为正则项",变分方法::概念
ROF模型的能量泛函是什么?,"E(u) = ||u||_TV + (λ/2)||f-u||²₂<br>- 第1项: TV正则化 (去噪)<br>- 第2项: L²保真项 (保持相似)<br>- λ: 平衡参数",变分方法::方法
Chambolle对偶公式是什么?,"u = f - λ·div(p)<br>其中 p 满足: |∇(div(p) - f/λ)| ≤ 1<br>优势: 将非光滑问题转化为投影问题",变分方法::公式
TV正则化的主要优点是什么?,"- 保持边缘锐利<br>- 去除噪声的同时不模糊边界<br>- 适合分段常数图像<br>- 数学理论完善",变分方法::概念
什么是ROF模型?,"Rudin-Osher-Fatemi模型 (1992)<br>首个基于TV的图像去噪模型<br>能量: min_u TV(u) + λ||f-u||²₂<br>开创了变分图像处理领域",变分方法::概念
TV的各向同性定义是什么?,"TV_iso(u) = ∫√(∂u/∂x)² + (∂u/∂y)² dx<br>旋转不变<br>更符合物理直觉",变分方法::公式
TV的各向异性定义是什么?,"TV_aniso(u) = ∫(|∂u/∂x| + |∂u/∂y|) dx<br>计算更简单<br>沿坐标轴方向偏好",变分方法::公式
什么是BV空间?,"有界变分函数空间 (Bounded Variation)<br>BV(Ω) = {u: TV(u) < ∞}<br>TV正则化的自然函数空间<br>允许不连续(边缘)",变分方法::概念
ROF模型的Euler-Lagrange方程是什么?,"div(∇u/|∇u|) + λ(u-f) = 0<br>边界条件: ∂u/∂n = 0<br>非线性PDE<br>需特殊数值方法求解",变分方法::公式
什么是梯度下降法求解ROF?,"∂u/∂t = div(∇u/|∇u|) + λ(f-u)<br>时间演化PDE<br>稳态解即为ROF解<br>收敛较慢",变分方法::方法
Chambolle投影算法的核心思想是什么?,"将ROF问题转化为对偶问题<br>u = f - Π_Κ(f/λ)<br>Π_Κ: 到凸集K的投影<br>K = {div(p): |p| ≤ 1}",变分方法::方法
Split Bregman方法如何求解TV问题?,"1. 引入辅助变量 d = ∇u<br>2. Bregman迭代更新<br>3. 交替优化u和d<br>4. 子问题有闭式解",变分方法::方法
ADMM求解TV问题的优势是什么?,"- 分离非光滑项<br>- 并行计算友好<br>- 收敛性好<br>- 子问题简单",变分方法::方法
什么是广义TV (Generalized TV)?,"GTV(u) = ∫|∇u|^α dx<br>α < 1: 更强的稀疏性<br>α > 1: 更光滑<br>α = 1: 标准TV",变分方法::概念
TV-L1模型是什么?,"min_u TV(u) + λ||f-u||₁<br>L1保真项<br>对椒盐噪声鲁棒<br>保持对比度不变性",变分方法::方法
什么是TV的对偶表示?,"TV(u) = sup_{p∈K} <u, -div(p)><br>K = {p: |p|∞ ≤ 1}<br>将对偶变量引入优化<br>避免∇u在零点不可导",变分方法::公式
Huber-TV是什么?,"混合L2-L1范数<br>小梯度: L2 (光滑)<br>大梯度: L1 (TV)<br>避免阶梯效应<br>平滑处理平坦区域",变分方法::概念
什么是阶梯效应(Staircase Effect)?,"TV去噪的常见伪影<br>平滑区域出现假边缘<br>形成阶梯状伪轮廓<br>Huber-TV可缓解",变分方法::概念
如何缓解阶梯效应?,"1. 高阶TV (TGV)<br>2. Huber-TV<br>3. 非局部TV<br>4. 自适应TV权重",变分方法::方法
什么是TGV (Total Generalized Variation)?,"TGV²_α(u) = α₁∫|∇u - v|dx + α₂∫|∇v|dx<br>二阶广义全变分<br>同时惩罚一阶和二阶导数<br>更好地保持光滑区域",变分方法::概念
ROF模型的凸性有什么意义?,"- 全局最优解<br>- 不依赖初始化<br>算法收敛保证<br>理论分析完善",变分方法::概念
什么是TV的次微分?,"∂TV(u) = {-div(p): p = ∇u/|∇u|, |∇u|>0}<br>在∇u=0处是多值的<br>非光滑优化的核心概念<br>用于构造最优性条件",变分方法::概念
Split Bregman迭代公式是什么?,"u^k+1 = argmin ||d^k - ∇u - b^k||² + λ||f-u||²<br>d^k+1 = shrink(∇u^k+1 + b^k, 1/λ)<br>b^k+1 = b^k + ∇u^k+1 - d^k+1",变分方法::公式
Shrinkage函数是什么?,"shrink(x, τ) = sign(x)·max(|x|-τ, 0)<br>软阈值算子<br>L1近端算子<br>TV优化的核心操作",变分方法::公式
什么是近端梯度法?,"x^k+1 = prox_{τg}(x^k - τ∇f(x^k))<br>处理f+g的复合优化<br>f光滑，g非光滑<br>TV问题中g=TV",变分方法::方法
ROF模型的参数λ如何选择?,"- 人工调参<br>- 交叉验证<br>- L-curve方法<br>- 基于噪声统计<br>λ越大越接近原图",变分方法::方法
什么是Morozov偏差原理?,"选择λ使||u-f|| = δ<br>δ: 噪声水平<br>平衡拟合与正则化<br>客观的参数选择准则",变分方法::概念
TV去噪的计算复杂度是多少?,"- Chambolle: O(N) 每次迭代<br>- Split Bregman: O(N)<br>- 总迭代数取决于λ<br>- 实际: O(50-200)次迭代",变分方法::概念
什么是Preconditioning加速?,"对PDE使用预条件子<br>加快收敛速度<br>常用: FFT-based预条件<br>对角预条件",变分方法::方法
TV在图像修复中的应用?,"min_u TV(u) + λ||u-f||²₂<br>在已知区域约束<br>未知区域由TV填充<br>保持边缘连续性",变分方法::应用
什么是加权TV?,"TV_w(u) = ∫w(x)|∇u|dx<br>w(x): 空间自适应权重<br>边缘处权重小<br>平坦区域权重大",变分方法::概念
TV与稀疏性的关系是什么?,"TV = L1范数在梯度域<br>促进梯度稀疏<br>分段常数图像<br>与压缩感知理论相关",变分方法::概念
什么是非局部TV?,"NLTV(u) = ∫∫w(x,y)|u(x)-u(y)|dydx<br>利用图像自相似性<br>更好的纹理保持<br>计算量更大",变分方法::概念
ROF模型的解存在性如何保证?,"BV空间完备<br>能量泛函强制<br>下半连续<br>直接法证明存在性",变分方法::概念
什么是Gamma收敛?,"能量泛函序列的收敛概念<br>保证最小化子收敛<br>近似理论的工具<br>用于分析离散化",变分方法::概念
TV的有限差分离散化是什么?,"TV_h(u) = Σ√((u_i+1,j - u_i,j)² + (u_i,j+1 - u_i,j)²)<br>前向差分<br>O(h)精度<br>简单但可能产生网格偏差",变分方法::公式
TV的有限元离散化是什么?,"在三角网格上定义TV<br>使用分片线性函数<br>更好的几何适应性<br>适合复杂区域",变分方法::方法
什么是TV的凸松弛?,"将非凸问题松弛为凸问题<br>例: 二值分割→Chan-Vese<br>保证全局最优<br>凸优化的核心思想",变分方法::概念
Chan-Vese模型的TV形式是什么?,"min_u TV(u) + λ∫(u-c₁)²H(u) + (u-c₂)²(1-H(u))<br>H: Heaviside函数<br>两相分割<br>凸松弛后可全局优化",变分方法::公式
什么是Mumford-Shah泛函?,"E(u,K) = ∫_Ω\K |∇u|²dx + λ∫_Ω(u-f)²dx + μ|K|<br>K: 边缘集合<br>分割和去噪统一<br>数学上困难(非凸)",变分方法::概念
Ambrosio-Tortorelli逼近是什么?,"用椭圆逼近Mumford-Shah<br>引入相场变量v<br>|K| ≈ ε|∇v|² + (1/4ε)(1-v)²<br>Γ-收敛到MS泛函",变分方法::方法
什么是水平集方法?,"用隐函数φ表示边界<br>C = {x: φ(x) = 0}<br>演化PDE驱动φ<br>自动处理拓扑变化",变分方法::方法
TV在图像去模糊中的应用?,"min_u TV(u) + λ||Au-f||²₂<br>A: 模糊算子<br>TV约束稳定化逆问题<br>边缘保持去模糊",变分方法::应用
什么是Bregman迭代?,"u^k+1 = argmin D_E^p(u^k, u)<br>D_E: Bregman距离<br>改善正则化偏差<br>逐步恢复细节",变分方法::方法
线性化Bregman迭代公式是什么?,"u^k+1 = τ·shrink(f - Au^k + v^k, λ)<br>v^k+1 = v^k + f - Au^k - u^k+1/τ<br>简单高效<br>适合大规模问题",变分方法::公式
什么是Split Bregman?,"Bregman迭代的分裂形式<br>分离L1和L2项<br>每个子问题有闭式解<br>高效处理复合优化",变分方法::方法
TV在CT重建中的应用?,"min_u TV(u) s.t. Au = f<br>A: Radon变换<br>TV约束改善欠采样重建<br>压缩感知CT的基础",变分方法::应用
什么是ROI重建?,"感兴趣区域重建<br>只重建部分区域<br>减少数据需求<br>TV正则化使问题适定",变分方法::应用
TV的变分形式有什么优势?,"- 物理意义清晰<br>- 数学理论完善<br>- 数值方法丰富<br>- 可扩展性强",变分方法::概念
什么是Primal-Dual方法?,"同时优化原问题和对偶问题<br>(x^k+1, y^k+1) = PD(x^k, y^k)<br>收敛快<br>适合非光滑问题",变分方法::方法
Chambolle-Pock算法是什么?,"经典的Primal-Dual算法<br>x^k+1 = prox_f(x^k - τK*y^k)<br>y^k+1 = prox_g*(y^k + σKx̄^k+1)<br>O(1/k)收敛率",变分方法::方法
什么是强凸性加速?,"当目标函数强凸时<br>线性收敛率<br>Chambolle-Pock加速版<br>O(1/k²)→O(exp(-k))",变分方法::方法
TV在MRI重建中的应用?,"min_u TV(u) + λ||Fu-f||²₂<br>F: 傅里叶采样<br>加速MRI扫描<br>压缩感知MRI的核心",变分方法::应用
什么是多尺度TV?,"在不同尺度计算TV<br>金字塔结构<br>捕获不同尺度特征<br>改善全局结构",变分方法::概念
TV与L2正则化的区别是什么?,"TV: 边缘保持，分段常数<br>L2: 光滑，可能模糊边缘<br>TV非光滑<br>L2光滑可微",变分方法::对比
什么是Group TV?,"向量值图像的TV<br>TV(u) = ∫√(Σ|∇u_i|²)dx<br>通道间耦合<br>彩色图像处理",变分方法::概念
TV在视频处理中的应用?,"时空TV: TV(u) = ∫√(|∇_xu|² + |∇_tu|²)dxdt<br>同时处理空间和时间<br>视频去噪和去模糊",变分方法::应用
什么是Infimal Convolution TV?,"TV₁ □ TV₂ = inf_x {TV₁(u-x) + TV₂(x)}<br>组合不同TV<br>更灵活的正则化<br>处理多特征",变分方法::概念正面,背面,标签
SLaT三阶段分割方法是什么?,"1. Smoothing: ROF变分平滑<br>2. Lifting: RGB+Lab维度提升<br>3. Thresholding: K-means阈值<br>创新: 双色彩空间融合<br>发表: IEEE TIP 2015",图像分割::论文
ROF与Mumford-Shah的主要区别是什么?,"ROF: 去噪，凸优化，连续输出<br>Mumford-Shah: 分割，非凸，分段常数输出<br>ROF是预处理工具<br>MS是分割框架",图像分割::对比
什么是Chan-Vese模型?,"min E = μ|C| + ∫_inside(c₁-f)² + ∫_outside(c₂-f)²<br>基于区域的主动轮廓<br>不依赖边缘梯度<br>水平集实现",图像分割::方法
水平集方法的优缺点是什么?,"优点: 拓扑自动变化，数值稳定<br>缺点: 计算量大，需要重初始化<br>适合复杂形状<br>隐式边界表示",图像分割::对比
什么是Graph Cut分割?,"将分割转化为图论最小割问题<br>能量: E = ΣD_p + ΣV_pq<br>数据项+平滑项<br>多项式时间全局最优",图像分割::方法
Graph Cut与水平集的区别是什么?,"Graph Cut: 离散，全局最优，固定拓扑<br>水平集: 连续，局部最优，可变拓扑<br>Graph Cut需要网格图<br>水平集需要PDE求解器",图像分割::对比
什么是GrabCut算法?,"交互式前景提取<br>迭代Graph Cut<br>GMM颜色模型<br>用户标注矩形框",图像分割::方法
Normalized Cut是什么?,"Shi & Malik提出<br>Ncut = cut(A,B)/assoc(A,V) + cut(A,B)/assoc(B,V)<br>平衡割的大小<br>特征向量近似求解",图像分割::方法
什么是Mean Shift分割?,"基于核密度估计<br>迭代寻找模式<br>无需指定类别数<br>自动聚类",图像分割::方法
分水岭算法的原理是什么?,"将图像视为地形<br>水从低到高淹没<br>不同流域汇合处为分割<br>易过分割",图像分割::方法
如何缓解分水岭过分割?,"1. 标记控制<br>2. 预处理平滑<br>3. 区域合并<br>4. 多尺度方法",图像分割::方法
什么是Otsu阈值分割?,"最大化类间方差<br>σ²_b = ω₁ω₂(μ₁-μ₂)²<br>自动选择阈值<br>适合双峰直方图",图像分割::方法
自适应阈值与全局阈值的区别?,"全局: 整图一个阈值<br>自适应: 局部窗口计算阈值<br>自适应处理不均匀光照<br>计算量更大",图像分割::对比
什么是区域生长算法?,"从种子点开始<br>根据相似性扩展<br>迭代直到收敛<br>需要人工种子",图像分割::方法
区域分裂合并算法是什么?,"递归四叉树分裂<br>相似区域合并<br>无需种子点<br>可能产生块效应",图像分割::方法
SLIC超像素的原理是什么?,"Simple Linear Iterative Clustering<br>在5D空间聚类(labxy)<br>紧凑的超像素<br>实时处理",图像分割::方法
超像素的评估指标有哪些?,"1. 边界召回率 (Boundary Recall)<br>2. 欠分割错误率 (Under-segmentation Error)<br>3. 可达分割准确度 (ASA)<br>4. 紧凑度",图像分割::概念
什么是活动轮廓模型(Active Contour)?,"Snakes模型: 能量最小化曲线<br>E = E_int + E_ext + E_con<br>内部力(光滑)+外部力(边缘)<br>对初始化敏感",图像分割::方法
活动轮廓的梯度向量流(GVF)是什么?,"扩展捕获范围<br>扩散边缘梯度<br>进入凹区域<br>Xu & Prince提出",图像分割::方法
什么是Distance Regularized Level Set?,"DRLSE<br>避免重初始化<br>距离正则化项<br>稳定数值演化",图像分割::方法
什么是窄带水平集?,"只在零水平集附近计算<br>大幅减少计算量<br>需要定期重新初始化<br>工业标准方法",图像分割::方法
多相分割与两相分割的区别?,"两相: 前景/背景<br>多相: 多个区域<br>需要多个水平集函数<br>Vese-Chan模型",图像分割::对比
什么是凸松弛分割?,"将非凸分割问题松弛为凸问题<br>二值变量→[0,1]连续<br>全局最优或强近似<br>阈值化得到分割",图像分割::方法
凸松弛的阈值定理是什么?,"凸松弛解u*∈[0,1]<br>对任意μ∈(0,1)<br>Σ_u*≥μ是原问题的近似解<br>保证阈值化有效",图像分割::概念
什么是连续最大流?,"Continuous Max-Flow<br>P(流) ≤ C(割)<br>强对偶成立<br>与Graph Cut等价",图像分割::方法
Yuan等人的连续最大流算法是什么?,"对偶形式: min_{u} ∫|∇u| + ΣD_p(u)<br>增广Lagrangian求解<br>GPU加速友好<br>实时分割",图像分割::论文
什么是交互式分割?,"用户提供种子/边界框<br>算法优化分割<br>结合先验和图像特征<br>半自动方法",图像分割::概念
DeepCut是什么?,"深度学习+Graph Cut<br>CNN提供外观模型<br>Graph Cut优化边界<br>端到端训练",图像分割::方法
什么是语义分割?,"每个像素分类<br>多类别问题<br>全卷积网络(FCN)<br>密集预测",图像分割::概念
实例分割与语义分割的区别?,"语义: 只分类像素<br>实例: 区分不同物体<br>例: 两个人分开标记<br>Mask R-CNN",图像分割::对比
什么是全景分割(Panoptic)?,"统一语义和实例分割<br>背景: 语义分割<br>前景物体: 实例分割<br>Panoptic FPN",图像分割::概念
U-Net的结构特点是什么?,"编码器-解码器结构<br>跳跃连接<br>适合医学图像<br>小数据集表现好",图像分割::方法
什么是特征金字塔网络(FPN)?,"多尺度特征融合<br>自顶向下+横向连接<br>金字塔特征图<br>适合多尺度物体",图像分割::方法
DeepLab的空洞卷积是什么?,"Atrous Convolution<br>扩大感受野<br>不增加参数<br>保持分辨率",图像分割::方法
DeepLab的ASPP是什么?,"Atrous Spatial Pyramid Pooling<br>多尺度空洞卷积并行<br>全局平均池化<br>捕获多尺度上下文",图像分割::方法
什么是条件随机场(CRF)后处理?,"全连接CRF<br>细化分割边界<br>成对势能考虑颜色和位置<br>均值场近似",图像分割::方法
注意力机制在分割中的作用?,"聚焦重要区域<br>通道注意力(SE)<br>空间注意力<br>自适应特征加权",图像分割::方法
什么是自注意力?,"Query-Key-Value机制<br>捕获长程依赖<br>计算复杂度O(n²)<br>Non-local模块",图像分割::方法
Transformer在分割中的应用?,"ViT+解码器<br>SETR, SegFormer等<br>全局上下文<br>大规模预训练",图像分割::方法
什么是边界损失?,"Boundary Loss<br>直接优化边界<br>基于距离变换<br>解决类别不平衡",图像分割::方法
Dice损失是什么?,"Dice = 2|X∩Y|/(|X|+|Y|)<br>区域重叠度量<br>对小目标友好<br>不均衡数据鲁棒",图像分割::方法
Tversky损失是什么?,"Tversky推广<br>控制FP和FN权重<br>T(α,β) = TP/(TP+αFP+βFN)<br>平衡精确率和召回率",图像分割::方法
什么是Focal Loss?,"FL = -α(1-p)^γ log(p)<br>降低易分样本权重<br>关注难分样本<br>γ=2典型值",图像分割::方法
弱监督分割的类型有哪些?,"1. 图像级标签<br>2. 边界框<br>3. 点标注<br>4. 涂鸦",图像分割::概念
CAM在弱监督分割中的作用?,"Class Activation Map<br>定位物体区域<br>生成伪标签<br>Grad-CAM改进",图像分割::方法
什么是亲和力传播?,"Affinity Net<br>学习像素相似性<br>扩展种子区域<br>弱监督训练",图像分割::方法
域适应分割的方法?,"1. 对抗训练<br>2. 特征对齐<br>3. 自训练<br>4. 风格迁移",图像分割::方法
3D医学图像分割的挑战是什么?,"- 数据量大<br>- 标注困难<br>- 类别不平衡<br>- 各向异性分辨率",图像分割::概念
V-Net的结构特点?,"3D U-Net变体<br>残差连接<br>Dice损失<br>前列腺分割",图像分割::方法
什么是nnU-Net?,"No New U-Net<br>自动配置网络<br>数据自适应预处理<br>医学分割SOTA",图像分割::方法
SLaT方法的Lifting阶段原理?,"RGB → RGB + Lab (6通道)<br>增加色彩区分度<br>Lab分离亮度和色度<br>改善颜色聚类",图像分割::论文
SLaT的Thresholding用什么方法?,"K-means聚类<br>在6D特征空间<br>自动确定类别数<br>Elbow方法选择K",图像分割::论文
SLaT的优势是什么?,"无需训练<br>快速执行<br>双色彩空间互补<br>变分平滑保边缘",图像分割::论文
SLaT的局限是什么?,"需要预设类别数<br>对复杂纹理效果有限<br>色彩空间固定<br>超参数敏感",图像分割::论文张量分解,张量分解,标签
什么是张量?,"多维数组<br>0阶: 标量<br>1阶: 向量<br>2阶: 矩阵<br>3阶+: 张量",张量分解::概念
张量的阶(order)和模态(mode)是什么?,"阶: 维度数量 (N-way)<br>模态: 第n个维度<br>例: 3阶张量有3个模态<br>视频: (高×宽×时间)",张量分解::概念
CP分解是什么?,"CANDECOMP/PARAFAC<br>T ≈ Σᵣ aᵣ ∘ bᵣ ∘ cᵣ<br>和秩-1张量<br>唯一性条件宽松",张量分解::方法
Tucker分解是什么?,"T ≈ G ×₁ A ×₂ B ×₃ C<br>G: 核心张量<br>A,B,C: 因子矩阵<br>高阶SVD",张量分解::方法
CP与Tucker的区别是什么?,"CP: 对角核心，秩-R<br>Tucker: 一般核心，(R₁,R₂,R₃)<br>CP更紧凑<br>Tucker更灵活",张量分解::对比
什么是张量秩?,"CP秩: 最小R使T可分解<br>秩计算是NP-hard<br>可能无闭式解<br>与矩阵秩不同",张量分解::概念
什么是n-模乘积?,"张量与矩阵在第n模态相乘<br>Y = T ×ₙ M<br>改变第n维度大小<br>Tucker分解核心操作",张量分解::公式
张量的矩阵化是什么?,"Matricization/Unfolding<br>将张量展开为矩阵<br>沿某模态排列<br>T(n): 第n模态展开",张量分解::概念
什么是Khatri-Rao积?,"列式Kronecker积<br>A ⊙ B = [a₁⊗b₁, a₂⊗b₂, ...]<br>CP分解的关键运算<br>用于展开公式",张量分解::公式
HOSVD是什么?,"Higher-Order SVD<br>每个模态做SVD<br>核心张量压缩<br>Tucker的特殊形式",张量分解::方法
HOSVD的计算复杂度是多少?,"O(I₁³ + I₂³ + ... + I_N³)<br>各模态SVD的代价<br>随维度立方增长<br>需要截断加速",张量分解::概念
ALS算法是什么?,"Alternating Least Squares<br>固定其他因子，优化一个<br>迭代收敛<br>CP分解标准方法",张量分解::方法
ALS的收敛性如何?,"目标函数单调下降<br>可能收敛到局部最优<br>依赖初始化<br>多随机重启",张量分解::概念
什么是张量补全?,"从部分观测恢复完整张量<br>利用低秩结构<br>矩阵补全的推广<br>推荐系统应用",张量分解::应用
张量补全的目标函数是什么?,"min rank(T) s.t. T_Ω = M_Ω<br>Ω: 观测索引集<br>rank非凸，用核范式松弛<br>优化困难",张量分解::公式
张量核范数是什么?,"张量SVD的核范数<br>多个矩阵核范式组合<br>凸松弛<br>不同定义版本",张量分解::概念
什么是TT分解?,"Tensor Train分解<br>T(i₁,...,i_N) = G₁(i₁)G₂(i₂)...G_N(i_N)<br>线性复杂度<br>避免维度灾难",张量分解::方法
TT秩是什么?,"TT分解的连接矩阵秩<br>r₀, r₁, ..., r_N<br>r₀=r_N=1<br>控制复杂度",张量分解::概念
什么是TR分解?,"Tensor Ring分解<br>TT的环形版本<br>首尾相连<br>更强表达能力",张量分解::方法
什么是HT分解?,"Hierarchical Tucker<br>树形层次结构<br>递归二分<br>适合张量网络",张量分解::方法
张量网络是什么?,"张量分解的图形表示<br>节点: 张量<br>边: 缩并指标<br>量子物理起源",张量分解::概念
张量列车与矩阵链乘法的联系?,"TT形如矩阵链<br>G_k是r_k×I_k×r_k+1<br>乘积得到元素<br>高效存储",张量分解::概念
什么是张量回归?,"Y = <T, X> + ε<br>高维特征映射<br>低秩约束<br>减少参数",张量分解::应用
张量PCA是什么?,"主成分分析的张量扩展<br>提取主要变化方向<br>降维<br>高阶相关性",张量分解::方法
张量在推荐系统中的应用?,"用户×物品×上下文<br>捕获三方交互<br>个性化推荐<br>时间动态",张量分解::应用
张量去噪的原理是什么?,"低秩假设<br>噪声破坏低秩结构<br>分解过滤噪声<br>重建干净张量",张量分解::应用
什么是张量卷积?,"高维卷积运算<br>张量核<br>时空特征提取<br>3D CNN基础",张量分解::应用
张量分解的并行算法?,"1. 分布式ALS<br>2. 随机梯度<br>3. 块坐标下降<br>4. ADMM",张量分解::方法
随机张量分解是什么?,"随机投影加速<br>近似SVD<br>可扩展性强<br>大规模数据",张量分解::方法
增量张量分解是什么?,"在线更新<br>流式数据<br>滑动窗口<br>时间序列",张量分解::方法
什么是非负张量分解?,"所有因子非负<br>NMF的张量扩展<br>可加性<br>部件学习",张量分解::方法
非负约束的优化方法?,"1. 乘法更新<br>2. 投影梯度<br>3. ADMM<br>4. 活跃集法",张量分解::方法
稀疏张量分解是什么?,"因子矩阵稀疏<br>L1正则化<br>可解释性强<br>高维数据",张量分解::方法
贝叶斯张量分解是什么?,"概率模型<br>自动确定秩<br>不确定性量化<br>GP先验",张量分解::方法
张量分解的初始化方法?,"1. 随机<br>2. SVD<br>3. HOSVD<br>4. 增量",张量分解::方法
如何选择张量秩?,"1. 交叉验证<br>2. 核一致性<br>3. AIC/BIC<br>4. 贝叶斯",张量分解::方法
什么是核心一致性?,"CORCONDIA<br>衡量CP拟合质量<br>高值(>80%)好<br>帮助选择R",张量分解::概念
张量分解的欠定问题是什么?,"多解情况<br>秩不唯一<br>退化<br>需要约束",张量分解::概念
旋转不确定性是什么?,"CP分解的排列和缩放自由度<br>A→AP, B→BP', C→CP''<br>PPP'=I<br>归一化处理",张量分解::概念
张量分解的唯一性条件是什么?,"k-rank条件<br>Kruskal定理<br>Σk_A ≥ 2R + (N-1)<br>比矩阵分解强",张量分解::概念
什么是Kruskal秩(k-rank)?,"k_A: 最大k使任意k列线性无关<br>唯一性的关键<br>比列秩更强<br>CP分解理论工具",张量分解::概念
张量在图像修复中的应用?,"图像块×行×列<br>低秩先验<br>填充缺失像素<br>非局部相似性",张量分解::应用
视频可以用什么张量表示?,"高×宽×时间×通道<br>4阶张量<br>时空相关性<br>压缩和去噪",张量分解::应用
张量在神经网络的压缩应用?,"全连接层: 矩阵→张量分解<br>卷积层: 4D核分解<br>减少参数<br>TT层",张量分解::应用
什么是TT层?,"Tensor Train Layer<br>权重用TT格式<br>参数O(NR²) vs O(N²)<br>巨幅压缩",张量分解::应用
张量分解在MRI的应用?,"动态MRI: x×y×t<br>低秩+稀疏<br>加速采集<br>压缩感知",张量分解::应用
张量在EEG分析中的应用?,"通道×时间×频率×受试者<br>脑电模式提取<br>BCI分类<br>时频分析",张量分解::应用
张量分解的计算软件?,"1. TensorLab (MATLAB)<br>2. Tensorly (Python)<br>3. TT-Toolbox<br>4. scikit-tensor",张量分解::工具
Tensorly的主要功能?,"Python库<br>CP, Tucker, TT<br>GPU支持<br>后端灵活",张量分解::工具
什么是张量环分解?,"Tensor Ring (TR)<br>循环连接<br>比TT更灵活<br>更低秩",张量分解::方法
张量分解的GPU加速?,"1. cuTensor<br>2. cuBLAS集成<br>3. 大矩阵乘法<br>4. 批处理操作",张量分解::方法正面,背面,标签
什么是3D重建?,"从2D图像恢复3D场景结构<br>相机位姿估计<br>点云生成<br>表面重建",3D视觉::概念
立体匹配的原理是什么?,"左右视图对应点<br>视差→深度<br>d = f·B/Z<br>基线距离影响精度",3D视觉::方法
立体匹配的基本步骤是什么?,"1. 极线校正<br>2. 代价计算<br>3. 代价聚合<br>4. 视差优化<br>5. 后处理",3D视觉::方法
什么是视差图?,"像素级对应关系<br>d = x_left - x_right<br>与深度反比<br>Z = f·B/d",3D视觉::概念
SGM算法是什么?,"Semi-Global Matching<br>多路径代价聚合<br>动态规划思想<br>实时立体匹配",3D视觉::方法
SGM的代价聚合公式是什么?,"S(p,d) = Σr Lr(p,d)<br>路径代价累加<br>P1, P2惩罚参数<br>平滑约束",3D视觉::公式
Census变换是什么?,"局部结构描述子<br>比较中心与邻域<br>汉明距离匹配<br>光照不变",3D视觉::方法
什么是深度估计?,"单图预测深度<br>学习驱动<br>相对深度/绝对深度<br>MiDaS, DPT",3D视觉::概念
单目深度估计的挑战?,"- 尺度模糊<br>- 透明/反光<br>- 纹理缺失<br>- 遮挡推理",3D视觉::概念
SLAM是什么?,"Simultaneous Localization and Mapping<br>同时定位与建图<br>机器人自主导航<br>实时性要求",3D视觉::概念
视觉SLAM的主要模块?,"1. 前端: 特征跟踪<br>2. 后端: 优化<br>3. 回环检测<br>4. 建图",3D视觉::方法
ORB-SLAM的特点?,"ORB特征<br>三线程架构<br>BA优化<br>回环检测",3D视觉::方法
什么是Bundle Adjustment?,"联合优化相机位姿和3D点<br>最小化重投影误差<br>非线性最小二乘<br>稀疏矩阵利用",3D视觉::方法
BA的目标函数是什么?,"min Σ||p_i - π(T_j, X_k)||²<br>p: 图像点<br>π: 投影函数<br>T: 相机位姿<br>X: 3D点",3D视觉::公式
什么是关键帧?,"代表性帧<br>减少计算量<br>场景变化时插入<br>BA的优化对象",3D视觉::概念
回环检测的作用?,"识别已访问位置<br>消除累积漂移<br>全局一致性<br>词袋模型",3D视觉::概念
词袋模型(BoW)是什么?,"视觉单词字典<br>图像表示为词频<br>快速检索<br>DBoW2库",3D视觉::方法
什么是IMU预积分?,"融合惯性测量<br>积分两帧间IMU<br>避免重新积分<br>流形优化",3D视觉::方法
VIO是什么?,"Visual-Inertial Odometry<br>视觉+IMU融合<br>VINS-Mono<br>ORB-SLAM3",3D视觉::概念
LiDAR与视觉融合的优势?,"LiDAR: 精确深度<br>视觉: 纹理语义<br>互补<br>鲁棒性提升",3D视觉::概念
什么是点云?,"3D点的集合<br>坐标+颜色+法向<br>激光扫描输出<br>无序数据结构",3D视觉::概念
PointNet的原理是什么?,"直接处理点云<br>共享MLP<br>对称函数(最大池化)<br>置换不变",3D视觉::方法
PointNet++的改进是什么?,"层次化特征学习<br>局部邻域聚合<br>多尺度分组<br>更细粒度",3D视觉::方法
什么是体素化?,"点云→3D网格<br>规则结构<br>3D卷积适用<br>内存消耗大",3D视觉::概念
3D卷积的计算量如何?,"O(D×H×W×C_in×C_out×K³)<br>计算密集<br>需要稀疏化<br>子流形卷积",3D视觉::概念
Sparse Convolution是什么?,"只在活跃体素计算<br>哈希表索引<br>大幅减少计算<br>MinkowskiNet",3D视觉::方法
什么是法向量估计?,"点云表面方向<br>局部PCA<br>邻域拟合平面<br>法向垂直平面",3D视觉::方法
点云分割的方法?,"1. PointNet系列<br>2. 图卷积<br>3. 体素+3D CNN<br>4. 投影+2D CNN",3D视觉::方法
什么是3D目标检测?,"3D边界框回归<br>点云输入<br>类+位置+尺寸+朝向<br>KITTI/nuScenes基准",3D视觉::概念
PointPillars的流程?,"1. 点云→伪图像<br>2. 2D CNN检测<br>3. 3D框解码<br>实时性好",3D视觉::方法
什么是BEV表示?,"Bird's Eye View<br>俯视图<br>避免透视畸变<br>统一尺度",3D视觉::概念
多视图3D检测方法?,"1. 特征变换到BEV<br>2. 注意力融合<br>3. 深度加权<br>DETR3D, BEVFormer",3D视觉::方法
NeRF是什么?,"Neural Radiance Fields<br>5D函数F(x,y,z,θ,φ)→(RGB,σ)<br>体积渲染<br>新颖视图合成",3D视觉::方法
NeRF的渲染公式是什么?,"C(r) = ∫T(t)σ(t)c(t)dt<br>T(t) = exp(-∫σ(s)ds)<br>光线累积<br>可微渲染",3D视觉::公式
NeRF的训练过程?,"1. 采样光线<br>2. 查询网络<br>3. 体积渲染<br>4. 与真实图比较<br>5. 反向传播",3D视觉::方法
Instant-NGP的改进是什么?,"哈希编码<br>小MLP<br>实时训练<br>秒级收敛",3D视觉::方法
什么是3D Gaussian Splatting?,"3D高斯基元<br>光栅化渲染<br>实时高质量<br>可微优化",3D视觉::方法
3DGS的表示优势?,"- 显式表示<br>- 高效光栅化<br>- 质量高<br>- 编辑友好",3D视觉::概念
MVS是什么?,"Multi-View Stereo<br>多视图立体重建<br>稠密点云<br>COLMAP流程",3D视觉::概念
MVSNet的原理?,"3D代价体<br>可微单应性<br>深度回归<br>端到端",3D视觉::方法
什么是代价体?,"匹配代价的3D体<br>深度假设×高×宽<br>匹配质量度量<br>深度推断基础",3D视觉::概念
深度图融合的步骤?,"1. 多视图深度估计<br>2. 一致性检查<br>3. 点云合并<br>4. 网格重建",3D视觉::方法
TSDF是什么?,"Truncated Signed Distance Function<br>截断符号距离<br>体素网格<br>融合多帧",3D视觉::方法
Marching Cubes是什么?,"等值面提取<br>体素→三角网格<br>查表法<br>经典算法",3D视觉::方法
什么是泊松重建?,"Poisson Surface Reconstruction<br>求解泊松方程<br>全局优化<br>光滑表面",3D视觉::方法
网格简化的方法?,"1. QEM (Quadric Error)<br>2. 边折叠<br>3. 顶点聚类<br>LOD生成",3D视觉::方法
纹理映射是什么?,"图像贴到网格<br>UV展开<br>光照一致<br>照片真实感",3D视觉::概念
什么是摄影测量?,"照片→3D模型<br>Structure from Motion<br>商业软件: Metashape<br>文化保护应用",3D视觉::应用
SfM的流程是什么?,"1. 特征提取<br>2. 特征匹配<br>3. 几何验证<br>4. 增量重建<br>5. BA优化",3D视觉::方法
COLMAP是什么?,"开源SfM/MVS工具<br>增量/全局重建<br>GPU加速<br>学术标准",3D视觉::工具
6DoF位姿估计是什么?,"3D旋转+3D平移<br>物体空间定位<br>机器人抓取<br>BOP基准",3D视觉::概念
位姿估计的方法?,"1. PnP求解<br>2. 模板匹配<br>3. 学习方法<br>4. 对称处理",3D视觉::方法
什么是PnP问题?,"Perspective-n-Point<br>已知3D-2D对应<br>估计相机位姿<br>EPnP, DLS求解器",3D视觉::方法
RANSAC在3D视觉中的作用?,"外点剔除<br>鲁棒估计<br>迭代采样<br>基础矩阵/单应性",3D视觉::方法正面,背面,标签
医学影像的主要模态有哪些?,"1. CT (X射线)<br>2. MRI (磁共振)<br>3. 超声<br>4. PET (正电子)<br>5. X-ray",医学影像::概念
CT图像的成像原理?,"X射线衰减<br>Hounsfield单位<br>-1000(空气)到+3000(骨头)<br>密度成像",医学影像::概念
MRI的优势是什么?,"- 无辐射<br>- 软组织对比度高<br>- 多参数成像<br>- 任意方向切片",医学影像::概念
MRI的主要序列?,"T1加权: 解剖结构<br>T2加权: 病变<br>FLAIR: 抑制脑脊液<br>DWI: 扩散成像",医学影像::概念
什么是DICOM格式?,"医学影像标准格式<br>包含元数据<br>患者信息<br>16位深度",医学影像::概念
医学图像预处理步骤?,"1. 去噪<br>2. 偏置场校正(MRI)<br>3. 强度归一化<br>4. 配准<br>5. 重采样",医学影像::方法
什么是偏置场?,"MRI磁场不均匀<br>低频伪影<br>影响分割<br>N4ITK校正",医学影像::概念
N4偏置场校正的原理?,"非参数非均匀强度归一化<br>B样条拟合<br>迭代优化<br>ITK实现",医学影像::方法
医学图像分割的挑战?,"- 边界模糊<br>- 类别不平衡<br>- 标注昂贵<br>- 个体差异大",医学影像::概念
U-Net在医学分割的成功原因?,"- 数据效率高<br>- 跳跃连接保留细节<br>- 端到端训练<br>- 小数据集友好",医学影像::方法
什么是nnU-Net?,"No New U-Net<br>自动配置网络<br>数据自适应预处理<br>医学分割SOTA",医学影像::方法
nnU-Net的关键配置?,"1. 网络拓扑<br>2. Batch大小<br>3. 优化器<br>4. 数据增强<br>5. 推理策略",医学影像::方法
3D医学分割的网络?,"3D U-Net<br>V-Net<br>nnU-Net 3D<br>体素级预测",医学影像::方法
什么是级联分割?,"粗到细策略<br>第一阶段: ROI定位<br>第二阶段: 精细分割<br>减少计算",医学影像::方法
多尺度特征融合方法?,"1. FPN<br>2. UNet++<br>3. Attention Gate<br>4. Deep Supervision",医学影像::方法
什么是Deep Supervision?,"多层输出监督<br>加速收敛<br>梯度流改善<br>中间层正则化",医学影像::方法
医学图像的类别不平衡如何处理?,"1. 加权损失<br>2. Dice损失<br>3. 过采样<br>4. 数据增强",医学影像::方法
医学图像数据增强策略?,"1. 几何变换<br>2. 弹性变形<br>3. 强度变换<br>4. Mixup/CutMix",医学影像::方法
什么是弹性变形?,"模拟器官形变<br>位移场插值<br>数据增强<br>生物组织特性",医学影像::方法
测试时增强(TTA)是什么?,"多次预测取平均<br>提高鲁棒性<br>旋转/翻转<br>集成思想",医学影像::方法
什么是半监督分割?,"少量标注+大量无标注<br>一致性正则<br>伪标签<br>Mean Teacher",医学影像::方法
自训练的流程?,"1. 标注数据训练初始模型<br>2. 预测无标注数据<br>3. 选择高置信样本<br>4. 加入训练集",医学影像::方法
对比学习在医学影像的应用?,"学习表征<br>无监督预训练<br>下游任务微调<br>SimCLR, MoCo",医学影像::方法
域适应的医学应用?,"多中心数据<br>设备差异<br>对抗训练<br>特征对齐",医学影像::方法
什么是联邦学习?,"隐私保护<br>数据不动模型动<br>多方协作<br>医学数据敏感",医学影像::方法
医学图像配准的目标?,"对齐解剖结构<br>单模态/多模态<br>刚性/非刚性<br>Atlas配准",医学影像::概念
VoxelMorph的原理?,"学习的变形场<br>UNet预测位移<br>空间变换层<br>无监督配准",医学影像::方法
SyN配准是什么?,"Symmetric Normalization<br>Diffeomorphic<br>可逆<br>ANTs工具",医学影像::方法
什么是Diffeomorphic配准?,"可微同胚<br>拓扑保持<br>可逆变换<br>平滑变形场",医学影像::概念
CT图像重建方法?,"1. 滤波反投影(FBP)<br>2. 迭代重建<br>3. 深度学习重建<br>4. 压缩感知",医学影像::方法
什么是迭代重建?,"优化问题求解<br>正则化约束<br>降低剂量<br>计算量大",医学影像::方法
低剂量CT去噪?,"剂量降低→噪声增加<br>TV正则化<br>深度学习方法<br>保持诊断质量",医学影像::应用
MRI加速采集的方法?,"1. 并行成像<br>2. 压缩感知<br>3. 深度学习重建<br>4. k空间欠采样",医学影像::方法
什么是k空间?,"傅里叶空间<br>MRI原始数据<br>欠采样加速<br>零填充插值",医学影像::概念
压缩感知MRI?,"稀疏变换<br>TV正则化<br>非线性重建<br>欠采样恢复",医学影像::方法
深度学习MRI重建?,"端到端网络<br>数据驱动先验<br>unrolled优化<br>U-Net/VarNet",医学影像::方法
什么是器官分割?,"提取特定器官区域<br>体积测量<br>手术规划<br>放疗靶区",医学影像::应用
脑肿瘤分割的挑战?,"- 边界不规则<br>- 水肿区<br>- 多模态融合<br>- 分级差异",医学影像::概念
BraTS数据集是什么?,"脑肿瘤分割挑战<br>多模态MRI<br>像素级标注<br>年度比赛",医学影像::资源
心脏分割的应用?,"1. 心功能评估<br>2. 心室体积<br>3. 射血分数<br>4. 形态分析",医学影像::应用
什么是血管分割?,"提取血管结构<br>管状结构检测<br>拓扑保持<br>MRA/CTA",医学影像::应用
肺部结节检测流程?,"1. 肺实质分割<br>2. 候选检测<br>3. 假阳性剔除<br>4. 分类",医学影像::应用
LUNA16数据集是什么?,"肺结节检测挑战<br>CT扫描<br>结节标注<br>评估指标:CPM",医学影像::资源
病理图像分析的特点?,"- 超大图像(10亿像素)<br>- 多尺度<br>- 颜色归一化<br>- 弱监督",医学影像::概念
WSI处理的策略?,"1. 切片<br>2. 多尺度金字塔<br>3. 流式读取<br>4. 空间索引",医学影像::方法
什么是注意力机制在医学分割的应用?,"聚焦病灶<br>抑制背景<br>Squeeze-Excitation<br>CBAM",医学影像::方法
Transformer在医学影像的应用?,"Swin-UNet<br>TransUNet<br>全局上下文<br>长程依赖",医学影像::方法
模型不确定性估计?,"Monte Carlo Dropout<br>Deep Ensemble<br>贝叶斯神经网络<br>临床决策支持",医学影像::方法
医学AI的评估指标?,"1. Dice系数<br>2. Hausdorff距离<br>3. 表面距离<br>4. 临床指标",医学影像::概念
Dice系数的计算公式?,"Dice = 2|X∩Y|/(|X|+|Y|)<br>重叠度量<br>0-1范围<br>1为完美匹配",医学影像::公式
Hausdorff距离是什么?,"h(A,B) = max(min d(a,b))<br>最远点距离<br>边界精度<br>对离群点敏感",医学影像::概念
医学AI临床部署的挑战?,"1. 监管审批<br>2. 可解释性<br>3. 泛化能力<br>4. 工作流集成",医学影像::概念
FDA批准的AI诊断工具有哪些?,"IDx-DR: 糖尿病视网膜病变<br>Lung Cancer Alert<br>Cardiologs: 心电图<br>越来越多",医学影像::应用正面,背面,标签
深度学习的三要素是什么?,"数据、模型、算力<br>大量标注数据<br>深度神经网络<br>GPU加速训练",深度学习::概念
反向传播的原理是什么?,"链式法则<br>梯度从输出层传回输入层<br>计算每个参数的梯度<br>更新权重",深度学习::概念
什么是梯度消失问题?,"激活函数梯度<1<br>深层网络梯度指数衰减<br>浅层几乎不更新<br>Sigmoid常见",深度学习::概念
如何缓解梯度消失?,"1. ReLU激活<br>2. 残差连接<br>3. BatchNorm<br>4. 合适初始化",深度学习::方法
什么是梯度爆炸?,"梯度>1<br>参数指数增长<br>NaN值<br>梯度裁剪解决",深度学习::概念
BatchNorm的作用是什么?,"标准化每层输入<br>加速收敛<br>允许大学习率<br>正则化效果",深度学习::方法
BatchNorm的训练/测试区别?,"训练: 使用当前batch统计<br>测试: 使用running统计<br>running_mean/var<br>移动平均",深度学习::概念
LayerNorm vs BatchNorm?,"LayerNorm: 样本维度归一化<br>BatchNorm: 特征维度归一化<br>LN适合序列数据<br>BN适合图像",深度学习::对比
Dropout的原理是什么?,"随机失活神经元<br>训练时p概率置零<br>测试时缩放<br>防止过拟合",深度学习::方法
Dropout的测试行为?,"输出乘以(1-p)<br>或训练时/ (1-p)<br>Inverted Dropout<br>期望一致",深度学习::概念
什么是残差连接?,"y = F(x) + x<br>跳跃连接<br>梯度直通<br>允许超深网络",深度学习::方法
ResNet解决了什么问题?,"- 梯度消失<br>- 退化问题<br>- 深度增加但性能下降<br>恒等映射学习",深度学习::概念
什么是Adam优化器?,"自适应学习率<br>动量+RMSprop<br>m_t, v_t<br>β₁=0.9, β₂=0.999",深度学习::方法
Adam的更新公式?,"m_t = β₁m_{t-1} + (1-β₁)g_t<br>v_t = β₂v_{t-1} + (1-β₂)g_t²<br>θ_t = θ_{t-1} - α·m̂_t/√v̂_t",深度学习::公式
学习率调度的方法?,"1. Step decay<br>2. Cosine annealing<br>3. Warmup<br>4. Reduce on plateau",深度学习::方法
什么是学习率Warmup?,"初始小学习率<br>逐步增加到目标值<br>稳定初始训练<br>Transformer常用",深度学习::方法
权重衰减是什么?,"L2正则化<br>loss + λ||w||²<br>防止过拟合<br>权重衰减=正则化梯度",深度学习::概念
AdamW与Adam的区别?,"AdamW: 解耦权重衰减<br>Adam: L2正则化混入梯度<br>AdamW泛化更好<br>Transformer标配",深度学习::对比
什么是Early Stopping?,"验证集性能停止改善时停止<br>防止过拟合<br>保存最佳模型<br>patience参数",深度学习::方法
数据增强的作用是什么?,"增加数据多样性<br>防止过拟合<br>提高泛化<br>模拟真实变化",深度学习::概念
图像数据增强方法?,"1. 几何: 旋转、翻转、缩放<br>2. 颜色: 亮度、对比度<br>3. Mixup<br>4. CutMix<br>5. AutoAugment",深度学习::方法
什么是Mixup?,"混合两张图像<br>x = λx₁ + (1-λ)x₂<br>y = λy₁ + (1-λ)y₂<br>标签平滑效果",深度学习::方法
CutMix的原理?,"裁剪并粘贴区域<br>x = M⊙x₁ + (1-M)⊙x₂<br>保留局部特征<br>比Mixup更自然",深度学习::方法
什么是迁移学习?,"预训练+微调<br>利用大规模数据知识<br>小数据集有效<br>领域适应",深度学习::方法
迁移学习的策略?,"1. 特征提取<br>2. 微调<br>3. 渐进解冻<br>4. 差异学习率",深度学习::方法
什么是知识蒸馏?,"Teacher→Student<br>软标签<br>温度参数<br>模型压缩",深度学习::方法
蒸馏的损失函数?,"L = αL_hard + (1-α)L_soft<br>L_soft: KL散度<br>T控制软度<br>暗知识传递",深度学习::公式
自监督学习是什么?,"无标注数据预训练<br>设计前置任务<br>学习通用表征<br>下游任务微调",深度学习::概念
对比学习的前置任务?,"1. SimCLR: 对比损失<br>2. MoCo: 动量编码器<br>3. BYOL: 无负样本<br>4. SimSiam: 停止梯度",深度学习::方法
SimCLR的原理?,"同一图像两个增强视图<br>拉近正样本，推开负样本<br>InfoNCE损失<br>大批量",深度学习::方法
MAE是什么?,"Masked Autoencoder<br>遮挡图像块<br>重建缺失部分<br>ViT预训练",深度学习::方法
什么是注意力机制?,"动态权重分配<br>Query-Key-Value<br>加权求和<br>关注重要区域",深度学习::概念
Self-Attention的计算公式?,"Attention(Q,K,V) = softmax(QK^T/√d)V<br>Q=XW_Q, K=XW_K, V=XW_V<br>d_k缩放防止梯度消失",深度学习::公式
Multi-Head Attention是什么?,"多个注意力头并行<br>捕获不同关系<br>拼接+线性<br>h=8典型值",深度学习::方法
Transformer的优势?,"- 并行计算<br>- 长程依赖<br>- 可扩展<br>- 通用架构",深度学习::概念
位置编码的作用?,"注入位置信息<br>Transformer无顺序概念<br>正弦编码/可学习编码<br>相对位置编码",深度学习::方法
ViT的原理?,"图像分块→序列<br>线性投影<br>Transformer编码器<br>分类token",深度学习::方法
Swin Transformer的特点?,"层级结构<br>滑动窗口注意力<br>线性复杂度<br>多尺度特征",深度学习::方法
什么是BERT?,"双向Transformer编码器<br>MLM预训练<br>NSP任务<br>NLP预训练模型",深度学习::方法
GPT的特点?,"单向Transformer<br>自回归生成<br>大规模预训练<br>零样本能力",深度学习::方法
什么是生成对抗网络?,"Generator vs Discriminator<br>博弈训练<br>G生成假样本<br>D判断真假",深度学习::方法
GAN的损失函数?,"min_G max_D V(D,G)<br>V = E[log D(x)] + E[log(1-D(G(z)))]<br>纳什均衡",深度学习::公式
GAN训练不稳定的原因?,"- 模式崩塌<br>- 梯度消失<br>- 非凸博弈<br>- 超参数敏感",深度学习::概念
如何稳定GAN训练?,"1. Wasserstein GAN<br>2. Spectral Normalization<br>3. Progressive Growing<br>4. 特征匹配",深度学习::方法
什么是WGAN?,"Wasserstein距离<br>推土机距离<br>梯度有意义<br>Lipschitz约束",深度学习::方法
StyleGAN的创新点?,"风格注入<br>AdaIN<br>渐进生成<br>高质量人脸",深度学习::方法
Diffusion Model的原理?,"前向加噪→逆向去噪<br>学习噪声预测<br>逐步恢复<br>DDPM, DDIM",深度学习::方法
DDPM的训练目标?,"预测噪声ε<br>L = E[||ε - ε_θ(x_t, t)||²]<br>t时刻噪声<br>网络学习去噪",深度学习::公式
Stable Diffusion是什么?,"Latent Diffusion<br>潜空间扩散<br>降低计算量<br>文生图SOTA",深度学习::方法
CLIP是什么?,"Contrastive Language-Image Pre-training<br>图文对齐<br>零样本分类<br>多模态理解",深度学习::方法
CLIP的训练方式?,"图像编码器+文本编码器<br>对比损失<br>N×N相似度矩阵<br>对角线最大化",深度学习::方法
什么是提示学习?,"Prompt Tuning<br>调整输入模板<br>冻结模型<br>参数高效",深度学习::方法
LoRA是什么?,"Low-Rank Adaptation<br>低秩分解<br>只训练少量参数<br>微调大模型",深度学习::方法
PEFT方法有哪些?,"1. LoRA<br>2. Adapter<br>3. Prefix Tuning<br>4. BitFit",深度学习::方法
模型量化的原理?,"FP32→INT8<br>减少存储和计算<br>精度损失权衡<br>PTQ/QAT",深度学习::方法
什么是剪枝?,"移除不重要权重<br>结构化/非结构化<br>稀疏模型<br>加速推理",深度学习::方法
知识图谱与深度学习的结合?,"图神经网络<br>实体/关系嵌入<br>多跳推理<br>可解释性",深度学习::应用正面,背面,标签
Xiaohao Cai的主要研究方向?,"1. 变分方法与PDE<br>2. 图像分割<br>3. 张量分解<br>4. 3D视觉<br>5. 医学影像分析",研究综合::概述
变分方法与深度学习的结合点?,"- 正则化网络<br>- Plug-and-Play先验<br>- 深度展开网络<br>- 可解释AI",研究综合::交叉
什么是深度展开网络?,"Unrolling iterative algorithm<br>迭代变分算法展开为网络层<br>LISTA, ADMM-Net<br>可解释+可学习",研究综合::方法
TV正则化的深度学习版本?,"1. 学习化TV参数<br>2. 各向异性TV网络<br>3. TGV网络<br>4. 非局部TV网络",研究综合::交叉
什么是Plug-and-Play先验?,"PnP: 用去噪器作为先验<br>替代显式正则项<br>ADMM框架<br>预训练网络可插入",研究综合::方法
图像分割的发展脉络?,"阈值→区域→边缘→能量→图→深度学习<br>从简单到复杂<br>从手工到学习<br>性能持续提升",研究综合::脉络
传统分割vs深度学习分割?,"传统: 可解释，数据少，调参难<br>深度: 黑盒，数据多，端到端<br>传统理论支撑强<br>深度性能上限高",研究综合::对比
张量分解在高维数据的优势?,"- 捕获多模态相关性<br>- 参数效率高<br>- 避免维度灾难<br>- 结构化表示",研究综合::优势
张量网络与深度学习的联系?,"- 权重张量化<br>- TT层<br>- 压缩神经网络<br>- 理论分析工具",研究综合::交叉
3D视觉的核心问题?,"1. 从2D到3D的映射<br>2. 多视图一致性<br>3. 遮挡处理<br>4. 尺度恢复",研究综合::概念
NeRF与传统重建的对比?,"传统: 显式几何(网格/点云)<br>NeRF: 隐式神经表示<br>传统需要后处理<br>NeRF端到端优化",研究综合::对比
医学影像AI的伦理考量?,"- 数据隐私<br>- 算法公平性<br>- 可解释性<br>- 责任归属",研究综合::伦理
医学AI临床落地的关键?,"1. 鲁棒性<br>2. 可解释性<br>3. 监管合规<br>4. 工作流整合",研究综合::应用
变分方法的理论基础?,"- 凸分析<br>- 泛函分析<br>- PDE理论<br>- 数值优化",研究综合::理论
如何评估图像处理算法?,"1. 客观指标(PSNR, SSIM)<br>2. 主观评估<br>3. 下游任务性能<br>4. 计算效率",研究综合::评估
PSNR的计算公式?,"PSNR = 10·log₁₀(MAX²/MSE)<br>MAX: 像素最大值<br>MSE: 均方误差<br>单位: dB",研究综合::公式
SSIM测量什么?,"结构相似性<br>亮度+对比度+结构<br>0-1范围<br>更符合人眼感知",研究综合::概念
什么是无参考图像质量评估?,"No-Reference IQA<br>无需原始图像<br>自然场景统计<br>盲评估",研究综合::概念
图像处理中的病态问题?,"不适定问题<br>解不唯一/不连续依赖数据<br>需要正则化<br>逆问题典型",研究综合::概念
正则化的作用是什么?,"引入先验<br>约束解空间<br>改善条件数<br>平衡拟合与复杂度",研究综合::概念
L1正则vs L2正则?,"L1: 稀疏解，特征选择<br>L2: 平滑解，权重衰减<br>L1非光滑<br>L2可微",研究综合::对比
压缩感知的核心思想?,"稀疏信号可从少量测量恢复<br>低于Nyquist采样<br>L1最小化<br>应用广泛",研究综合::概念
压缩感知的条件?,"1. 信号稀疏<br>2. 测量矩阵满足RIP<br>3. 优化算法<br>理论保证",研究综合::概念
RIP是什么?,"Restricted Isometry Property<br>限制等距性质<br>保持稀疏信号的几何<br>测量矩阵质量指标",研究综合::概念
图像修复的常用方法?,"1. 变分方法(TV)<br>2. 稀疏表示<br>3. 低秩矩阵<br>4. 深度学习",研究综合::方法
稀疏表示的原理?,"信号 = 字典 × 稀疏系数<br>过完备字典<br>L0/L1优化<br>OMP算法",研究综合::方法
低秩矩阵补全?,"矩阵秩最小化<br>核范数松弛<br>SVD分解<br>Netflix推荐",研究综合::方法
字典学习是什么?,"学习过完备基<br>K-SVD算法<br>自适应稀疏表示<br>去噪/修复应用",研究综合::方法
多尺度分析的意义?,"捕获不同尺度特征<br>金字塔表示<br>小波变换<br>从粗到细策略",研究综合::概念
小波变换的优势?,"- 时频局部化<br>- 多分辨率<br>- 稀疏表示<br>- 快速算法",研究综合::概念
图像金字塔类型?,"1. 高斯金字塔<br>2. 拉普拉斯金字塔<br>3. 小波金字塔<br>4. 深度特征金字塔",研究综合::概念
什么是特征提取?,"从原始数据提取有用信息<br>降维<br>手工/学习特征<br>下游任务输入",研究综合::概念
传统图像特征有哪些?,"1. SIFT<br>2. HOG<br>3. LBP<br>4. Haar<br>5. SURF",研究综合::概念
深度特征的优势?,"- 端到端学习<br>- 层次化表示<br>- 任务优化<br>- 大规模数据驱动",研究综合::对比
什么是迁移学习?,"源域知识迁移到目标域<br>预训练+微调<br>小数据场景<br>领域自适应",研究综合::概念
领域自适应的类型?,"1. 无监督DA<br>2. 半监督DA<br>3. 多源DA<br>4. 目标域有少量标签",研究综合::概念
对抗性领域自适应?,"域对抗训练<br>DANN<br>特征分布对齐<br>梯度反转层",研究综合::方法
什么是元学习?,"学习如何学习<br>少量样本适应<br>MAML, Prototypical Networks<br>通用学习算法",研究综合::概念
元学习的应用场景?,"- 小样本学习<br>- 快速适应新任务<br>- 超参数优化<br>- 神经架构搜索",研究综合::应用
神经网络架构搜索(NAS)?,"自动设计网络结构<br>搜索空间+策略+评估<br>DARTS, ENAS<br>计算昂贵",研究综合::方法
什么是AutoML?,"自动化机器学习<br>特征工程+模型选择+超参优化<br>降低门槛<br>Auto-sklearn, TPOT",研究综合::概念
可解释AI的重要性?,"- 信任建立<br>- 错误诊断<br>- 合规要求<br>- 科学理解",研究综合::概念
可解释性方法分类?,"1. 事后解释(LIME, SHAP)<br>2. 内在可解释(决策树)<br>3. 全局vs局部<br>4. 模型无关vs特定",研究综合::概念
注意力图作为解释?,"可视化注意力权重<br>突出重要区域<br>直观但可能误导<br>不是完整解释",研究综合::方法
什么是因果推理?,"超越相关性<br>因果关系推断<br>干预和反事实<br>更稳健决策",研究综合::概念
因果性vs相关性?,"相关性: X和Y一起变化<br>因果性: X导致Y<br>机器学习侧重相关性<br>因果推理探索机制",研究综合::对比
研究方法论的关键步骤?,"1. 问题定义<br>2. 文献调研<br>3. 方法设计<br>4. 实验验证<br>5. 论文撰写",研究综合::方法
如何设计对比实验?,"- 公平对比(相同设置)<br>- 消融实验<br>- 多数据集<br>- 统计显著性",研究综合::方法
消融实验的作用?,"验证各组件贡献<br>找出关键设计<br>逐一移除/替换<br>理解模型",研究综合::概念
如何阅读学术论文?,"1. 标题摘要速览<br>2. 图表先行<br>3. 方法核心<br>4. 实验验证<br>5. 批判思考",研究综合::方法
如何撰写论文?,"1. 明确贡献<br>2. 逻辑清晰<br>3. 图表辅助<br>4. 实验充分<br>5. 反复修改",研究综合::方法
开源代码的意义?,"- 可复现<br>- 社区贡献<br>- 影响力<br>- 协作基础",研究综合::概念
研究趋势预测方法?,"1. 追踪顶会<br>2. 工业界需求<br>3. 技术瓶颈<br>4. 跨领域借鉴",研究综合::方法
跨学科研究的价值?,"- 新视角<br>- 方法迁移<br>- 突破瓶颈<br>- 创新源泉",研究综合::概念
学术交流的形式?,"1. 会议报告<br>2. 论文合作<br>3. 访问交流<br>4. 社交媒体",研究综合::方法
如何选择研究方向?,"1. 兴趣驱动<br>2. 社会需求<br>3. 可行性<br>4. 竞争格局<br>5. 长期价值",研究综合::方法
研究中的失败如何处理?,"- 分析原因<br>- 调整方向<br>- 积累经验<br>- 换角度思考",研究综合::方法
终身学习的重要性?,"技术快速迭代<br>持续更新知识<br>保持竞争力<br>适应变化",研究综合::概念
如何保持研究动力?,"1. 好奇心<br>2. 社会影响<br>3. 同行交流<br>4. 小目标激励<br>5. 平衡工作生活",研究综合::方法