Framelet-Based Algorithm for Segmentation
of Tubular Structures
Xiaohao Cai1, Raymond H. Chan1, Serena Morigi2, and Fiorella Sgallari2
1 Department of Mathematics,
The Chinese University of Hong Kong, Shatin, N.T., Hong Kong
{xhcai,rchan}@math.cuhk.edu.hk
2 Department of Mathematics-CIRAM, University of Bologna, Bologna, Italy
{morigi,sgallari}@dm.unibo.it
Abstract. Framelets have been used successfully in various problems
in image processing, including inpainting, impulse noise removal, super-
resolution image restoration, etc. Segmentation is the process of iden-
tifying object outlines within images. There are quite a few eﬃcient
algorithms for segmentation that depend on the partial diﬀerential equa-
tion modeling. In this paper, we apply the framelet-based approach to
identify tube-like structures such as blood vessels in medical images. Our
method iteratively reﬁnes a region that encloses the possible boundary
or surface of the vessels. In each iteration, we apply the framelet-based
algorithm to denoise and smooth the possible boundary and sharpen the
region. Numerical experiments of real 2D/3D images demonstrate that
the proposed method is very eﬃcient and outperforms other existing
methods.
1
Introduction
In this paper, we consider the segmentation problem of branching tubular objects
from 2D and 3D images. This kind of problem arises in several application ﬁelds,
for example, extracting roads in aerial photography, and anatomical surfaces of
tubular structures like blood vessels in Magnetic Resonance Angiography (MRA)
images. Because of the necessity to obtain as much ﬁne details as possible in real
time, automatic, robust and eﬃcient methods are needed.
There are several vessel segmentation algorithms that are based on deformable
models, see [21] for an extended review. Because the explicit deformable model
representation is usually impractical, level set techniques to evolve a deformable
model have been introduced, and they provide implicit representation of a de-
formable model. However, the level set segmentation approach is computation-
ally more expensive as it needs to cover the entire domain of interest, which
is generally one dimension higher than the original one. Interested readers are
referred to recent literature on the level set segmentation strategy for tubular
structures [18,20,24].
A new model for active contours to detect objects in a given image based
on techniques of curve evolution, Mumford-Shah functional and level sets was
A.M. Bruckstein et al. (Eds.): SSVM 2011, LNCS 6667, pp. 411–422, 2012.
c
⃝Springer-Verlag Berlin Heidelberg 2012
412
X. Cai et al.
proposed in [10]. A generalization of the active contour without edges model was
proposed in [23] for object detection using logic operations. This logic framework
suﬀers from the same limits as in the active contour model and is not suitable
for detecting tubular structures.
In [16], a geometric deformable model for the segmentation of tubular-like
structures was proposed. The model is characterized mainly by two components:
the mean curvature ﬂow and the directionality of the tubular structures. The
major advantage of this technique is the ability to segment twisted, convoluted
and occluded structures without user interactions; and it can follow the branch-
ing of diﬀerent layers, from thinner to larger structures. The dependence on the
grid resolution chosen to solve the discretized partial diﬀerential equation (PDE)
model is still an open problem. The authors in [16] have also applied a variant of
the proposed PDE model to the challenging problem of composed segmentation
in [17].
There are some work on texture classiﬁcation and segmentation using wavelets
or wavelet frames [25,1]. Framelet-based approach is a versatile and eﬀective
tool for many diﬀerent applications in image processing, see [4,7,8,3]. Recently,
the authors in [13] proposed to combine the framelet-based image restoration
model of [5] and the total variation based segmentation model of [10,9,2] to do
segmentation. In this paper, we also derive a segmentation algorithm that uses
the framelet-based approach. However our method is not based on minimizing
any variational model and hence it is diﬀerent from the method in [13]. In fact,
our algorithm gradually updates an interval that contains pixel values of possible
boundary pixels. Like the method in [16], our method also has the ability to
segment twisted, convoluted and occluded structures. In addition, our method
is very eﬀective in denoising and can extract more details from the given image.
The rest of the paper is organized as follows. In Section 2, we recall some
basic facts about tight frames and framelet-based algorithms. Our segmentation
algorithm is given in Section 3. Section 4 discusses how to ﬁnd an interval that
contains pixel values of possible boundary pixels. In Section 5 we test our algo-
rithm on various real 2D and 3D images. Comparisons with other methods will
be also given. Conclusions are given in Section 6.
2
Framelet-Based Algorithm
In this section, we brieﬂy introduce the framelet-based algorithm. For theories
of tight frames and framelets, we refer the readers to [11] for more details. In
order to apply the framelet-based algorithm, one only needs to know the ﬁlters
corresponding to the framelets. For the framelets derived from the piecewise
linear B-spline, the corresponding ﬁlters are:
h0 = 1
4[1, 2, 1],
h1 =
√
2
4 [1, 0, −1],
h2 = 1
4[−1, 2, −1],
(1)
see [22]. The framelet coeﬃcients of any given vector v corresponding to ﬁlter
hi can be obtained by convolving hi with v. In matrix terms, we can construct,
Framelet-Based Algorithm for Segmentation of Tubular Structures
413
for each ﬁlter, its corresponding ﬁlter matrix which is just the Toeplitz matrix
with diagonals given by the ﬁlter coeﬃcients, e.g. H0 = 1
4tridiag[1, 2, 1]. Then
the 1D framelet forward transform is given by
A =
⎡
⎣
H0
H1
H2
⎤
⎦.
(2)
To apply the framelet transform onto v is equivalent to computing Av, and Hiv
gives the framelet coeﬃcients corresponding to the ﬁlter hi, i = 1, 2, 3.
The d-dimensional framelet system is constructed by tensor products from
the 1D framelets, see [14]. For example, in 2D, there are nine framelets given
by hij ≡hT
i ⊗hj for i, j = 1, 2, 3, where hi is given in (1). For any 2D image
f, the framelet coeﬃcients with respect to hij are obtained by convolving hij
with f. In 3D, there are twenty-seven ﬁlters and the framelet coeﬃcients can
also be obtained by convolutions. Let A represent the corresponding framelet
forward transform matrix (cf. (2)). In 2D case, A will be a stack of nine block-
Toeplitz-Toeplitz-block matrices, see [4]. In this notation, given any image f, the
matrix-vector product A · vec(f) gives all the framelet coeﬃcients. Here vec(f)
denotes the vector obtained by concatenating the columns of f.
All framelet transforms have a very important property, the “perfect recon-
struction property”: AT A = I, the identity matrix, see [22]. Unlike the wavelets,
in general, AAT ̸= I. The framelet-based algorithms, as given in [8,4,3], are of
the following generic form:
f (i+ 1
2 ) = U(f (i)),
(3)
f (i+1) = AT Tλ(Af (i+ 1
2 )),
i = 1, 2, . . ..
(4)
Here f (i) is an approximate solution, U is a problem-dependent operator, and
Tλ(·) is the soft-thresholding operator deﬁned as follows. Given vectors v =
[v1, · · · , vn]T and λ = [λ1, · · · , λn]T , Tλ(v) ≡[tλ1(v1), · · · , tλn(vn)]T , where
tλk(vk) ≡
sgn(vk)(|vk| −λk), if |vk| > λk,
0,
if |vk| ≤λk.
(5)
For how to choose λk, see [15].
Algorithm (4) is usually called the isotropic framelet-based algorithm. This is
because the thresholding operator Tλ is applied on all the framelet coeﬃcients
Af (i+ 1
2 ) in (4). In [7], the anisotropic framelet-based algorithm was proposed.
The main idea is that the ﬁlter h1 in (1) is the central-diﬀerence apart from a
scalar multiple. Hence the corresponding framelet coeﬃcients are related to the
gradient ∇f of the image f. One should therefore rotate these coeﬃcients along
the tangential and normal direction, and threshold only the components along
the tangential direction, see [26]. For the coeﬃcients corresponding to other
ﬁlters, we threshold as in the isotropic framelet-based algorithm. In [7], it was
shown that the anisotropic thresholding scheme can give better restoration than
the isotropic one, and can follow edges more closely. Later in the numerical tests,
we have tried both thresholding schemes, and found that anisotropic thresholding
can give the tubular structures better.
414
X. Cai et al.
3
Framelet-Based Algorithm for Segmentation
The technology of MRA imaging is based on detection of signals from ﬂowing
blood and suppression of signals from other static tissues, so that the blood
vessels appear as high intensity regions in the image, see Fig. 1(a). The structures
to be segmented are vessels of variable diameters which are close to each other.
Partial occlusions and intersections make the segmentation very challenging.
Moreover, the real image can be aﬀected by speckle noise. In general in medical
images, speckle noise and weak edges make it diﬃcult to identify the structures
in the image. Fortunately, the MRA images also contain some properties that can
be used to construct our algorithm. From Fig. 1(a), we see that the pixels near
the boundary of the vessels are not exactly of one value, but they are in some
range, whereas the values of the pixels in other parts are far from this range.
Thus the main idea of our algorithm is to approximate this range accurately.
We will obtain the range iteratively by a framelet-based algorithm. The main
steps are as follows. Suppose in the beginning of the ith iteration, we are given
an approximate image f (i), and an approximate range [αi, βi] for αi ≤βi which
contains the pixel values of all the possible boundary pixels. Then we (i) use
the range to threshold the image into three parts—below, inside, and above the
range; (ii) denoise and smooth the inside part by the framelet-based algorithm to
get a new image f (i+1); and (iii) reﬁne the range to [αi+1, βi+1] by using f (i+1).
We stop when f (i+1) becomes a binary image. In the followings, we elaborate
each of the steps. Without loss of generality, we assume all images have dynamic
range in [0, 1].
Step (i): Thresholding the Image into Three Parts. Using the range
[αi, βi] ⊆[0, 1], we can separate the image f (i) into three parts—below, inside,
and above the range, see Fig. 1(b). To emphasize the boundary, we threshold
those pixel values that are smaller than αi to 0, those larger than βi to 1, and
those in between, we stretch them between 0 and 1 using a simple linear contrast
stretch, see [19]. More precisely, let Ω be the index set of all the pixels in the
image, f (i)
j
be the pixel value of pixel j in image f (i), and
Mi = max{f (i)
j
| αi ≤f (i)
j
≤βi, j ∈Ω},
mi = min{f (i)
j
| αi ≤f (i)
j
≤βi, j ∈Ω}.
Then we deﬁne
f
(i+ 1
2 )
j
=
⎧
⎪
⎪
⎨
⎪
⎪
⎩
0,
if f (i)
j
≤αi,
f (i)
j
−mi
Mi−mi , αi ≤f (i)
j
≤βi,
for all j ∈Ω.
1,
if βi ≤f (i)
j ,
(6)
Fig. 1(c) shows the threshold and stretched image from Fig. 1(b). In the follow-
ing, we write (6) simply as f (i+ 1
2 ) = U(f (i)) (cf. (3)), and we denote
Λ(i) = {j | mi < f (i)
j
< Mi, j ∈Ω},
(7)
Framelet-Based Algorithm for Segmentation of Tubular Structures
415
the index set for pixels with values inside the range (mi, Mi), i.e., the index set
for pixels of f (i+ 1
2 ) with values neither 0 nor 1. Our next step is to denoise and
smooth the image f (i+ 1
2 ) on Λ(i).
(a)
(b)
(c)
Fig. 1. (a) Given image. (b) Three parts of the given image (green–below, red–in
between, and yellow–above). (c) Threshold and stretched image by (6) (yellow pixels
are with value 0 or 1).
Step (ii): Framelet-Based Iteration. To denoise and smooth the image
f (i+ 1
2 ) on Λ(i), we apply the framelet-based iteration (4) on Λ(i). More pre-
cisely, if j ̸∈Λ(i), then we set f (i+1)
j
= f
(i+ 1
2 )
j
; otherwise, we use (4) to get
f (i+1)
j
. To write it out clearly, let f (i+ 1
2 ) = vec(f (i+ 1
2 )), and P (i) be the diagonal
matrix where the diagonal entry is 1 if the corresponding index is in Λ(i), and 0
otherwise. Then
f (i+1) ≡(I −P (i))f (i+ 1
2 ) + P (i)AT Tλ(Af (i+ 1
2 )).
(8)
By reordering the entries of the vector f (i+1) into columns, we obtain the image
f (i+1). Note that the eﬀect of (8) is to denoise and smooth the image on Λ(i),
see [4]. Since the pixel values of all pixels outside Λ(i) are either 0 or 1, the
cost of matrix-vector multiplications in (8), such as Af (i+ 1
2 ), can be reduced
signiﬁcantly by taking advantage of this.
Step (iii): Reﬁning the Range. The process of ﬁnding the new range [αi+1,
βi+1] from f (i+1) is very similar to the process of ﬁnding the initial interval
[α0, β0] from the given image. We postpone it till the next section. We will see
that [αi+1, βi+1] ⊊[0, 1] for all i ≥0. This point guarantees the convergence of
our method, see Theorem 1.
Stopping Criterion. We stop the iteration when all the pixels of f (i+ 1
2 ) are ei-
ther of value 0 or 1, or equivalently when |Λ(i)| = 0. For the binary image f (i+ 1
2 ),
all the pixels with value 1 constitute the tubular structures. In the numerical
tests, we use the matlab command “contour” and “isosurface” respectively
to obtain the boundary of f (i+ 1
2 ) in 2D and 3D respectively.
416
X. Cai et al.
4
Initializing and Reﬁning the Range
In this section, we discuss how to ﬁnd [αi, βi] given f (i). When i = 0, the initial
guess f (0) is chosen to be the given image. Recall that [αi, βi] is an interval
containing the pixel values of the possible boundary pixels. Our idea of ﬁnding
it is as follows: (i) ﬁnd the average μ(i) of the pixel values of the possible boundary
pixels; and (ii) determine a suitable interval [αi, βi] ⊊[0, 1] that contains μ(i).
For i = 0, since we do not have any knowledge of where the boundary will
possibly be, we use the gradient of f (0) to ﬁnd it. Deﬁne the gradient image g
of f (0) as:
gj =
 d

ℓ=1
(∂xℓf (0)
j
)2
1/2
,
for all j ∈Ω,
where ∂xℓis the forward-diﬀerence in the xℓ-direction, and d = 2 for 2D and
d = 3 for 3D. Our ﬁrst approximation of the boundary is composed of those pixels
where gj > ϵ for a given ϵ. (In our numerical tests, we choose ϵ ∈[10−3, 10−1].)
Thus let Γ = {j | gj > ϵ, j ∈Ω}, the index set of those pixels; and let μΓ be the
average of f (0) on Γ, i.e.
μΓ = 1
|Γ|

j∈Γ
f (0)
j
,
where |Γ| is the cardinality of Γ. Obviously the smaller the ϵ is, the larger
cardinality of |Γ| will be.
Naturally, those pixels in Γ can be separated into two parts by μΓ : one part
contains the pixels near to the tubulars (yellow part of Fig. 1(b)), and the other
part is near to the background (green part of Fig. 1(b)). More precisely, we deﬁne
Γ+ = {j | fj > μΓ , j ∈Γ}
and
Γ−= {j | fj < μΓ , j ∈Γ}.
Let μ+ and μ−be the averages of f (0) on Γ+ and Γ−respectively. Note that μ+
(and respectively μ−) is the average of those possible boundary pixels that are
close to the tubulars (and respectively close to the background). We use them
to compute μ(0), the average of the possible boundary pixels. Deﬁne
Λ(−1) = {j | μ−< f (0)
j
< μ+, j ∈Ω}.
Then
μ(0) =
1
|Λ(−1)|

j∈Λ(−1)
f (0)
j
.
(9)
For i ≥0, we deﬁne μ(i+1) similarly as in (9):
μ(i+1) =
1
|Λ(i)|

j∈Λ(i)
f (i+1)
j
,
(10)
where Λ(i) is given by (7) and f (i+1) is given by (8).
Framelet-Based Algorithm for Segmentation of Tubular Structures
417
Finally we discuss how to choose the interval [αi, βi] that contains μ(i) for
i ≥0. Our idea is ﬁrst to compute coarse interval [αL
i , βH
i ] that contains μ(i) by
αL
i =
1
|{j : f (i)
j
≤μ(i)}|

{j:f (i)
j
≤μ(i)}
f (i)
j , βH
i
=
1
|{j : f (i)
j
≥μ(i)}|

{j:f (i)
j
≥μ(i)}
f (i)
j ,
where j ∈Λ(i−1) for i ≥1 and j ∈Ω for i = 0. From the above formulas, we can
see that [αL
i , βH
i ] will never be [0, 1] if the given image is not a binary image.
(If αL
i = βH
i , then all remaining pixels have the same pixel value. Hence we set
them all to 1 and the image is thus a binary image, and the algorithm stops.)
Next we compute, for all α ∈[αL
i , βH
i ] (αL
i ̸= βH
i ),
c(α) ≡
1
|{j : f (i)
j
≥α}|

{j:f (i)
j
≥α}
f (i)
j
−
1
|{j : f (i)
j
≤α}|

{j:f (i)
j
≤α}
f (i)
j ,
where j ∈Ω. Let the range of c(α) be [cm, cM] and ℓ= cM −cm. Then
αi ≡min{α ∈[αL
i , βH
i ] | c(α) = c(μ(i)) −γℓ},
(11)
βi ≡max{α ∈[αL
i , βH
i ] | c(α) = c(μ(i)) + γℓ}.
(12)
Here γ ∈(0, 1/2) is a parameter that controls the length of the interval [αi, βi].
Clearly the larger the interval is, the more pixels are to be considered as possible
boundary pixels. So the smaller the γ is, the faster convergence of our method
will have. In the numerical tests, we choose γ = 1/5. We give the full algorithm
below and show that it always converges to a binary image.
Algorithm: Framelet-based algorithm for segmentation
1. Initialize: set f (0) = f, μ(0) by (9), and [α0, β0] by (11) and (12).
2. Do i = 0, 1, . . ., until stopped
(a) Compute f (i+ 1
2 ) = U(f (i)) by (6).
(b) Stop if f (i+ 1
2 ) is a binary image.
(c) Update f (i+ 1
2 ) to f (i+1) by (8).
(d) Update μ(i+1) by (10), and then [αi+1, βi+1] by (11) and (12).
3. Extract the boundary from the binary image f (i+ 1
2 ).
Theorem 1. Our framelet-based algorithm will converge to a binary image.
Proof. Obviously, we just need to prove that |Λ(i)| = 0 at some ﬁnite step i, see
(6) and (7). If the given image f (0) is a binary image, we are done. Without loss of
generality, we assume that f (0) is not a binary image. Given Λ(i−1) deﬁned by (7)
for any i ≥1, note that the pixel values of those pixels not in Λ(i−1) will not be
changed by (8), i.e., they will stay at either 0 or 1. Then [αi, βi] will be obtained
by (11) and (12), where [αi, βi] ⊆[αL
i , βH
i ] ⊊[0, 1]. Since [mi, Mi] ⊆[αi, βi],
we have mi ̸= 0 or Mi ̸= 1. By (6) and (7), the pixels satisfying f (i) ≤mi
or f (i) ≥Mi are set to 0 or 1 respectively. Thus, there will be at least one
pixel in Λ(i−1) with value neither 0 nor 1 that is set to 0 or 1 by (6). Hence
|Λ(i)| < |Λ(i−1)|, where | · | denotes the cardinality of the set. Since |Λ(0)| is
ﬁnite, there must exist some i such that |Λ(i)| = 0.
418
X. Cai et al.
Finally, let us estimate the computation cost of our method for a given image
with n pixels: (i) the cost of computing each μ(i) and [αi, βi] is O(n), see (9)–(12)
respectively; and (ii) the cost of steps (a) and (c) in the above algorithm is O(n),
see (6) and (8). Hence the cost of our method is O(n) per iteration. We remark
that our algorithm usually converges within a few iterations, see the numerical
results in the next section.
5
Numerical Examples
In this section, we test our proposed framelet-based segmentation method on
three 2D/3D real images. All the data are obtained from [16] and [17]. We
use the piece-wise linear ﬁlters given in (1) with only the ﬁrst level, i.e. no
downsampling. We tried both isotropic and anisotropic thresholding schemes,
see the discussion at the end of Section 2. The thresholding parameters λk used
in (5) are chosen to be λk ≡2−1/2 for isotropic thresholding. For anisotropic
thresholding, λk = 0.1×2−1/2 for the components along the tangential direction
and λk = 2−1/2 for other coeﬃcients.
(a)
(b)
(c)
(d)
(e)
Fig. 2. Carotid vascular system segmentation. (a) Given image. (b) and (c) Results
by the methods in [10] and [16] respectively. (d) and (e) Results by our method with
isotropic and anisotropic thresholding schemes respectively.
Example 1. The test image is a 182 × 62 MRA image of a carotid vascular
system, see Fig. 2(a). The results by our method using isotropic and anisotropic
thresholding are given by Fig. 2(d) and (e) respectively. With the parameters
γ = 1/5 and ϵ = 1.6 × 10−2, our method converges in 6 iterations for both
thresholding schemes. The ﬁrst and second rows of Table 1 give |Λ(i)| at each
iteration, from which, we can see that only very few pixels (comparing with |Ω| =
182 × 62 = 11, 284) need to be classiﬁed after 3 iterations. For the purpose of
Framelet-Based Algorithm for Segmentation of Tubular Structures
419
(a)
(b)
(c)
(d)
(e)
(f)
(g)
(h)
(i)
(j)
(k)
(l)
Fig. 3. Kidney vascular system segmentation. (a) and (b) Results by the methods
in [10] and [16] respectively. (c) and (d) Results by our method with isotropic and
anisotropic thresholding respectively. (e)–(g) and (i)–(k) Zoomed in rectangular parts
of (b) and (c) respectively. (h) and (l) Superimposed boundaries inside the ellipses of
(c) and (d) (red—in (c), green—in (d), and black–intersection of (c) and (d)).
Table 1. Cardinality of Λ(i) at each iteration of the three examples
n = |Ω| |Λ(0)| |Λ(1)| |Λ(2)| |Λ(3)| |Λ(4)| |Λ(5)| |Λ(6)| |Λ(7)| |Λ(8)| |Λ(9)|
Fig. 2(d)
11284
2374
307
83
23
7
1
0
-
-
-
Fig. 2(e)
11284
2374
233
48
13
5
1
0
-
-
-
Fig. 3(c)
66049
8314
1834
565
137
29
18
4
0
-
-
Fig. 3(d)
66049
8314
1557
406
95
19
5
1
0
-
-
Fig. 4(d) 8120601 104329 21333 5460 1430
326
70
9
3
1
0
Fig. 4(e) 8120601 104329 20020 4984 1260
299
72
19
6
0
-
comparison, we also give the results by the methods in [10] and [16] respectively,
see Fig. 2(b) and (c). Clearly, the result of Fig. 2(b) is not satisfactory since the
tubulars obtained are disconnected. By comparing the parts inside the rectangles
in Fig. 2 (c) with those in Fig. 2(d) and (e), we see that our method can extract
420
X. Cai et al.
(a)
(b)
(c)
(d)
(e)
(f)
Fig. 4. Segmentation of the kidney volume data set. (a) Given CTA image. (b) Result
by the method in [17]. (d) and (e) Results by our method with isotropic and anisotropic
thresholding respectively. (c) and (f) Zoomed in the bottom-left corners of (d) and (e)
respectively.
more details than the method in [16]. Finally, the parts inside the ellipses of
Fig. 2(d) and (e) demonstrate that the anisotropic thresholding keeps the edge
better than isotropic thresholding.
Example 2. The test image is a 257 × 257 MRA image of a kidney vascular
system as shown in Fig. 1(a). This example shows the ability of our method
to reconstruct structures which present small occlusions along the coherence
direction. With the parameters γ = 1/5 and ϵ = 5×10−3, our method converges
in 7 iterations for both thresholding schemes. The third and fourth rows in
Table 1 give |Λ(i)| at each iteration. The result of Fig. 3(a) by the method in
[10] is not good since it can not connect the small occlusions along the coherence
direction, while this can be done by our method and the method in [16], see Fig.
3(b), (c) and (d). Furthermore, our method is better than the method in [16]
by comparing the rectangular parts of Fig. 3(b) with those in Fig. 3(c) and (d),
since our method can detect smoother edges. More precisely, see Fig. 3(e)–(g)
and (i)–(k), which are the results of zooming in the rectangular parts of Fig.
3(b) and (c) respectively. This also shows that our method is very eﬀective in
denoising. In order to compare Fig. 3(c) with (d) explicitly, we superimpose the
boundaries of them, see Fig. 3(h) and (l). Clearly, the boundary of the tubulars
is tighter and more pixels at the tips are obtained by anisotropic thresholding.
Framelet-Based Algorithm for Segmentation of Tubular Structures
421
Example 3. This is a 3D example where we extracted a volumetric data set of
size 201 × 201 × 201 from a 436 × 436 × 540 CTA (Computed Tomographic
Angiography) image of the kidney vasculature system, see Fig. 4(a). With the
parameters γ = 1/5 and ϵ = 6×10−2, our method converges in 9 and 8 iterations
for isotropic and anisotropic thresholding respectively. The last two rows in Table
1 show |Λ(i)| at each iteration. By comparing our method with the method in
[17], the results show that our method can give many more details, see Fig.
4(b), (d) and (e). The zoomed in bottom-left corners of Fig. 4(d) and (e) clearly
give the diﬀerence of the results of our method by isotropic and anisotropic
thresholding, see Fig. 4(c) and (f). We see that more pixels at the tips of the
tubular structures are detected and the tubular structures are connected better
by the anisotropic thresholding than by the isotropic thresholding.
6
Conclusions and Future Work
In this paper, we introduced a new segmentation method based on the framelet-
based approach. The numerical results demonstrate the ability of our method for
segmenting tubular structures. The method can be implemented fast and give
very accurate, smooth boundaries or surfaces. In addition, since the pixel values
of more and more pixels will be set to either 0 or 1 during the iteration, by
taking advantage of this, one can construct a sparse data structure to accelerate
the method. Moreover, one can use diﬀerent tight frame systems such as those
from contourlets and curvelets [12,6] to better capture the boundary. These are
directions we will explore in the future.
References
1. Arivazhagan, S., Ganesan, L.: Texture segmentation using wavelet transform. Pat-
tern Recognition Letters 24, 3197–3203 (2003)
2. Bresson, X., Esedoglu, S., Vandergheynst, P., Thiran, J., Osher, S.: Fast global
minimization of the active contour/snake model. J. Math. Imaging Vision 28, 151–
167 (2007)
3. Cai, J.F., Chan, R.H., Shen, L.X., Shen, Z.W.: Simultaneously inpainting in image
and transformed domains. Numer. Math. 112, 509–533 (2009)
4. Cai, J.F., Chan, R.H., Shen, Z.W.: A framelet-based image inpainting algorithm.
Appl. Comput. Harmon. Anal. 24, 131–149 (2008)
5. Cai, J.F., Osher, S., Shen, Z.W.: Split Bregman methods and frame based image
restoration. Multiscale Modeling and Simulation 8, 337–369 (2009)
6. Cand`es, E., Demanet, L., Donoho, D., Ying, L.: Fast discrete curvelet transforms.
Multiscale Modeling and Simulation 5, 861–899 (2006)
7. Chan, R.H., Setzer, S., Steidl, G.: Inpainting by ﬂexible Haar-wavelet shrinkage.
SIAM J. Imaging Sci. 1, 273–293 (2008)
8. Chan, R.H., Chan, T.F., Shen, L.X., Shen, Z.W.: Wavelet algorithms for high-
resolution image reconstruction. SIAM J. Sci. Comput. 24, 1408–1432 (2003)
9. Chan, T.F., Esedoglu, S., Nikolova, M.: Algorithms for ﬁnding global minimizers
of image segmentation and denoising models. Technical Report 54, UCLA (2004)
422
X. Cai et al.
10. Chan, T.F., Vese, L.A.: Active contours without edges. IEEE Trans. Image Pro-
cess. 10, 266–277 (2001)
11. Daubechies, I.: Ten lectures on wavelets. Lecture Notes, vol. CBMS-NSF(61).
SIAM, Philadelphia (1992)
12. Do, M.N., Vetterli, M.: The contourlet transform: an eﬃcient directional multires-
olution image representation. IEEE Trans. Image Process. 14, 2091–2106 (2004)
13. Dong, B., Chien, A., Shen, Z.W.: Frame based segmentation for medical images.
Technical Report 22, UCLA (2010)
14. Dong, B., Shen, Z.W.: MRA based wavelet frames and applications. IAS Lecture
Notes Series, Summer Program on The Mathematics of Image Processing, Park
City Mathematics Institute (2010)
15. Donoho, D.L.: De-noising by soft-thresholding. IEEE Trans. Inform. Theory 41,
613–627 (1995)
16. Franchini, E., Morigi, S., Sgallari, F.: Segmentation of 3D tubular structures by
a PDE-based anisotropic diﬀusion model. In: Dæhlen, M., Floater, M., Lyche, T.,
Merrien, J.-L., Mørken, K., Schumaker, L.L. (eds.) MMCS 2008. LNCS, vol. 5862,
pp. 224–241. Springer, Heidelberg (2010)
17. Franchini, E., Morigi, S., Sgallari, F.: Composed segmentation of tubular structures
by an anisotropic PDE model. In: Tai, X.-C., Mørken, K., Lysaker, M., Lie, K.-A.
(eds.) SSVM 2009. LNCS, vol. 5567, pp. 75–86. Springer, Heidelberg (2009)
18. Gooya, A., Liao, H., et al.: A variational method for geometric regularization of
vascular segmentation in medical images. IEEE Trans. Image Process. 17, 1295–
1312 (2008)
19. Gonzales, R.C., Woods, R.E.: Digital Image Processing, 3rd edn. Prentice Hall,
Englewood Cliﬀs (2008)
20. Hassan, H., Farag, A.A.: Cerebrovascular segmentation for MRA data using levels
set. International Congress Series, vol. 1256, pp. 246–252 (2003)
21. Kirbas, C., Quek, F.: A review of vessel extraction techniques and algorithms.
ACM Computing Surveys 36, 81–121 (2004)
22. Ron, A., Shen, Z.W.: Aﬃne Systems in L2(Rd): The Analysis of the Analysis
Operator. J. Funct. Anal. 148, 408–447 (1997)
23. Sandberg, B., Chan, T.F.: A logic framework for active contours on multi-channel
images. J. Vis. Commun. Image R. 16, 333–358 (2005)
24. Scherl, H., et al.: Semi automatic level set segmentation and stenosis quantiﬁcation
of internal carotid artery in 3D CTA data sets. Medical Image Analysis 11, 21–34
(2007)
25. Unser, M.: Texture classiﬁcation and segmentation using wavelet frames. IEEE
Trans. Image Process. 4, 1549–1560 (1995)
26. Weickert, J.: Anisotropic Diﬀusion in Image Processing. Teubner, Stuttgart (1998)
