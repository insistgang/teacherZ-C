# [3-02] tCURLoRAå¼ é‡åˆ†è§£ (Tensor CUR Decomposition LoRA)

## è®ºæ–‡ä¿¡æ¯

**æ ‡é¢˜**: tCURLoRA: Tensor CUR Decomposition for Low-Rank Adaptation of Large Language Models

**ä½œè€…**: Xiaohao Cai ç­‰

**å‘è¡¨**: 2024 (å¼ é‡åˆ†è§£ + å‚æ•°é«˜æ•ˆå¾®è°ƒ)

**è®ºæ–‡è·¯å¾„**: `xiaohao_cai_papers/[3-02] å¼ é‡CURåˆ†è§£LoRA tCURLoRA.pdf`

---

## æ ¸å¿ƒè´¡çŒ®ç®€ä»‹

æœ¬è®ºæ–‡æå‡ºäº†tCURLoRAï¼Œä¸€ç§åŸºäºå¼ é‡CURåˆ†è§£çš„å‚æ•°é«˜æ•ˆå¾®è°ƒæ–¹æ³•ï¼š

### 1. å¼ é‡CURåˆ†è§£

**CURåˆ†è§£**:
- C: é€‰å–çš„åˆ— (Columns)
- U: è¿æ¥çŸ©é˜µ
- R: é€‰å–çš„è¡Œ (Rows)

**å¼ é‡æ‰©å±• (tCUR)**:
- å°†çŸ©é˜µCURæ‰©å±•åˆ°é«˜é˜¶å¼ é‡
- ä¿æŒä½ç§©ç»“æ„çš„åŒæ—¶å‡å°‘å‚æ•°

### 2. LoRAæ”¹è¿›

**ä¼ ç»ŸLoRA**:
```
W = W_0 + BA
å‚æ•°: r Ã— (d_in + d_out)
```

**tCURLoRA**:
```
W = W_0 + CUR
å‚æ•°: å¤§å¤§å‡å°‘ï¼Œç‰¹åˆ«æ˜¯é«˜ç»´æƒ…å†µ
```

**ä¼˜åŠ¿**:
- âœ… æ›´å°‘çš„å¯è®­ç»ƒå‚æ•°
- âœ… ä¿æŒæˆ–æå‡æ¨¡å‹æ€§èƒ½
- âœ… æ›´å¿«çš„è®­ç»ƒé€Ÿåº¦
- âœ… æ›´å¥½çš„å¯è§£é‡Šæ€§

### 3. åº”ç”¨åœºæ™¯

- å¤§è¯­è¨€æ¨¡å‹å¾®è°ƒ
- å¤šæ¨¡æ€æ¨¡å‹é€‚åº”
- è·¨è¯­è¨€è¿ç§»å­¦ä¹ 

---

## å¤ç°çŠ¶æ€

| ç»„ä»¶ | çŠ¶æ€ | è¯´æ˜ |
|:---|:---:|:---|
| å¼ é‡CURåˆ†è§£ | ğŸŸ¡ è¿›è¡Œä¸­ | æ ¸å¿ƒç®—æ³•æ¡†æ¶å·²æ­å»º |
| tCURLoRAå±‚ | ğŸŸ¡ è¿›è¡Œä¸­ | åŸºç¡€å®ç°å®Œæˆ |
| è®­ç»ƒæ¡†æ¶ | ğŸ”´ å¾…å®Œæˆ | å¾…é›†æˆ |
| è¯„ä¼°æŒ‡æ ‡ | ğŸ”´ å¾…å®Œæˆ | å¾…å®ç° |
| ç¤ºä¾‹è„šæœ¬ | ğŸŸ¡ è¿›è¡Œä¸­ | åŸºç¡€ç¤ºä¾‹å¯ç”¨ |

**æ€»ä½“çŠ¶æ€**: ğŸŸ¡ **è¿›è¡Œä¸­** (çº¦50%å®Œæˆ)

---

## æ–‡ä»¶ç»“æ„è¯´æ˜

```
[3-02]_tCURLoRA/
â”œâ”€â”€ README.md                    # æœ¬æ–‡ä»¶
â”œâ”€â”€ requirements.txt             # Pythonä¾èµ–
â”œâ”€â”€ src/                         # æºä»£ç 
â”‚   â”œâ”€â”€ __init__.py             # åŒ…åˆå§‹åŒ–
â”‚   â”œâ”€â”€ tcur_lora.py            # tCURLoRAæ ¸å¿ƒå®ç°
â”‚   â”œâ”€â”€ tensor_ops.py           # å¼ é‡æ“ä½œ
â”‚   â””â”€â”€ train.py                # è®­ç»ƒè„šæœ¬
â””â”€â”€ examples/                    # ç¤ºä¾‹ä»£ç 
    â””â”€â”€ finetune_example.py     # å¾®è°ƒç¤ºä¾‹
```

---

## ä½¿ç”¨æ–¹æ³•

### ç¯å¢ƒå‡†å¤‡

```bash
# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

### å¿«é€Ÿå¼€å§‹

```python
# å¯¼å…¥æ¨¡å—
from src.tcur_lora import tCURLoRAModel

# åˆ›å»ºtCURLoRAæ¨¡å‹
model = tCURLoRAModel(
    base_model="gpt2",
    tensor_rank=8,
    num_columns=16,
    num_rows=16
)

# æ‰“å°å‚æ•°ç»Ÿè®¡
model.print_trainable_parameters()

# è®­ç»ƒ
model.finetune(dataset, num_epochs=3)
```

### ä½¿ç”¨ç¤ºä¾‹è„šæœ¬

```bash
# è¿è¡Œå¾®è°ƒç¤ºä¾‹
python examples/finetune_example.py --model gpt2 --dataset wikitext
```

---

## æ ¸å¿ƒæ¦‚å¿µ

### çŸ©é˜µCURåˆ†è§£

ç»™å®šçŸ©é˜µ A âˆˆ â„^{mÃ—n}:
```
A â‰ˆ CUR
```

å…¶ä¸­:
- C âˆˆ â„^{mÃ—c}: é€‰å–çš„cåˆ—
- U âˆˆ â„^{cÃ—r}: è¿æ¥çŸ©é˜µ
- R âˆˆ â„^{rÃ—n}: é€‰å–çš„rè¡Œ

### å¼ é‡CURåˆ†è§£

å¯¹äº3é˜¶å¼ é‡ ğ’œ âˆˆ â„^{IÃ—JÃ—K}:
```
ğ’œ â‰ˆ ğ’ Ã—â‚ Uâ‚ Ã—â‚‚ Uâ‚‚ Ã—â‚ƒ Uâ‚ƒ Ã— â„›
```

å…¶ä¸­ Ã—â‚™ è¡¨ç¤ºn-æ¨¡ä¹˜ç§¯ã€‚

### tCURLoRAçš„ä¼˜åŠ¿

| æ–¹æ³• | å‚æ•°æ•°é‡ | å­˜å‚¨æ•ˆç‡ |
|:---|:---:|:---:|
| Full Fine-tuning | d Ã— d | 1Ã— |
| LoRA | rÃ—(d_in+d_out) | ~10Ã— |
| **tCURLoRA** | cÃ—d + rÃ—c + rÃ—d | ~20Ã— |

---

## ä¾èµ–è¦æ±‚

- Python >= 3.8
- PyTorch >= 2.0
- Transformers >= 4.30
- NumPy >= 1.24
- tensorly >= 0.8 (å¼ é‡åˆ†è§£)

---

## å‚è€ƒæ–‡çŒ®

1. Cai, X., et al. (2024). tCURLoRA: Tensor CUR Decomposition for Low-Rank Adaptation.
2. Mahoney, M. W., & Drineas, P. (2009). CUR matrix decompositions for improved data analysis.
3. Hu, E. J., et al. (2022). LoRA: Low-Rank Adaptation of Large Language Models.
4. Kolda, T. G., & Bader, B. W. (2009). Tensor decompositions and applications.

---

## æ›´æ–°æ—¥å¿—

- **2024-XX-XX**: åˆ›å»ºå¤ç°æ¡†æ¶
- **2024-XX-XX**: å®ç°åŸºç¡€å¼ é‡CURåˆ†è§£
- **2024-XX-XX**: é›†æˆLoRAæ¡†æ¶
