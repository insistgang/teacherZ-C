#!/usr/bin/env python3
"""
æ£€æŸ¥ç¬”è®°ä¸PDFçš„å¯¹åº”å…³ç³»
"""
import os
import re
from pathlib import Path

# ç›®å½•è®¾ç½®
PDF_DIR = Path("web-viewer/00_papers")
NOTE_DIR = Path("xiaohao_cai_ultimate_notes")

# PDFåˆ—è¡¨
pdf_files = list(PDF_DIR.glob("*.pdf"))
print(f"PDFæ€»æ•°: {len(pdf_files)}")

# ç¬”è®°åˆ—è¡¨
note_files = list(NOTE_DIR.glob("*è¶…ç²¾è¯»ç¬”è®°*.md")) + list(NOTE_DIR.glob("[0-9]*.md")) + list(NOTE_DIR.glob("[A-Z]*.md"))
note_files = [f for f in note_files if f.name not in ["README.md", "00_åˆ†ææŠ¥å‘Šæ±‡æ€».md", "è®ºæ–‡ç²¾è¯»å®ŒæˆæŠ¥å‘Š_20260220.md"]]
print(f"ç¬”è®°æ€»æ•°: {len(note_files)}")

# æå–ç¬”è®°ä¸­çš„å…ƒæ•°æ®
note_metadata = []
for note_file in note_files:
    try:
        content = note_file.read_text(encoding="utf-8")
        # æå–arXiv ID
        arxiv_match = re.search(r"arXiv[ï¼š:]\s*([\d.]+v?\d*)", content)
        arxiv_id = arxiv_match.group(1) if arxiv_match else None

        # æå–æ ‡é¢˜
        title_match = re.search(r"\*\*æ ‡é¢˜\*\*\s*\|\s*([^\n|]+)", content)
        title = title_match.group(1).strip() if title_match else None

        # æå–ä½œè€…
        author_match = re.search(r"\*\*ä½œè€…\*\*\s*\|\s*([^\n|]+)", content)
        author = author_match.group(1).strip() if author_match else None

        # æ£€æŸ¥æ˜¯å¦å·²å¡«å……
        is_filled = "å·²å¡«å……" in note_file.name

        note_metadata.append({
            "file": note_file.name,
            "arxiv_id": arxiv_id,
            "title": title,
            "author": author,
            "is_filled": is_filled
        })
    except Exception as e:
        print(f"è¯»å–ç¬”è®°å¤±è´¥: {note_file.name}, {e}")

# PDF-ç¬”è®°æ˜ å°„è¡¨
pdf_note_mapping = {
    "3Dæ–¹å‘åœºå˜æ¢ 3D Orientation Field.pdf": "3D_Orientation_Field_Transform",
    "SLaTä¸‰é˜¶æ®µåˆ†å‰² SLaT Segmentation.pdf": "SLaT_Three-stage_Segmentation",
    "HiFi-Mamba MRIé‡å»º HiFi-Mamba MRI Reconstruction.pdf": "HiFi-Mamba_MRI_Reconstruction",
    "3Dæ ‘æœ¨æç»˜å›¾å‰² 3D Tree Delineation.pdf": "3D_Tree_Delineation_Graph_Cut",
    "3Dæ ‘æœ¨åˆ†å‰²å›¾ 3D Tree Segmentation.pdf": "3D_Tree_Segmentation_MCGC",
    "3DKMI KrawtchoukçŸ©å½¢çŠ¶ç­¾å 3DKMI.pdf": "3DKMI",
    "2014_1410.0226_LiDAR Hyperspectral Registration.pdf": "LiDAR_Hyperspectral_Registration",
    "Bilevel Peer-Reviewing": "Bilevel_Peer-Reviewing_Problem",
    "CornerPoint3D 3Dæ£€æµ‹æ–°å°ºåº¦ CornerPoint3D.pdf": "CornerPoint3D",
    "å˜åˆ†åˆ†å‰²åŸºç¡€Mumford-Shahä¸ROF Mumford-Shah ROF.pdf": "Mumford-Shah_and_ROF_Linkage",
    "ä¸¤é˜¶æ®µåˆ†ç±» Two-Stage.pdf": "Two_Stage_High_Dimensional_Classification",
    "GAMEDè™šå‡æ–°é—»æ£€æµ‹ GAMED Fake News.pdf": "GAMED",
    "HiFi-MambaV2åˆ†å±‚MRI HiFi-MambaV2 Hierarchical MRI.pdf": "HiFi-MambaV2",
    "Equalizing Protected Attributes.pdf": "Equalizing_Protected_Attributes",
    "åŒ»å­¦å›¾åƒå°æ ·æœ¬å­¦ä¹  Medical Few-Shot.pdf": "Few-shot_Medical_Imaging_Inference",
    "é«˜ç»´é€†é—®é¢˜ä¸ç¡®å®šæ€§é‡åŒ– Uncertainty Quantification.pdf": "High-Dimensional_Inverse_Problems",
    "IIHT Medical Report IIHT.pdf": "IIHT",
    "è¿‘ç«¯åµŒå¥—é‡‡æ · Proximal Nested Sampling.pdf": "Proximal_Nested_Sampling",
    "æ— çº¿ç”µå¹²æ¶‰ä¸ç¡®å®šæ€§I Radio Interferometric I.pdf": "Radio_Interferometric_Imaging_I",
    "æ— çº¿ç”µå¹²æ¶‰ä¸ç¡®å®šæ€§II Radio Interferometric II.pdf": "Radio_Interferometric_Imaging_II",
    "åœ¨çº¿æ— çº¿ç”µå¹²æ¶‰æˆåƒ Online Radio Imaging.pdf": "Online_Radio_Interferometric_Imaging",
    "Tuckerè¿‘ä¼¼ Tucker Approximation.pdf": "Practical_Sketching_Tucker_Approximation",
    "Tensor_Train_Approximation.pdf": "Tensor_Train_Approximation",
    "åŒé¢Sketchingå¼ é‡ Two-Sided Sketching.pdf": "Two_Sided_Sketching",
    "GO-LDA": "GO-LDA",
    "ç‚¹äº‘ç¥ç»è¡¨ç¤º Neural Varifolds.pdf": "Neural_varifolds",
    "è¯­ä¹‰æ¯”ä¾‹åˆ†å‰² Semantic Proportions.pdf": "Semantic_Segmentation_by_Proportions",
    "è·¨åŸŸLiDARæ£€æµ‹ Cross-Domain LiDAR.pdf": "Cross-Domain_LiDAR",
    "å¯è§è¡¨é¢æ£€æµ‹ Detect Closer Surfaces.pdf": "Detect_Closer_Surfaces",
    "Diffusion Brain MRI.pdf": "Discrepancy-based_Diffusion_MRI",
    "EmoPerso Emotion-Aware.pdf": "EmoPerso",
    "é«˜æ•ˆPEFTå¾®è°ƒ Less but Better PEFT.pdf": "Less_but_Better_PEFT",
    "è›‹ç™½è´¨ç»“æ„ç½‘ç»œå›¾LL4G LL4G Graph.pdf": "LL4G",
    "HIPPD Brain-Inspired.pdf": "HIPPD",
    "å¤§æ¨¡å‹é«˜æ•ˆå¾®è°ƒCALM CALM Fine-tuning.pdf": "CALM",
    "æ¦‚å¿µçº§XAIæŒ‡æ ‡ Concept XAI.pdf": "Concept-Based_XAI_Metrics",
    "TransNetåŠ¨ä½œè¯†åˆ« TransNet HAR.pdf": "TransNet",
    "æ·±åº¦å­¦ä¹ æ¶æ„ç»¼è¿° CNNs RNNs Transformers.pdf": "CNNs_RNNs_Transformers",
    "å¤šå±‚æ¬¡å¯è§£é‡ŠAI Multilevel XAI.pdf": "Multilevel_Explainable_AI",
    "æ¡†æ¶åˆ†å‰²ç®¡çŠ¶ç»“æ„ Framelet Tubular.pdf": "Framelet",
    "å¤šç±»åˆ†å‰²è¿­ä»£ROF Iterated ROF.pdf": "å¤šç±»åˆ†å‰²è¿­ä»£ROF",
    "åˆ†å‰²æ–¹æ³•è®ºæ€»è§ˆ SaT Overview.pdf": "åˆ†å‰²æ–¹æ³•è®ºæ€»è§ˆ",
    "é«˜æ•ˆå˜åˆ†åˆ†ç±» Efficient Variational.pdf": "é«˜æ•ˆå˜åˆ†åˆ†ç±»",
    "GRASPTrack": "GRASPTrack",
    "MotionDuet 3D Motion.pdf": "MotionDuet",
    "MOGO 3Däººä½“è¿åŠ¨ç”Ÿæˆ MOGO Motion.pdf": "MOGO",
    "Talk2Radar": "Talk2Radar",
    "tCURLoRA": "tCURLoRA",
    "CenSegNetä¸­å¿ƒä½“": "CenSegNet",
    "DNCNet": "DNCNet",
    "ISAR": "ISAR",
    "PURIFY": "PURIFY",
    "RobustPCA": "RobustPCA",
    "èˆ¹èˆ¶åŒ¹é…é¥æ„Ÿ Ship Matching.pdf": "Ship_Matching",
    "ç¨€ç–è´å¶æ–¯": "ç¨€ç–è´å¶æ–¯",
    "æ•°æ®å¢å¼ºç»¼è¿°": "æ•°æ®å¢å¼º",
    "å¯è§£é‡ŠAIç»¼è¿° XAI Survey.pdf": "å¯è§£é‡ŠAIç»¼è¿°",
    "é›·è¾¾å·¥ä½œæ¨¡å¼è¯†åˆ«": "é›·è¾¾å·¥ä½œæ¨¡å¼",
    "å¹³è¡¡ç¥ç»ç½‘ç»œæœç´¢": "å¹³è¡¡ç¥ç»ç½‘ç»œæœç´¢",
    "Biologically-Inspired": "Biologically-Inspired",
    "Federated_Learning": "Federated_Learning",
    "Deep_Learning_Rectum": "Deep_Learning_Rectum",
    "2019_Thylakoid": "2019_Thylakoid",
    "2023_Limpets": "2023_Limpets",
    "2025_Genes_Shells": "2025_Genes_Shells",
    "éè´Ÿå­ç©ºé—´": "Non-negative_Subspace",
    "åˆ†å‰²æ¢å¤è”åˆæ¨¡å‹ Segmentation Restoration.pdf": "Variational_Segmentation-Restoration",
    "çƒé¢å°æ³¢åˆ†å‰² Wavelet Sphere.pdf": "Wavelet_Segmentation_on_Sphere",
    "ä¸¤é˜¶æ®µå›¾åƒåˆ†å‰²": "Two-Stage_Segmentation",
    "å°æ³¢æ¡†æ¶è¡€ç®¡åˆ†å‰² Tight-Frame Vessel.pdf": "Tight-Frame_Vessel",
    "ç”Ÿç‰©å­”éš™åˆ†å‰² Bio-Pores.pdf": "ç”Ÿç‰©å­”éš™",
    "3Dæ ‘æœ¨åˆ†å‰²å›¾å‰² 3D Tree Graph Cut.pdf": "3D_Tree_Delineation",  # æ³¨æ„
    "3D_Growth": "3D_Growth_Trajectory",
}

# æ£€æŸ¥å¯¹åº”å…³ç³»
matched = []
unmatched_pdfs = []
mismatched = []

for pdf in pdf_files:
    pdf_name = pdf.name
    matched_note = None

    for pdf_key, note_key in pdf_note_mapping.items():
        if pdf_key.lower() in pdf_name.lower() or pdf_name.lower().replace(' ', '_') in note_key.lower():
            # æ£€æŸ¥ç¬”è®°æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            possible_notes = [
                NOTE_DIR / f"{note_key}_è¶…ç²¾è¯»ç¬”è®°_å·²å¡«å…….md",
                NOTE_DIR / f"{note_key}_è¶…ç²¾è¯»ç¬”è®°.md",
                NOTE_DIR / f"{note_key}.md",
            ]
            for note_path in possible_notes:
                if note_path.exists():
                    matched_note = note_path
                    break
            break

    if matched_note:
        matched.append((pdf_name, matched_note.name))
    else:
        unmatched_pdfs.append(pdf_name)

# æ£€æŸ¥æ˜¯å¦æœ‰ç¬”è®°æ²¡æœ‰å¯¹åº”PDF
all_matched_notes = set([n for _, n in matched])
unmatched_notes = []
for note in note_files:
    if note.name not in all_matched_notes:
        unmatched_notes.append(note.name)

print("\n" + "="*60)
print("PDFä¸ç¬”è®°å¯¹åº”å…³ç³»æ£€æŸ¥ç»“æœ")
print("="*60)
print(f"\næ€»PDFæ•°: {len(pdf_files)}")
print(f"æ€»ç¬”è®°æ•°: {len(note_files)}")
print(f"å·²åŒ¹é…: {len(matched)}")
print(f"æœªåŒ¹é…PDF: {len(unmatched_pdfs)}")
print(f"æœªåŒ¹é…ç¬”è®°: {len(unmatched_notes)}")

print("\n" + "-"*60)
print("å·²åŒ¹é…ç¤ºä¾‹ (å‰15ä¸ª):")
print("-"*60)
for pdf, note in matched[:15]:
    print(f"  {pdf[:50]:<50} <-> {note[:40]}")

if len(unmatched_pdfs) > 0:
    print("\n" + "-"*60)
    print(f"æœªåŒ¹é…çš„PDF ({len(unmatched_pdfs)}ä¸ª):")
    print("-"*60)
    for pdf in unmatched_pdfs[:20]:
        print(f"  - {pdf}")

if len(unmatched_notes) > 0:
    print("\n" + "-"*60)
    print(f"æœªåŒ¹é…çš„ç¬”è®° ({len(unmatched_notes)}ä¸ª):")
    print("-"*60)
    for note in unmatched_notes[:20]:
        print(f"  - {note}")

# æ£€æŸ¥ç¬”è®°è´¨é‡ - æŠ½æ ·æ£€æŸ¥å·²å¡«å……ç¬”è®°
print("\n" + "="*60)
print("ç¬”è®°è´¨é‡æŠ½æ ·æ£€æŸ¥ (å·²å¡«å……ç¬”è®°)")
print("="*60)

filled_notes = [n for n in note_files if "å·²å¡«å……" in n.name]
print(f"\nå·²å¡«å……ç¬”è®°æ•°: {len(filled_notes)}")

# æ£€æŸ¥5ä¸ªå·²å¡«å……ç¬”è®°çš„å†…å®¹è´¨é‡
print("\næŠ½æ ·æ£€æŸ¥5ä¸ªå·²å¡«å……ç¬”è®°çš„ç»“æ„:")
sample_notes = filled_notes[:5]
for note in sample_notes:
    content = note.read_text(encoding="utf-8")
    has_math = "## ğŸ”¢ 1. æ•°å­¦å®¶Agent" in content or "### 1.1 æ ¸å¿ƒæ•°å­¦æ¡†æ¶" in content
    has_engineer = "## ğŸ”§ 2. å·¥ç¨‹å¸ˆAgent" in content or "### 2.1 ç®—æ³•æ¶æ„" in content
    has_app = "## ğŸ’¼ 3. åº”ç”¨ä¸“å®¶Agent" in content
    has_skeptic = "## ğŸ¤¨ 4. è´¨ç–‘è€…Agent" in content
    has_summary = "## ğŸ¯ 5. ç»¼åˆç†è§£" in content
    has_code = "```python" in content
    has_formula = "$$" in content

    quality_score = sum([has_math, has_engineer, has_app, has_skeptic, has_summary, has_code, has_formula])
    status = "âœ… ä¼˜ç§€" if quality_score >= 6 else "âš ï¸ ä¸€èˆ¬" if quality_score >= 4 else "âŒ å·®"

    print(f"\n  {note.name[:50]}")
    print(f"    çŠ¶æ€: {status} | è´¨é‡åˆ†: {quality_score}/7")
    print(f"    æ•°å­¦å®¶:{has_math} å·¥ç¨‹å¸ˆ:{has_engineer} åº”ç”¨:{has_app} è´¨ç–‘:{has_skeptic} æ€»ç»“:{has_summary} ä»£ç :{has_code} å…¬å¼:{has_formula}")
