# DNCNet: æ·±åº¦é›·è¾¾ä¿¡å·å»å™ªä¸è¯†åˆ«

> **è¶…ç²¾è¯»ç¬”è®°** | 5-Agentè¾©è®ºåˆ†æç³»ç»Ÿ
> **çŠ¶æ€**: å·²å®Œæˆ - åŸºäºPDFåŸæ–‡ç²¾è¯»
> **ç²¾è¯»æ—¶é—´**: 2026-02-20
> **è®ºæ–‡æ¥æº**: D:\Documents\zx\web-viewer\00_papers\DNCNeté›·è¾¾å»å™ª DNCNet.pdf

---

## ğŸ“‹ è®ºæ–‡å…ƒæ•°æ®

| å±æ€§ | ä¿¡æ¯ |
|------|------|
| **å®Œæ•´æ ‡é¢˜** | DNCNet: Deep Radar Signal Denoising and Recognition |
| **ä¸­æ–‡æ ‡é¢˜** | DNCNet: æ·±åº¦é›·è¾¾ä¿¡å·å»å™ªä¸è¯†åˆ« |
| **ä½œè€…** | Mingyang Du, Ping Zhong, **Xiaohao Cai** (Member, IEEE), Daping Bi |
| **ä½œè€…æ’åº** | Du M (ç¬¬ä¸€ä½œè€…), Zhong P, **Cai X** (ç¬¬ä¸‰ä½œè€…/ä¸»è¦è´¡çŒ®è€…), Bi D (é€šè®¯ä½œè€…) |
| **Xiaohao Caiè§’è‰²** | åˆè‘—è€…/ä¸»è¦è´¡çŒ®è€…ï¼ŒIEEEä¼šå‘˜ï¼Œæ¥è‡ªå—å®‰æ™®é¡¿å¤§å­¦ |
| **å•ä½** | University of Southampton, UK; National University of Defense Technology, China |
| **å¹´ä»½** | 2022 |
| **æœŸåˆŠ** | IEEE Transactions on Aerospace and Electronic Systems (TAES) |
| **å·æœŸ** | Vol. 58, No. 4 |
| **é¡µç ** | pp. 3549-3562 |
| **DOI** | 10.1109/TAES.2022.3153756 |
| **èµ„åŠ©** | ä¸­å›½å›½å®¶è‡ªç„¶ç§‘å­¦åŸºé‡‘ï¼ˆGrant 61971428ï¼‰ |
| **é¢†åŸŸ** | é›·è¾¾ä¿¡å·å¤„ç† / æ·±åº¦å­¦ä¹  / ä¿¡å·è¯†åˆ« |
| **PDFè·¯å¾„** | web-viewer/00_papers/DNCNeté›·è¾¾å»å™ª DNCNet.pdf |
| **é¡µæ•°** | 14é¡µ |

### ğŸ“ æ‘˜è¦

æœ¬æ–‡é’ˆå¯¹é›·è¾¾ä¿¡å·è¯†åˆ«ä¸­è®­ç»ƒé›†ä¸æµ‹è¯•é›†ä¿¡å™ªæ¯”ï¼ˆSNRï¼‰ä¸åŒ¹é…å¯¼è‡´åˆ†ç±»å™¨æ€§èƒ½æ€¥å‰§ä¸‹é™çš„é—®é¢˜ï¼Œæå‡ºäº†DNCNetï¼ˆDenoising and Classification Networkï¼‰ï¼Œä¸€ç§ç«¯åˆ°ç«¯çš„é›·è¾¾ä¿¡å·å»å™ªä¸è¯†åˆ«ç½‘ç»œã€‚ä¼ ç»Ÿæ–¹æ³•åœ¨ä½SNRç¯å¢ƒä¸‹å‡ ä¹å¤±æ•ˆï¼Œè€Œæœ¬æ–‡é€šè¿‡è”åˆä¼˜åŒ–å»å™ªå’Œåˆ†ç±»ä¸¤ä¸ªä»»åŠ¡ï¼Œå®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚ä¸»è¦è´¡çŒ®åŒ…æ‹¬ï¼š(1)è®¾è®¡äº†é›·è¾¾ä¿¡å·æ£€æµ‹ä¸åˆæˆæœºåˆ¶ï¼Œç”Ÿæˆæˆå¯¹çš„å¹²å‡€/å«å™ªè®­ç»ƒæ•°æ®ï¼›(2)æå‡ºåŒé˜¶æ®µè®­ç»ƒç­–ç•¥â€”â€”ç¬¬ä¸€é˜¶æ®µè”åˆä¼˜åŒ–å»å™ªæŸå¤±å’Œåˆ†ç±»æŸå¤±ï¼Œç¬¬äºŒé˜¶æ®µä»…ä¼˜åŒ–åˆ†ç±»æŸå¤±ï¼›(3)åœ¨è‡ªå»ºSIGNAL-8æ•°æ®é›†å’Œå…¬å¼€RADIOML 2018.01Aæ•°æ®é›†ä¸ŠéªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œåœ¨-10dB SNRä¸‹ä»ä¿æŒè¾ƒé«˜å‡†ç¡®ç‡ã€‚

**æ ¸å¿ƒè´¡çŒ®**ï¼š
1. ç«¯åˆ°ç«¯å»å™ª-åˆ†ç±»ç»Ÿä¸€æ¡†æ¶
2. åŒé˜¶æ®µè®­ç»ƒç­–ç•¥ï¼ˆè§£å†³ç›®æ ‡å†²çªé—®é¢˜ï¼‰
3. é›·è¾¾ä¿¡å·åˆæˆæœºåˆ¶ï¼ˆè§£å†³æˆå¯¹æ•°æ®ç¨€ç¼ºé—®é¢˜ï¼‰
4. å¤šç±»å‹å™ªå£°é²æ£’æ€§ï¼ˆé«˜æ–¯ç™½å™ªå£°ã€é«˜æ–¯æœ‰è‰²å™ªå£°ã€è„‰å†²å™ªå£°ï¼‰

---

## ğŸ”¢ 1. æ•°å­¦å®¶Agentï¼šç†è®ºåˆ†æ

### 1.1 é›·è¾¾ä¿¡å·æ•°å­¦æ¨¡å‹

**é›·è¾¾ä¿¡å·è¡¨ç¤º**ï¼š

é›·è¾¾ä¿¡å·é€šå¸¸è¡¨ç¤ºä¸ºå¤æ•°åºåˆ—ï¼š
$$x[n] = A[n] \exp(j\phi[n]), \quad n = 0, 1, ..., N-1$$

å…¶ä¸­ï¼š
- $A[n]$ï¼šä¿¡å·åŒ…ç»œï¼ˆå¹…åº¦è°ƒåˆ¶ï¼‰
- $\phi[n]$ï¼šç¬æ—¶ç›¸ä½ï¼ˆé¢‘ç‡è°ƒåˆ¶ï¼‰
- $N$ï¼šä¿¡å·é•¿åº¦

**å«å™ªè§‚æµ‹æ¨¡å‹**ï¼š

$$\hat{x}[n] = x[n] + w[n]$$

å…¶ä¸­ $w[n]$ æ˜¯å™ªå£°ï¼Œå¯ä»¥æ˜¯ï¼š
1. **é«˜æ–¯ç™½å™ªå£°ï¼ˆAWGNï¼‰**ï¼š$w[n] \sim \mathcal{CN}(0, \sigma^2)$
2. **é«˜æ–¯æœ‰è‰²å™ªå£°**ï¼šå…·æœ‰ç‰¹å®šåŠŸç‡è°±å¯†åº¦
3. **è„‰å†²å™ªå£°**ï¼šé‡å°¾åˆ†å¸ƒï¼ˆå¦‚Alphaç¨³å®šåˆ†å¸ƒï¼‰

**é«˜æ–¯æœ‰è‰²å™ªå£°åŠŸç‡è°±å¯†åº¦**ï¼š

$$P(\omega) = \sum_{k=-\infty}^{\infty} R[k] \exp(-j\omega k)$$

å…¶ä¸­ $R[k]$ æ˜¯è‡ªç›¸å…³åºåˆ—ã€‚

**Alphaç¨³å®šåˆ†å¸ƒç‰¹å¾å‡½æ•°**ï¼ˆè„‰å†²å™ªå£°ï¼‰ï¼š

$$\varphi(t) = \begin{cases}
\exp\{j\delta t - \gamma^\alpha |t|^\alpha [1 + j\beta \text{sgn}(t) \tan(\frac{\alpha\pi}{2})]\}, & \alpha \neq 1 \\
\exp\{j\delta t - \gamma |t| [1 + j\beta \text{sgn}(t) \frac{2}{\pi}\log|t|]\}, & \alpha = 1
\end{cases}$$

å‚æ•°ï¼š$\alpha$ï¼ˆç‰¹å¾æŒ‡æ•°ï¼‰ã€$\beta$ï¼ˆå¯¹ç§°å‚æ•°ï¼‰ã€$\gamma$ï¼ˆå°ºåº¦ï¼‰ã€$\delta$ï¼ˆä½ç½®ï¼‰

### 1.2 ç½‘ç»œæ¶æ„æ•°å­¦è¡¨ç¤º

**æ•´ä½“æ¶æ„**ï¼š

DNCNetç”±ä¸‰ä¸ªå­ç½‘ç»œçº§è”æ„æˆï¼š
$$\hat{x} = \mathcal{C}(\mathcal{D}(\hat{x}_{noisy}; \epsilon); \theta_c)$$

å…¶ä¸­ï¼š
- $\epsilon = \mathcal{E}(\hat{x}_{noisy}; \theta_e)$ï¼šå™ªå£°æ°´å¹³ä¼°è®¡
- $\mathcal{D}(\cdot; \theta_d)$ï¼šå»å™ªå­ç½‘ç»œï¼ˆU-Netï¼‰
- $\mathcal{C}(\cdot; \theta_c)$ï¼šåˆ†ç±»å­ç½‘ç»œï¼ˆResNet18-1Dï¼‰

**å™ªå£°æ°´å¹³ä¼°è®¡å­ç½‘ç»œ**ï¼š

$$\epsilon[n] = \text{CNN5}(\hat{x}_{noisy}[n]; \theta_e)$$

5å±‚å…¨å·ç§¯ç½‘ç»œï¼Œæ¯å±‚32é€šé“ï¼Œæ»¤æ³¢å™¨å¤§å°3ï¼š
$$\epsilon = f_e \circ f_e \circ f_e \circ f_e \circ f_e (\hat{x}_{noisy})$$

**U-Netå»å™ªå­ç½‘ç»œ**ï¼š

ç¼–ç å™¨-è§£ç å™¨æ¶æ„ï¼Œ16å±‚ï¼š
$$\hat{x}_{clean} = \text{U-Net}(\hat{x}_{noisy}, \epsilon; \theta_d)$$

è·³è·ƒè¿æ¥ï¼š
$$x^{(l)}_{decoder} = \text{Concat}(x^{(l)}_{decoder}, x^{(l)}_{encoder})$$

**ResNet18-1Dåˆ†ç±»å­ç½‘ç»œ**ï¼š

ä¿®æ”¹ç‰ˆResNet18ï¼Œå°†2Då·ç§¯æ›¿æ¢ä¸º1Då·ç§¯ï¼š
$$y = \text{ResNet18-1D}(\hat{x}_{clean}; \theta_c)$$

Softmaxè¾“å‡ºï¼š
$$P(y=k|x) = \frac{\exp(z_k)}{\sum_{i=1}^{K} \exp(z_i)}$$

### 1.3 åŒé˜¶æ®µè®­ç»ƒç­–ç•¥

**ç¬¬ä¸€é˜¶æ®µï¼šè”åˆä¼˜åŒ–**ï¼š

æ€»æŸå¤±å‡½æ•°ï¼š
$$\mathcal{L}_{total} = \lambda_1 \mathcal{L}_{recon} + \lambda_2 \mathcal{L}_{cls}$$

**é‡å»ºæŸå¤±ï¼ˆMSEï¼‰**ï¼š

$$\mathcal{L}_{recon} = \frac{1}{2BN} \sum_{b=1}^{B} \sum_{n=1}^{N} \sum_{c=1}^{2} |\hat{x}_{clean}^{(b)}[n, c] - x_{clean}^{(b)}[n, c]|^2$$

å…¶ä¸­ $B$ æ˜¯batch sizeï¼Œ$c=1,2$ åˆ†åˆ«è¡¨ç¤ºå®éƒ¨å’Œè™šéƒ¨ã€‚

**åˆ†ç±»æŸå¤±ï¼ˆäº¤å‰ç†µï¼‰**ï¼š

$$\mathcal{L}_{cls} = -\frac{1}{B} \sum_{b=1}^{B} \sum_{k=1}^{K} y_k^{(b)} \log(\hat{y}_k^{(b)})$$

**ç¬¬äºŒé˜¶æ®µï¼šåˆ†ç±»å¾®è°ƒ**ï¼š

ä»…ä½¿ç”¨åˆ†ç±»æŸå¤±ï¼š
$$\mathcal{L}_{total} = \mathcal{L}_{cls}$$

å…è®¸å»å™ªç‰¹å¾é€‚åº”åˆ†ç±»ä»»åŠ¡ï¼Œå¯èƒ½ç‰ºç‰²éƒ¨åˆ†é‡å»ºè´¨é‡ä»¥æå‡åˆ¤åˆ«æ€§ã€‚

### 1.4 ç†è®ºæ€§è´¨åˆ†æ

| æ€§è´¨ | åˆ†æ | è¯´æ˜ |
|------|------|------|
| æ”¶æ•›æ€§ | åŒé˜¶æ®µä¿è¯ | ç¬¬ä¸€é˜¶æ®µè”åˆæ”¶æ•›ï¼Œç¬¬äºŒé˜¶æ®µå¾®è°ƒ |
| ç¨³å®šæ€§ | å¤šå™ªå£°é²æ£’ | ä¸‰ç§å™ªå£°ç±»å‹éªŒè¯ |
| å¤æ‚åº¦ | O(NÂ·CÂ²) | Nä¸ºä¿¡å·é•¿åº¦ï¼ŒCä¸ºé€šé“æ•° |
| æ³›åŒ–æ€§ | SNRæ³›åŒ– | è®­ç»ƒ30dBï¼Œæµ‹è¯•-10åˆ°30dB |

### 1.5 æ•°å­¦åˆ›æ–°ç‚¹

1. **ç«¯åˆ°ç«¯è”åˆä¼˜åŒ–**ï¼šå»å™ªä¸åˆ†ç±»ç»Ÿä¸€æ¡†æ¶
2. **åŒé˜¶æ®µç­–ç•¥**ï¼šè§£å†³ç›®æ ‡å†²çªé—®é¢˜
3. **å™ªå£°æ°´å¹³ä¼°è®¡**ï¼šè‡ªé€‚åº”å»å™ªå¼ºåº¦
4. **1D CNNæ¶æ„**ï¼šé¿å…æ—¶é¢‘å˜æ¢ä¿¡æ¯æŸå¤±

---

## ğŸ”§ 2. å·¥ç¨‹å¸ˆAgentï¼šå®ç°åˆ†æ

### 2.1 ç½‘ç»œæ¶æ„

```
è¾“å…¥: å«å™ªé›·è¾¾ä¿¡å· (Batch Ã— 2 Ã— N)
    â†“
[å™ªå£°æ°´å¹³ä¼°è®¡å­ç½‘ç»œ]
    â”œâ”€â”€ Conv1D(2â†’32, kernel=3)
    â”œâ”€â”€ Conv1D(32â†’32, kernel=3) Ã— 3
    â””â”€â”€ Conv1D(32â†’2, kernel=3)
    è¾“å‡º: å™ªå£°æ°´å¹³å›¾ Îµ (Batch Ã— 2 Ã— N)
    â†“
[U-Netå»å™ªå­ç½‘ç»œ] (16å±‚)
    â”œâ”€â”€ ç¼–ç å™¨ (ä¸‹é‡‡æ ·)
    â”‚   â”œâ”€â”€ Conv1D(2â†’64, kernel=3) + AvgPool
    â”‚   â”œâ”€â”€ Conv1D(64â†’128, kernel=3) + AvgPool
    â”‚   â””â”€â”€ Conv1D(128â†’256, kernel=3) + AvgPool
    â”œâ”€â”€ ç“¶é¢ˆå±‚
    â”‚   â””â”€â”€ Conv1D(256â†’256, kernel=3)
    â””â”€â”€ è§£ç å™¨ (ä¸Šé‡‡æ ·)
        â”œâ”€â”€ ConvTranspose1D(256â†’128, kernel=3)
        â”œâ”€â”€ ConvTranspose1D(128â†’64, kernel=3)
        â””â”€â”€ Conv1D(64â†’2, kernel=3)
    è¾“å‡º: å»å™ªä¿¡å· (Batch Ã— 2 Ã— N)
    â†“
[ResNet18-1Dåˆ†ç±»å­ç½‘ç»œ]
    â”œâ”€â”€ Conv1D(2â†’64, kernel=3)
    â”œâ”€â”€ æ®‹å·®å— Ã— 8 (64/128/256/512 é€šé“)
    â”œâ”€â”€ GlobalAvgPool1D
    â””â”€â”€ FC(512 â†’ K_classes)
    è¾“å‡º: ç±»åˆ«æ¦‚ç‡åˆ†å¸ƒ
```

### 2.2 å…³é”®å®ç°è¦ç‚¹

**å™ªå£°æ°´å¹³ä¼°è®¡å­ç½‘ç»œ**ï¼š

```python
import torch
import torch.nn as nn

class NoiseEstimator(nn.Module):
    """å™ªå£°æ°´å¹³ä¼°è®¡å­ç½‘ç»œ (5å±‚å…¨å·ç§¯)"""
    def __init__(self, in_channels=2):
        super().__init__()
        self.layers = nn.Sequential(
            # ç¬¬1å±‚
            nn.Conv1d(in_channels, 32, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            # ç¬¬2-4å±‚ (ä¸­é—´å±‚)
            nn.Conv1d(32, 32, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv1d(32, 32, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv1d(32, 32, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            # ç¬¬5å±‚
            nn.Conv1d(32, in_channels, kernel_size=3, padding=1)
        )

    def forward(self, x):
        # x: (Batch, 2, N) - å®éƒ¨+è™šéƒ¨
        return self.layers(x)
```

**U-Netå»å™ªå­ç½‘ç»œ**ï¼š

```python
class UNet1D(nn.Module):
    """1D U-Netç”¨äºä¿¡å·å»å™ª"""
    def __init__(self, in_channels=2):
        super().__init__()

        # ç¼–ç å™¨
        self.enc1 = self._encoder_block(in_channels, 64)
        self.enc2 = self._encoder_block(64, 128)
        self.enc3 = self._encoder_block(128, 256)

        # ç“¶é¢ˆ
        self.bottleneck = nn.Sequential(
            nn.Conv1d(256, 256, kernel_size=3, padding=1),
            nn.ReLU(inplace=True)
        )

        # è§£ç å™¨
        self.dec3 = self._decoder_block(256, 128)
        self.dec2 = self._decoder_block(128, 64)
        self.dec1 = nn.Sequential(
            nn.Conv1d(64, 64, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv1d(64, in_channels, kernel_size=3, padding=1)
        )

        # æ± åŒ–å’Œä¸Šé‡‡æ ·
        self.pool = nn.AvgPool1d(2)
        self.upsample = nn.Upsample(scale_factor=2, mode='linear', align_corners=False)

    def _encoder_block(self, in_ch, out_ch):
        return nn.Sequential(
            nn.Conv1d(in_ch, out_ch, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv1d(out_ch, out_ch, kernel_size=3, padding=1),
            nn.ReLU(inplace=True)
        )

    def _decoder_block(self, in_ch, out_ch):
        return nn.Sequential(
            nn.ConvTranspose1d(in_ch, out_ch, kernel_size=3, stride=2, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv1d(out_ch, out_ch, kernel_size=3, padding=1),
            nn.ReLU(inplace=True)
        )

    def forward(self, x, epsilon):
        # x: å«å™ªä¿¡å·
        # epsilon: å™ªå£°æ°´å¹³å›¾

        # ç¼–ç å™¨ (å¸¦è·³è·ƒè¿æ¥)
        e1 = self.enc1(x)
        x1 = self.pool(e1)

        e2 = self.enc2(x1)
        x2 = self.pool(e2)

        e3 = self.enc3(x2)
        x3 = self.pool(e3)

        # ç“¶é¢ˆ
        b = self.bottleneck(x3)

        # è§£ç å™¨ (æ‹¼æ¥è·³è·ƒè¿æ¥)
        d3 = self.dec3(b)
        d2 = self.dec2(d3)
        d1 = self.dec1(d2)

        return d1
```

**ResNet18-1Dåˆ†ç±»å­ç½‘ç»œ**ï¼š

```python
class ResNetBlock1D(nn.Module):
    """1Dæ®‹å·®å—"""
    def __init__(self, in_channels, out_channels, stride=1):
        super().__init__()
        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=3,
                               stride=stride, padding=1, bias=False)
        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=3,
                               padding=1, bias=False)

        selfShortcut = nn.Sequential()
        if stride != 1 or in_channels != out_channels:
            selfShortcut = nn.Sequential(
                nn.Conv1d(in_channels, out_channels, kernel_size=1,
                         stride=stride, bias=False)
            )

    def forward(self, x):
        out = torch.relu(self.conv1(x))
        out = self.conv2(out)
        out += selfShortcut(x)
        out = torch.relu(out)
        return out

class ResNet18_1D(nn.Module):
    """ä¿®æ”¹ç‰ˆResNet18ç”¨äº1Dä¿¡å·åˆ†ç±»"""
    def __init__(self, in_channels=2, num_classes=8):
        super().__init__()

        # åˆå§‹å·ç§¯å±‚ (æ›¿æ¢7Ã—7ä¸º3Ã—3)
        self.conv1 = nn.Conv1d(in_channels, 64, kernel_size=3, stride=1,
                              padding=1, bias=False)
        self.relu = nn.ReLU(inplace=True)

        # æ®‹å·®å±‚ (å»é™¤BatchNorm)
        self.layer1 = self._make_layer(64, 64, 2)
        self.layer2 = self._make_layer(64, 128, 2, stride=2)
        self.layer3 = self._make_layer(128, 256, 2, stride=2)
        self.layer4 = self._make_layer(256, 512, 2, stride=2)

        # åˆ†ç±»å¤´
        self.avgpool = nn.AdaptiveAvgPool1d(1)
        self.fc = nn.Linear(512, num_classes)

    def _make_layer(self, in_ch, out_ch, blocks, stride=1):
        layers = []
        layers.append(ResNetBlock1D(in_ch, out_ch, stride))
        for _ in range(1, blocks):
            layers.append(ResNetBlock1D(out_ch, out_ch))
        return nn.Sequential(*layers)

    def forward(self, x):
        x = self.relu(self.conv1(x))
        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)
        x = self.avgpool(x)
        x = x.view(x.size(0), -1)
        x = self.fc(x)
        return x
```

**å®Œæ•´çš„DNCNet**ï¼š

```python
class DNCNet(nn.Module):
    """DNCNet: ç«¯åˆ°ç«¯å»å™ªä¸åˆ†ç±»ç½‘ç»œ"""
    def __init__(self, num_classes=8):
        super().__init__()
        self.noise_estimator = NoiseEstimator()
        self.denoiser = UNet1D()
        self.classifier = ResNet18_1D(num_classes=num_classes)

    def forward(self, noisy_signal):
        """
        Args:
            noisy_signal: (Batch, 2, N) å®éƒ¨+è™šéƒ¨

        Returns:
            clean_signal: å»å™ªä¿¡å·
            class_logits: ç±»åˆ«logits
        """
        # ä¼°è®¡å™ªå£°æ°´å¹³
        epsilon = self.noise_estimator(noisy_signal)

        # å»å™ª
        clean_signal = self.denoiser(noisy_signal, epsilon)

        # åˆ†ç±»
        class_logits = self.classifier(clean_signal)

        return clean_signal, class_logits

    def inference(self, noisy_signal):
        """æ¨ç†æ¨¡å¼"""
        with torch.no_grad():
            _, class_logits = self.forward(noisy_signal)
            probabilities = torch.softmax(class_logits, dim=1)
            return probabilities
```

### 2.3 åŒé˜¶æ®µè®­ç»ƒ

```python
def train_dncnet(model, train_loader, val_loader, device, num_epochs_stage1=100, num_epochs_stage2=50):
    """
    åŒé˜¶æ®µè®­ç»ƒç­–ç•¥

    Args:
        model: DNCNetæ¨¡å‹
        train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
        val_loader: éªŒè¯æ•°æ®åŠ è½½å™¨
        device: è®¡ç®—è®¾å¤‡
        num_epochs_stage1: ç¬¬ä¸€é˜¶æ®µè½®æ•°
        num_epochs_stage2: ç¬¬äºŒé˜¶æ®µè½®æ•°
    """
    model = model.to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs_stage1)

    # æŸå¤±å‡½æ•°
    mse_loss = nn.MSELoss()
    ce_loss = nn.CrossEntropyLoss()

    # ========== ç¬¬ä¸€é˜¶æ®µï¼šè”åˆä¼˜åŒ– ==========
    print("=== ç¬¬ä¸€é˜¶æ®µï¼šè”åˆä¼˜åŒ–å»å™ªå’Œåˆ†ç±» ===")
    lambda_recon = 1.0
    lambda_cls = 1.0

    for epoch in range(num_epochs_stage1):
        model.train()
        train_loss = 0.0

        for batch in train_loader:
            noisy_signal, clean_signal, labels = batch
            noisy_signal = noisy_signal.to(device)
            clean_signal = clean_signal.to(device)
            labels = labels.to(device)

            # å‰å‘ä¼ æ’­
            denoised_signal, class_logits = model(noisy_signal)

            # è®¡ç®—æŸå¤±
            loss_recon = mse_loss(denoised_signal, clean_signal)
            loss_cls = ce_loss(class_logits, labels)
            loss_total = lambda_recon * loss_recon + lambda_cls * loss_cls

            # åå‘ä¼ æ’­
            optimizer.zero_grad()
            loss_total.backward()
            optimizer.step()

            train_loss += loss_total.item()

        # éªŒè¯
        val_acc = evaluate(model, val_loader, device)
        print(f"Epoch [{epoch+1}/{num_epochs_stage1}], Loss: {train_loss/len(train_loader):.4f}, Val Acc: {val_acc:.2f}%")

        scheduler.step()

    # ========== ç¬¬äºŒé˜¶æ®µï¼šåˆ†ç±»å¾®è°ƒ ==========
    print("\n=== ç¬¬äºŒé˜¶æ®µï¼šä»…ä¼˜åŒ–åˆ†ç±» ===")

    # é‡ç½®ä¼˜åŒ–å™¨
    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs_stage2)

    for epoch in range(num_epochs_stage2):
        model.train()
        train_loss = 0.0

        for batch in train_loader:
            noisy_signal, _, labels = batch
            noisy_signal = noisy_signal.to(device)
            labels = labels.to(device)

            # å‰å‘ä¼ æ’­
            _, class_logits = model(noisy_signal)

            # ä»…åˆ†ç±»æŸå¤±
            loss_cls = ce_loss(class_logits, labels)

            # åå‘ä¼ æ’­
            optimizer.zero_grad()
            loss_cls.backward()
            optimizer.step()

            train_loss += loss_cls.item()

        # éªŒè¯
        val_acc = evaluate(model, val_loader, device)
        print(f"Epoch [{epoch+1}/{num_epochs_stage2}], Loss: {train_loss/len(train_loader):.4f}, Val Acc: {val_acc:.2f}%")

        scheduler.step()

def evaluate(model, data_loader, device):
    """è¯„ä¼°åˆ†ç±»å‡†ç¡®ç‡"""
    model.eval()
    correct = 0
    total = 0

    with torch.no_grad():
        for batch in data_loader:
            noisy_signal, _, labels = batch
            noisy_signal = noisy_signal.to(device)
            labels = labels.to(device)

            _, class_logits = model(noisy_signal)
            _, predicted = torch.max(class_logits, 1)

            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    return 100.0 * correct / total
```

### 2.4 è®¡ç®—å¤æ‚åº¦

| ç»„ä»¶ | å‚æ•°é‡ | FLOPs | è¯´æ˜ |
|------|--------|-------|------|
| å™ªå£°ä¼°è®¡å™¨ | ~50K | ~NÂ·32Â²Â·5 | è½»é‡çº§ |
| U-Netå»å™ªå™¨ | ~2M | ~NÂ·64Â²Â·8 | ä¸»å¯¼ |
| ResNet18-1D | ~11M | ~NÂ·64Â² | ä¸»å¯¼ |
| **æ€»è®¡** | **~13M** | **~NÂ·(64Â²Â·10)** | ä¸­ç­‰è§„æ¨¡ |

å…¶ä¸­Næ˜¯ä¿¡å·é•¿åº¦ã€‚

### 2.5 å®ç°å»ºè®®

- **æ¡†æ¶**ï¼šPyTorch 1.10+
- **ä¼˜åŒ–å™¨**ï¼šAdam (lr=0.001 â†’ 0.0001)
- **æ‰¹æ¬¡å¤§å°**ï¼š32-64
- **GPUè¦æ±‚**ï¼š4GB+ VRAM
- **è®­ç»ƒæ—¶é—´**ï¼šçº¦2-4å°æ—¶ï¼ˆå•å¡V100ï¼‰

---

## ğŸ’¼ 3. åº”ç”¨ä¸“å®¶Agentï¼šä»·å€¼åˆ†æ

### 3.1 åº”ç”¨åœºæ™¯

**æ ¸å¿ƒé¢†åŸŸ**ï¼š
- [x] é›·è¾¾ä¿¡å·å¤„ç†
- [x] ç‰¹å®šè¾å°„æºè¯†åˆ«ï¼ˆSEIï¼‰
- [x] ç”µå­æˆ˜
- [x] é€šä¿¡ä¿¡å·è¯†åˆ«
- [x] é¢‘è°±ç›‘æµ‹

**å…·ä½“åœºæ™¯**ï¼š

1. **ä½ä¿¡å™ªæ¯”ç¯å¢ƒè¯†åˆ«**
   - åœºæ™¯ï¼šç”µå­å¯¹æŠ—ä¸­çš„è¿œè·ç¦»ä¿¡å·è¯†åˆ«
   - æŒ‘æˆ˜ï¼šSNRå¯ä½è‡³-10dB
   - è§£å†³æ–¹æ¡ˆï¼šDNCNetçš„å»å™ªé¢„å¤„ç†

2. **å¤šå™ªå£°ç±»å‹é²æ£’æ€§**
   - é«˜æ–¯ç™½å™ªå£°ï¼šçƒ­å™ªå£°
   - é«˜æ–¯æœ‰è‰²å™ªå£°ï¼šå¹²æ‰°ä¿¡å·
   - è„‰å†²å™ªå£°ï¼šè„‰å†²å¹²æ‰°

3. **å®æ—¶ä¿¡å·å¤„ç†**
   - åœºæ™¯ï¼šåœ¨çº¿ä¿¡å·åˆ†ç±»ç³»ç»Ÿ
   - è¦æ±‚ï¼šä½å»¶è¿Ÿã€é«˜åå
   - å®ç°ï¼šæ¨¡å‹å‹ç¼©ã€FPGAéƒ¨ç½²

### 3.2 æŠ€æœ¯ä»·å€¼

**è§£å†³çš„é—®é¢˜**ï¼š

1. **è®­ç»ƒ-æµ‹è¯•åˆ†å¸ƒä¸åŒ¹é…**ï¼š
   - é—®é¢˜ï¼šè®­ç»ƒé«˜SNRï¼Œæµ‹è¯•ä½SNRå¯¼è‡´æ€§èƒ½å´©æºƒ
   - ä¼ ç»Ÿæ–¹æ³•ï¼šåœ¨-10dBä¸‹å‡†ç¡®ç‡æ¥è¿‘0%
   - DNCNetï¼šä¿æŒè¾ƒé«˜å‡†ç¡®ç‡

2. **ä¼ ç»Ÿå»å™ªæ–¹æ³•å±€é™**ï¼š
   - å°æ³¢é˜ˆå€¼ï¼šéœ€æ‰‹åŠ¨è°ƒå‚
   - ç»´çº³æ»¤æ³¢ï¼šå‡è®¾ä¿¡å·ç»Ÿè®¡ç‰¹æ€§å·²çŸ¥
   - æ·±åº¦å­¦ä¹ å•ä»»åŠ¡ï¼šå»å™ªä¸ä¿è¯åˆ†ç±»æ€§èƒ½

3. **ç«¯åˆ°ç«¯ä¼˜åŠ¿**ï¼š
   - å»å™ªä¸ºåˆ†ç±»æœåŠ¡
   - è”åˆä¼˜åŒ–é¿å…æ¬¡ä¼˜è§£

**æ€§èƒ½æå‡**ï¼š

| SNR | ä¼ ç»Ÿæ–¹æ³• | DNCNet | æå‡ |
|-----|---------|--------|------|
| 30dB | 95.2% | 96.8% | +1.6% |
| 20dB | 88.7% | 95.1% | +6.4% |
| 10dB | 72.3% | 92.4% | +20.1% |
| 0dB | 35.6% | 85.7% | +50.1% |
| -10dB | 5.2% | 68.3% | +63.1% |

### 3.3 è½åœ°å¯è¡Œæ€§

| å› ç´  | è¯„ä¼° | è¯´æ˜ |
|------|------|------|
| æ•°æ®éœ€æ±‚ | ä¸­ | éœ€è¦æˆå¯¹è®­ç»ƒæ•°æ® |
| è®¡ç®—èµ„æº | ä¸­-é«˜ | GPUæ¨èï¼ŒCPUå¯è¡Œ |
| éƒ¨ç½²éš¾åº¦ | ä¸­ | æ·±åº¦å­¦ä¹ æ¨¡å‹ |
| å®æ—¶æ€§ | ä¸­ | æ¨¡å‹å‹ç¼©åå¯è¾¾å®æ—¶ |
| é²æ£’æ€§ | é«˜ | å¤šå™ªå£°ç±»å‹ |

### 3.4 å•†ä¸š/å›½é˜²æ½œåŠ›

- **ç›®æ ‡å¸‚åœº**ï¼š
  - å›½é˜²ç”µå­
  - é›·è¾¾ç³»ç»Ÿåˆ¶é€ å•†
  - é¢‘è°±ç›‘æµ‹å…¬å¸
  - é€šä¿¡è®¾å¤‡å•†

- **ç«äº‰ä¼˜åŠ¿**ï¼š
  - ä½SNRé²æ£’æ€§
  - ç«¯åˆ°ç«¯ä¼˜åŒ–
  - å¤šå™ªå£°ç±»å‹

- **éƒ¨ç½²è·¯å¾„**ï¼š
  - åµŒå…¥å¼FPGA
  - GPUæœåŠ¡å™¨
  - äº‘ç«¯API

---

## ğŸ¤¨ 4. è´¨ç–‘è€…Agentï¼šæ‰¹åˆ¤åˆ†æ

### 4.1 æ–¹æ³•è®ºè´¨ç–‘

**ç†è®ºå‡è®¾**ï¼š
1. **å™ªå£°å¯ä¼°è®¡**ï¼šå‡è®¾å™ªå£°æ°´å¹³å¯ç²¾ç¡®ä¼°è®¡
   - é—®é¢˜ï¼šå®é™…å™ªå£°å¤æ‚å¤šå˜
   - å½±å“ï¼šä¼°è®¡è¯¯å·®ä¼ æ’­

2. **è®­ç»ƒè¦†ç›–æµ‹è¯•**ï¼šå‡è®¾è®­ç»ƒSNRèŒƒå›´è¦†ç›–æµ‹è¯•åœºæ™¯
   - é—®é¢˜ï¼šåˆ†å¸ƒå¤–å¯èƒ½å¤±æ•ˆ
   - å½±å“ï¼šæ³›åŒ–èƒ½åŠ›æœ‰é™

3. **ç«¯åˆ°ç«¯æœ€ä¼˜**ï¼šå‡è®¾è”åˆä¼˜åŒ–ä¼˜äºçº§è”
   - é—®é¢˜ï¼šç›®æ ‡å‡½æ•°å¯èƒ½å†²çª
   - è§£å†³ï¼šåŒé˜¶æ®µç­–ç•¥ç¼“è§£

**æ•°å­¦ä¸¥è°¨æ€§**ï¼š
- åŒé˜¶æ®µè®­ç»ƒç¼ºä¹ç†è®ºä¿è¯
- æŸå¤±æƒé‡Î»éœ€ç»éªŒè°ƒä¼˜
- æ”¶æ•›æ€§åˆ†æä¸è¶³

### 4.2 å®éªŒè¯„ä¼°æ‰¹åˆ¤

**æ•°æ®é›†é—®é¢˜**ï¼š
- SIGNAL-8ä¸ºè‡ªå»ºæ•°æ®é›†ï¼Œè§„æ¨¡æœ‰é™
- RADIOML 2018.01Aç›¸å¯¹è¾ƒå°
- ç¼ºä¹å¤§è§„æ¨¡çœŸå®é›·è¾¾æ•°æ®éªŒè¯

**è¯„ä¼°æŒ‡æ ‡**ï¼š
- ä¸»è¦å…³æ³¨å‡†ç¡®ç‡
- ç¼ºä¹å¯¹ï¼š
  - å®æ—¶æ€§ï¼ˆå»¶è¿Ÿï¼‰
  - è®¡ç®—å¤æ‚åº¦
  - æ¨¡å‹å¤§å°
  - é²æ£’æ€§è¾¹ç•Œ

**åŸºçº¿å¯¹æ¯”**ï¼š
- ä¸ä¼ ç»Ÿæ–¹æ³•å¯¹æ¯”å……åˆ†
- ä½†æœªä¸æœ€æ–°æ·±åº¦å­¦ä¹ å¯¹æ¯”ï¼š
  - Attentionæœºåˆ¶
  - Transformeræ¶æ„
  - è‡ªç›‘ç£æ–¹æ³•

### 4.3 å±€é™æ€§åˆ†æ

**æ–¹æ³•é™åˆ¶**ï¼š

1. **é€‚ç”¨èŒƒå›´**ï¼š
   - ä¸»è¦è€ƒè™‘åŠ æ€§å™ªå£°
   - å¤±æ•ˆåœºæ™¯ï¼šä¹˜æ€§å™ªå£°ã€æ—¶å˜å™ªå£°

2. **è®¡ç®—å¤æ‚åº¦**ï¼š
   - U-Netåœ¨é•¿åºåˆ—ä¸Šå¼€é”€å¤§
   - å®æ—¶éƒ¨ç½²éœ€å‹ç¼©

3. **å‚æ•°æ•æ„Ÿæ€§**ï¼š
   - Î»â‚ã€Î»â‚‚éœ€è°ƒä¼˜
   - åŒé˜¶æ®µåˆ‡æ¢æ—¶æœºéœ€ç»éªŒ

**å®é™…é™åˆ¶**ï¼š

1. **æ•°æ®éœ€æ±‚**ï¼š
   - éœ€è¦æˆå¯¹ï¼ˆå¹²å‡€/å«å™ªï¼‰æ•°æ®
   - çœŸå®åœºæ™¯éš¾ä»¥è·å–

2. **æ³›åŒ–èƒ½åŠ›**ï¼š
   - æ–°å™ªå£°ç±»å‹éœ€é‡æ–°è®­ç»ƒ
   - ä¸åŒé›·è¾¾å‚æ•°éœ€é€‚é…

### 4.4 æ”¹è¿›å»ºè®®

**çŸ­æœŸæ”¹è¿›**ï¼ˆ1-2å¹´ï¼‰ï¼š
1. **æ¨¡å‹å‹ç¼©**ï¼š
   - å‰ªæ
   - é‡åŒ–
   - çŸ¥è¯†è’¸é¦

2. **æ‰©å±•**ï¼š
   - æ›´å¤šå™ªå£°ç±»å‹
   - å¤šæ¨¡æ€è¾“å…¥ï¼ˆI/Q+æ—¶é¢‘å›¾ï¼‰

3. **éƒ¨ç½²ä¼˜åŒ–**ï¼š
   - FPGAå®ç°
   - è¾¹ç¼˜è®¾å¤‡

**é•¿æœŸæ–¹å‘**ï¼ˆ3-5å¹´ï¼‰ï¼š
1. **è‡ªé€‚åº”æƒé‡**ï¼š
   - è‡ªåŠ¨Î»è°ƒæ•´
   - åŠ¨æ€é˜¶æ®µåˆ‡æ¢

2. **å°æ ·æœ¬å­¦ä¹ **ï¼š
   - å…ƒå­¦ä¹ 
   - é›¶æ ·æœ¬è¯†åˆ«

3. **è‡ªç›‘ç£**ï¼š
   - æ— éœ€æˆå¯¹æ•°æ®
   - å¯¹æ¯”å­¦ä¹ 

---

## ğŸ¯ 5. ç»¼åˆç†è§£ï¼šæ ¸å¿ƒåˆ›æ–°ä¸æ„ä¹‰

### 5.1 æ ¸å¿ƒåˆ›æ–°ç‚¹

| ç»´åº¦ | åˆ›æ–°å†…å®¹ | åˆ›æ–°ç­‰çº§ |
|------|----------|----------|
| ç†è®º | å»å™ª-åˆ†ç±»è”åˆä¼˜åŒ– | â˜…â˜…â˜…â˜…â˜† |
| æ–¹æ³• | åŒé˜¶æ®µè®­ç»ƒç­–ç•¥ | â˜…â˜…â˜…â˜…â˜… |
| åº”ç”¨ | ä½SNRä¿¡å·è¯†åˆ« | â˜…â˜…â˜…â˜…â˜… |
| ç³»ç»Ÿ | ç«¯åˆ°ç«¯æ¡†æ¶ | â˜…â˜…â˜…â˜…â˜† |

### 5.2 ç ”ç©¶æ„ä¹‰

**å­¦æœ¯è´¡çŒ®**ï¼š
1. æå‡ºé›·è¾¾ä¿¡å·å»å™ª-åˆ†ç±»ç»Ÿä¸€æ¡†æ¶
2. åŒé˜¶æ®µè®­ç»ƒç­–ç•¥æœ‰å‚è€ƒä»·å€¼
3. å¤šå™ªå£°é²æ£’æ€§éªŒè¯å……åˆ†

**å®é™…ä»·å€¼**ï¼š
1. è§£å†³ä½SNRè¯†åˆ«éš¾é¢˜
2. å¯ç›´æ¥åº”ç”¨äºå·¥ç¨‹å®è·µ
3. ä¸ºå›½é˜²ç”µå­æä¾›æŠ€æœ¯æ”¯æ’‘

### 5.3 æŠ€æœ¯æ¼”è¿›ä½ç½®

```
[ä¼ ç»Ÿæ–¹æ³•] â†’ [æ·±åº¦å­¦ä¹ å•åˆ†ç±»å™¨] â†’ [å»å™ª+åˆ†ç±»çº§è”] â†’ [DNCNetç«¯åˆ°ç«¯]
   â†“              â†“                    â†“                    â†“
 é«˜SNRæœ‰æ•ˆ     ä¸­ç­‰SNR           éœ€è¦æˆå¯¹æ•°æ®          ä½SNRé²æ£’
 æ‰‹å·¥ç‰¹å¾      CNNç‰¹å¾        åˆ†ç¦»è®­ç»ƒæ¬¡ä¼˜        è”åˆä¼˜åŒ–
```

### 5.4 è·¨Agentè§‚ç‚¹æ•´åˆ

**æ•°å­¦å®¶ + å·¥ç¨‹å¸ˆ**ï¼š
- ç†è®ºæ¡†æ¶æ¸…æ™°ï¼Œå·¥ç¨‹å®ç°å¯è¡Œ
- åŒé˜¶æ®µè®­ç»ƒç­–ç•¥å®ç”¨æœ‰æ•ˆ

**åº”ç”¨ä¸“å®¶ + è´¨ç–‘è€…**ï¼š
- è§£å†³å®é™…ç—›ç‚¹ï¼Œä½†éœ€è¦æ›´å¤šéªŒè¯
- è®¡ç®—å¤æ‚åº¦éœ€è¿›ä¸€æ­¥ä¼˜åŒ–

### 5.5 æœªæ¥å±•æœ›

**çŸ­æœŸæ–¹å‘**ï¼š
1. æ¨¡å‹å‹ç¼©ä¸åŠ é€Ÿ
2. æ‰©å±•åˆ°æ›´å¤šä¿¡å·ç±»å‹
3. å®æ—¶éƒ¨ç½²ä¼˜åŒ–

**é•¿æœŸæ–¹å‘**ï¼š
1. è‡ªé€‚åº”å™ªå£°å¤„ç†
2. å°æ ·æœ¬/é›¶æ ·æœ¬å­¦ä¹ 
3. ç¡¬ä»¶åŠ é€Ÿå®ç°

### 5.6 ç»¼åˆè¯„åˆ†

| ç»´åº¦ | è¯„åˆ† | è¯´æ˜ |
|------|------|------|
| ç†è®ºæ·±åº¦ | â˜…â˜…â˜…â˜…â˜† | æ¡†æ¶æ¸…æ™° |
| æ–¹æ³•åˆ›æ–° | â˜…â˜…â˜…â˜…â˜… | åŒé˜¶æ®µç­–ç•¥ |
| å®ç°éš¾åº¦ | â˜…â˜…â˜…â˜†â˜† | ä¸­ç­‰å¤æ‚åº¦ |
| åº”ç”¨ä»·å€¼ | â˜…â˜…â˜…â˜…â˜… | è§£å†³å®é™…ç—›ç‚¹ |
| è®ºæ–‡è´¨é‡ | â˜…â˜…â˜…â˜…â˜† | IEEE TAES |
| å¯å¤ç°æ€§ | â˜…â˜…â˜…â˜…â˜† | å¼€æºä»£ç  |

**æ€»åˆ†ï¼šâ˜…â˜…â˜…â˜…â˜† (4.3/5.0)**

**æ¨èé˜…è¯»ä»·å€¼**: é«˜ â­â­â­â­â­
- é›·è¾¾ä¿¡å·å¤„ç†ç ”ç©¶è€…
- æ·±åº¦å­¦ä¹ åº”ç”¨ç ”ç©¶è€…
- å›½é˜²ç”µå­å·¥ç¨‹å¸ˆ
- ä¿¡å·å¤„ç†ç®—æ³•å·¥ç¨‹å¸ˆ

---

## ğŸ“š å…³é”®å‚è€ƒæ–‡çŒ®

1. **æœ¬è®ºæ–‡**ï¼š
   Du M, Zhong P, Cai X, et al. DNCNet: Deep radar signal denoising and recognition[J]. IEEE Transactions on Aerospace and Electronic Systems, 2022, 58(4): 3549-3562.

2. **RPCAåŸºç¡€**ï¼š
   CandÃ¨s E J, Li X, Ma Y, et al. Robust principal component analysis?[J]. Journal of the ACM, 2011.

3. **U-Net**ï¼š
   Ronneberger O, Fischer P, Brox T. U-Net: Convolutional networks for biomedical image segmentation[C]. MICCAI, 2015.

4. **ResNet**ï¼š
   He K, Zhang X, Ren S, et al. Deep residual learning for image recognition[C]. CVPR, 2016.

5. **RADIOMLæ•°æ®é›†**ï¼š
   O'Shea T J, Corgan J, Clancy T K. Convolutional radio modulation classification networks[C]. IWCNC, 2018.

---

## ğŸ“ åˆ†æç¬”è®°

### æ ¸å¿ƒæ´å¯Ÿ

1. **åŒé˜¶æ®µè®­ç»ƒçš„å·§å¦™**ï¼š
   - ç¬¬ä¸€é˜¶æ®µï¼šè”åˆä¼˜åŒ–ç¡®ä¿å»å™ªè´¨é‡
   - ç¬¬äºŒé˜¶æ®µï¼šä»…åˆ†ç±»å…è®¸ç‰¹å¾é€‚åº”ä»»åŠ¡
   - è§£å†³äº†"å®Œç¾å»å™ªâ‰ æœ€ä¼˜åˆ†ç±»"çš„é—®é¢˜

2. **å™ªå£°æ°´å¹³ä¼°è®¡çš„ä½œç”¨**ï¼š
   - æä¾›ç©ºé—´å˜åŒ–çš„å»å™ªå¼ºåº¦
   - æ¯”"ä¸€åˆ€åˆ‡"æ›´ç²¾ç»†
   - ç±»ä¼¼äºæ³¨æ„åŠ›æœºåˆ¶

3. **1Då¤„ç†çš„ä¼˜åŠ¿**ï¼š
   - é¿å…æ—¶é¢‘å˜æ¢ä¿¡æ¯æŸå¤±
   - ä¿ç•™ç›¸ä½ä¿¡æ¯ï¼ˆå¤æ•°å¤„ç†ï¼‰
   - ç«¯åˆ°ç«¯å¯å¾®åˆ†

4. **å®é™…åº”ç”¨è€ƒè™‘**ï¼š
   - è®­ç»ƒæ•°æ®åˆæˆæ˜¯å…³é”®
   - éœ€è¦æ¨¡æ‹ŸçœŸå®å™ªå£°ç‰¹æ€§
   - æ¨¡å‹å‹ç¼©å¯¹éƒ¨ç½²å¾ˆé‡è¦

### å®è·µå»ºè®®

- å¯¹äºä½SNRåœºæ™¯ï¼šDNCNetæ˜¯ä¼˜ç§€é€‰æ‹©
- å¯¹äºå®æ—¶åº”ç”¨ï¼šè€ƒè™‘æ¨¡å‹å‰ªæ/é‡åŒ–
- å¯¹äºæ–°å™ªå£°ç±»å‹ï¼šéœ€è¦é‡æ–°è®­ç»ƒ
- å¯¹äºèµ„æºå—é™è®¾å¤‡ï¼šä½¿ç”¨è½»é‡åŒ–ç‰ˆæœ¬

---

*æœ¬ç¬”è®°åŸºäºPDFåŸæ–‡ç²¾è¯»å®Œæˆï¼Œä½¿ç”¨5-Agentè¾©è®ºåˆ†æç³»ç»Ÿç”Ÿæˆã€‚*
*å»ºè®®ç»“åˆåŸæ–‡è¿›è¡Œæ·±å…¥ç ”è¯»ã€‚*
