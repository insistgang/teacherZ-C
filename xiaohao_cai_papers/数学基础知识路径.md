# 数学基础知识学习路径

> **创建日期**: 2026年2月9日
> **目标**: 掌握Xiaohao Cai师门研究必备的数学基础知识
> **预计学习周期**: 12-16周

---

## 数学知识体系架构

```
数学基础
    ├── 变分法 (Variational Methods)
    │   ├── Mumford-Shah模型
    │   ├── ROF模型
    │   ├── 欧拉-拉格朗日方程
    │   └── 能量泛函设计
    │
    ├── 凸优化 (Convex Optimization)
    │   ├── 凸集与凸函数
    │   ├── 凸松弛技术
    │   ├── 对偶理论
    │   └── Split Bregman迭代
    │
    ├── 贝叶斯方法 (Bayesian Methods)
    │   ├── 贝叶斯推断基础
    │   ├── 不确定性量化
    │   ├── 嵌套采样
    │   └── 稀疏贝叶斯学习
    │
    ├── 张量分解 (Tensor Decomposition) ⭐ 重点加强
    │   ├── 张量基础与运算
    │   ├── CP分解 (CANDECOMP/PARAFAC)
    │   ├── Tucker分解 (核心张量)
    │   ├── CUR分解 (可解释分解)
    │   ├── 张量Train (TT) 分解
    │   ├── 随机Sketching加速
    │   └── 与tCURLoRA的关联 ⭐
    │
    └── 图论 (Graph Theory)
        ├── 图论基础
        ├── 图割算法
        ├── 图神经网络
        └── Varifolds度量
```

---

## 学习路线图

---

### 第一阶段: 变分法基础 (第1-3周)

**学习目标**: 理解变分法在图像处理中的应用,掌握能量泛函设计方法

#### 第1周: 变分法数学基础

| 知识点 | 论文参考 | 推荐资源 | 优先级 |
|--------|----------|----------|--------|
| 变分法基本概念 | [1-04] 变分法基础 | 《变分法教程》- Gelfand | ⭐⭐⭐⭐⭐ |
| Mumford-Shah泛函 | [1-04] | 原始论文: Mumford-Shah 1989 | ⭐⭐⭐⭐⭐ |
| ROF模型 | [1-04] | Rudin-Osher-Fatemi 1992 | ⭐⭐⭐⭐⭐ |
| 欧拉-拉格朗日方程 | [1-04] | 《微积分学教程》- Fichtenholz | ⭐⭐⭐⭐ |

**核心概念**:
- 能量泛函: E(u) = ∫Ω (u-f)² dx + λ∫Ω|∇u| dx
- 变分导数与梯度流
- 边界条件与正则项

**实践练习**:
- 手推Mumford-Shah泛函的欧拉-拉格朗日方程
- 实现简单的ROF去噪算法

---

#### 第2周: 图像分割中的变分法

| 知识点 | 论文参考 | 推荐资源 | 优先级 |
|--------|----------|----------|--------|
| 图像分割能量泛函 | [2-01] 凸优化分割 | Chan-Vese论文 2001 | ⭐⭐⭐⭐⭐ |
| 水平集方法 | [2-03] SLaT分割 | Osher Sethian 1988 | ⭐⭐⭐⭐ |
| 多类分割 | [2-02] 多类分割迭代ROF | Zach et al. 2012 | ⭐⭐⭐⭐ |
| 光流分割 | [2-07] 光流分割 | Cremers 2008 | ⭐⭐⭐ |

**核心概念**:
- 分割能量泛函设计
- 曲线演化与水平集
- 多相分割扩展

**实践练习**:
- 实现Chan-Vese分割算法
- 理解SLaT三阶段框架的数学原理

---

#### 第3周: 变分法数值方法

| 知识点 | 论文参考 | 推荐资源 | 优先级 |
|--------|----------|----------|--------|
| 梯度下降法 | [2-01] | 《数值优化》- Nocedal | ⭐⭐⭐⭐ |
| 对偶方法 | [2-01] | Chambolle 2004 | ⭐⭐⭐⭐⭐ |
| Split Bregman | [2-01] | Goldstein Osher 2009 | ⭐⭐⭐⭐⭐ |
| 原始-对偶混合梯度 | [4-06] | Zhu Chan 2018 | ⭐⭐⭐⭐ |

**核心概念**:
- 离散化方案
- 收敛性分析
- 算法复杂度

**实践练习**:
- 实现Split Bregman算法
- 对比不同数值方法的收敛速度

---

### 第二阶段: 凸优化 (第4-6周)

**学习目标**: 掌握凸优化理论,理解凸松弛技术在图像处理中的应用

#### 第4周: 凸优化基础

| 知识点 | 论文参考 | 推荐资源 | 优先级 |
|--------|----------|----------|--------|
| 凸集与凸函数 | [2-01] | 《凸优化》- Boyd Vandenberghe | ⭐⭐⭐⭐⭐ |
| 凸优化问题 | [2-01] | Boyd Vandenberghe 第4-5章 | ⭐⭐⭐⭐⭐ |
| KKT条件 | [2-01] | Nocedal Wright 第12章 | ⭐⭐⭐⭐ |
| 对偶理论 | [2-01] | Boyd Vandenberghe 第5章 | ⭐⭐⭐⭐⭐ |

**核心概念**:
- 凸集分离定理
- Slater条件
- 强对偶性

---

#### 第5周: 凸松弛技术

| 知识点 | 论文参考 | 推荐资源 | 优先级 |
|--------|----------|----------|--------|
| 标签松弛 | [2-01] 凸优化分割 | Pock et al. 2008 | ⭐⭐⭐⭐⭐ |
| 连续松弛 | [2-01] | Zach et al. 2008 | ⭐⭐⭐⭐⭐ |
| 全局最优解 | [2-01] | Bredies et al. 2010 | ⭐⭐⭐⭐ |
| 多类松弛 | [2-02] | Pock et al. 2013 | ⭐⭐⭐⭐ |

**核心概念**:
- 离散问题连续化
- 松弛误差分析
- 阈值化后处理

---

#### 第6周: 分布式优化

| 知识点 | 论文参考 | 推荐资源 | 优先级 |
|--------|----------|----------|--------|
| 分布式梯度下降 | [4-06] 分布式优化 | Bertsekas 2012 | ⭐⭐⭐⭐ |
| ADMM | [4-06] | Boyd et al. 2011 | ⭐⭐⭐⭐⭐ |
| 增量优化 | [4-06] | Wright 2015 | ⭐⭐⭐ |
| 在线优化 | [4-05] 在线重建 | Shalev-Shwartz 2011 | ⭐⭐⭐⭐ |

**核心概念**:
- 一致性约束
- 增量vs批量
- 收敛速率

---

### 第三阶段: 贝叶斯方法 (第7-10周)

**学习目标**: 理解贝叶斯推断框架,掌握不确定性量化方法

#### 第7周: 贝叶斯推断基础

| 知识点 | 论文参考 | 推荐资源 | 优先级 |
|--------|----------|----------|--------|
| 贝叶斯定理 | [4-07] 高维逆问题 | 《贝叶斯数据分析》- Gelman | ⭐⭐⭐⭐⭐ |
| 先验与后验 | [4-07] | Gelman 第2章 | ⭐⭐⭐⭐⭐ |
| 共轭先验 | [4-07] | Bishop PRML 第2章 | ⭐⭐⭐⭐ |
| 层次贝叶斯 | [4-07] | Gelman 第5章 | ⭐⭐⭐ |

**核心概念**:
- 贝叶斯更新
- 最大后验估计(MAP)
- 贝叶斯预测

---

#### 第8周: 不确定性量化

| 知识点 | 论文参考 | 推荐资源 | 优先级 |
|--------|----------|----------|--------|
| 不确定性来源 | [4-07] 高维不确定性 | Kennedy O'Hagan 2001 | ⭐⭐⭐⭐⭐ |
| 传播不确定性 | [4-07] | Smith 2013 | ⭐⭐⭐⭐ |
| 高维问题 | [4-07] | Cai 论文核心内容 | ⭐⭐⭐⭐⭐ |
| 逆问题 | [4-07] | Stuart 2010 | ⭐⭐⭐⭐ |

**核心概念**:
- 认知不确定性 vs 偶然不确定性
- 高维诅咒
- 逆问题不适定性

---

#### 第9周: 嵌套采样

| 知识点 | 论文参考 | 推荐资源 | 优先级 |
|--------|----------|----------|--------|
| 嵌套采样基础 | [4-08] 近端嵌套采样 | Skilling 2006 | ⭐⭐⭐⭐⭐ |
| 模型选择 | [4-08] | Mukherjee et al. 2006 | ⭐⭐⭐⭐⭐ |
| 近端方法 | [4-08] | Cai论文核心 | ⭐⭐⭐⭐⭐ |
| 收敛性 | [4-08] | Chopin & Robert 2010 | ⭐⭐⭐⭐ |

**核心概念**:
- 证据计算
- 似然面探索
| 自适应采样

---

#### 第10周: 稀疏贝叶斯

| 知识点 | 论文参考 | 推荐资源 | 优先级 |
|--------|----------|----------|--------|
| 稀疏先验 | [4-30/31/32] 稀疏贝叶斯 | Tipping 2001 | ⭐⭐⭐⭐ |
| 质量映射 | [4-30] | Cai 论文核心 | ⭐⭐⭐⭐⭐ |
| 假设检验 | [4-30] | Casella Berger | ⭐⭐⭐⭐ |
| 可信区间 | [4-31] | Gelman 第4章 | ⭐⭐⭐⭐ |

**核心概念**:
| 自动相关性确定(ARD)
| 贝叶斯因子
| 后验预测检验

---

### 第四阶段: 张量分解 (第11-13周)

**学习目标**: 掌握张量分解理论,理解高维数据建模方法

#### 第11周: 张量基础

| 知识点 | 论文参考 | 推荐资源 | 优先级 |
|--------|----------|----------|--------|
| 张量定义 | [3-05] 大规模张量分解 | 《张量分解》- Kolda Bader | ⭐⭐⭐⭐⭐ |
| 张量运算 | [3-05] | Kolda Bader综述 | ⭐⭐⭐⭐⭐ |
| 张量秩 | [3-05] | De Lathauwer 2000 | ⭐⭐⭐⭐ |
| 张量范数 | [3-05] | 习题与文献 | ⭐⭐⭐ |

**核心概念**:
| 多线性代数
| 张量分解与矩阵分解对比
| 张量可视化

---

#### 第12周: CP与Tucker分解 ⭐ 重点加强

| 知识点 | 论文参考 | 推荐资源 | 优先级 |
|--------|----------|----------|--------|
| CP分解 | [3-04] 低秩Tucker近似 | Hitchcock 1927 | ⭐⭐⭐⭐ |
| Tucker分解 | [3-04] ⭐⭐⭐⭐⭐ | Tucker 1966 | ⭐⭐⭐⭐⭐ |
| 核心张量 | [3-04] | De Lathauwer 2000 | ⭐⭐⭐⭐⭐ |
| ALS算法 | [3-04] | Kolda Bader | ⭐⭐⭐⭐⭐ |
| HOSVD | [3-04] | De Lathauwer 2000 | ⭐⭐⭐⭐ |
| HOOI | [3-04] | Cai 论文核心 | ⭐⭐⭐⭐⭐ |

**核心概念**:
- 分解唯一性 (Kruskal条件)
- 初始化策略 (随机/HOSVD)
- 收敛分析 (ALS单调性)
- 核心张量vs因子矩阵

**与tCURLoRA关联**:
- Tucker分解是tCURLoRA的数学基础
- 核心张量对应LoRA中的低秩适配器
- 因子矩阵对应预训练权重的分解结构

**实践练习**:
- 手动计算3阶张量的Tucker分解
- 对比CP vs Tucker的压缩率
- 实现HOOI算法

---

#### 第13周: CUR分解与Sketching ⭐ tCURLoRA核心

| 知识点 | 论文参考 | 推荐资源 | 优先级 |
|--------|----------|----------|--------|
| CUR分解 | [3-02] tCURLoRA ⭐⭐⭐⭐⭐ | Mahoney Drineas 2009 | ⭐⭐⭐⭐⭐ |
| 随机Sketching | [3-04/05] ⭐⭐⭐⭐ | Mahoney 2011 | ⭐⭐⭐⭐⭐ |
| 双边Sketching | [3-05] ⭐⭐⭐⭐⭐ | Cai 论文核心 | ⭐⭐⭐⭐⭐ |
| 低秩近似 | [3-04] | Halko et al. 2011 | ⭐⭐⭐⭐ |
| 张量CUR | [3-02] | Cai ICML 2024 | ⭐⭐⭐⭐⭐ |

**核心概念**:
- 可解释性: CUR保留原矩阵行列 (物理意义清晰)
- 随机投影: Johnson-Lindenstrauss引理
- 增量更新: CUR优于SVD (适合在线学习)
| 列/行采样策略: 重要性采样

**tCURLoRA深度解析** (ICML 2024):
```
传统LoRA: W = W₀ + ΔW = W₀ + BA (矩阵低秩)
tCURLoRA:  W = W₀ + ΔW = W₀ + C×U×R (张量CUR分解)

优势:
1. 更好建模高维结构 (张量 > 矩阵)
2. 可解释性更强 (C/R保留实际行列)
3. 更适合增量更新 (CUR性质)
4. 医学图像分割上显著优于LoRA
```

**Sketching加速框架**:
- 高斯随机投影
- Sparse Sketching (稀疏投影)
- 双边Sketching (行列同时)
- 误差界分析

**实践练习**:
- 实现矩阵CUR分解
- 对比SVD vs CUR的重建误差
- 理解tCURLoRA在医学分割中的应用

---

#### 第13周+补充: 张量Train (TT) 分解

| 知识点 | 论文参考 | 推荐资源 | 优先级 |
|--------|----------|----------|--------|
| TT分解基础 | 张量分解扩展 | Oseledets 2011 | ⭐⭐⭐⭐ |
| TT-cores | | 张量网络 | ⭐⭐⭐⭐ |
| TT-SVD | | Oseledets Tyrtyshnikov | ⭐⭐⭐ |
| 应用场景 | | RNN/深度学习 | ⭐⭐⭐ |

**张量分解方法完整对比**:

| 方法 | 分解形式 | 可解释性 | 唯一性 | 计算复杂度 | 应用场景 |
|------|----------|----------|--------|------------|----------|
| **CP** | Σₖ λₖ aₖ∘bₖ∘cₖ | 中 | 条件唯一 | 低 | 简单张量 |
| **Tucker** | G ×₁A ×₂B ×₃C | 中 | 唯一(旋转) | 中 | 多维数据分析 |
| **CUR** | C × U × R | ⭐高 | 不唯一 | 低( Sketching) | ⭐tCURLoRA |
| **TT** | G₁×G₂×...×Gₙ | 低 | 唯一 | 低 | 高维张量 |

**选择指南**:
- 追求可解释性 → CUR (tCURLoRA)
| 追求压缩率 → Tucker/TT
| 追求唯一性 → CP(满足Kruskal条件)
| 大规模数据 → CUR + Sketching

---

### 第五阶段: 图论 (第14-16周)

**学习目标**: 掌握图论基础,理解图割和图神经网络

#### 第14周: 图论基础

| 知识点 | 论文参考 | 推荐资源 | 优先级 |
|--------|----------|----------|--------|
| 图的基本概念 | [2-15] 3D树木分割 | 《图论》- Bondy Murty | ⭐⭐⭐⭐ |
| 图的表示 | [2-15] | Diestel 图论教程 | ⭐⭐⭐⭐ |
| 最短路算法 | [2-15] | Dijkstra, Floyd-Warshall | ⭐⭐⭐ |
| 最小生成树 | [2-15] | Kruskal, Prim | ⭐⭐⭐ |

**核心概念**:
| 邻接矩阵与边列表
| 连通性与路径
| 加权图

---

#### 第15周: 图割算法

| 知识点 | 论文参考 | 推荐资源 | 优先级 |
|--------|----------|----------|--------|
| 最大流最小割 | [2-15] 图割分割 | Ford Fulkerson 1962 | ⭐⭐⭐⭐⭐ |
| 图割分割 | [2-15] [2-16] | Boykov Jolly 2001 | ⭐⭐⭐⭐⭐ |
| 多类图割 | [2-15] | Boykov Kolmogorov 2004 | ⭐⭐⭐⭐ |
| 能量最小化 | [2-15] | Kolmogorov Rother 2007 | ⭐⭐⭐⭐⭐ |

**核心概念**:
| s-t最小割
| 能量函数与图构造
| 亚模性

---

#### 第16周: 图神经网络与Varifolds

| 知识点 | 论文参考 | 推荐资源 | 优先级 |
|--------|----------|----------|--------|
| GCN基础 | [3-03] 图神经网络 | Kipf Welling 2017 | ⭐⭐⭐⭐⭐ |
| GNN变体 | [3-03] | Zhou et al. 2020综述 | ⭐⭐⭐⭐ |
| Varifolds | [2-12] Neural Varifolds | Charon 2017 | ⭐⭐⭐⭐⭐ |
| 神经Varifolds | [2-12] | Cai 论文核心 | ⭐⭐⭐⭐⭐ |

**核心概念**:
| 消息传递
| 点云作为图
| Varifolds度量

---

## 推荐资源

### 教科书

**变分法**
- 《变分法教程》- I.M. Gelfand
- 《图像处理中的变分方法和PDE》- Aubert Kornprobst

**凸优化**
- 《凸优化》- Stephen Boyd, Lieven Vandenberghe
- 《数值优化》- Nocedal, Wright

**贝叶斯方法**
- 《贝叶斯数据分析》- Andrew Gelman
- 《Pattern Recognition and Machine Learning》- Bishop

**张量分解**
- 《Tensor Decompositions and Applications》- Kolda, Bader (SIAM Review)
- 《矩阵分析与应用》- Golub, Van Loan

**图论**
- 《图论》- Bondy, Murty
- 《图论及其应用》- West

### 在线课程

| 课程 | 平台 | 链接 |
|------|------|------|
| Convex Optimization | Stanford | https://see.stanford.edu/Course/EE364A |
| Bayesian Methods | Coursera | Statistics with R Specialization |
| Graph Neural Networks | Stanford | CS224W |

### 关键论文（必读）

**变分法奠基**
1. Mumford & Shah (1989) - Optimal approximations by piecewise smooth functions
2. Rudin, Osher & Fatemi (1992) - Nonlinear total variation based noise removal

**凸优化突破**
3. Zach et al. (2008) - A globally optimal algorithm for convex PDE
4. Chambolle (2004) - An algorithm for total variation minimization

**贝叶斯方法**
5. Cai et al. (2017) - High-dimensional Bayesian inference
6. Skilling (2006) - Nested sampling

**张量分解**
7. Mahoney & Drineas (2009) - CUR matrix decompositions
8. Cai et al. (2024) - tCURLoRA: Tensor CUR for LoRA (ICML) ⭐⭐⭐⭐⭐
9. Cai et al. (2021) - Sketching for low-rank Tucker (SIMODS) ⭐⭐⭐⭐
10. Cai et al. (2022) - Two-sided sketching for tensors (SIMAX) ⭐⭐⭐⭐

**tCURLoRA深度关联** (ICML 2024 核心论文):
- **问题**: 大模型全量微调成本高, 传统LoRA使用矩阵SVD分解
- **创新**: 首次将张量CUR分解应用于参数高效微调
- **优势**:
  1. CUR保留原张量的实际行列(可解释)
  2. 适合增量更新(在线学习友好)
  3. 更好建模高维参数结构
- **应用**: 医学图像分割任务上显著优于LoRA/Adapter等PEFT方法

**图神经网络**
9. Kipf & Welling (2017) - Semi-supervised classification with GCNs
10. Cai et al. (2022) - Neural Varifolds for point clouds

---

## 学习检查清单

### 变分法
- [ ] 理解Mumford-Shah能量泛函
- [ ] 能推导欧拉-拉格朗日方程
- [ ] 掌握Split Bregman迭代算法
- [ ] 实现至少一种变分分割算法

### 凸优化
- [ ] 理解凸集与凸函数判定
- [ ] 掌握KKT条件
- [ ] 理解凸松弛技术
- [ ] 能实现对偶算法

### 贝叶斯方法
- [ ] 理解先验/似然/后验关系
- [ ] 掌握不确定性量化方法
- [ ] 理解嵌套采样原理
- [ ] 能实现简单贝叶斯推断

### 张量分解
- [ ] 理解张量基本运算
- [ ] 掌握CP/Tucker/CUR分解
- [ ] 理解sketching方法
- [ ] 能实现张量分解算法

### 图论
- [ ] 掌握图割算法
- [ ] 理解GNN消息传递
- [ ] 理解Varifolds度量
- [ ] 能实现简单GNN

---

## 学习建议

### 学习顺序
1. **按顺序学习**: 变分法 → 凸优化 → 贝叶斯 → 张量分解 → 图论
2. **理论+实践**: 每个知识点都要配合代码实现
3. **论文结合**: 学习理论时同步阅读相关论文

### 时间分配
- 理论学习: 40%
- 论文阅读: 30%
- 代码实现: 30%

### 实践平台
- Python + PyTorch
- CVXOPT (凸优化)
- emcee (贝叶斯采样)
- TensorLy (张量分解)
| PyTorch Geometric (图神经网络)

---

*创建日期: 2026年2月9日*
*版本: 1.0*
*创建者: 论文学习小分队*
