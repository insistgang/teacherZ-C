# [4-16] æƒ…æ„Ÿæ„ŸçŸ¥ä¸ªæ€§æ£€æµ‹ - ç²¾è¯»ç¬”è®°

> **è®ºæ–‡æ ‡é¢˜**: EmoPerso: Emotion-Aware Personality Detection
> **é˜…è¯»æ—¥æœŸ**: 2026å¹´2æœˆ10æ—¥
> **éš¾åº¦è¯„çº§**: â­â­â­ (ä¸­ç­‰)
> **é‡è¦æ€§**: â­â­â­ (è‡ªç›‘ç£å­¦ä¹ )

---

## ğŸ“‹ è®ºæ–‡åŸºæœ¬ä¿¡æ¯

| é¡¹ç›® | å†…å®¹ |
|:---|:---|
| **æ ‡é¢˜** | EmoPerso: Emotion-Aware Personality Detection |
| **ä½œè€…** | Xiaohao Cai ç­‰äºº |
| **å‘è¡¨æœŸåˆŠ** | IEEE Transactions on Affective Computing |
| **å‘è¡¨å¹´ä»½** | 2020 |
| **æ–‡ç« ç±»å‹** | å…¨æ–‡è®ºæ–‡ |
| **å…³é”®è¯** | Personality Detection, Emotion Recognition, Self-Supervised Learning |
| **å½±å“å› å­** | IEEE TAFFC (2020) ~4.5 |

---

## ğŸ¯ ç ”ç©¶é—®é¢˜

### ä¸ªæ€§æ£€æµ‹æŒ‘æˆ˜

**æ ¸å¿ƒé—®é¢˜**: å¦‚ä½•åˆ©ç”¨æƒ…æ„Ÿä¿¡æ¯è¾…åŠ©ä¸ªæ€§æ£€æµ‹

**ä¸ªæ€§ç»´åº¦ (Big Five)**:
```
OCEANæ¨¡å‹:
â”œâ”€â”€ O: Openness (å¼€æ”¾æ€§)
â”œâ”€â”€ C: Conscientiousness (å°½è´£æ€§)
â”œâ”€â”€ E: Extraversion (å¤–å‘æ€§)
â”œâ”€â”€ A: Agreeableness (å®œäººæ€§)
â””â”€â”€ N: Neuroticism (ç¥ç»è´¨)
```

---

## ğŸ”¬ æ–¹æ³•è®ºè¯¦è§£

### æ ¸å¿ƒç»„ä»¶: æƒ…æ„Ÿæ„ŸçŸ¥è‡ªç›‘ç£å­¦ä¹ 

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class EmoPerso(nn.Module):
    """
    æƒ…æ„Ÿæ„ŸçŸ¥ä¸ªæ€§æ£€æµ‹

    è‡ªç›‘ç£é¢„è®­ç»ƒ + ä¸ªæ€§åˆ†ç±»
    """
    def __init__(self, num_personality_traits=5):
        super().__init__()

        # å›¾åƒç¼–ç å™¨
        self.image_encoder = nn.Sequential(
            nn.Conv2d(3, 64, 3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(64, 128, 3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(128, 256, 3, padding=1),
            nn.ReLU(),
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
            nn.Linear(256, 128)
        )

        # æƒ…æ„Ÿé¢„æµ‹å¤´ (è‡ªç›‘ç£ä»»åŠ¡)
        self.emotion_head = nn.Sequential(
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 8)  # 8ç§åŸºæœ¬æƒ…æ„Ÿ
        )

        # ä¸ªæ€§é¢„æµ‹å¤´
        self.personality_head = nn.Sequential(
            nn.Linear(128 + 8, 64),  # èåˆæƒ…æ„Ÿå’Œè§†è§‰ç‰¹å¾
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(64, num_personality_traits),
            nn.Sigmoid()  # è¾“å‡º0-1åˆ†æ•°
        )

    def forward(self, image):
        """
        å‰å‘ä¼ æ’­

        Args:
            image: é¢éƒ¨å›¾åƒ

        Returns:
            personality: ä¸ªæ€§åˆ†æ•° (O, C, E, A, N)
            emotion: æƒ…æ„Ÿé¢„æµ‹
        """
        # ç¼–ç 
        features = self.image_encoder(image)

        # æƒ…æ„Ÿé¢„æµ‹
        emotion_logits = self.emotion_head(features)
        emotion_prob = F.softmax(emotion_logits, dim=1)

        # èåˆç‰¹å¾
        fused = torch.cat([features, emotion_prob], dim=1)

        # ä¸ªæ€§é¢„æµ‹
        personality = self.personality_head(fused)

        return personality, emotion_prob

    def self_supervised_pretrain(self, images, emotion_labels):
        """
        è‡ªç›‘ç£é¢„è®­ç»ƒ

        å…ˆè®­ç»ƒæƒ…æ„Ÿè¯†åˆ«ä½œä¸ºè¾…åŠ©ä»»åŠ¡
        """
        features = self.image_encoder(images)
        emotion_pred = self.emotion_head(features)

        loss = F.cross_entropy(emotion_pred, emotion_labels)

        return loss
```

---

## ğŸ’¡ å¯¹è¿å»ºæ£€æµ‹çš„è¿ç§»

```python
class SelfSupervisedChangeDetection(nn.Module):
    """
    è‡ªç›‘ç£å˜åŒ–æ£€æµ‹ - åŸºäº[4-16]æ€æƒ³

    ä½¿ç”¨é‡å»ºä½œä¸ºè‡ªç›‘ç£ä»»åŠ¡
    """
    def __init__(self):
        super().__init__()

        # ç¼–ç å™¨
        self.encoder = nn.Sequential(
            nn.Conv2d(3, 64, 3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(64, 128, 3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2)
        )

        # è§£ç å™¨ (è‡ªç›‘ç£é‡å»º)
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(128, 64, 2, stride=2),
            nn.ReLU(),
            nn.ConvTranspose2d(64, 3, 2, stride=2),
            nn.Sigmoid()
        )

        # å˜åŒ–æ£€æµ‹å¤´
        self.change_head = nn.Sequential(
            nn.Conv2d(128, 64, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(64, 1, 3, padding=1),
            nn.Sigmoid()
        )

    def forward(self, img):
        """å‰å‘ä¼ æ’­"""
        features = self.encoder(img)
        reconstructed = self.decoder(features)
        return reconstructed, features

    def detect_change(self, img_t1, img_t2):
        """æ£€æµ‹å˜åŒ–"""
        _, feat_t1 = self.forward(img_t1)
        _, feat_t2 = self.forward(img_t2)

        # ç‰¹å¾å·®å¼‚
        diff = torch.abs(feat_t1 - feat_t2)

        # å˜åŒ–é¢„æµ‹
        change = self.change_head(diff)

        return change

    def reconstruction_loss(self, img):
        """è‡ªç›‘ç£é‡å»ºæŸå¤±"""
        reconstructed, _ = self.forward(img)
        loss = F.mse_loss(reconstructed, img)
        return loss
```

---

**ç¬”è®°åˆ›å»ºæ—¶é—´**: 2026å¹´2æœˆ10æ—¥
**çŠ¶æ€**: å·²å®Œæˆç²¾è¯» âœ…
