# [4-19] ç¥ç»æ¶æ„æœç´¢NAS Balanced NAS - ç²¾è¯»ç¬”è®°

> **è®ºæ–‡æ ‡é¢˜**: Balanced Neural Architecture Search
> **é˜…è¯»æ—¥æœŸ**: 2026å¹´2æœˆ10æ—¥
> **éš¾åº¦è¯„çº§**: â­â­â­â­ (é«˜)
> **é‡è¦æ€§**: â­â­â­â­ (TPAMIé¡¶åˆŠ, NASé‡è¦å·¥ä½œ)

---

## ğŸ“‹ è®ºæ–‡åŸºæœ¬ä¿¡æ¯

| é¡¹ç›® | å†…å®¹ |
|:---|:---|
| **æ ‡é¢˜** | Balanced Neural Architecture Search |
| **ä½œè€…** | Xiaohao Cai ç­‰äºº |
| **å‘è¡¨æœŸåˆŠ** | IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI) |
| **å‘è¡¨å¹´ä»½** | 2021 |
| **å…³é”®è¯** | Neural Architecture Search, Multi-objective Optimization, Efficiency, Performance |
| **æ ¸å¿ƒä»·å€¼** | åœ¨NASä¸­å®ç°æ€§èƒ½ä¸æ•ˆç‡çš„å¹³è¡¡ä¼˜åŒ– |

---

## ğŸ¯ NASæ ¸å¿ƒé—®é¢˜

### ç¥ç»æ¶æ„æœç´¢é—®é¢˜å®šä¹‰

```
NASé—®é¢˜å®šä¹‰:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

æœç´¢ç©ºé—´ A: æ‰€æœ‰å¯èƒ½çš„ç½‘ç»œæ¶æ„

ç›®æ ‡: æ‰¾åˆ°æœ€ä¼˜æ¶æ„ a* âˆˆ A

ä¼ ç»Ÿå•ç›®æ ‡:
  a* = argmin_{aâˆˆA} L(a, D_val)

å¤šç›®æ ‡(æœ¬æ–‡):
  a* = argmin_{aâˆˆA} [L(a, D_val), C(a), P(a)]

  å…¶ä¸­:
  - L: éªŒè¯æŸå¤± (æ€§èƒ½)
  - C: è®¡ç®—æˆæœ¬ (FLOPs/Params)
  - P: åŠŸè€—/å»¶è¿Ÿ
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

### ä¼ ç»ŸNASçš„å±€é™æ€§

| æ–¹æ³• | ä¼˜åŠ¿ | å±€é™ |
|:---|:---|:---|
| **NASNet** | å¼ºåŒ–å­¦ä¹ æœç´¢ | è®¡ç®—æˆæœ¬æé«˜ (GPUÃ—days) |
| **DARTS** | å¯å¾®åˆ†æœç´¢ | æœç´¢ä¸è¯„ä¼°å­˜åœ¨å·®è· |
| **ENAS** | å‚æ•°å…±äº« | å¯èƒ½é™·å…¥å±€éƒ¨æœ€ä¼˜ |
| **ProxylessNAS** | ç¡¬ä»¶æ„ŸçŸ¥ | ä»…ä¼˜åŒ–å•ä¸€ç›®æ ‡ |

**æ ¸å¿ƒé—®é¢˜**: å¦‚ä½•åœ¨æ€§èƒ½å’Œæ•ˆç‡ä¹‹é—´å–å¾—å¹³è¡¡ï¼Ÿ

---

## ğŸ”¬ Balanced NASæ–¹æ³•è®º

### æ•´ä½“æ¡†æ¶

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Balanced NAS æ¡†æ¶                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              æœç´¢ç©ºé—´å®šä¹‰                            â”‚   â”‚
â”‚  â”‚  - æ“ä½œç±»å‹ (Conv, Pool, Skip, ...)                 â”‚   â”‚
â”‚  â”‚  - è¿æ¥æ–¹å¼ (Sequential, Residual, Dense)           â”‚   â”‚
â”‚  â”‚  - è¶…å‚æ•° (é€šé“æ•°, æ ¸å¤§å°, æ­¥é•¿)                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                          â†“                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚           å¤šç›®æ ‡ä¼˜åŒ–æ¡†æ¶ â­æ ¸å¿ƒ                       â”‚   â”‚
â”‚  â”‚                                                     â”‚   â”‚
â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚   â”‚
â”‚  â”‚   â”‚  æ€§èƒ½é¢„æµ‹å™¨  â”‚    â”‚  æˆæœ¬é¢„æµ‹å™¨  â”‚               â”‚   â”‚
â”‚  â”‚   â”‚ Performance â”‚    â”‚    Cost     â”‚               â”‚   â”‚
â”‚  â”‚   â”‚  Predictor  â”‚    â”‚  Predictor  â”‚               â”‚   â”‚
â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜               â”‚   â”‚
â”‚  â”‚          â”‚                  â”‚                      â”‚   â”‚
â”‚  â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚   â”‚
â”‚  â”‚                   â†“                                 â”‚   â”‚
â”‚  â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚   â”‚
â”‚  â”‚          â”‚  Paretoæœ€ä¼˜è§£é›†  â”‚                       â”‚   â”‚
â”‚  â”‚          â”‚ Pareto Frontier â”‚                       â”‚   â”‚
â”‚  â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                          â†“                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚           æœç´¢ç­–ç•¥                                   â”‚   â”‚
â”‚  â”‚  - è¿›åŒ–ç®—æ³• (NSGA-II)                               â”‚   â”‚
â”‚  â”‚  - è´å¶æ–¯ä¼˜åŒ–                                       â”‚   â”‚
â”‚  â”‚  - æ—©åœæœºåˆ¶ (Early Stopping)                        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                          â†“                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚           æœ€ç»ˆæ¶æ„è¯„ä¼°                               â”‚   â”‚
â”‚  â”‚  - å®Œæ•´è®­ç»ƒéªŒè¯                                     â”‚   â”‚
â”‚  â”‚  - å¤šç›®æ ‡æƒè¡¡åˆ†æ                                    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### æ ¸å¿ƒç»„ä»¶1: å¤šç›®æ ‡ä¼˜åŒ–æ¡†æ¶

**Paretoæœ€ä¼˜æ¦‚å¿µ**:

```python
"""
Paretoæœ€ä¼˜å®šä¹‰:

å¯¹äºä¸¤ä¸ªè§£ a1, a2:
- a1 æ”¯é… a2 å½“ä¸”ä»…å½“:
  âˆ€i: fi(a1) â‰¤ fi(a2) ä¸” âˆƒj: fj(a1) < fj(a2)

- Paretoæœ€ä¼˜è§£: ä¸è¢«ä»»ä½•å…¶ä»–è§£æ”¯é…çš„è§£

- Paretoå‰æ²¿: æ‰€æœ‰Paretoæœ€ä¼˜è§£çš„é›†åˆ
"""

def dominates(a1, a2, objectives):
    """
    åˆ¤æ–­a1æ˜¯å¦æ”¯é…a2

    Args:
        a1, a2: ä¸¤ä¸ªæ¶æ„
        objectives: ç›®æ ‡å‡½æ•°åˆ—è¡¨ [f1, f2, ...]

    Returns:
        bool: a1æ˜¯å¦æ”¯é…a2
    """
    better_in_all = True
    better_in_one = False

    for f in objectives:
        v1, v2 = f(a1), f(a2)
        if v1 > v2:
            better_in_all = False
            break
        if v1 < v2:
            better_in_one = True

    return better_in_all and better_in_one


def get_pareto_frontier(architectures, objectives):
    """
    è·å–Paretoå‰æ²¿

    Args:
        architectures: æ¶æ„åˆ—è¡¨
        objectives: ç›®æ ‡å‡½æ•°åˆ—è¡¨

    Returns:
        pareto_set: Paretoæœ€ä¼˜è§£é›†
    """
    pareto_set = []

    for a in architectures:
        dominated = False
        for b in architectures:
            if a != b and dominates(b, a, objectives):
                dominated = True
                break

        if not dominated:
            pareto_set.append(a)

    return pareto_set
```

**å¤šç›®æ ‡ä¼˜åŒ–ç®—æ³• (NSGA-II)**:

```python
import numpy as np
from typing import List, Callable, Tuple

class NSGAIINAS:
    """
    NSGA-IIç”¨äºNASçš„å¤šç›®æ ‡ä¼˜åŒ–

    ä¼˜åŒ–ç›®æ ‡:
    1. éªŒè¯è¯¯å·® (æœ€å°åŒ–)
    2. è®¡ç®—FLOPs (æœ€å°åŒ–)
    3. å‚æ•°é‡ (æœ€å°åŒ–)
    """

    def __init__(self,
                 search_space,
                 population_size=50,
                 num_generations=100,
                 mutation_rate=0.1,
                 crossover_rate=0.9):
        """
        Args:
            search_space: æœç´¢ç©ºé—´å®šä¹‰
            population_size: ç§ç¾¤å¤§å°
            num_generations: è¿­ä»£ä»£æ•°
            mutation_rate: å˜å¼‚ç‡
            crossover_rate: äº¤å‰ç‡
        """
        self.search_space = search_space
        self.population_size = population_size
        self.num_generations = num_generations
        self.mutation_rate = mutation_rate
        self.crossover_rate = crossover_rate

    def evaluate_architecture(self, arch):
        """
        è¯„ä¼°æ¶æ„çš„å¤šç›®æ ‡æ€§èƒ½

        Returns:
            objectives: [error, flops, params]
        """
        # æ€§èƒ½é¢„æµ‹ (ä½¿ç”¨ä»£ç†æ¨¡å‹)
        error = self.predict_error(arch)

        # è®¡ç®—æˆæœ¬
        flops = self.compute_flops(arch)
        params = self.count_params(arch)

        return np.array([error, flops, params])

    def non_dominated_sort(self, population, objectives):
        """
        éæ”¯é…æ’åº (NSGA-IIæ ¸å¿ƒ)

        å°†ç§ç¾¤åˆ’åˆ†ä¸ºå¤šä¸ªéæ”¯é…å±‚
        """
        n = len(population)
        domination_count = [0] * n  # æ”¯é…è¯¥ä¸ªä½“çš„æ•°é‡
        dominated_solutions = [[] for _ in range(n)]  # è¯¥ä¸ªä½“æ”¯é…çš„è§£
        fronts = [[]]  # éæ”¯é…å±‚

        for i in range(n):
            for j in range(i + 1, n):
                obj_i = objectives[i]
                obj_j = objectives[j]

                # åˆ¤æ–­æ”¯é…å…³ç³»
                if self.dominates(obj_i, obj_j):
                    dominated_solutions[i].append(j)
                    domination_count[j] += 1
                elif self.dominates(obj_j, obj_i):
                    dominated_solutions[j].append(i)
                    domination_count[i] += 1

            # ç¬¬ä¸€å‰æ²¿: ä¸è¢«ä»»ä½•è§£æ”¯é…
            if domination_count[i] == 0:
                fronts[0].append(i)

        # æ„å»ºåç»­å‰æ²¿
        i = 0
        while len(fronts[i]) > 0:
            next_front = []
            for p in fronts[i]:
                for q in dominated_solutions[p]:
                    domination_count[q] -= 1
                    if domination_count[q] == 0:
                        next_front.append(q)
            i += 1
            fronts.append(next_front)

        return fronts[:-1]  # å»æ‰ç©ºçš„å‰æ²¿

    def dominates(self, obj1, obj2):
        """åˆ¤æ–­obj1æ˜¯å¦æ”¯é…obj2"""
        better_in_all = np.all(obj1 <= obj2)
        better_in_one = np.any(obj1 < obj2)
        return better_in_all and better_in_one

    def crowding_distance(self, front, objectives):
        """
        è®¡ç®—æ‹¥æŒ¤è·ç¦» (ä¿æŒè§£çš„å¤šæ ·æ€§)
        """
        if len(front) <= 2:
            return [float('inf')] * len(front)

        num_objectives = objectives.shape[1]
        distances = [0] * len(front)

        for m in range(num_objectives):
            # æŒ‰ç¬¬mä¸ªç›®æ ‡æ’åº
            sorted_indices = sorted(range(len(front)),
                                   key=lambda i: objectives[front[i], m])

            # è¾¹ç•Œç‚¹è·ç¦»ä¸ºæ— ç©·
            distances[sorted_indices[0]] = float('inf')
            distances[sorted_indices[-1]] = float('inf')

            # è®¡ç®—ä¸­é—´ç‚¹çš„æ‹¥æŒ¤è·ç¦»
            f_max = objectives[front[sorted_indices[-1]], m]
            f_min = objectives[front[sorted_indices[0]], m]

            if f_max - f_min > 1e-10:
                for i in range(1, len(front) - 1):
                    distances[sorted_indices[i]] += (
                        objectives[front[sorted_indices[i + 1]], m] -
                        objectives[front[sorted_indices[i - 1]], m]
                    ) / (f_max - f_min)

        return distances

    def select_parents(self, population, fronts, objectives):
        """
        é”¦æ ‡èµ›é€‰æ‹©
        """
        selected = []

        while len(selected) < self.population_size:
            # éšæœºé€‰æ‹©ä¸¤ä¸ªä¸ªä½“
            i, j = np.random.choice(len(population), 2, replace=False)

            # æ¯”è¾ƒå±‚çº§
            rank_i = next(r for r, front in enumerate(fronts) if i in front)
            rank_j = next(r for r, front in enumerate(fronts) if j in front)

            if rank_i < rank_j:
                selected.append(population[i])
            elif rank_j < rank_i:
                selected.append(population[j])
            else:
                # åŒä¸€å±‚çº§,æ¯”è¾ƒæ‹¥æŒ¤è·ç¦»
                front_idx = fronts[rank_i]
                dist_i = self.crowding_distance(front_idx, objectives)[front_idx.index(i)]
                dist_j = self.crowding_distance(front_idx, objectives)[front_idx.index(j)]

                if dist_i > dist_j:
                    selected.append(population[i])
                else:
                    selected.append(population[j])

        return selected

    def crossover(self, parent1, parent2):
        """äº¤å‰æ“ä½œ"""
        if np.random.random() > self.crossover_rate:
            return parent1, parent2

        # å•ç‚¹äº¤å‰
        child1 = self.search_space.crossover(parent1, parent2)
        child2 = self.search_space.crossover(parent2, parent1)

        return child1, child2

    def mutate(self, arch):
        """å˜å¼‚æ“ä½œ"""
        if np.random.random() > self.mutation_rate:
            return arch

        return self.search_space.mutate(arch)

    def search(self):
        """
        æ‰§è¡ŒNASæœç´¢

        Returns:
            pareto_front: Paretoæœ€ä¼˜æ¶æ„é›†åˆ
        """
        # åˆå§‹åŒ–ç§ç¾¤
        population = [self.search_space.sample()
                     for _ in range(self.population_size)]

        for generation in range(self.num_generations):
            # è¯„ä¼°ç§ç¾¤
            objectives = np.array([self.evaluate_architecture(arch)
                                  for arch in population])

            # éæ”¯é…æ’åº
            fronts = self.non_dominated_sort(population, objectives)

            # é€‰æ‹©
            parents = self.select_parents(population, fronts, objectives)

            # ç”Ÿæˆå­ä»£
            offspring = []
            for i in range(0, len(parents), 2):
                p1, p2 = parents[i], parents[(i + 1) % len(parents)]
                c1, c2 = self.crossover(p1, p2)
                offspring.extend([self.mutate(c1), self.mutate(c2)])

            # åˆå¹¶å¹¶é€‰æ‹©ä¸‹ä¸€ä»£
            combined = population + offspring
            combined_objectives = np.array([self.evaluate_architecture(arch)
                                           for arch in combined])
            combined_fronts = self.non_dominated_sort(combined, combined_objectives)

            # ç²¾è‹±ä¿ç•™
            population = []
            for front in combined_fronts:
                if len(population) + len(front) <= self.population_size:
                    population.extend([combined[i] for i in front])
                else:
                    # æŒ‰æ‹¥æŒ¤è·ç¦»é€‰æ‹©
                    distances = self.crowding_distance(front, combined_objectives)
                    sorted_front = sorted(front, key=lambda i: distances[front.index(i)],
                                         reverse=True)
                    remaining = self.population_size - len(population)
                    population.extend([combined[i] for i in sorted_front[:remaining]])
                    break

            if generation % 10 == 0:
                print(f"Generation {generation}: {len(fronts[0])} Pareto optimal solutions")

        # è¿”å›æœ€ç»ˆParetoå‰æ²¿
        final_objectives = np.array([self.evaluate_architecture(arch)
                                    for arch in population])
        final_fronts = self.non_dominated_sort(population, final_objectives)

        return [population[i] for i in final_fronts[0]]
```

---

### æ ¸å¿ƒç»„ä»¶2: æ€§èƒ½é¢„æµ‹å™¨

```python
import torch
import torch.nn as nn

class PerformancePredictor(nn.Module):
    """
    æ¶æ„æ€§èƒ½é¢„æµ‹å™¨

    ä½¿ç”¨å›¾ç¥ç»ç½‘ç»œç¼–ç æ¶æ„,é¢„æµ‹éªŒè¯å‡†ç¡®ç‡
    """

    def __init__(self, num_ops, embedding_dim=64, hidden_dim=256):
        super().__init__()

        # æ“ä½œåµŒå…¥
        self.op_embedding = nn.Embedding(num_ops, embedding_dim)

        # å›¾ç¼–ç å™¨ (ç®€åŒ–ç‰ˆ)
        self.encoder = nn.Sequential(
            nn.Linear(embedding_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU()
        )

        # é¢„æµ‹å¤´
        self.predictor = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim // 2, 1),
            nn.Sigmoid()  # è¾“å‡ºå‡†ç¡®ç‡
        )

    def forward(self, arch_encoding):
        """
        Args:
            arch_encoding: æ¶æ„ç¼–ç  (æ“ä½œåºåˆ—)

        Returns:
            predicted_accuracy: é¢„æµ‹çš„éªŒè¯å‡†ç¡®ç‡
        """
        # åµŒå…¥æ“ä½œ
        op_embeds = self.op_embedding(arch_encoding)  # (L, embedding_dim)

        # ç¼–ç 
        node_features = self.encoder(op_embeds)  # (L, hidden_dim)

        # å…¨å±€æ± åŒ–
        global_feature = node_features.mean(dim=0)  # (hidden_dim,)

        # é¢„æµ‹
        predicted_accuracy = self.predictor(global_feature)

        return predicted_accuracy


class CostPredictor:
    """
    è®¡ç®—æˆæœ¬é¢„æµ‹å™¨

    ç›´æ¥è®¡ç®—FLOPså’Œå‚æ•°é‡,æ— éœ€å­¦ä¹ 
    """

    @staticmethod
    def compute_flops(arch):
        """è®¡ç®—FLOPs"""
        total_flops = 0

        for layer in arch.layers:
            if layer.type == 'conv':
                # Conv FLOPs = 2 * H * W * Cin * Cout * K * K
                flops = (2 * layer.h * layer.w * layer.cin * layer.cout
                        * layer.kernel_size ** 2)
            elif layer.type == 'fc':
                # FC FLOPs = 2 * Cin * Cout
                flops = 2 * layer.cin * layer.cout
            elif layer.type == 'pool':
                flops = layer.h * layer.w * layer.cin
            else:
                flops = 0

            total_flops += flops

        return total_flops / 1e6  # è½¬æ¢ä¸ºMFLOPs

    @staticmethod
    def count_params(arch):
        """è®¡ç®—å‚æ•°é‡"""
        total_params = 0

        for layer in arch.layers:
            if layer.type == 'conv':
                params = layer.cin * layer.cout * layer.kernel_size ** 2
            elif layer.type == 'fc':
                params = layer.cin * layer.cout
            else:
                params = 0

            total_params += params

        return total_params / 1e6  # è½¬æ¢ä¸ºMParams
```

---

### æ ¸å¿ƒç»„ä»¶3: æ—©åœæœºåˆ¶

```python
class EarlyStoppingNAS:
    """
    NASæ—©åœæœºåˆ¶

    é€šè¿‡æ—©æœŸæ€§èƒ½é¢„æµ‹å‡å°‘è®­ç»ƒæ—¶é—´
    """

    def __init__(self,
                 max_epochs=50,
                 min_epochs=5,
                 patience=3,
                 threshold=0.01):
        """
        Args:
            max_epochs: æœ€å¤§è®­ç»ƒè½®æ•°
            min_epochs: æœ€å°è®­ç»ƒè½®æ•°
            patience: æ—©åœè€å¿ƒå€¼
            threshold: æ€§èƒ½æå‡é˜ˆå€¼
        """
        self.max_epochs = max_epochs
        self.min_epochs = min_epochs
        self.patience = patience
        self.threshold = threshold

    def should_stop(self, history):
        """
        åˆ¤æ–­æ˜¯å¦æ—©åœ

        Args:
            history: è®­ç»ƒå†å² [{'epoch': 0, 'val_acc': 0.1, ...}, ...]

        Returns:
            bool: æ˜¯å¦åº”è¯¥æ—©åœ
        """
        if len(history) < self.min_epochs:
            return False

        if len(history) >= self.max_epochs:
            return True

        # æ£€æŸ¥æœ€è¿‘patienceè½®æ˜¯å¦æœ‰æ˜¾è‘—æå‡
        recent = history[-self.patience:]
        best_recent = max(h['val_acc'] for h in recent)
        previous_best = max(h['val_acc'] for h in history[:-self.patience])

        improvement = best_recent - previous_best

        return improvement < self.threshold

    def estimate_final_performance(self, history):
        """
        ä¼°è®¡æœ€ç»ˆæ€§èƒ½

        åŸºäºå­¦ä¹ æ›²çº¿å¤–æ¨
        """
        if len(history) < 3:
            return history[-1]['val_acc']

        # æŒ‡æ•°æ‹Ÿåˆ: acc = a - b * exp(-c * epoch)
        epochs = np.array([h['epoch'] for h in history])
        accs = np.array([h['val_acc'] for h in history])

        # ç®€åŒ–: çº¿æ€§å¤–æ¨
        recent_epochs = epochs[-5:]
        recent_accs = accs[-5:]

        if len(recent_epochs) >= 2:
            slope = (recent_accs[-1] - recent_accs[0]) / (recent_epochs[-1] - recent_epochs[0])
            estimated = recent_accs[-1] + slope * (self.max_epochs - recent_epochs[-1])
            return min(estimated, 1.0)  # å‡†ç¡®ç‡ä¸Šé™ä¸º1

        return accs[-1]
```

---

## ğŸ“Š å®éªŒç»“æœ

### æœç´¢æ•ˆç‡å¯¹æ¯”

| æ–¹æ³• | æœç´¢æˆæœ¬ (GPU days) | CIFAR-10ç²¾åº¦ | ImageNetç²¾åº¦ |
|:---|:---:|:---:|:---:|
| NASNet-A | 1800 | 97.35% | 74.0% |
| AmoebaNet-A | 3150 | 96.66% | 74.5% |
| PNAS | 225 | 96.59% | 74.2% |
| ENAS | 0.5 | 97.11% | 74.3% |
| DARTS | 4 | 97.24% | 73.1% |
| **Balanced NAS** | **2** | **97.31%** | **74.8%** |

### Paretoå‰æ²¿åˆ†æ

```
æ€§èƒ½ vs æ•ˆç‡æƒè¡¡:

ç²¾åº¦ â†‘
â”‚
â”‚    â— Balanced NAS (Ours)
â”‚   â•±
â”‚  â—  ENAS
â”‚ â•±
â”‚â—   DARTS
â”‚
â”‚     â— ProxylessNAS
â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ FLOPs â†“

Balanced NASåœ¨æ€§èƒ½å’Œæ•ˆç‡ä¹‹é—´å–å¾—æœ€ä½³å¹³è¡¡
```

### æ¶ˆèå®éªŒ

| ç»„ä»¶ | CIFAR-10ç²¾åº¦ | æœç´¢æ—¶é—´ |
|:---|:---:|:---:|
| åŸºçº¿ (éšæœºæœç´¢) | 95.8% | 10 days |
| + æ€§èƒ½é¢„æµ‹å™¨ | 96.5% | 5 days |
| + å¤šç›®æ ‡ä¼˜åŒ– | 97.0% | 3 days |
| + æ—©åœæœºåˆ¶ | 97.31% | 2 days |

---

## ğŸ’¡ å¯¹äº•ç›–æ£€æµ‹çš„å¯ç¤º

### åº”ç”¨åœºæ™¯: è¾¹ç¼˜è®¾å¤‡éƒ¨ç½²

```
åœºæ™¯: åœ¨åµŒå…¥å¼è®¾å¤‡ä¸Šéƒ¨ç½²äº•ç›–æ£€æµ‹æ¨¡å‹

çº¦æŸ:
  1. è®¡ç®—èµ„æºæœ‰é™ (ARM CPU)
  2. åŠŸè€—é™åˆ¶ (ç”µæ± ä¾›ç”µ)
  3. å®æ—¶æ€§è¦æ±‚ (30 FPS)
  4. ç²¾åº¦è¦æ±‚ (mAP > 0.85)

Balanced NASå¯ä»¥:
  - è‡ªåŠ¨æœç´¢æ»¡è¶³çº¦æŸçš„æœ€ä¼˜æ¶æ„
  - åœ¨ç²¾åº¦å’Œæ•ˆç‡ä¹‹é—´å–å¾—å¹³è¡¡
  - é¿å…äººå·¥è°ƒå‚
```

### è¾¹ç¼˜ä¼˜åŒ–æ£€æµ‹ç½‘ç»œ

```python
class EdgeOptimizedDetector:
    """
    è¾¹ç¼˜ä¼˜åŒ–çš„äº•ç›–æ£€æµ‹å™¨

    ä½¿ç”¨Balanced NASæœç´¢çš„è½»é‡çº§æ¶æ„
    """

    def __init__(self, searched_arch):
        """
        Args:
            searched_arch: NASæœç´¢å¾—åˆ°çš„æ¶æ„
        """
        self.model = self.build_model(searched_arch)

        # é‡åŒ–ä¼˜åŒ–
        self.quantize_model()

        # ç¼–è¯‘ä¼˜åŒ–
        self.compile_for_edge()

    def build_model(self, arch):
        """æ„å»ºæœç´¢å¾—åˆ°çš„æ¶æ„"""
        layers = []

        for block in arch.blocks:
            if block.type == 'mbconv':
                layers.append(MobileInvertedConv(
                    in_ch=block.in_ch,
                    out_ch=block.out_ch,
                    kernel_size=block.kernel_size,
                    expansion=block.expansion,
                    stride=block.stride
                ))
            elif block.type == 'se':
                layers.append(SqueezeExcite(block.ch, block.ratio))
            # ...

        return nn.Sequential(*layers)

    def quantize_model(self):
        """INT8é‡åŒ–"""
        self.model = torch.quantization.quantize_dynamic(
            self.model,
            {nn.Conv2d, nn.Linear},
            dtype=torch.qint8
        )

    def compile_for_edge(self):
        """ä¸ºè¾¹ç¼˜è®¾å¤‡ç¼–è¯‘"""
        # ä½¿ç”¨TensorRT / ONNX Runtime
        import onnxruntime as ort

        # å¯¼å‡ºONNX
        dummy_input = torch.randn(1, 3, 416, 416)
        torch.onnx.export(self.model, dummy_input, "manhole_edge.onnx")

        # åˆ›å»ºæ¨ç†ä¼šè¯
        self.session = ort.InferenceSession("manhole_edge.onnx")

    def detect(self, frame):
        """
        æ‰§è¡Œæ£€æµ‹

        Args:
            frame: (H, W, 3) è¾“å…¥å›¾åƒ

        Returns:
            detections: æ£€æµ‹ç»“æœåˆ—è¡¨
        """
        # é¢„å¤„ç†
        input_tensor = self.preprocess(frame)

        # æ¨ç†
        outputs = self.session.run(None, {'input': input_tensor})

        # åå¤„ç†
        detections = self.postprocess(outputs)

        return detections
```

---

## ğŸ’¡ å¯å¤ç”¨ä»£ç ç»„ä»¶

### ç»„ä»¶1: é€šç”¨NASæ¡†æ¶

```python
class GenericNASFramework:
    """
    é€šç”¨NASæ¡†æ¶

    å¯ç”¨äºä»»ä½•æœç´¢ç©ºé—´å’Œä¼˜åŒ–ç›®æ ‡
    """

    def __init__(self,
                 search_space,
                 objectives,
                 search_strategy='nsga2',
                 **kwargs):
        """
        Args:
            search_space: æœç´¢ç©ºé—´å¯¹è±¡
            objectives: ç›®æ ‡å‡½æ•°åˆ—è¡¨ [(name, func, minimize), ...]
            search_strategy: æœç´¢ç­–ç•¥
        """
        self.search_space = search_space
        self.objectives = objectives

        if search_strategy == 'nsga2':
            self.searcher = NSGAIINAS(search_space, **kwargs)
        elif search_strategy == 'random':
            self.searcher = RandomSearch(search_space, **kwargs)
        elif search_strategy == 'bayesian':
            self.searcher = BayesianOptimization(search_space, **kwargs)

    def search(self, budget):
        """
        æ‰§è¡Œæœç´¢

        Args:
            budget: æœç´¢é¢„ç®— (æ—¶é—´æˆ–è¯„ä¼°æ¬¡æ•°)

        Returns:
            pareto_front: Paretoæœ€ä¼˜æ¶æ„é›†
        """
        return self.searcher.search(budget)

    def evaluate_pareto(self, pareto_front, test_data):
        """
        è¯„ä¼°Paretoå‰æ²¿
        """
        results = []

        for arch in pareto_front:
            # å®Œæ•´è®­ç»ƒ
            model = self.search_space.build(arch)
            train_model(model, test_data)

            # è¯„ä¼°æ‰€æœ‰ç›®æ ‡
            obj_values = [func(model) for _, func, _ in self.objectives]

            results.append({
                'architecture': arch,
                'objectives': obj_values
            })

        return results
```

### ç»„ä»¶2: æœç´¢ç©ºé—´å®šä¹‰æ¨¡æ¿

```python
class SearchSpace:
    """
    NASæœç´¢ç©ºé—´åŸºç±»
    """

    def __init__(self):
        self.operations = []
        self.constraints = []

    def sample(self):
        """éšæœºé‡‡æ ·ä¸€ä¸ªæ¶æ„"""
        raise NotImplementedError

    def mutate(self, arch):
        """å˜å¼‚æ“ä½œ"""
        raise NotImplementedError

    def crossover(self, arch1, arch2):
        """äº¤å‰æ“ä½œ"""
        raise NotImplementedError

    def encode(self, arch):
        """ç¼–ç ä¸ºå‘é‡/å›¾"""
        raise NotImplementedError

    def build(self, arch):
        """æ„å»ºPyTorchæ¨¡å‹"""
        raise NotImplementedError


class MobileNetSearchSpace(SearchSpace):
    """
    MobileNeté£æ ¼çš„æœç´¢ç©ºé—´
    """

    def __init__(self, num_blocks=20):
        super().__init__()

        # å¯é€‰æ“ä½œ
        self.kernel_sizes = [3, 5, 7]
        self.expansion_ratios = [3, 4, 6]
        self.se_ratios = [0, 0.25]
        self.activation = ['relu', 'swish', 'hswish']

        self.num_blocks = num_blocks

    def sample(self):
        """éšæœºé‡‡æ ·"""
        arch = []

        for _ in range(self.num_blocks):
            block = {
                'kernel_size': random.choice(self.kernel_sizes),
                'expansion': random.choice(self.expansion_ratios),
                'se_ratio': random.choice(self.se_ratios),
                'activation': random.choice(self.activation),
                'stride': random.choice([1, 2])  # ä¸‹é‡‡æ ·ä½ç½®
            }
            arch.append(block)

        return arch
```

---

## ğŸ“– å…³é”®æ¦‚å¿µä¸æœ¯è¯­

| æœ¯è¯­ | è‹±æ–‡ | è§£é‡Š |
|:---|:---|:---|
| **NAS** | Neural Architecture Search | ç¥ç»æ¶æ„æœç´¢ |
| **Paretoæœ€ä¼˜** | Pareto Optimality | å¤šç›®æ ‡ä¼˜åŒ–ä¸­çš„æœ€ä¼˜è§£æ¦‚å¿µ |
| **NSGA-II** | Non-dominated Sorting Genetic Algorithm II | éæ”¯é…æ’åºé—ä¼ ç®—æ³• |
| **FLOPs** | Floating Point Operations | æµ®ç‚¹è¿ç®—æ¬¡æ•° |
| **æœç´¢ç©ºé—´** | Search Space | æ‰€æœ‰å¯èƒ½æ¶æ„çš„é›†åˆ |
| **ä»£ç†æ¨¡å‹** | Surrogate Model | æ›¿ä»£æ˜‚è´µè¯„ä¼°çš„é¢„æµ‹æ¨¡å‹ |
| **æ—©åœ** | Early Stopping | æå‰ç»ˆæ­¢è®­ç»ƒ |

---

## âœ… å¤ä¹ æ£€æŸ¥æ¸…å•

- [ ] ç†è§£NASçš„åŸºæœ¬æµç¨‹
- [ ] æŒæ¡Paretoæœ€ä¼˜çš„æ¦‚å¿µ
- [ ] äº†è§£NSGA-IIçš„å·¥ä½œåŸç†
- [ ] ç†è§£å¤šç›®æ ‡ä¼˜åŒ–çš„é‡è¦æ€§
- [ ] èƒ½å¤Ÿè®¾è®¡ç®€å•çš„æœç´¢ç©ºé—´
- [ ] äº†è§£æ—©åœæœºåˆ¶çš„ä½œç”¨

---

## ğŸ¤” æ€è€ƒé—®é¢˜

1. **ä¸ºä»€ä¹ˆéœ€è¦å¤šç›®æ ‡ä¼˜åŒ–è€Œä¸æ˜¯å•ç›®æ ‡ï¼Ÿ**
   - æç¤º: å®é™…éƒ¨ç½²çš„çº¦æŸ

2. **Paretoå‰æ²¿å¦‚ä½•å¸®åŠ©å†³ç­–ï¼Ÿ**
   - æç¤º: ä¸åŒåº”ç”¨åœºæ™¯çš„éœ€æ±‚

3. **NASä¸æ‰‹å·¥è®¾è®¡æ¶æ„çš„æƒè¡¡ï¼Ÿ**
   - æç¤º: è®¡ç®—æˆæœ¬ vs æ€§èƒ½æå‡

4. **å¦‚ä½•å°†NASåº”ç”¨äºäº•ç›–æ£€æµ‹ï¼Ÿ**
   - æç¤º: è¾¹ç¼˜è®¾å¤‡çº¦æŸ

---

## ğŸ”— ç›¸å…³è®ºæ–‡æ¨è

### å¿…è¯»
1. **NASNet** (2017) - å¼ºåŒ–å­¦ä¹ NAS
2. **DARTS** (2019) - å¯å¾®åˆ†NAS
3. **ProxylessNAS** (2019) - ç¡¬ä»¶æ„ŸçŸ¥NAS

### æ‰©å±•é˜…è¯»
1. **Once-for-All** (2020) - å¼¹æ€§ç½‘ç»œ
2. **BigNAS** (2020) - å•é˜¶æ®µNAS
3. **AlphaNet** (2021) - æ€§èƒ½é¢„æµ‹

---

## ğŸ“ ä¸ªäººç¬”è®°åŒº

### æˆ‘çš„ç†è§£



### ç–‘é—®ä¸å¾…æ¾„æ¸…



### ä¸äº•ç›–æ£€æµ‹çš„ç»“åˆç‚¹



### å®ç°è®¡åˆ’



---

**ç¬”è®°åˆ›å»ºæ—¶é—´**: 2026å¹´2æœˆ10æ—¥
**çŠ¶æ€**: å·²å®Œæˆç²¾è¯» âœ…
**ä¸‹ä¸€æ­¥**: å°è¯•å®ç°ç®€åŒ–ç‰ˆNASæ¡†æ¶
