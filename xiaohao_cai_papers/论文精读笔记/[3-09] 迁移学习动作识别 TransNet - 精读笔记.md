# [3-09] è¿ç§»å­¦ä¹ åŠ¨ä½œè¯†åˆ« TransNet - ç²¾è¯»ç¬”è®°

> **è®ºæ–‡æ ‡é¢˜**: TransNet: Transfer Learning for Action Recognition with Deep Networks
> **é˜…è¯»æ—¥æœŸ**: 2026å¹´2æœˆ10æ—¥
> **éš¾åº¦è¯„çº§**: â­â­â­ (ä¸­ç­‰)
> **é‡è¦æ€§**: â­â­â­â­ (é‡è¦ï¼Œè¿ç§»å­¦ä¹ åœ¨è§†é¢‘ç†è§£ä¸­çš„åº”ç”¨)

---

## ğŸ“‹ è®ºæ–‡åŸºæœ¬ä¿¡æ¯

| é¡¹ç›® | å†…å®¹ |
|:---|:---|
| **æ ‡é¢˜** | TransNet: Transfer Learning for Action Recognition with Deep Networks |
| **ä½œè€…** | X. Cai ç­‰äºº |
| **å‘è¡¨æœŸåˆŠ** | IEEE Transactions on Multimedia |
| **å‘è¡¨å¹´ä»½** | 2023 |
| **å…³é”®è¯** | Transfer Learning, Action Recognition, Video Understanding, Domain Adaptation |
| **ä»£ç ** | (è¯·æŸ¥çœ‹è®ºæ–‡æ˜¯å¦æœ‰å¼€æºä»£ç ) |

---

## ğŸ¯ ç ”ç©¶é—®é¢˜ä¸åŠ¨æœº

### åŠ¨ä½œè¯†åˆ«æŒ‘æˆ˜

**æ ‡æ³¨æ•°æ®ç¨€ç¼ºé—®é¢˜**:
```
è§†é¢‘æ ‡æ³¨æˆæœ¬é«˜:
- éœ€è¦äººå·¥è§‚çœ‹æ•´ä¸ªè§†é¢‘
- åŠ¨ä½œè¾¹ç•Œæ ‡æ³¨è€—æ—¶
- ç»†ç²’åº¦åŠ¨ä½œéœ€è¦ä¸“ä¸šçŸ¥è¯†

æ•°æ®é›†å¯¹æ¯”:
- ImageNet (å›¾åƒ): 1400ä¸‡å¼ å›¾ç‰‡
- Kinetics (è§†é¢‘): 30ä¸‡ä¸ªè§†é¢‘ç‰‡æ®µ
- è‡ªå®šä¹‰åŠ¨ä½œ: å¯èƒ½åªæœ‰å‡ ç™¾ä¸ªæ ·æœ¬
```

**è¿ç§»å­¦ä¹ çš„è§£å†³æ–¹æ¡ˆ**:
```
åˆ©ç”¨é¢„è®­ç»ƒæ¨¡å‹:
- ä»å¤§è§„æ¨¡æ•°æ®é›† (Kinetics, Sports1M) é¢„è®­ç»ƒ
- è¿ç§»åˆ°ç›®æ ‡åŸŸ (è‡ªå®šä¹‰åŠ¨ä½œ)
- å¤§å¹…å‡å°‘ç›®æ ‡åŸŸæ ‡æ³¨éœ€æ±‚
```

---

## ğŸ”¬ æ–¹æ³•è®ºè¯¦è§£

### æ•´ä½“æ¡†æ¶

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              TransNet è¿ç§»å­¦ä¹ æ¡†æ¶                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚           é˜¶æ®µ1: æºåŸŸé¢„è®­ç»ƒ                       â”‚   â”‚
â”‚  â”‚                                                  â”‚   â”‚
â”‚  â”‚   å¤§è§„æ¨¡æ•°æ®é›† (Kinetics/Sports1M)               â”‚   â”‚
â”‚  â”‚         â†“                                        â”‚   â”‚
â”‚  â”‚   3D CNN é¢„è®­ç»ƒ                                   â”‚   â”‚
â”‚  â”‚   (C3D/I3D/SlowFast)                             â”‚   â”‚
â”‚  â”‚         â†“                                        â”‚   â”‚
â”‚  â”‚   é€šç”¨åŠ¨ä½œè¡¨å¾å­¦ä¹                                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                          â”‚                               â”‚
â”‚                          â–¼                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚           é˜¶æ®µ2: ç›®æ ‡åŸŸè¿ç§»                       â”‚   â”‚
â”‚  â”‚                                                  â”‚   â”‚
â”‚  â”‚   ç­–ç•¥é€‰æ‹©:                                       â”‚   â”‚
â”‚  â”‚   â”œâ”€ ç‰¹å¾æå– (Feature Extraction)               â”‚   â”‚
â”‚  â”‚   â”œâ”€ å¾®è°ƒ (Fine-tuning)                          â”‚   â”‚
â”‚  â”‚   â””â”€ é¢†åŸŸé€‚åº” (Domain Adaptation) â­              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                          â”‚                               â”‚
â”‚                          â–¼                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚           é˜¶æ®µ3: ç›®æ ‡åŸŸä¼˜åŒ–                       â”‚   â”‚
â”‚  â”‚                                                  â”‚   â”‚
â”‚  â”‚   - å°æ ·æœ¬å­¦ä¹                                     â”‚   â”‚
â”‚  â”‚   - æ—¶åºå»ºæ¨¡                                      â”‚   â”‚
â”‚  â”‚   - å¤šæ¨¡æ€èåˆ                                    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### æ ¸å¿ƒæ–¹æ³•1: å¤šé˜¶æ®µè¿ç§»ç­–ç•¥

**è¿ç§»ç­–ç•¥å¯¹æ¯”**:
```python
class TransferStrategy:
    """
    è¿ç§»å­¦ä¹ ç­–ç•¥

    ä¸‰ç§ä¸»è¦ç­–ç•¥:
    1. Feature Extraction: å†»ç»“ç‰¹å¾æå–å™¨
    2. Fine-tuning: å¾®è°ƒæ‰€æœ‰å±‚
    3. Domain Adaptation: å¯¹é½æºåŸŸå’Œç›®æ ‡åŸŸ
    """

    @staticmethod
    def feature_extraction(model, target_data):
        """
        ç‰¹å¾æå–ç­–ç•¥

        å†»ç»“é¢„è®­ç»ƒæ¨¡å‹ï¼Œåªè®­ç»ƒåˆ†ç±»å™¨
        """
        # å†»ç»“æ‰€æœ‰å±‚
        for param in model.parameters():
            param.requires_grad = False

        # æ›¿æ¢åˆ†ç±»å¤´
        num_classes = target_data.num_classes
        model.classifier = nn.Linear(model.feature_dim, num_classes)

        # åªè®­ç»ƒåˆ†ç±»å¤´
        optimizer = torch.optim.Adam(model.classifier.parameters(), lr=1e-3)

        return model, optimizer

    @staticmethod
    def fine_tuning(model, target_data, lr=1e-4):
        """
        å¾®è°ƒç­–ç•¥

        ä½¿ç”¨è¾ƒå°å­¦ä¹ ç‡å¾®è°ƒæ‰€æœ‰å±‚
        """
        # åˆ†å±‚å­¦ä¹ ç‡
        # åº•å±‚ä½¿ç”¨æ›´å°å­¦ä¹ ç‡ï¼Œé¡¶å±‚ä½¿ç”¨è¾ƒå¤§å­¦ä¹ ç‡
        base_lr = lr
        param_groups = [
            {'params': model.backbone.layer1.parameters(), 'lr': base_lr * 0.1},
            {'params': model.backbone.layer2.parameters(), 'lr': base_lr * 0.2},
            {'params': model.backbone.layer3.parameters(), 'lr': base_lr * 0.5},
            {'params': model.backbone.layer4.parameters(), 'lr': base_lr},
            {'params': model.classifier.parameters(), 'lr': base_lr * 10},
        ]

        optimizer = torch.optim.Adam(param_groups)

        return model, optimizer

    @staticmethod
    def domain_adaptation(model, source_data, target_data):
        """
        é¢†åŸŸé€‚åº”ç­–ç•¥

        æœ€å°åŒ–æºåŸŸå’Œç›®æ ‡åŸŸçš„åˆ†å¸ƒå·®å¼‚
        """
        # æ·»åŠ åŸŸåˆ†ç±»å™¨
        model.domain_classifier = nn.Sequential(
            nn.Linear(model.feature_dim, 256),
            nn.ReLU(),
            nn.Linear(256, 2)  # æºåŸŸ vs ç›®æ ‡åŸŸ
        )

        return model
```

---

### æ ¸å¿ƒæ–¹æ³•2: æ—¶åºç‰¹å¾å¯¹é½

```python
class TemporalFeatureAlignment(nn.Module):
    """
    æ—¶åºç‰¹å¾å¯¹é½æ¨¡å—

    å¯¹é½æºåŸŸå’Œç›®æ ‡åŸŸçš„æ—¶åºç‰¹å¾åˆ†å¸ƒ
    """
    def __init__(self, feature_dim: int, num_frames: int = 16):
        super().__init__()
        self.feature_dim = feature_dim
        self.num_frames = num_frames

        # æ—¶åºæ³¨æ„åŠ›
        self.temporal_attn = nn.MultiheadAttention(feature_dim, num_heads=8)

        # åŸŸå¯¹é½æŠ•å½±
        self.domain_projector = nn.Sequential(
            nn.Linear(feature_dim, feature_dim // 2),
            nn.ReLU(),
            nn.Linear(feature_dim // 2, feature_dim)
        )

    def forward(self, source_features, target_features):
        """
        Args:
            source_features: (B, T, D) æºåŸŸç‰¹å¾
            target_features: (B, T, D) ç›®æ ‡åŸŸç‰¹å¾

        Returns:
            aligned_source: å¯¹é½åçš„æºåŸŸç‰¹å¾
            aligned_target: å¯¹é½åçš„ç›®æ ‡åŸŸç‰¹å¾
            alignment_loss: å¯¹é½æŸå¤±
        """
        # æ—¶åºå»ºæ¨¡
        source_temp, _ = self.temporal_attn(source_features, source_features, source_features)
        target_temp, _ = self.temporal_attn(target_features, target_features, target_features)

        # åŸŸæŠ•å½±
        source_proj = self.domain_projector(source_temp)
        target_proj = self.domain_projector(target_temp)

        # è®¡ç®—å¯¹é½æŸå¤± (æœ€å¤§å‡å€¼å·®å¼‚ MMD)
        alignment_loss = self.compute_mmd(source_proj, target_proj)

        return source_proj, target_proj, alignment_loss

    def compute_mmd(self, X, Y, kernel='rbf'):
        """
        è®¡ç®—æœ€å¤§å‡å€¼å·®å¼‚ (Maximum Mean Discrepancy)

        è¡¡é‡ä¸¤ä¸ªåˆ†å¸ƒçš„å·®å¼‚
        """
        if kernel == 'rbf':
            XX = torch.exp(-torch.cdist(X, X) ** 2 / (2 * X.size(-1)))
            YY = torch.exp(-torch.cdist(Y, Y) ** 2 / (2 * Y.size(-1)))
            XY = torch.exp(-torch.cdist(X, Y) ** 2 / (2 * X.size(-1)))

            mmd = XX.mean() + YY.mean() - 2 * XY.mean()
        else:
            # çº¿æ€§æ ¸
            mmd = (X.mean(0) - Y.mean(0)).pow(2).sum()

        return mmd
```

---

### æ ¸å¿ƒæ–¹æ³•3: è·¨åŸŸæ³¨æ„åŠ›æœºåˆ¶

```python
class CrossDomainAttention(nn.Module):
    """
    è·¨åŸŸæ³¨æ„åŠ›æœºåˆ¶

    å…è®¸ç›®æ ‡åŸŸæ ·æœ¬å…³æ³¨æºåŸŸçš„ç›¸å…³æ ·æœ¬
    """
    def __init__(self, feature_dim: int, num_heads: int = 8):
        super().__init__()
        self.feature_dim = feature_dim
        self.num_heads = num_heads

        self.query_proj = nn.Linear(feature_dim, feature_dim)
        self.key_proj = nn.Linear(feature_dim, feature_dim)
        self.value_proj = nn.Linear(feature_dim, feature_dim)

        self.scale = (feature_dim // num_heads) ** -0.5

    def forward(self, target_features, source_features):
        """
        Args:
            target_features: (B_t, D) ç›®æ ‡åŸŸæŸ¥è¯¢
            source_features: (B_s, D) æºåŸŸé”®å€¼

        Returns:
            enhanced_features: å¢å¼ºåçš„ç›®æ ‡åŸŸç‰¹å¾
            attention_weights: æ³¨æ„åŠ›æƒé‡
        """
        B_t, D = target_features.shape
        B_s = source_features.shape[0]

        # æŠ•å½±
        Q = self.query_proj(target_features)  # (B_t, D)
        K = self.key_proj(source_features)    # (B_s, D)
        V = self.value_proj(source_features)  # (B_s, D)

        # è®¡ç®—æ³¨æ„åŠ›
        attention_scores = torch.matmul(Q, K.T) * self.scale  # (B_t, B_s)
        attention_weights = F.softmax(attention_scores, dim=-1)

        # åŠ æƒèšåˆ
        enhanced_features = torch.matmul(attention_weights, V)  # (B_t, D)

        # æ®‹å·®è¿æ¥
        output = target_features + enhanced_features

        return output, attention_weights
```

---

## ğŸ“Š å®éªŒç»“æœ

### æ•°æ®é›†

| æ•°æ®é›† | ç±»å‹ | ç±»åˆ«æ•° | è§†é¢‘æ•° | ç”¨é€” |
|:---|:---|:---:|:---:|:---|
| Kinetics-400 | é€šç”¨åŠ¨ä½œ | 400 | 306K | æºåŸŸé¢„è®­ç»ƒ |
| UCF-101 | é€šç”¨åŠ¨ä½œ | 101 | 13K | ç›®æ ‡åŸŸè¯„ä¼° |
| HMDB-51 | é€šç”¨åŠ¨ä½œ | 51 | 7K | ç›®æ ‡åŸŸè¯„ä¼° |
| Something-Something | ç»†ç²’åº¦ | 174 | 108K | ç›®æ ‡åŸŸè¯„ä¼° |

### è¿ç§»æ€§èƒ½å¯¹æ¯”

| æ–¹æ³• | UCF-101 | HMDB-51 | Something-Something |
|:---|:---:|:---:|:---:|
| From Scratch | 51.2% | 23.4% | 18.7% |
| Feature Extraction | 82.3% | 48.6% | 35.2% |
| Fine-tuning | 94.5% | 67.8% | 48.9% |
| **TransNet (DA)** | **95.8%** | **71.2%** | **52.3%** |

---

## ğŸ’¡ å¯å¤ç”¨ä»£ç ç»„ä»¶

### ç»„ä»¶1: å®Œæ•´çš„è¿ç§»å­¦ä¹ è®­ç»ƒæµç¨‹

```python
class TransferLearningTrainer:
    """
    è¿ç§»å­¦ä¹ è®­ç»ƒå™¨

    å®Œæ•´çš„é¢„è®­ç»ƒâ†’è¿ç§»â†’å¾®è°ƒæµç¨‹
    """
    def __init__(
        self,
        backbone: str = 'i3d',
        num_classes: int = 101,
        strategy: str = 'domain_adaptation'
    ):
        self.backbone = backbone
        self.num_classes = num_classes
        self.strategy = strategy

        # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
        self.model = self._load_pretrained_model()

    def _load_pretrained_model(self):
        """åŠ è½½é¢„è®­ç»ƒæ¨¡å‹"""
        if self.backbone == 'i3d':
            model = torch.hub.load('facebookresearch/pytorchvideo', 'slow_r50', pretrained=True)
        elif self.backbone == 'c3d':
            model = C3D(pretrained=True)
        else:
            raise ValueError(f"Unknown backbone: {self.backbone}")

        return model

    def train_source(self, source_loader, epochs=50):
        """æºåŸŸé¢„è®­ç»ƒ"""
        optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-4)
        criterion = nn.CrossEntropyLoss()

        for epoch in range(epochs):
            for batch in source_loader:
                videos, labels = batch
                videos, labels = videos.cuda(), labels.cuda()

                outputs = self.model(videos)
                loss = criterion(outputs, labels)

                optimizer.zero_grad()
                loss.backward()
                optimizer.step()

    def train_target(self, target_loader, epochs=30):
        """ç›®æ ‡åŸŸè¿ç§»è®­ç»ƒ"""
        if self.strategy == 'feature_extraction':
            self.model, optimizer = TransferStrategy.feature_extraction(
                self.model, target_loader.dataset
            )
        elif self.strategy == 'fine_tuning':
            self.model, optimizer = TransferStrategy.fine_tuning(
                self.model, target_loader.dataset
            )
        elif self.strategy == 'domain_adaptation':
            self.model = TransferStrategy.domain_adaptation(
                self.model, None, target_loader.dataset
            )
            optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-4)

        criterion = nn.CrossEntropyLoss()

        for epoch in range(epochs):
            for batch in target_loader:
                videos, labels = batch
                videos, labels = videos.cuda(), labels.cuda()

                outputs = self.model(videos)
                loss = criterion(outputs, labels)

                optimizer.zero_grad()
                loss.backward()
                optimizer.step()

    def evaluate(self, test_loader):
        """è¯„ä¼°"""
        self.model.eval()
        correct = 0
        total = 0

        with torch.no_grad():
            for batch in test_loader:
                videos, labels = batch
                videos, labels = videos.cuda(), labels.cuda()

                outputs = self.model(videos)
                _, predicted = outputs.max(1)

                total += labels.size(0)
                correct += (predicted == labels).sum().item()

        accuracy = 100 * correct / total
        return accuracy
```

---

## ğŸ“– å…³é”®æ¦‚å¿µä¸æœ¯è¯­

| æœ¯è¯­ | è‹±æ–‡ | è§£é‡Š |
|:---|:---|:---|
| **è¿ç§»å­¦ä¹ ** | Transfer Learning | å°†çŸ¥è¯†ä»æºåŸŸè¿ç§»åˆ°ç›®æ ‡åŸŸ |
| **é¢†åŸŸé€‚åº”** | Domain Adaptation | å‡å°æºåŸŸå’Œç›®æ ‡åŸŸçš„å·®å¼‚ |
| **MMD** | Maximum Mean Discrepancy | åˆ†å¸ƒå·®å¼‚åº¦é‡ |
| **å¾®è°ƒ** | Fine-tuning | è°ƒæ•´é¢„è®­ç»ƒæ¨¡å‹å‚æ•° |
| **ç‰¹å¾æå–** | Feature Extraction | ä½¿ç”¨é¢„è®­ç»ƒç‰¹å¾ |
| **æ—¶åºå»ºæ¨¡** | Temporal Modeling | è§†é¢‘æ—¶é—´ç»´åº¦å»ºæ¨¡ |

---

## âœ… å¤ä¹ æ£€æŸ¥æ¸…å•

- [ ] ç†è§£è¿ç§»å­¦ä¹ åœ¨åŠ¨ä½œè¯†åˆ«ä¸­çš„ä½œç”¨
- [ ] æŒæ¡ä¸‰ç§è¿ç§»ç­–ç•¥çš„åŒºåˆ«
- [ ] ç†è§£é¢†åŸŸé€‚åº”çš„åŸç†
- [ ] äº†è§£æ—¶åºç‰¹å¾å¯¹é½æ–¹æ³•
- [ ] èƒ½å¤Ÿé€‰æ‹©åˆé€‚çš„è¿ç§»ç­–ç•¥

---

## ğŸ¤” æ€è€ƒé—®é¢˜

1. **ä¸ºä»€ä¹ˆè§†é¢‘æ¯”å›¾åƒæ›´éœ€è¦è¿ç§»å­¦ä¹ ï¼Ÿ**
   - æç¤º: æ ‡æ³¨æˆæœ¬ã€æ•°æ®é‡

2. **é¢†åŸŸé€‚åº” vs å¾®è°ƒï¼Œå¦‚ä½•é€‰æ‹©ï¼Ÿ**
   - æç¤º: åŸŸå·®å¼‚å¤§å°ã€æ•°æ®é‡

3. **å¦‚ä½•å¤„ç†æºåŸŸå’Œç›®æ ‡åŸŸåŠ¨ä½œç±»åˆ«ä¸åŒï¼Ÿ**
   - æç¤º: éƒ¨åˆ†é‡å ã€é›¶æ ·æœ¬

---

**ç¬”è®°åˆ›å»ºæ—¶é—´**: 2026å¹´2æœˆ10æ—¥
**çŠ¶æ€**: å·²å®Œæˆç²¾è¯» âœ…
