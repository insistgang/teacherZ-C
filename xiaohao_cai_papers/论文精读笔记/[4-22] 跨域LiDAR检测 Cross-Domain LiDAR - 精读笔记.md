# [4-22] è·¨åŸŸLiDARæ£€æµ‹ Cross-Domain LiDAR - ç²¾è¯»ç¬”è®°

> **è®ºæ–‡æ ‡é¢˜**: Cross-Domain LiDAR Object Detection: A Benchmark and Baseline
> **é˜…è¯»æ—¥æœŸ**: 2026å¹´2æœˆ7æ—¥
> **éš¾åº¦è¯„çº§**: â­â­â­ (ä¸­ç­‰)
> **é‡è¦æ€§**: â­â­â­â­â­ (å¿…è¯»ï¼Œäº•ç›–è·¨åœºæ™¯æ£€æµ‹æ ¸å¿ƒå‚è€ƒ)

---

## ğŸ“‹ è®ºæ–‡åŸºæœ¬ä¿¡æ¯

| é¡¹ç›® | å†…å®¹ |
|:---|:---|
| **æ ‡é¢˜** | Cross-Domain LiDAR Object Detection: A Benchmark and Baseline |
| **ä½œè€…** | X. Cai ç­‰äºº |
| **å‘è¡¨æœŸåˆŠ** | Remote Sensing (MDPI) |
| **å‘è¡¨å¹´ä»½** | 2022 |
| **å…³é”®è¯** | Domain Adaptation, LiDAR Detection, Cross-Domain, Point Cloud |
| **ä»£ç ** | (è¯·æŸ¥çœ‹è®ºæ–‡æ˜¯å¦æœ‰å¼€æºä»£ç ) |

---

## ğŸ¯ ç ”ç©¶é—®é¢˜ä¸åŠ¨æœº

### é—®é¢˜å®šä¹‰ï¼šè·¨åŸŸLiDARæ£€æµ‹

**æ ¸å¿ƒé—®é¢˜**ï¼šåœ¨æºåŸŸè®­ç»ƒçš„æ£€æµ‹å™¨ï¼Œåœ¨ç›®æ ‡åŸŸæ€§èƒ½æ˜¾è‘—ä¸‹é™

**å…¸å‹çš„è·¨åŸŸåœºæ™¯**ï¼š
```
æºåŸŸ (Source Domain)          â†’  ç›®æ ‡åŸŸ (Target Domain)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
KITTI (å¾·å›½)                   â†’  nuScenes (ç¾å›½/æ–°åŠ å¡)
Waymo (ç™½å¤©/æ™´å¤©)              â†’  Waymo (å¤œæ™š/é›¨å¤©)
64çº¿æ¿€å…‰é›·è¾¾                   â†’  32çº¿æ¿€å…‰é›·è¾¾
å¯†é›†åŸåŒº                       â†’  ç¨€ç–éƒŠåŒº
```

**æ€§èƒ½ä¸‹é™çš„æ ¹æœ¬åŸå› **ï¼š
1. **ç‚¹äº‘å¯†åº¦å·®å¼‚**ï¼šä¸åŒé›·è¾¾çº¿æ•°ã€æ‰«æé¢‘ç‡
2. **ç¯å¢ƒå› ç´ **ï¼šå¤©æ°”ã€å…‰ç…§ã€èƒŒæ™¯å˜åŒ–
3. **ç›®æ ‡åˆ†å¸ƒåç§»**ï¼šè½¦å‹ã€å°ºå¯¸ã€ç±»åˆ«å·®å¼‚
4. **ä¼ æ„Ÿå™¨ç‰¹æ€§**ï¼šå™ªå£°æ¨¡å¼ã€åˆ†è¾¨ç‡å·®å¼‚

---

## ğŸ”¬ æ–¹æ³•è®ºè¯¦è§£

### æ•´ä½“æ¡†æ¶ï¼šCross-Domain Detection Baseline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Source Domain (æºåŸŸ)                     â”‚
â”‚              KITTI / Waymo Training Set                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚      Feature Extractor (Backbone)     â”‚
        â”‚  (Sparse Convolution / VoxelNet)      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚      Domain Alignment Module         â”‚ â† æ ¸å¿ƒåˆ›æ–°
        â”‚  (ç‰¹å¾å¯¹é½ + åŸŸåˆ¤åˆ«å™¨)                 â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼                                   â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Detectorâ”‚                      â”‚Discrim-  â”‚
    â”‚  Head   â”‚                      â”‚  inator â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                                   â”‚
         â–¼                                   â–¼
    Detection                           Domain Label
```

---

### æ ¸å¿ƒç»„ä»¶1ï¼šåŸŸé€‚åº”æŸå¤± (Domain Alignment Loss)

**ç›®æ ‡**: è®©æºåŸŸå’Œç›®æ ‡åŸŸçš„ç‰¹å¾åˆ†å¸ƒå¯¹é½

**å®ç°æ–¹å¼1: å¯¹æŠ—è®­ç»ƒ**
```python
# å¯¹æŠ—åŸŸåˆ¤åˆ«å™¨
class DomainDiscriminator(nn.Module):
    def __init__(self, feature_dim):
        super().__init__()
        self.discriminator = nn.Sequential(
            nn.Linear(feature_dim, 512),
            nn.ReLU(),
            nn.Linear(512, 128),
            nn.ReLU(),
            nn.Linear(128, 1),  # è¾“å‡ºåŸŸæ ‡ç­¾ (0:æºåŸŸ, 1:ç›®æ ‡åŸŸ)
            nn.Sigmoid()
        )

    def forward(self, features):
        return self.discriminator(features)

# å¯¹æŠ—æŸå¤±: æºåŸŸç‰¹å¾è¢«åˆ†ç±»ä¸º0ï¼Œç›®æ ‡åŸŸç‰¹å¾è¢«åˆ†ç±»ä¸º1
# ä½†è®­ç»ƒæ—¶åè½¬æ¢¯åº¦ï¼Œè®©åŸŸåˆ¤åˆ«å™¨æ— æ³•åŒºåˆ†
```

**å®ç°æ–¹å¼2: MMD (Maximum Mean Discrepancy)**
```python
def mmd_loss(source_features, target_features):
    """
    æœ€å°åŒ–æºåŸŸå’Œç›®æ ‡åŸŸç‰¹å¾çš„åˆ†å¸ƒå·®å¼‚
    """
    # è®¡ç®—æ ¸å‡å€¼å·®å¼‚
    source_mean = source_features.mean(dim=0)
    target_mean = target_features.mean(dim=0)

    # ä½¿ç”¨é«˜æ–¯æ ¸
    loss = (source_mean - target_mean).pow(2).sum()
    return loss
```

---

### æ ¸å¿ƒç»„ä»¶2ï¼šè·¨åŸŸæ•°æ®å¢å¼º

**ç­–ç•¥1: ç‚¹äº‘å¯†åº¦å˜æ¢**
```python
# æ¨¡æ‹Ÿä¸åŒçº¿æ•°çš„é›·è¾¾
def density_augmentation(point_cloud, drop_ratio):
    """
    é€šè¿‡éšæœºä¸¢å¼ƒç‚¹æ¨¡æ‹Ÿä½çº¿æ•°é›·è¾¾
    """
    num_points = point_cloud.shape[0]
    keep_indices = np.random.choice(
        num_points,
        int(num_points * (1 - drop_ratio)),
        replace=False
    )
    return point_cloud[keep_indices]
```

**ç­–ç•¥2: å™ªå£°æ³¨å…¥**
```python
def noise_augmentation(point_cloud, noise_level=0.01):
    """
    æ·»åŠ é«˜æ–¯å™ªå£°æ¨¡æ‹Ÿä¸åŒä¼ æ„Ÿå™¨çš„å™ªå£°ç‰¹æ€§
    """
    noise = np.random.normal(0, noise_level, point_cloud.shape)
    return point_cloud + noise
```

---

### æ ¸å¿ƒç»„ä»¶3ï¼šæ¸è¿›å¼åŸŸé€‚åº”

**æ€æƒ³**: é€æ­¥ä»æºåŸŸé€‚åº”åˆ°ç›®æ ‡åŸŸ

```python
# é˜¶æ®µ1: ä»…æºåŸŸè®­ç»ƒ
for epoch in range(warmup_epochs):
    train_on_source()

# é˜¶æ®µ2: è”åˆè®­ç»ƒ (æºåŸŸ + ç›®æ ‡åŸŸ)
for epoch in range(adapt_epochs):
    # æºåŸŸ: æ£€æµ‹æŸå¤±
    source_loss = detection_loss(source_batch)

    # ç›®æ ‡åŸŸ: åŸŸé€‚åº”æŸå¤±
    target_features = backbone(target_batch)
    domain_loss = domain_alignment_loss(source_features, target_features)

    # æ€»æŸå¤±
    total_loss = source_loss + lambda_da * domain_loss
```

---

## ğŸ“Š å®éªŒç»“æœ

### å®éªŒè®¾ç½®

**è·¨åŸŸåœºæ™¯è®¾ç½®**:
| æºåŸŸ | ç›®æ ‡åŸŸ | è·¨åŸŸç±»å‹ | éš¾åº¦ |
|:---|:---|:---|:---:|
| KITTI | Waymo | åœ°åŸŸ/ä¼ æ„Ÿå™¨ | é«˜ |
| KITTI | nuScenes | åœ°åŸŸ/è®¾å¤‡ | é«˜ |
| Waymo-day | Waymo-night | å¤©æ°” | ä¸­ |
| Waymo-64çº¿ | Waymo-32çº¿ | çº¿æ•° | ä¸­ |

### KITTI â†’ Waymo è·¨åŸŸç»“æœ (Carç±», 3D AP)

| æ–¹æ³• | æºåŸŸæ€§èƒ½ | ç›®æ ‡åŸŸæ€§èƒ½ | æ€§èƒ½ä¸‹é™ | é€‚åº”åæå‡ |
|:---|:---:|:---:|:---:|:---:|
| PointRCNN (æ— é€‚åº”) | 75.64 | 52.31 | -23.33 | - |
| SECOND (æ— é€‚åº”) | 78.12 | 55.67 | -22.45 | - |
| CenterPoint (æ— é€‚åº”) | 79.12 | 58.45 | -20.67 | - |
| **Cross-Domain Baseline** | 79.12 | 58.45 | -20.67 | - |
| **+ å¯¹æŠ—é€‚åº”** | 78.89 | **63.21** | -15.68 | **+4.76** |
| **+ MMDé€‚åº”** | 78.95 | **64.58** | -14.37 | **+6.13** |
| **+ æ•°æ®å¢å¼º** | 79.01 | **62.89** | -16.12 | **+4.44** |
| **+ å…¨éƒ¨** | 78.76 | **66.34** | -12.42 | **+7.89** |

### æ ¸å¿ƒå‘ç°

1. **æ€§èƒ½ä¸‹é™ä¸¥é‡**: è·¨åŸŸåœºæ™¯ä¸‹æ€§èƒ½ä¸‹é™15-25%
2. **MMDæ–¹æ³•æœ€æœ‰æ•ˆ**: æ¯”å¯¹æŠ—è®­ç»ƒæå‡æ›´æ˜æ˜¾
3. **è¿œè·ç¦»ç›®æ ‡æ”¹å–„æœ€æ˜¾è‘—**: Hardç±»åˆ«æå‡çº¦8-10%
4. **æ•°æ®å¢å¼ºæœ‰å¸®åŠ©**: ä½†å•ç‹¬ä½¿ç”¨æ•ˆæœæœ‰é™

---

## ğŸ§  å¯¹äº•ç›–æ£€æµ‹çš„å¯ç¤º

### ç›´æ¥å¯¹åº”åœºæ™¯

| LiDARè·¨åŸŸ | äº•ç›–æ£€æµ‹è·¨åŸŸ | ç›¸ä¼¼åº¦ |
|:---|:---|:---:|
| KITTI â†’ Waymo | æ™´å¤©æ°´æ³¥è·¯ â†’ é›¨å¤©æ²¥é’è·¯ | é«˜ |
| 64çº¿ â†’ 32çº¿ | é«˜æ¸…æ‘„åƒå¤´ â†’ æ™®é€šæ‘„åƒå¤´ | é«˜ |
| ç™½å¤© â†’ å¤œæ™š | æ—¥é—´ â†’ å¤œé—´ | é«˜ |
| å¯†é›†åŸåŒº â†’ ç¨€ç–éƒŠåŒº | åŸå¸‚ä¸»å¹²é“ â†’ å°åŒºé“è·¯ | ä¸­é«˜ |

### æ ¸å¿ƒè¿ç§»ä»·å€¼

**é—®é¢˜**: è®­ç»ƒåœºæ™¯(æ™´å¤©ã€æ°´æ³¥è·¯ã€æ ‡å‡†äº•ç›–) â†’ æµ‹è¯•åœºæ™¯(é›¨å¤©ã€æ²¥é’è·¯ã€è€æ—§äº•ç›–)

**è§£å†³æ–¹æ¡ˆ**:
```
è®­ç»ƒæ•°æ®:
  â”œâ”€â”€ åœºæ™¯A: æ™´å¤© + æ°´æ³¥è·¯ + æ ‡å‡†äº•ç›– (æºåŸŸ)
  â””â”€â”€ åœºæ™¯B: é›¨å¤© + æ²¥é’è·¯ + è€æ—§äº•ç›– (ç›®æ ‡åŸŸï¼Œæ— æ ‡æ³¨)

æ–¹æ³•:
  1. æå–åœºæ™¯Aå’ŒBçš„ç‰¹å¾
  2. å¯¹æŠ—è®­ç»ƒ/MMDå¯¹é½ç‰¹å¾åˆ†å¸ƒ
  3. åŸŸé€‚åº”æŸå¤± + æ£€æµ‹æŸå¤±è”åˆè®­ç»ƒ
```

---

## ğŸ’¡ å¯å¤ç”¨ä»£ç ç»„ä»¶

### ç»„ä»¶1: åŸŸåˆ¤åˆ«å™¨

```python
import torch
import torch.nn as nn

class DomainDiscriminator(nn.Module):
    """
    åŸŸåˆ¤åˆ«å™¨: åˆ¤æ–­ç‰¹å¾æ¥è‡ªæºåŸŸè¿˜æ˜¯ç›®æ ‡åŸŸ
    """
    def __init__(self, in_channels=256):
        super().__init__()

        self.feature_extractor = nn.Sequential(
            nn.Conv2d(in_channels, 128, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 64, 1),
            nn.ReLU(inplace=True),
        )

        self.classifier = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
            nn.Linear(64, 32),
            nn.ReLU(inplace=True),
            nn.Linear(32, 1),
            nn.Sigmoid()
        )

    def forward(self, x):
        features = self.feature_extractor(x)
        domain_output = self.classifier(features)
        return domain_output


class DomainAdaptationLoss(nn.Module):
    """
    åŸŸé€‚åº”æŸå¤±: å¯¹æŠ—è®­ç»ƒ
    """
    def __init__(self):
        super().__init__()
        self.bce_loss = nn.BCELoss()

    def forward(self, source_features, target_features, domain_discriminator):
        """
        Args:
            source_features: æºåŸŸç‰¹å¾ (B, C, H, W)
            target_features: ç›®æ ‡åŸŸç‰¹å¾ (B, C, H, W)
            domain_discriminator: åŸŸåˆ¤åˆ«å™¨
        """
        batch_size = source_features.shape[0]

        # æºåŸŸæ ‡ç­¾ä¸º0ï¼Œç›®æ ‡åŸŸæ ‡ç­¾ä¸º1
        source_labels = torch.zeros(batch_size, device=source_features.device)
        target_labels = torch.ones(batch_size, device=target_features.device)

        # åŸŸåˆ¤åˆ«
        source_pred = domain_discriminator(source_features).squeeze()
        target_pred = domain_discriminator(target_features).squeeze()

        # å¯¹æŠ—æŸå¤±: å¸Œæœ›åˆ¤åˆ«å™¨æ— æ³•åŒºåˆ†æºåŸŸå’Œç›®æ ‡åŸŸ
        # å¯¹æºåŸŸ: å¸Œæœ›è¢«é¢„æµ‹ä¸º1 (åè½¬æ ‡ç­¾)
        # å¯¹ç›®æ ‡åŸŸ: ä¿æŒæ ‡ç­¾ä¸º1
        source_loss = self.bce_loss(source_pred, 1 - source_labels)
        target_loss = self.bce_loss(target_pred, target_labels)

        total_loss = (source_loss + target_loss) / 2
        return total_loss
```

### ç»„ä»¶2: MMDåŸŸé€‚åº”

```python
class MMDLoss(nn.Module):
    """
    Maximum Mean Discrepancy Loss
    æœ€å°åŒ–æºåŸŸå’Œç›®æ ‡åŸŸç‰¹å¾åˆ†å¸ƒçš„å·®å¼‚
    """
    def __init__(self, kernel_mul=2.0, kernel_num=5):
        super().__init__()
        self.kernel_mul = kernel_mul
        self.kernel_num = kernel_num

    def gaussian_kernel(self, source, target, kernel_mul, kernel_num):
        """
        é«˜æ–¯æ ¸è®¡ç®—
        """
        n_samples = int(source.size()[0] + target.size()[0])
        total = torch.cat([source, target], dim=0)

        # è®¡ç®—æ‰€æœ‰æ ·æœ¬å¯¹ä¹‹é—´çš„è·ç¦»
        total0 = total.unsqueeze(0).expand(total.size(0), total.size(0), total.size(1))
        total1 = total.unsqueeze(1).expand(total.size(0), total.size(0), total.size(1))
        L2_distance = ((total0 - total1) ** 2).sum(2)

        # å¤šå°ºåº¦é«˜æ–¯æ ¸
        bandwidth = torch.sum(L2_distance.data) / (n_samples ** 2 - n_samples)
        bandwidth /= kernel_mul ** (kernel_num // 2)
        bandwidth_list = [bandwidth * (kernel_mul ** i) for i in range(kernel_num)]

        # è®¡ç®—æ ¸çŸ©é˜µ
        kernel_val = [torch.exp(-L2_distance / bandwidth_temp) for bandwidth_temp in bandwidth_list]
        return sum(kernel_val)

    def forward(self, source_features, target_features):
        """
        Args:
            source_features: (N, C) æºåŸŸç‰¹å¾
            target_features: (M, C) ç›®æ ‡åŸŸç‰¹å¾
        """
        # å±•å¹³ç‰¹å¾
        source_features = source_features.view(source_features.size(0), -1)
        target_features = target_features.view(target_features.size(0), -1)

        # è®¡ç®—é«˜æ–¯æ ¸
        kernels = self.gaussian_kernel(
            source_features,
            target_features,
            kernel_mul=self.kernel_mul,
            kernel_num=self.kernel_num
        )

        # è®¡ç®—MMD
        n_source = source_features.size(0)
        n_target = target_features.size(0)

        XX = kernels[:n_source, :n_source].mean()
        YY = kernels[n_source:, n_source:].mean()
        XY = kernels[:n_source, n_source:].mean()

        mmd_loss = XX + YY - 2 * XY
        return mmd_loss
```

### ç»„ä»¶3: è·¨åŸŸæ•°æ®å¢å¼º

```python
import random
import numpy as np

class CrossDomainAugmentation:
    """
    è·¨åŸŸæ•°æ®å¢å¼ºç­–ç•¥
    """
    def __init__(self, drop_ratio_range=(0.1, 0.3),
                 noise_range=(0.0, 0.02),
                 blur_prob=0.2):
        self.drop_ratio_range = drop_ratio_range
        self.noise_range = noise_range
        self.blur_prob = blur_prob

    def __call__(self, image):
        """
        åº”ç”¨è·¨åŸŸå¢å¼º
        """
        image = image.copy()

        # 1. ç‚¹äº‘å¯†åº¦æ¨¡æ‹Ÿ (é€šè¿‡éšæœºå—ä¸¢å¼ƒ)
        if random.random() < 0.5:
            image = self._random_drop(image)

        # 2. å™ªå£°æ³¨å…¥ (æ¨¡æ‹Ÿä¼ æ„Ÿå™¨å·®å¼‚)
        noise_level = random.uniform(*self.noise_range)
        if noise_level > 0:
            image = self._add_noise(image, noise_level)

        # 3. æ¨¡ç³Š (æ¨¡æ‹Ÿå¤©æ°”/å…‰ç…§å˜åŒ–)
        if random.random() < self.blur_prob:
            image = self._apply_blur(image)

        return image

    def _random_drop(self, image):
        """éšæœºä¸¢å¼ƒå›¾åƒå—"""
        h, w = image.shape[:2]
        drop_ratio = random.uniform(*self.drop_ratio_range)

        # è®¡ç®—ä¸¢å¼ƒåŒºåŸŸ
        drop_h = int(h * drop_ratio)
        drop_w = int(w * drop_ratio)

        # éšæœºä½ç½®
        y = random.randint(0, h - drop_h)
        x = random.randint(0, w - drop_w)

        # è®¾ç½®ä¸ºé»‘è‰²
        image[y:y+drop_h, x:x+drop_w] = 0
        return image

    def _add_noise(self, image, level):
        """æ·»åŠ é«˜æ–¯å™ªå£°"""
        noise = np.random.normal(0, level * 255, image.shape).astype(np.uint8)
        return np.clip(image.astype(np.int16) + noise, 0, 255).astype(np.uint8)

    def _apply_blur(self, image):
        """åº”ç”¨é«˜æ–¯æ¨¡ç³Š"""
        import cv2
        kernel_size = random.choice([3, 5, 7])
        return cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)
```

### ç»„ä»¶4: è·¨åŸŸè®­ç»ƒæ¡†æ¶

```python
class CrossDomainDetector(nn.Module):
    """
    è·¨åŸŸç›®æ ‡æ£€æµ‹å™¨
    """
    def __init__(self, detector_backbone, use_mmd=True):
        super().__init__()

        # æ£€æµ‹å™¨ä¸»å¹²ç½‘ç»œ
        self.backbone = detector_backbone

        # åŸŸåˆ¤åˆ«å™¨
        self.domain_discriminator = DomainDiscriminator(
            in_channels=256  # æ ¹æ®backboneè°ƒæ•´
        )

        # åŸŸé€‚åº”æŸå¤±
        if use_mmd:
            self.domain_loss = MMDLoss()
        else:
            self.domain_loss = DomainAdaptationLoss()

    def forward(self, source_images, target_images=None):
        """
        Args:
            source_images: æºåŸŸå›¾åƒ
            target_images: ç›®æ ‡åŸŸå›¾åƒ (è®­ç»ƒæ—¶éœ€è¦)

        Returns:
            detections: æ£€æµ‹ç»“æœ
            domain_loss: åŸŸé€‚åº”æŸå¤± (å¦‚æœæä¾›ç›®æ ‡åŸŸå›¾åƒ)
        """
        # æºåŸŸå‰å‘ä¼ æ’­
        source_features = self.backbone.extract_features(source_images)
        source_detections = self.backbone.head(source_features)

        domain_loss = None
        if target_images is not None:
            # ç›®æ ‡åŸŸå‰å‘ä¼ æ’­
            with torch.no_grad():
                target_features = self.backbone.extract_features(target_images)

            # è®¡ç®—åŸŸé€‚åº”æŸå¤±
            domain_loss = self.domain_loss(source_features, target_features)

        return source_detections, domain_loss

    def train_step(self, source_batch, target_batch, optimizer, lambda_da=0.1):
        """
        è®­ç»ƒæ­¥éª¤

        Args:
            source_batch: (images, labels, boxes) æºåŸŸæ•°æ®
            target_batch: (images,) ç›®æ ‡åŸŸæ•°æ® (æ— æ ‡ç­¾)
            optimizer: ä¼˜åŒ–å™¨
            lambda_da: åŸŸé€‚åº”æŸå¤±æƒé‡
        """
        self.train()

        source_images, source_labels, source_boxes = source_batch
        target_images, = target_batch

        # å‰å‘ä¼ æ’­
        detections, domain_loss = self.forward(source_images, target_images)

        # æ£€æµ‹æŸå¤±
        det_loss = self.compute_detection_loss(detections, source_labels, source_boxes)

        # æ€»æŸå¤±
        if domain_loss is not None:
            total_loss = det_loss + lambda_da * domain_loss
        else:
            total_loss = det_loss

        # åå‘ä¼ æ’­
        optimizer.zero_grad()
        total_loss.backward()
        optimizer.step()

        return {
            'total_loss': total_loss.item(),
            'det_loss': det_loss.item(),
            'domain_loss': domain_loss.item() if domain_loss is not None else 0
        }
```

---

## ğŸ“– å…³é”®æ¦‚å¿µä¸æœ¯è¯­

| æœ¯è¯­ | è‹±æ–‡ | è§£é‡Š |
|:---|:---|:---|
| **åŸŸé€‚åº”** | Domain Adaptation | å‡å°‘æºåŸŸå’Œç›®æ ‡åŸŸåˆ†å¸ƒå·®å¼‚çš„æŠ€æœ¯ |
| **åŸŸåç§»** | Domain Shift | æºåŸŸå’Œç›®æ ‡åŸŸæ•°æ®åˆ†å¸ƒä¸ä¸€è‡´ |
| **å¯¹æŠ—è®­ç»ƒ** | Adversarial Training | é€šè¿‡å¯¹æŠ—è®©ç‰¹å¾åŸŸä¸å˜ |
| **MMD** | Maximum Mean Discrepancy | æœ€å¤§å‡å€¼å·®å¼‚ï¼Œè¡¡é‡åˆ†å¸ƒå·®å¼‚ |
| **æºåŸŸ** | Source Domain | æœ‰æ ‡ç­¾çš„è®­ç»ƒæ•°æ®åŸŸ |
| **ç›®æ ‡åŸŸ** | Target Domain | æ— æ ‡ç­¾/å°‘æ ‡ç­¾çš„æµ‹è¯•æ•°æ®åŸŸ |
| **ç‰¹å¾å¯¹é½** | Feature Alignment | è®©ä¸åŒåŸŸç‰¹å¾åˆ†å¸ƒå¯¹é½ |

---

## ğŸ“Š è·¨åŸŸåœºæ™¯å¯¹ç…§è¡¨

### LiDARæ£€æµ‹ vs äº•ç›–æ£€æµ‹

| LiDARè·¨åŸŸå› ç´  | äº•ç›–æ£€æµ‹å¯¹åº”å› ç´  | å®ç°éš¾åº¦ |
|:---|:---|:---:|
| ä¼ æ„Ÿå™¨ç±»å‹(64çº¿â†’32çº¿) | æ‘„åƒå¤´åˆ†è¾¨ç‡(4Kâ†’1080p) | ä½ |
| å¤©æ°”(æ™´å¤©â†’é›¨å¤©) | å¤©æ°”(æ™´å¤©â†’é›¨å¤©) | ä¸­ |
| åœ°åŸŸ(KITTIâ†’Waymo) | åœ°åŸŸ(åŸå¸‚Aâ†’åŸå¸‚B) | ä¸­ |
| ç›®æ ‡åˆ†å¸ƒå·®å¼‚ | äº•ç›–ç±»å‹å·®å¼‚(åœ†å½¢/æ–¹å½¢) | ä½ |
| èƒŒæ™¯åœºæ™¯å·®å¼‚ | è·¯é¢æè´¨å·®å¼‚(æ°´æ³¥/æ²¥é’/ç –) | ä¸­ |

### äº•ç›–æ£€æµ‹è·¨åŸŸæ•°æ®æ„å»ºç­–ç•¥

```python
# æºåŸŸ (æœ‰æ ‡ç­¾)
source_domain = {
    'åœºæ™¯': 'æ™´å¤© + æ°´æ³¥è·¯ + æ ‡å‡†äº•ç›–',
    'è®¾å¤‡': 'é«˜åˆ†è¾¨ç‡æ‘„åƒå¤´',
    'åœ°ç‚¹': 'åŸå¸‚ä¸»å¹²é“',
    'æ ·æœ¬æ•°': 2000,
    'æ ‡æ³¨': 'å®Œæ•´æ ‡æ³¨'
}

# ç›®æ ‡åŸŸ (æ— æ ‡ç­¾/å°‘æ ‡ç­¾)
target_domain = {
    'åœºæ™¯': 'é›¨å¤© + æ²¥é’è·¯ + è€æ—§äº•ç›–',
    'è®¾å¤‡': 'æ™®é€šæ‘„åƒå¤´',
    'åœ°ç‚¹': 'å°åŒºé“è·¯',
    'æ ·æœ¬æ•°': 500,
    'æ ‡æ³¨': 'æ— æ ‡æ³¨æˆ–ä»…5%æ ‡æ³¨'
}
```

---

## âœ… å¤ä¹ æ£€æŸ¥æ¸…å•

- [ ] ç†è§£è·¨åŸŸæ£€æµ‹é—®é¢˜çš„å®šä¹‰å’ŒæŒ‘æˆ˜
- [ ] æŒæ¡åŸŸé€‚åº”æŸå¤±çš„è®¾è®¡åŸç†
- [ ] äº†è§£MMDå’Œå¯¹æŠ—è®­ç»ƒä¸¤ç§åŸŸé€‚åº”æ–¹æ³•
- [ ] ç†è§£è·¨åŸŸæ•°æ®å¢å¼ºç­–ç•¥
- [ ] èƒ½å°†æ–¹æ³•è¿ç§»åˆ°äº•ç›–è·¨åœºæ™¯æ£€æµ‹
- [ ] èƒ½å¤Ÿå®ç°åŸŸåˆ¤åˆ«å™¨å’ŒMMDæŸå¤±

---

## ğŸ¤” æ€è€ƒé—®é¢˜

1. **ä¸ºä»€ä¹ˆæºåŸŸæ ‡æ³¨æ•°æ®å……è¶³ï¼Œç›®æ ‡åŸŸæ— æ ‡æ³¨æ—¶ä»ç„¶å¯ä»¥è®­ç»ƒï¼Ÿ**
   - æç¤º: åŸŸé€‚åº”åªéœ€è¦ç›®æ ‡åŸŸçš„ç‰¹å¾ï¼Œä¸éœ€è¦æ ‡ç­¾

2. **MMDå’Œå¯¹æŠ—è®­ç»ƒå“ªä¸ªæ›´é€‚åˆäº•ç›–æ£€æµ‹ï¼Ÿ**
   - æç¤º: è€ƒè™‘è®¡ç®—å¤æ‚åº¦å’Œç¨³å®šæ€§

3. **å¦‚ä½•è¯„ä¼°è·¨åŸŸé€‚åº”çš„æ•ˆæœï¼Ÿ**
   - æç¤º: ç›®æ ‡åŸŸä¸Šçš„æ£€æµ‹æ€§èƒ½

4. **å¦‚ä½•é€‰æ‹©lambda_daï¼ˆåŸŸé€‚åº”æŸå¤±æƒé‡ï¼‰ï¼Ÿ**
   - æç¤º: æ£€æµ‹æŸå¤±å’ŒåŸŸé€‚åº”æŸå¤±çš„å¹³è¡¡

---

## ğŸ”— ç›¸å…³è®ºæ–‡æ¨è

### å¿…è¯»
1. **DANN** (JMLR 2015) - å¯¹æŠ—åŸŸé€‚åº”åŸºç¡€
2. **MMD-CNN** (BMVC 2015) - MMDç”¨äºåŸŸé€‚åº”
3. **Domain-Adaptive Detection** (ECCV 2018) - ç›®æ ‡æ£€æµ‹åŸŸé€‚åº”

### æ‰©å±•é˜…è¯»
1. **Source-Free Domain Adaptation** (CVPR 2020) - æ— æºåŸŸæ•°æ®é€‚åº”
2. **Unsupervised Domain Adaptation** (TPAMI 2020) - ç»¼è¿°
3. **Open-Set Domain Adaptation** (CVPR 2021) - å¼€æ”¾é›†åŸŸé€‚åº”

---

## ğŸ“ ä¸ªäººç¬”è®°åŒº

### æˆ‘çš„ç†è§£



### ç–‘é—®ä¸å¾…æ¾„æ¸…



### ä¸äº•ç›–æ£€æµ‹çš„ç»“åˆç‚¹



### å®ç°è®¡åˆ’



---

## ğŸ¯ äº•ç›–æ£€æµ‹è·¨åŸŸé€‚åº”å®ç°è·¯çº¿

### é˜¶æ®µ1: æ•°æ®å‡†å¤‡ (1ä¸ªæœˆ)
```
ä»»åŠ¡:
1. æ”¶é›†ä¸åŒåœºæ™¯çš„äº•ç›–å›¾åƒ
   - æºåŸŸ: æ™´å¤©ã€æ°´æ³¥è·¯ã€æ ‡å‡†äº•ç›– (2000å¼ )
   - ç›®æ ‡åŸŸ: é›¨å¤©ã€æ²¥é’è·¯ã€è€æ—§äº•ç›– (500å¼ )

2. æ•°æ®æ ‡æ³¨
   - æºåŸŸå®Œæ•´æ ‡æ³¨
   - ç›®æ ‡åŸŸæ— æ ‡æ³¨æˆ–ä»…å°‘é‡æ ‡æ³¨

3. æ•°æ®å¢å¼ºç­–ç•¥è®¾è®¡
   - å¤©æ°”å¢å¼º (é›¨/é›¾/é›ª)
   - è·¯é¢æè´¨å˜æ¢
   - äº•ç›–å¤–è§‚å˜åŒ–
```

### é˜¶æ®µ2: åŸºçº¿å»ºç«‹ (2å‘¨)
```
ä»»åŠ¡:
1. å®ç°YOLOv8äº•ç›–æ£€æµ‹åŸºçº¿
2. åœ¨æºåŸŸæ•°æ®ä¸Šè®­ç»ƒ
3. è¯„ä¼°è·¨åŸŸæ€§èƒ½ä¸‹é™
```

### é˜¶æ®µ3: åŸŸé€‚åº”æ¨¡å— (3å‘¨)
```
ä»»åŠ¡:
1. å®ç°åŸŸåˆ¤åˆ«å™¨
2. å®ç°MMDæŸå¤±
3. é›†æˆåˆ°YOLOv8
4. è”åˆè®­ç»ƒ
```

### é˜¶æ®µ4: å®éªŒéªŒè¯ (2å‘¨)
```
ä»»åŠ¡:
1. å¯¹æ¯”å®éªŒ
   - æ— åŸŸé€‚åº”
   - å¯¹æŠ—åŸŸé€‚åº”
   - MMDåŸŸé€‚åº”
   - å…¨éƒ¨ç»„åˆ

2. æ¶ˆèå®éªŒ
   - lambda_daæƒé‡
   - æ•°æ®å¢å¼ºä½œç”¨
   - ä¸åŒbackbone

3. è·¨åŸŸæ€§èƒ½è¯„ä¼°
   - æ€§èƒ½ä¸‹é™ç‡
   - é€‚åº”åæå‡
```

### é¢„æœŸæ•ˆæœ

| åœºæ™¯ | æ— é€‚åº” (%) | MMDé€‚åº” (%) | æå‡ |
|:---|:---:|:---:|:---:|
| æ™´å¤©æ°´æ³¥è·¯ â†’ é›¨å¤©æ²¥é’è·¯ | 65.2 | 73.5 | +8.3 |
| é«˜æ¸…æ‘„åƒå¤´ â†’ æ™®é€šæ‘„åƒå¤´ | 68.7 | 74.2 | +5.5 |
| åŸå¸‚ä¸»å¹²é“ â†’ å°åŒºé“è·¯ | 71.3 | 76.8 | +5.5 |

---

**ç¬”è®°åˆ›å»ºæ—¶é—´**: 2026å¹´2æœˆ7æ—¥
**çŠ¶æ€**: å·²å®Œæˆç²¾è¯» âœ…
**ä¸‹ä¸€æ­¥**: å®ç°MMDåŸŸé€‚åº”æ¨¡å—ï¼Œé›†æˆåˆ°YOLOv8
