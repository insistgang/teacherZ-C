# [4-21] GRASPTrack - ç²¾è¯»ç¬”è®°

> **è®ºæ–‡æ ‡é¢˜**: GRASPTrack: Geometric Reasoning and Association for Multiple Object Tracking
> **é˜…è¯»æ—¥æœŸ**: 2026å¹´2æœˆ7æ—¥
> **éš¾åº¦è¯„çº§**: â­â­â­â­ (é«˜)
> **é‡è¦æ€§**: â­â­â­â­â­ (å¿…è¯»ï¼ŒIEEE TIPå¤šç›®æ ‡è·Ÿè¸ª)

---

## ğŸ“‹ è®ºæ–‡åŸºæœ¬ä¿¡æ¯

| é¡¹ç›® | å†…å®¹ |
|:---|:---|
| **æ ‡é¢˜** | GRASPTrack: Geometric Reasoning and Association for Multiple Object Tracking |
| **ä½œè€…** | Xiaohao Cai ç­‰äºº |
| **å‘è¡¨æœŸåˆŠ** | IEEE Transactions on Image Processing (TIP) |
| **å‘è¡¨å¹´ä»½** | 2020 |
| **å…³é”®è¯** | Multi-Object Tracking, Geometric Reasoning, Data Association |
| **æ ¸å¿ƒä»·å€¼** | å‡ ä½•æ¨ç† + æ•°æ®å…³è”çš„åˆ›æ–°ç»“åˆ |

---

## ğŸ¯ å¤šç›®æ ‡è·Ÿè¸ªé—®é¢˜

### MOTæ ¸å¿ƒæŒ‘æˆ˜

```
é—®é¢˜å®šä¹‰:
  ç»™å®šè§†é¢‘åºåˆ—,ä¼°è®¡æ¯ä¸ªç›®æ ‡çš„:
    - è½¨è¿¹ (trajectory)
    - èº«ä»½ (identity)
    - çŠ¶æ€ (position, velocity, ...)

ä¸»è¦æŒ‘æˆ˜:
  1. ç›®æ ‡é®æŒ¡
  2. ç›¸ä¼¼å¤–è§‚æ··æ·†
  3. ç›®æ ‡è¿›å‡ºåœºæ™¯
  4. å®æ—¶æ€§è¦æ±‚
```

### ä¼ ç»Ÿæ–¹æ³•å±€é™æ€§

| æ–¹æ³• | ä¼˜åŠ¿ | å±€é™ |
|:---|:---|:---|
| **å¡å°”æ›¼æ»¤æ³¢** | ç®€å•é«˜æ•ˆ | ä»…é€‚ç”¨äºçº¿æ€§é«˜æ–¯ç³»ç»Ÿ |
| **åŒˆç‰™åˆ©ç®—æ³•** | å…¨å±€æœ€ä¼˜ | ä»…è€ƒè™‘å•å¸§å…³è” |
| **æ·±åº¦å­¦ä¹ å…³è”** | ç‰¹å¾å¼ºå¤§ | å¿½ç•¥å‡ ä½•çº¦æŸ |

---

## ğŸ”¬ GRASPTrackæ–¹æ³•è®º

### æ•´ä½“æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    å¸§tè¾“å…¥                               â”‚
â”‚              Detection + Re-Identification              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  ç‰¹å¾æå–æ¨¡å—                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚å¤–è§‚ç‰¹å¾      â”‚         â”‚å‡ ä½•ç‰¹å¾      â”‚              â”‚
â”‚  â”‚Appearance   â”‚         â”‚Geometric     â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  GRASPå…³è”æ¨¡å— â­æ ¸å¿ƒ                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚   å‡ ä½•æ¨ç† (Geometric Reasoning)             â”‚       â”‚
â”‚  â”‚   è¿åŠ¨é¢„æµ‹ + ç©ºé—´çº¦æŸ                          â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚   åˆ†å‰²å…³è” (Segmentation Association)        â”‚       â”‚
â”‚  â”‚   APç®—æ³• + æ‹†åˆ†åˆå¹¶                            â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  è½¨è¿¹ç®¡ç†                               â”‚
â”‚  åˆå§‹åŒ– â†’ æ›´æ–° â†’ åˆ é™¤ â†’ èº«ä»½åˆ‡æ¢                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### æ ¸å¿ƒç»„ä»¶1: å‡ ä½•æ¨ç†æ¨¡å—

**è¿åŠ¨é¢„æµ‹**:
```python
class GeometricReasoning(nn.Module):
    """
    å‡ ä½•æ¨ç†æ¨¡å—

    ç»“åˆè¿åŠ¨æ¨¡å‹å’Œå‡ ä½•çº¦æŸè¿›è¡ŒçŠ¶æ€é¢„æµ‹
    """
    def __init__(self, state_dim=4):
        super().__init__()
        self.state_dim = state_dim  # [x, y, vx, vy]

        # å¡å°”æ›¼æ»¤æ³¢å™¨å‚æ•°
        self.F = torch.tensor([
            [1, 0, 1, 0],  # x = x + vx
            [0, 1, 0, 1],  # y = y + vy
            [0, 0, 1, 0],  # vx = vx
            [0, 0, 0, 1]   # vy = vy
        ], dtype=torch.float32)

        # è¿‡ç¨‹å™ªå£°åæ–¹å·®
        self.Q = torch.eye(state_dim) * 0.1

        # è§‚æµ‹å™ªå£°åæ–¹å·®
        self.R = torch.eye(state_dim // 2) * 1.0

    def predict(self, tracks_state):
        """
        é¢„æµ‹ä¸‹ä¸€æ—¶åˆ»çŠ¶æ€

        Args:
            tracks_state: (N, 4) Nä¸ªè½¨è¿¹çš„çŠ¶æ€ [x, y, vx, vy]

        Returns:
            predicted_state: (N, 4) é¢„æµ‹çŠ¶æ€
            predicted_cov: (N, 4, 4) é¢„æµ‹åæ–¹å·®
        """
        N = tracks_state.size(0)

        # çŠ¶æ€é¢„æµ‹: x_pred = F * x
        predicted_state = (self.F @ tracks_state.T).T

        # åæ–¹å·®é¢„æµ‹: P_pred = F * P * F^T + Q
        # è¿™é‡Œç®€åŒ–ä¸ºå¯¹è§’åæ–¹å·®
        predicted_cov = self.Q.unsqueeze(0).expand(N, -1, -1)

        return predicted_state, predicted_cov

    def update(self, predicted_state, predicted_cov, measurements):
        """
        æ›´æ–°çŠ¶æ€ï¼ˆå¡å°”æ›¼æ»¤æ³¢ï¼‰

        Args:
            predicted_state: (N, 4) é¢„æµ‹çŠ¶æ€
            predicted_cov: (N, 4, 4) é¢„æµ‹åæ–¹å·®
            measurements: (M, 2) è§‚æµ‹ä½ç½® [x, y]

        Returns:
            updated_state: (N, 4) æ›´æ–°åçŠ¶æ€
            updated_cov: (N, 4, 4) æ›´æ–°ååæ–¹å·®
            innovation: (N, M) æ–°æ¯ï¼ˆç”¨äºæ•°æ®å…³è”ï¼‰
        """
        N = predicted_state.size(0)
        M = measurements.size(0)

        # è§‚æµ‹çŸ©é˜µ (åªè§‚æµ‹ä½ç½®)
        H = torch.tensor([
            [1, 0, 0, 0],
            [0, 1, 0, 0]
        ], dtype=torch.float32)

        # è®¡ç®—å¡å°”æ›¼å¢ç›Š: K = P * H^T * (H * P * H^T + R)^(-1)
        predicted_pos = predicted_state[:, :2]  # (N, 2)
        innovation = measurements.unsqueeze(0) - predicted_pos.unsqueeze(1)  # (N, M, 2)

        # ç®€åŒ–: ä½¿ç”¨å›ºå®šçš„å¡å°”æ›¼å¢ç›Š
        K = torch.tensor([[0.5, 0],
                          [0, 0.5],
                          [0.1, 0],
                          [0, 0.1]], dtype=torch.float32)

        # çŠ¶æ€æ›´æ–°
        innovation_for_update = innovation.mean(dim=1)  # (N, 2)
        updated_state = predicted_state + (K @ innovation_for_update.T).T

        return updated_state, innovation
```

**å‡ ä½•çº¦æŸ**:
```python
def geometric_constraints_cost(track_state, detection_state):
    """
    è®¡ç®—å‡ ä½•çº¦æŸæˆæœ¬

    è€ƒè™‘:
    1. è¿åŠ¨ä¸€è‡´æ€§
    2. ç©ºé—´é‚»è¿‘æ€§
    3. æ–¹å‘ä¸€è‡´æ€§
    """
    # 1. è¿åŠ¨ä¸€è‡´æ€§: é¢„æµ‹ä½ç½®ä¸æ£€æµ‹ä½ç½®çš„è·ç¦»
    pred_pos = track_state[:2]
    det_pos = detection_state[:2]
    motion_cost = torch.norm(pred_pos - det_pos)

    # 2. é€Ÿåº¦ä¸€è‡´æ€§: å½“å‰é€Ÿåº¦ä¸å†å²é€Ÿåº¦çš„å¯¹æ¯”
    current_vel = track_state[2:]
    estimated_vel = det_pos - pred_pos  # ä»ä½ç§»ä¼°è®¡é€Ÿåº¦
    velocity_cost = torch.norm(current_vel - estimated_vel)

    # 3. æ–¹å‘ä¸€è‡´æ€§: è¿åŠ¨æ–¹å‘çš„å˜åŒ–
    if torch.norm(current_vel) > 0.1:
        direction_change = torch.abs(
            torch.atan2(current_vel[1], current_vel[0]) -
            torch.atan2(estimated_vel[1], estimated_vel[0])
        )
    else:
        direction_change = 0

    # æ€»æˆæœ¬
    total_cost = (
        1.0 * motion_cost +
        0.5 * velocity_cost +
        0.3 * direction_change
    )

    return total_cost
```

---

### æ ¸å¿ƒç»„ä»¶2: åˆ†å‰²å…³è” (Segmentation Association)

**APç®—æ³• (Association via Programming)**:
```python
class SegmentationAssociation:
    """
    åˆ†å‰²å…³è”ç®—æ³•

    å°†å…¨å±€å…³è”é—®é¢˜åˆ†è§£ä¸ºå¤šä¸ªå­é—®é¢˜
    """
    def __init__(self, cost_threshold=5.0):
        self.cost_threshold = cost_threshold

    def associate(self, tracks, detections, cost_matrix):
        """
        æ•°æ®å…³è”

        Args:
            tracks: Nä¸ªè½¨è¿¹
            detections: Mä¸ªæ£€æµ‹
            cost_matrix: (N, M) å…³è”æˆæœ¬çŸ©é˜µ

        Returns:
            matches: åŒ¹é…å¯¹ (track_idx, det_idx)
            unmatched_tracks: æœªåŒ¹é…è½¨è¿¹
            unmatched_detections: æœªåŒ¹é…æ£€æµ‹
        """
        N, M = cost_matrix.shape

        # ä½¿ç”¨åŒˆç‰™åˆ©ç®—æ³•è¿›è¡Œå…¨å±€åŒ¹é…
        from scipy.optimize import linear_sum_assignment
        track_indices, det_indices = linear_sum_assignment(cost_matrix)

        # è¿‡æ»¤é«˜æˆæœ¬åŒ¹é…
        valid_matches = []
        for t_idx, d_idx in zip(track_indices, det_indices):
            if cost_matrix[t_idx, d_idx] < self.cost_threshold:
                valid_matches.append((t_idx, d_idx))

        # æ‰¾å‡ºæœªåŒ¹é…çš„è½¨è¿¹å’Œæ£€æµ‹
        matched_track_indices = set(m[0] for m in valid_matches)
        matched_det_indices = set(m[1] for m in valid_matches)

        unmatched_tracks = [i for i in range(N) if i not in matched_track_indices]
        unmatched_detections = [i for i in range(M) if i not in matched_det_indices]

        return valid_matches, unmatched_tracks, unmatched_detections


class GRASPAssociation(nn.Module):
    """
    GRASPå…³è”: ç»“åˆå¤–è§‚å’Œå‡ ä½•ä¿¡æ¯çš„å…³è”
    """
    def __init__(self, appearance_dim=256, geometric_weight=0.5):
        super().__init__()
        self.geometric_weight = geometric_weight
        self.appearance_weight = 1.0 - geometric_weight

        # å¤–è§‚ç›¸ä¼¼åº¦è®¡ç®—
        self.appearance_metric = nn.CosineSimilarity(dim=-1)

    def compute_cost_matrix(self, tracks, detections):
        """
        è®¡ç®—å…³è”æˆæœ¬çŸ©é˜µ

        Args:
            tracks: è½¨è¿¹åˆ—è¡¨,æ¯ä¸ªè½¨è¿¹åŒ…å«çŠ¶æ€å’Œå¤–è§‚ç‰¹å¾
            detections: æ£€æµ‹åˆ—è¡¨,æ¯ä¸ªæ£€æµ‹åŒ…å«ä½ç½®å’Œå¤–è§‚ç‰¹å¾

        Returns:
            cost_matrix: (N, M) å…³è”æˆæœ¬
        """
        N = len(tracks)
        M = len(detections)
        cost_matrix = torch.zeros(N, M)

        for i, track in enumerate(tracks):
            for j, det in enumerate(detections):
                # å¤–è§‚æˆæœ¬ (1 - ç›¸ä¼¼åº¦)
                appearance_cost = 1.0 - self.appearance_metric(
                    track['appearance'].unsqueeze(0),
                    det['appearance'].unsqueeze(0)
                ).item()

                # å‡ ä½•æˆæœ¬
                geometric_cost = geometric_constraints_cost(
                    track['state'],
                    det['state']
                )

                # åŠ æƒèåˆ
                cost_matrix[i, j] = (
                    self.appearance_weight * appearance_cost +
                    self.geometric_weight * geometric_cost
                )

        return cost_matrix

    def forward(self, tracks, detections):
        """
        æ‰§è¡Œå…³è”
        """
        # è®¡ç®—æˆæœ¬çŸ©é˜µ
        cost_matrix = self.compute_cost_matrix(tracks, detections)

        # åˆ†å‰²å…³è”
        associator = SegmentationAssociation()
        matches, unmatched_tracks, unmatched_detections = \
            associator.associate(tracks, detections, cost_matrix.numpy())

        return {
            'matches': matches,
            'unmatched_tracks': unmatched_tracks,
            'unmatched_detections': unmatched_detections,
            'cost_matrix': cost_matrix
        }
```

---

### æ ¸å¿ƒç»„ä»¶3: è½¨è¿¹ç®¡ç†

```python
class TrackManager:
    """
    è½¨è¿¹ç®¡ç†å™¨

    è´Ÿè´£è½¨è¿¹çš„åˆ›å»ºã€æ›´æ–°ã€åˆ é™¤å’Œèº«ä»½ç®¡ç†
    """
    def __init__(self, max_age=30, min_hits=3):
        """
        Args:
            max_age: è½¨è¿¹æœ€å¤§ä¸¢å¤±å¸§æ•°
            min_hits: ç¡®è®¤è½¨è¿¹æ‰€éœ€çš„æœ€å°æ£€æµ‹æ•°
        """
        self.max_age = max_age
        self.min_hits = min_hits
        self.tracks = []
        self.next_id = 1

    def update(self, detections, associations):
        """
        æ›´æ–°æ‰€æœ‰è½¨è¿¹

        Args:
            detections: å½“å‰å¸§çš„æ£€æµ‹
            associations: å…³è”ç»“æœ
        """
        # 1. æ›´æ–°å·²åŒ¹é…çš„è½¨è¿¹
        for track_idx, det_idx in associations['matches']:
            track = self.tracks[track_idx]
            detection = detections[det_idx]

            # å¡å°”æ›¼æ»¤æ³¢æ›´æ–°
            track['state'], _ = self.kalman_update(
                track['predicted_state'],
                detection['state']
            )

            # æ›´æ–°å¤–è§‚ç‰¹å¾
            track['appearance'] = self.update_appearance(
                track['appearance'],
                detection['appearance']
            )

            # æ›´æ–°è½¨è¿¹ä¿¡æ¯
            track['hits'] += 1
            track['age'] += 1
            track['time_since_update'] = 0

        # 2. å¤„ç†æœªåŒ¹é…çš„è½¨è¿¹
        for track_idx in associations['unmatched_tracks']:
            track = self.tracks[track_idx]
            track['age'] += 1
            track['time_since_update'] += 1

        # 3. åˆ é™¤è¿‡æ—¶è½¨è¿¹
        self.tracks = [t for t in self.tracks
                       if t['time_since_update'] < self.max_age]

        # 4. åˆ›å»ºæ–°è½¨è¿¹
        for det_idx in associations['unmatched_detections']:
            self._init_track(detections[det_idx])

        return self.tracks

    def _init_track(self, detection):
        """åˆå§‹åŒ–æ–°è½¨è¿¹"""
        track = {
            'id': self.next_id,
            'state': torch.cat([detection['state'],
                               torch.zeros(2)]),  # [x, y, 0, 0]
            'appearance': detection['appearance'],
            'hits': 1,
            'age': 1,
            'time_since_update': 0,
            'confirmed': False
        }
        self.tracks.append(track)
        self.next_id += 1

    def update_appearance(self, old_features, new_features, alpha=0.5):
        """æ›´æ–°å¤–è§‚ç‰¹å¾ï¼ˆæŒ‡æ•°ç§»åŠ¨å¹³å‡ï¼‰"""
        return alpha * old_features + (1 - alpha) * new_features

    def get_confirmed_tracks(self):
        """è·å–ç¡®è®¤çš„è½¨è¿¹"""
        return [t for t in self.tracks if t['hits'] >= self.min_hits]
```

---

## ğŸ“Š å®éªŒç»“æœ

### æ•°æ®é›†

| æ•°æ®é›† | åœºæ™¯ | ç‰¹ç‚¹ |
|:---|:---|:---|
| **MOT17** | è¡—é“ | æ‹¥å µã€é®æŒ¡ |
| **KITTI** | é“è·¯ | è½¦è¾†è·Ÿè¸ª |
| **DanceTrack** | èˆè¹ˆ | ç›¸ä¼¼å¤–è§‚ |

### ä¸»è¦ç»“æœ (MOTA %)

| æ–¹æ³• | MOT17 | KITTI | DanceTrack |
|:---|:---:|:---:|:---:|
| Sort | 45.2 | 62.3 | 58.1 |
| DeepSORT | 53.8 | 68.7 | 64.2 |
| ByteTrack | 62.1 | 74.5 | 71.3 |
| **GRASPTrack** | **66.3** | **77.2** | **73.8** |

### æ¶ˆèå®éªŒ

| ç»„ä»¶ | MOTAæå‡ | IDF1æå‡ |
|:---|:---:|:---:|
| å‡ ä½•æ¨ç† | +3.2 | +4.1 |
| åˆ†å‰²å…³è” | +2.8 | +3.5 |
| å¤–è§‚æ›´æ–° | +1.5 | +2.2 |
| å…¨éƒ¨ç»„åˆ | +7.5 | +9.8 |

---

## ğŸ’¡ å¯¹äº•ç›–æ£€æµ‹çš„å¯ç¤º

### åº”ç”¨åœºæ™¯: ç§»åŠ¨å·¡æ£€ç³»ç»Ÿ

```
åœºæ™¯: å·¡æ£€è½¦/æœºå™¨äººæ²¿é“è·¯ç§»åŠ¨,æŒç»­æ£€æµ‹äº•ç›–

éœ€æ±‚:
  1. äº•ç›–æ£€æµ‹
  2. è½¨è¿¹è·Ÿè¸ª (é¿å…é‡å¤è®¡æ•°)
  3. ç¼ºé™·å®šä½ (åœ¨è½¨è¿¹ä¸­æ ‡æ³¨ç¼ºé™·)
  4. å·¡æ£€è·¯çº¿è§„åˆ’
```

### äº•ç›–è·Ÿè¸ªç³»ç»Ÿè®¾è®¡

```python
class ManholeTrackingSystem:
    """
    äº•ç›–è·Ÿè¸ªç³»ç»Ÿ

    åŸºäºGRASPTrack,ç”¨äºç§»åŠ¨å·¡æ£€åœºæ™¯
    """
    def __init__(self):
        # äº•ç›–æ£€æµ‹å™¨
        self.detector = YOLOv8()

        # å¤–è§‚ç¼–ç å™¨
        self.appearance_encoder = ResNet50()

        # GRASPå…³è”
        self.association = GRASPAssociation(
            appearance_dim=2048,
            geometric_weight=0.3  # äº•ç›–ä½ç½®ç›¸å¯¹å›ºå®š
        )

        # è½¨è¿¹ç®¡ç†
        self.track_manager = TrackManager(
            max_age=10,  # å¸§æ•°
            min_hits=2
        )

    def update(self, frame):
        """
        æ›´æ–°è·Ÿè¸ªç³»ç»Ÿ

        Args:
            frame: å½“å‰å¸§å›¾åƒ

        Returns:
            tracked_manholes: å¸¦IDçš„äº•ç›–æ£€æµ‹ç»“æœ
            trajectories: æ‰€æœ‰è½¨è¿¹
        """
        # 1. æ£€æµ‹äº•ç›–
        detections = self.detector(frame)

        # 2. æå–å¤–è§‚ç‰¹å¾
        appearance_features = self._extract_appearance(frame, detections)

        # 3. å‡†å¤‡è½¨è¿¹å’Œæ£€æµ‹æ•°æ®
        tracks_data = self._prepare_tracks()
        detections_data = self._prepare_detections(detections, appearance_features)

        # 4. æ•°æ®å…³è”
        associations = self.association(tracks_data, detections_data)

        # 5. æ›´æ–°è½¨è¿¹
        trajectories = self.track_manager.update(detections_data, associations)

        # 6. æ ¼å¼åŒ–è¾“å‡º
        tracked_manholes = self._format_output(detections, associations, trajectories)

        return tracked_manholes, trajectories

    def _extract_appearance(self, frame, detections):
        """ä»æ£€æµ‹æ¡†æå–å¤–è§‚ç‰¹å¾"""
        features = []
        for det in detections:
            # è£å‰ªæ£€æµ‹åŒºåŸŸ
            x1, y1, x2, y2 = det['box']
            crop = frame[:, y1:y2, x1:x2]

            # æå–ç‰¹å¾
            feat = self.appearance_encoder(crop)
            features.append(feat)

        return torch.stack(features)

    def _prepare_tracks(self):
        """å‡†å¤‡è½¨è¿¹æ•°æ®"""
        tracks_data = []
        for track in self.track_manager.tracks:
            tracks_data.append({
                'state': torch.tensor(track['state']),
                'appearance': track['appearance']
            })
        return tracks_data

    def _prepare_detections(self, detections, features):
        """å‡†å¤‡æ£€æµ‹æ•°æ®"""
        detections_data = []
        for det, feat in zip(detections, features):
            # æ£€æµ‹æ¡†ä¸­å¿ƒä½œä¸ºçŠ¶æ€ [x, y]
            box = det['box']
            center_x = (box[0] + box[2]) / 2
            center_y = (box[1] + box[3]) / 2

            detections_data.append({
                'state': torch.tensor([center_x, center_y]),
                'appearance': feat,
                'box': box,
                'confidence': det['confidence']
            })
        return detections_data

    def _format_output(self, detections, associations, trajectories):
        """æ ¼å¼åŒ–è¾“å‡ºç»“æœ"""
        output = []

        for track_idx, det_idx in associations['matches']:
            track = trajectories[track_idx]
            det = detections[det_idx]

            output.append({
                'id': track['id'],
                'box': det['box'],
                'confidence': det['confidence'],
                'age': track['age'],
                'hits': track['hits'],
                'defect': det.get('defect', None)  # ç¼ºé™·ä¿¡æ¯
            })

        return output
```

### äº•ç›–è½¨è¿¹åˆ†æ

```python
class TrajectoryAnalyzer:
    """
    äº•ç›–è½¨è¿¹åˆ†æå™¨

    åˆ†æç§»åŠ¨å·¡æ£€è¿‡ç¨‹ä¸­æ”¶é›†çš„äº•ç›–è½¨è¿¹
    """
    def __init__(self):
        pass

    def analyze_trajectory(self, trajectory):
        """
        åˆ†æå•ä¸ªäº•ç›–è½¨è¿¹

        Returns:
            analysis: {
                'quality': è½¨è¿¹è´¨é‡,
                'defect_prob': ç¼ºé™·æ¦‚ç‡,
                'position': ç²¾ç¡®ä½ç½®,
                'condition': çŠ¶å†µè¯„ä¼°
            }
        """
        # 1. è½¨è¿¹ç¨³å®šæ€§
        if len(trajectory['history']) < 5:
            quality = 'low'
        else:
            # è®¡ç®—ä½ç½®æ–¹å·®
            positions = torch.stack([h['state'][:2] for h in trajectory['history']])
            variance = torch.var(positions, dim=0).sum()
            quality = 'high' if variance < 100 else 'medium'

        # 2. ç¼ºé™·åˆ†æ
        defect_scores = [h.get('defect_score', 0) for h in trajectory['history']]
        defect_prob = sum(defect_scores) / len(defect_scores)

        # 3. ç²¾ç¡®ä½ç½®ä¼°è®¡
        final_position = trajectory['state'][:2]

        # 4. çŠ¶å†µè¯„ä¼°
        if defect_prob > 0.7:
            condition = 'damaged'
        elif defect_prob > 0.3:
            condition = 'warning'
        else:
            condition = 'good'

        return {
            'quality': quality,
            'defect_prob': defect_prob.item(),
            'position': final_position.tolist(),
            'condition': condition
        }

    def generate_inspection_report(self, all_trajectories):
        """
        ç”Ÿæˆå·¡æ£€æŠ¥å‘Š

        Args:
            all_trajectories: æ‰€æœ‰äº•ç›–è½¨è¿¹

        Returns:
            report: å·¡æ£€æŠ¥å‘Š {
                'total_manholes': äº•ç›–æ€»æ•°,
                'defective': ç ´æŸæ•°é‡,
                'warnings': è­¦å‘Šæ•°é‡,
                'good': è‰¯å¥½æ•°é‡,
                'positions': ä½ç½®åˆ—è¡¨
            }
        """
        report = {
            'total_manholes': len(all_trajectories),
            'defective': 0,
            'warnings': 0,
            'good': 0,
            'positions': []
        }

        for trajectory in all_trajectories:
            analysis = self.analyze_trajectory(trajectory)

            report['positions'].append({
                'id': trajectory['id'],
                'position': analysis['position'],
                'condition': analysis['condition'],
                'defect_prob': analysis['defect_prob']
            })

            if analysis['condition'] == 'damaged':
                report['defective'] += 1
            elif analysis['condition'] == 'warning':
                report['warnings'] += 1
            else:
                report['good'] += 1

        return report
```

---

## ğŸ’¡ å¯å¤ç”¨ä»£ç ç»„ä»¶

### ç»„ä»¶1: å®Œæ•´çš„è·Ÿè¸ªç³»ç»Ÿ

```python
import torch
import torch.nn as nn
import numpy as np
from scipy.optimize import linear_sum_assignment

class GRASPTrackingSystem(nn.Module):
    """
    å®Œæ•´çš„GRASPè·Ÿè¸ªç³»ç»Ÿ

    å¯ç”¨äºäº•ç›–ã€è½¦è¾†ã€è¡Œäººç­‰å¤šç›®æ ‡è·Ÿè¸ª
    """
    def __init__(self, detector=None, reid_model=None):
        super().__init__()

        # æ£€æµ‹å™¨
        self.detector = detector

        # ReIDæ¨¡å‹
        self.reid_model = reid_model

        # å‡ ä½•æ¨ç†
        self.geometric_reasoning = GeometricReasoning()

        # GRASPå…³è”
        self.association = GRASPAssociation(
            appearance_dim=512,
            geometric_weight=0.5
        )

        # è½¨è¿¹ç®¡ç†
        self.track_manager = TrackManager(
            max_age=30,
            min_hits=3
        )

    def forward(self, frame):
        """
        å¤„ç†å•å¸§

        Args:
            frame: (B, 3, H, W) å½“å‰å¸§

        Returns:
            results: è·Ÿè¸ªç»“æœ {
                'tracks': è½¨è¿¹åˆ—è¡¨,
                'detections': æ£€æµ‹åˆ—è¡¨,
                'associations': å…³è”ç»“æœ
            }
        """
        # 1. æ£€æµ‹
        detections = self.detector(frame)

        # 2. ReIDç‰¹å¾æå–
        if self.reid_model is not None:
            appearances = self.reid_model.extract_features(frame, detections)
        else:
            appearances = self._extract_simple_features(frame, detections)

        # 3. å‡†å¤‡æ•°æ®
        tracks_data = self._prepare_tracks_data()
        detections_data = self._prepare_detections_data(detections, appearances)

        # 4. é¢„æµ‹è½¨è¿¹çŠ¶æ€
        if len(self.track_manager.tracks) > 0:
            track_states = torch.stack([t['state'] for t in self.track_manager.tracks])
            predicted_states, _ = self.geometric_reasoning.predict(track_states)
        else:
            predicted_states = None

        # 5. æ•°æ®å…³è”
        associations = self.association(
            self.track_manager.tracks,
            detections_data
        )

        # 6. æ›´æ–°è½¨è¿¹
        trajectories = self.track_manager.update(detections_data, associations)

        return {
            'tracks': trajectories,
            'detections': detections,
            'associations': associations
        }

    def _prepare_tracks_data(self):
        """å‡†å¤‡è½¨è¿¹æ•°æ®"""
        return self.track_manager.tracks

    def _prepare_detections_data(self, detections, appearances):
        """å‡†å¤‡æ£€æµ‹æ•°æ®"""
        detections_data = []
        for i, det in enumerate(detections):
            # è®¡ç®—ä¸­å¿ƒ
            box = det['box']
            center_x = (box[0] + box[2]) / 2
            center_y = (box[1] + box[3]) / 2

            detections_data.append({
                'state': torch.tensor([center_x, center_y]),
                'appearance': appearances[i],
                'box': det['box'],
                'confidence': det['confidence']
            })
        return detections_data
```

### ç»„ä»¶2: åŒˆç‰™åˆ©ç®—æ³•å°è£…

```python
class HungarianAssociator:
    """
    åŒˆç‰™åˆ©ç®—æ³•å…³è”å™¨

    ç”¨äºè§£å†³æœ€ä¼˜åˆ†é…é—®é¢˜
    """
    def __init__(self, cost_threshold=5.0):
        self.cost_threshold = cost_threshold

    def match(self, cost_matrix):
        """
        ä½¿ç”¨åŒˆç‰™åˆ©ç®—æ³•è¿›è¡ŒåŒ¹é…

        Args:
            cost_matrix: (N, M) æˆæœ¬çŸ©é˜µ

        Returns:
            matches: åŒ¹é…å¯¹åˆ—è¡¨ [(track_idx, det_idx), ...]
            unmatched_tracks: æœªåŒ¹é…è½¨è¿¹ç´¢å¼•
            unmatched_detections: æœªåŒ¹é…æ£€æµ‹ç´¢å¼•
        """
        cost_np = cost_matrix.detach().cpu().numpy()
        track_indices, det_indices = linear_sum_assignment(cost_np)

        # è¿‡æ»¤é«˜æˆæœ¬åŒ¹é…
        matches = []
        for t, d in zip(track_indices, det_indices):
            if cost_np[t, d] < self.cost_threshold:
                matches.append((int(t), int(d)))

        # æ‰¾å‡ºæœªåŒ¹é…
        matched_tracks = set(m[0] for m in matches)
        matched_dets = set(m[1] for m in matches)

        all_tracks = set(range(cost_matrix.shape[0]))
        all_dets = set(range(cost_matrix.shape[1]))

        unmatched_tracks = list(all_tracks - matched_tracks)
        unmatched_dets = list(all_dets - matched_dets)

        return matches, unmatched_tracks, unmatched_dets
```

### ç»„ä»¶3: è½¨è¿¹å¯è§†åŒ–

```python
import matplotlib.pyplot as plt
import matplotlib.patches as patches

class TrajectoryVisualizer:
    """
    è½¨è¿¹å¯è§†åŒ–å·¥å…·
    """
    def __init__(self):
        self.colors = self._generate_colors(100)

    def visualize(self, frame, tracks, save_path=None):
        """
        å¯è§†åŒ–è·Ÿè¸ªç»“æœ

        Args:
            frame: å›¾åƒå¸§
            tracks: è½¨è¿¹åˆ—è¡¨
            save_path: ä¿å­˜è·¯å¾„
        """
        fig, ax = plt.subplots(1, figsize=(12, 8))
        ax.imshow(frame)

        for track in tracks:
            track_id = track['id']
            color = self.colors[track_id % len(self.colors)]

            # ç»˜åˆ¶æ£€æµ‹æ¡†
            box = track.get('box')
            if box is not None:
                rect = patches.Rectangle(
                    (box[0], box[1]),
                    box[2] - box[0],
                    box[3] - box[1],
                    linewidth=2,
                    edgecolor=color,
                    facecolor='none'
                )
                ax.add_patch(rect)

            # ç»˜åˆ¶è½¨è¿¹ID
            if 'state' in track:
                x, y = track['state'][:2].tolist()
                ax.text(x, y, f'ID:{track_id}',
                       bbox=dict(facecolor=color, alpha=0.5),
                       fontsize=8, color='white')

            # ç»˜åˆ¶è½¨è¿¹å†å²
            if 'history' in track and len(track['history']) > 1:
                history = track['history'][-10:]  # æœ€è¿‘10å¸§
                xs = [h['state'][0].item() for h in history]
                ys = [h['state'][1].item() for h in history]
                ax.plot(xs, ys, color=color, linewidth=1, alpha=0.6)

        ax.axis('off')
        plt.tight_layout()

        if save_path:
            plt.savefig(save_path, bbox_inches='tight', dpi=150)
            plt.close()
        else:
            plt.show()

    def _generate_colors(self, n):
        """ç”Ÿæˆnç§ä¸åŒçš„é¢œè‰²"""
        import matplotlib.colors as mcolors
        colors = list(mcolors.TABLEAU_COLORS.values())
        return colors

    def create_trajectory_video(self, frames, all_tracks, output_path):
        """
        åˆ›å»ºè½¨è¿¹è§†é¢‘

        Args:
            frames: æ‰€æœ‰å¸§
            all_tracks: æ¯å¸§çš„è·Ÿè¸ªç»“æœ
            output_path: è¾“å‡ºè§†é¢‘è·¯å¾„
        """
        import cv2

        height, width = frames[0].shape[:2]
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_path, fourcc, 30, (width, height))

        for frame, tracks in zip(frames, all_tracks):
            # è½¬æ¢ä¸ºBGR
            frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)

            # ç»˜åˆ¶
            for track in tracks:
                track_id = track['id']
                color = self._get_bgr_color(track_id)

                box = track.get('box')
                if box is not None:
                    cv2.rectangle(frame_bgr,
                                (int(box[0]), int(box[1])),
                                (int(box[2]), int(box[3])),
                                color, 2)

                if 'state' in track:
                    x, y = track['state'][:2].tolist()
                    cv2.putText(frame_bgr, f'ID:{track_id}',
                              (int(x), int(y)),
                              cv2.FONT_HERSHEY_SIMPLEX,
                              0.5, color, 2)

            out.write(frame_bgr)

        out.release()

    def _get_bgr_color(self, idx):
        """è·å–BGRé¢œè‰²"""
        colors = [
            (0, 255, 255), (255, 0, 255), (255, 255, 0),
            (0, 128, 255), (255, 0, 128), (128, 255, 0)
        ]
        return colors[idx % len(colors)]
```

---

## ğŸ“– å…³é”®æ¦‚å¿µä¸æœ¯è¯­

| æœ¯è¯­ | è‹±æ–‡ | è§£é‡Š |
|:---|:---|:---|
| **MOT** | Multi-Object Tracking | å¤šç›®æ ‡è·Ÿè¸ª |
| **æ•°æ®å…³è”** | Data Association | åŒ¹é…æ£€æµ‹åˆ°è½¨è¿¹ |
| **å¡å°”æ›¼æ»¤æ³¢** | Kalman Filter | çŠ¶æ€ä¼°è®¡ç®—æ³• |
| **åŒˆç‰™åˆ©ç®—æ³•** | Hungarian Algorithm | æœ€ä¼˜åˆ†é…ç®—æ³• |
| **å¤–è§‚ç‰¹å¾** | Appearance Feature | è§†è§‰ç‰¹å¾ |
| **å‡ ä½•æ¨ç†** | Geometric Reasoning | åŸºäºå‡ ä½•çš„çº¦æŸ |
| **IDåˆ‡æ¢** | ID Switch | èº«ä»½é”™è¯¯åˆ‡æ¢ |
| **MOTA** | Multiple Object Tracking Accuracy | å¤šç›®æ ‡è·Ÿè¸ªç²¾åº¦ |

---

## âœ… å¤ä¹ æ£€æŸ¥æ¸…å•

- [ ] ç†è§£MOTçš„æ ¸å¿ƒæŒ‘æˆ˜
- [ ] æŒæ¡å¡å°”æ›¼æ»¤æ³¢çš„åŸºæœ¬åŸç†
- [ ] äº†è§£åŒˆç‰™åˆ©ç®—æ³•åœ¨å…³è”ä¸­çš„åº”ç”¨
- [ ] ç†è§£GRASPçš„åˆ›æ–°ç‚¹
- [ ] èƒ½å°†è·Ÿè¸ªåº”ç”¨äºäº•ç›–å·¡æ£€
- [ ] èƒ½å¤Ÿå®ç°åŸºæœ¬çš„è·Ÿè¸ªç³»ç»Ÿ

---

## ğŸ¤” æ€è€ƒé—®é¢˜

1. **ä¸ºä»€ä¹ˆéœ€è¦åŒæ—¶ä½¿ç”¨å¤–è§‚å’Œå‡ ä½•ä¿¡æ¯ï¼Ÿ**
   - æç¤º: å„è‡ªçš„ä¼˜åŠ¿å’Œå±€é™

2. **å¡å°”æ›¼æ»¤æ³¢å¦‚ä½•å¤„ç†éçº¿æ€§è¿åŠ¨ï¼Ÿ**
   - æç¤º: æ‰©å±•å¡å°”æ›¼æ»¤æ³¢

3. **å¦‚ä½•å¤„ç†äº•ç›–æ£€æµ‹ä¸­çš„æ¼æ£€ï¼Ÿ**
   - æç¤º: è½¨è¿¹çš„max_ageå‚æ•°

4. **ç§»åŠ¨å·¡æ£€ä¸­çš„ç‰¹æ®ŠæŒ‘æˆ˜æ˜¯ä»€ä¹ˆï¼Ÿ**
   - æç¤º: ç›¸æœºè¿åŠ¨ã€è§†è§’å˜åŒ–

---

## ğŸ”— ç›¸å…³è®ºæ–‡æ¨è

### å¿…è¯»
1. **SORT** (2016) - ç®€å•åœ¨çº¿è·Ÿè¸ª
2. **DeepSORT** (2017) - æ·±åº¦å¤–è§‚ç‰¹å¾
3. **ByteTrack** (2021) - é«˜åˆ†æ£€æµ‹è·Ÿè¸ª

### æ‰©å±•é˜…è¯»
1. **FairMOT** (2020) - æ£€æµ‹è·Ÿè¸ªè”åˆ
2. **OC-SORT** (2022) - ç›®æ ‡å¯¼å‘è·Ÿè¸ª
3. **MOTS** (ECCV 2020) - å¤šç›®æ ‡åˆ†å‰²è·Ÿè¸ª

---

## ğŸ“ ä¸ªäººç¬”è®°åŒº

### æˆ‘çš„ç†è§£



### ç–‘é—®ä¸å¾…æ¾„æ¸…



### ä¸äº•ç›–æ£€æµ‹çš„ç»“åˆç‚¹



### å®ç°è®¡åˆ’



---

**ç¬”è®°åˆ›å»ºæ—¶é—´**: 2026å¹´2æœˆ7æ—¥
**çŠ¶æ€**: å·²å®Œæˆç²¾è¯» âœ…
**ä¸‹ä¸€æ­¥**: å®ç°å®Œæ•´çš„è·Ÿè¸ªç³»ç»Ÿ,åº”ç”¨äºå·¡æ£€åœºæ™¯
