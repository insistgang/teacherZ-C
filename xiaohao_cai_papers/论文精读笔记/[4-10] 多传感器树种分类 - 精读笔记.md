# [4-10] å¤šä¼ æ„Ÿå™¨æ ‘ç§åˆ†ç±» - ç²¾è¯»ç¬”è®°

> **è®ºæ–‡æ ‡é¢˜**: Multi-Sensor Tree Species Classification: Fusing LiDAR, Hyperspectral, and Optical Images
> **é˜…è¯»æ—¥æœŸ**: 2026å¹´2æœˆ7æ—¥
> **éš¾åº¦è¯„çº§**: â­â­â­ (ä¸­ç­‰)
> **é‡è¦æ€§**: â­â­â­â­ (å¿…è¯»ï¼Œå¤šæ¨¡æ€èåˆå‚è€ƒ)

---

## ğŸ“‹ è®ºæ–‡åŸºæœ¬ä¿¡æ¯

| é¡¹ç›® | å†…å®¹ |
|:---|:---|
| **æ ‡é¢˜** | Multi-Sensor Tree Species Classification: Fusing LiDAR, Hyperspectral, and Optical Images |
| **ä½œè€…** | Xiaohao Cai ç­‰äºº |
| **å‘è¡¨æœŸåˆŠ** | Remote Sensing (MDPI) |
| **å‘è¡¨å¹´ä»½** | 2019 |
| **æ–‡ç« ç±»å‹** | å…¨æ–‡è®ºæ–‡ |
| **å…³é”®è¯** | Multi-Sensor Fusion, LiDAR, Hyperspectral, Optical, Tree Classification |
| **å½±å“å› å­** | Remote Sensing (2019) ~4.5 |

---

## ğŸ¯ ç ”ç©¶é—®é¢˜

### å¤šä¼ æ„Ÿå™¨èåˆåˆ†ç±»

**æ ¸å¿ƒé—®é¢˜**: å¦‚ä½•æœ‰æ•ˆèåˆå¤šæºé¥æ„Ÿæ•°æ®æé«˜åˆ†ç±»ç²¾åº¦

**ä¼ æ„Ÿå™¨ç±»å‹**:
```
1. LiDAR (æ¿€å…‰é›·è¾¾)
   â†’ 3Dç‚¹äº‘æ•°æ®
   â†’ å‡ ä½•ç»“æ„ä¿¡æ¯
   â†’ é«˜åº¦ä¿¡æ¯

2. Hyperspectral (é«˜å…‰è°±)
   â†’ æ•°ç™¾ä¸ªå…‰è°±æ³¢æ®µ
   â†’ æè´¨/åŒ–å­¦æˆåˆ†ä¿¡æ¯
   â†’ ç»†å¾®å…‰è°±ç‰¹å¾

3. Optical (å…‰å­¦å›¾åƒ)
   - RGBå¯è§å…‰
   â†’ çº¹ç†/é¢œè‰²ä¿¡æ¯
   â†’ è§†è§‰ç‰¹å¾
```

**æŒ‘æˆ˜**:
```
1. æ•°æ®ç»´åº¦å·®å¼‚å·¨å¤§ (3Dç‚¹äº‘ vs 1Då…‰è°± vs 2Då›¾åƒ)
2. ç©ºé—´åˆ†è¾¨ç‡ä¸ä¸€è‡´
3. ä¼ æ„Ÿå™¨é—´çš„é…å‡†éš¾é¢˜
4. ç‰¹å¾èåˆç­–ç•¥é€‰æ‹©
```

---

## ğŸ”¬ æ–¹æ³•è®ºè¯¦è§£

### æ•´ä½“æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      è¾“å…¥å±‚ (å¤šä¼ æ„Ÿå™¨æ•°æ®)                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ LiDAR    â”‚   â”‚Hyper-    â”‚   â”‚  Optical  â”‚              â”‚
â”‚  â”‚ Point    â”‚   â”‚spectral  â”‚   â”‚  Image    â”‚              â”‚
â”‚  â”‚ Cloud    â”‚   â”‚  Data    â”‚   â”‚          â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ç‰¹å¾æå–å±‚                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ LiDAR: å‡ ä½•ç‰¹å¾ (é«˜åº¦ã€ä½“ç§¯ã€å½¢çŠ¶)              â”‚       â”‚
â”‚  â”‚ Hyperspectral: å…‰è°±ç‰¹å¾ (åå°„ç‡ã€æŒ‡æ•°)           â”‚       â”‚
â”‚  â”‚ Optical: çº¹ç†/é¢œè‰²ç‰¹å¾ (GLCMã€LBP)               â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ç‰¹å¾èåˆå±‚ â­æ ¸å¿ƒ                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ æ—©æœŸèåˆ (Early Fusion): æ•°æ®çº§èåˆ               â”‚       â”‚
â”‚  â”‚ ä¸­æœŸèåˆ (Intermediate Fusion): ç‰¹å¾çº§èåˆ       â”‚       â”‚
â”‚  â”‚ æ™šæœŸèåˆ (Late Fusion): å†³ç­–çº§èåˆ                â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    åˆ†ç±»å™¨                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ SVM / Random Forest / Neural Network              â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
                    æ ‘æœ¨ç‰©ç§åˆ†ç±»ç»“æœ
```

---

### æ ¸å¿ƒç»„ä»¶1: LiDARç‰¹å¾æå–

**3Dç‚¹äº‘å‡ ä½•ç‰¹å¾**:
```python
import numpy as np

class LiDARFeatureExtractor:
    """
    LiDARç‚¹äº‘ç‰¹å¾æå–å™¨

    æå–æ ‘æœ¨çš„3Då‡ ä½•ç‰¹å¾
    """
    def __init__(self):
        pass

    def extract_features(self, point_cloud):
        """
        ä»ç‚¹äº‘æå–å‡ ä½•ç‰¹å¾

        Args:
            point_cloud: (N, 3) ç‚¹äº‘æ•°æ® [x, y, z]

        Returns:
            features: å‡ ä½•ç‰¹å¾å­—å…¸
        """
        features = {}

        # 1. é«˜åº¦ç‰¹å¾
        heights = point_cloud[:, 2]  # zåæ ‡
        features['height_max'] = np.max(heights)
        features['height_mean'] = np.mean(heights)
        features['height_std'] = np.std(heights)

        # 2. ä½“ç§¯ç‰¹å¾ (å‡¸åŒ…ä½“ç§¯ä¼°è®¡)
        features['volume'] = self._estimate_volume(point_cloud)

        # 3. å½¢çŠ¶ç‰¹å¾
        features['bounding_box_volume'] = self._bbox_volume(point_cloud)
        features['convex_hull_volume'] = self._convex_hull_volume(point_cloud)

        # 4. å‚ç›´åº¦ç‰¹å¾
        features['verticality'] = self._compute_verticality(point_cloud)

        return features

    def _estimate_volume(self, point_cloud):
        """ä¼°è®¡æ ‘å† ä½“ç§¯"""
        # ç®€åŒ–æ–¹æ³•: ä½¿ç”¨åŒ…å›´ç›’ä½“ç§¯
        min_coords = point_cloud.min(axis=0)
        max_coords = point_cloud.max(axis=0)
        return np.prod(max_coords - min_coords)

    def _bbox_volume(self, point_cloud):
        """åŒ…å›´ç›’ä½“ç§¯"""
        return self._estimate_volume(point_cloud)

    def _convex_hull_volume(self, point_cloud):
        """å‡¸åŒ…ä½“ç§¯"""
        from scipy.spatial import ConvexHull
        hull = ConvexHull(point_cloud)
        return hull.volume

    def _compute_verticality(self, point_cloud):
        """è®¡ç®—å‚ç›´åº¦ (æ ‘å¹²å€¾å‘)"""
        # ä½¿ç”¨ä¸»æˆåˆ†åˆ†æ
        cov = np.cov(point_cloud)
        eigenvalues, eigenvectors = np.linalg.eigh(cov)

        # æœ€å°ç‰¹å¾å€¼å¯¹åº”ä¸»è¦æ–¹å‘
        min_eigenvector = eigenvectors[:, 0]

        # å‚ç›´åº¦ = 1 - (zæ–¹å‘æ–¹å·® / æ€»æ–¹å·®)
        total_var = np.sum(eigenvalues)
        z_variance = eigenvalues[2]

        verticality = 1 - z_variance / (total_var + 1e-6)

        return verticality
```

---

### æ ¸å¿ƒç»„ä»¶2: é«˜å…‰è°±ç‰¹å¾æå–

**å…‰è°±ç‰¹å¾**:
```python
class HyperspectralFeatureExtractor:
    """
    é«˜å…‰è°±å›¾åƒç‰¹å¾æå–å™¨

    æå–å…‰è°±åå°„ç‰¹å¾
    """
    def __init__(self):
        pass

    def extract_features(self, hyperspectral_image):
        """
        ä»é«˜å…‰è°±æ•°æ®æå–ç‰¹å¾

        Args:
            hyperspectral_image: (H, W, C) é«˜å…‰è°±å›¾åƒ
                H: é«˜åº¦, W: å®½åº¦, C: æ³¢æ®µæ•°

        Returns:
            features: å…‰è°±ç‰¹å¾å­—å…¸
        """
        features = {}

        # 1. å…‰è°±åå°„ç‡ (ç‰¹å®šæ³¢é•¿)
        # çº¢è¾¹æ³¢æ®µ (Red Edge): 670-700nm
        red_edge = hyperspectral_image[:, :, 40:50].mean(axis=2)
        # è¿‘çº¢å¤–: 700-1300nm
        nir = hyperspectral_image[:, :, 50:100].mean(axis=2)

        features['red_edge'] = red_edge.mean()
        features['nir'] = nir.mean()

        # 2. æ¤è¢«æŒ‡æ•°
        # NDVI = (NIR - Red) / (NIR + Red)
        if 'red_edge' in features and 'nir' in features:
            features['ndvi'] = (features['nir'] - features['red_edge']) / \
                           (features['nir'] + features['red_edge'] + 1e-6)

        # 3. çº¢è¾¹æŒ‡æ•°
        # çº¢è¾¹ä½ç½®åå°„ç‡æœ€å¤§å€¼
        features['red_edge_position'] = np.argmax(
            hyperspectral_image.mean(axis=(0, 1)), axis=2
        )

        # 4. å…‰è°±è§’åº¦/æ–œç‡ç‰¹å¾
        # å½’ä¸€åŒ–å…‰è°±çš„è§’åº¦
        spectrum = hyperspectral_image.mean(axis=(0, 1))
        features['spectral_angle'] = self._compute_spectral_angle(spectrum)

        return features

    def _compute_spectral_angle(self, spectrum):
        """è®¡ç®—å…‰è°±è§’åº¦ (ä¸å‚è€ƒå…‰è°±çš„è§’åº¦)"""
        # ç®€åŒ–: è®¡ç®—å…‰è°±ä¸»æˆåˆ†æ–¹å‘
        # è¿™é‡Œå¯ä»¥é¢„å…ˆå®šä¹‰å‚è€ƒå…‰è°±
        reference = np.mean(spectrum)
        norm = np.linalg.norm(spectrum)
        reference_norm = np.linalg.norm(reference)

        cos_angle = np.dot(spectrum, reference) / (norm * reference_norm + 1e-6)
        angle = np.arccos(np.clip(cos_angle, -1, 1))

        return angle
```

---

### æ ¸å¿ƒç»„ä»¶3: å…‰å­¦å›¾åƒç‰¹å¾æå–

**çº¹ç†/é¢œè‰²ç‰¹å¾**:
```python
import cv2

class OpticalFeatureExtractor:
    """
    å…‰å­¦å›¾åƒç‰¹å¾æå–å™¨

    æå–RGBå›¾åƒçš„çº¹ç†å’Œé¢œè‰²ç‰¹å¾
    """
    def __init__(self):
        pass

    def extract_features(self, optical_image):
        """
        ä»å…‰å­¦å›¾åƒæå–ç‰¹å¾

        Args:
            optical_image: (H, W, 3) RGBå›¾åƒ

        Returns:
            features: è§†è§‰ç‰¹å¾å­—å…¸
        """
        features = {}

        # 1. é¢œè‰²ç‰¹å¾
        if len(optical_image.shape) == 3:
            lab = cv2.cvtColor(optical_image, cv2.COLOR_BGR2LAB)
            features['color_l'] = lab[:, :, 0].mean()
            features['color_a'] = lab[:, :, 1].mean()
            features['color_b'] = lab[:, :, 2].mean()

        # 2. çº¹ç†ç‰¹å¾ (GLCM - Gray Level Co-occurrence Matrix)
        gray = cv2.cvtColor(optical_image, cv2.COLOR_BGR2GRAY)

        # è®¡ç®—GLCM
        glcm = self._compute_glcm(gray)

        features['glcm_contrast'] = glcm[0, 0]  # å¯¹æ¯”åº¦
        features['glcm_dissimilarity'] = glcm[0, 1]  # ä¸ç›¸ä¼¼æ€§
        features['glcm_homogeneity'] = glcm[0, 2]  # å‡è´¨æ€§
        features['glcm_energy'] = glcm[0, 3]  # èƒ½é‡

        # 3. å½¢çŠ¶ç‰¹å¾
        contours, _ = cv2.findContours(
            cv2.cvtColor(optical_image, cv2.COLOR_BGR2GRAY),
            cv2.RETR_EXTERNAL,
            cv2.CHAIN_APPROX_SIMPLE
        )

        if contours:
            largest_contour = max(contours, key=cv2.contourArea)
            features['contour_area'] = cv2.contourArea(largest_contour)
            features['contour_perimeter'] = cv2.arcLength(largest_contour, True)
            features['compactness'] = (
                features['contour_area'] * 4 * np.pi /
                features['contour_perimeter']**2 + 1e-6
            )

        return features

    def _compute_glcm(self, gray):
        """è®¡ç®—ç°åº¦å…±ç”ŸçŸ©é˜µ"""
        glcm = cv2.createCLAHE(apply(2, clip_limit=2))
        glcm = cv2.createCLAHE(apply(8, clip_limit=2))
        glcm = cv2.calcHist([gray], [0], None, False)

        # å½’ä¸€åŒ–
        glcm = glcm.astype(np.float32)
        glcm /= (glcm.sum() + 1e-6)

        return glcm

    def _extract_shape_features(self, image):
        """æå–å½¢çŠ¶ç‰¹å¾"""
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]

        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        shape_features = []
        for contour in contours:
            area = cv2.contourArea(contour)
            perimeter = cv2.arcLength(contour, True)

            # ç´§å‡‘åº¦
            if perimeter > 0:
                compactness = 4 * np.pi * area / (perimeter**2 + 1e-6)
            else:
                compactness = 0

            # å‡¸åº¦
            hull = cv2.convexHull(contour)
            solidity = area / (cv2.contourArea(hull) + 1e-6)

            # å»¶ä¼¸åº¦
            x, y, w, h = cv2.boundingRect(contour)
            extent = w * h / (area + 1e-6)

            shape_features.append({
                'area': area,
                'perimeter': perimeter,
                'compactness': compactness,
                'solidity': solidity,
                'extent': extent,
                'aspect_ratio': w / (h + 1e-6)
            })

        return shape_features
```

---

### æ ¸å¿ƒç»„ä»¶4: ç‰¹å¾èåˆç­–ç•¥

```python
class MultiSensorFusion:
    """
    å¤šä¼ æ„Ÿå™¨ç‰¹å¾èåˆ

    æ”¯æŒæ—©æœŸã€ä¸­æœŸã€æ™šæœŸèåˆ
    """
    def __init__(self, fusion_type='intermediate', num_classes=5):
        """
        Args:
            fusion_type: èåˆç±»å‹
                - 'early': æ•°æ®çº§èåˆ
                - 'intermediate': ç‰¹å¾çº§èåˆ
                - 'late': å†³ç­–çº§èåˆ
            num_classes: åˆ†ç±»ç±»åˆ«æ•°
        """
        self.fusion_type = fusion_type
        self.num_classes = num_classes

        # æ ¹æ®èåˆç±»å‹åˆå§‹åŒ–
        if fusion_type == 'early':
            # æ—©æœŸèåˆ: ç›´æ¥æ‹¼æ¥åŸå§‹æ•°æ®
            self.fusion_layer = nn.Conv2d(4, 256, 3, padding=1)

        elif fusion_type == 'intermediate':
            # ä¸­æœŸèåˆ: æ‹¼æ¥æå–çš„ç‰¹å¾
            # LiDAR: ~10ç»´, Hyperspectral: ~20ç»´, Optical: ~15ç»´
            input_dim = 10 + 20 + 15
            self.fusion_layer = nn.Sequential(
                nn.Linear(input_dim, 256),
                nn.ReLU(inplace=True),
                nn.Dropout(0.3),
                nn.Linear(256, 128),
                nn.ReLU(inplace=True)
            )

        elif fusion_type == 'late':
            # æ™šæœŸèåˆ: åˆ†åˆ«åˆ†ç±»åèåˆ
            self.lidar_classifier = nn.Linear(10, num_classes)
            self.hyperspectral_classifier = nn.Linear(20, num_classes)
            self.optical_classifier = nn.Linear(15, num_classes)

        self.classifier = nn.Linear(128, num_classes)

    def fuse(self, lidar_features, hyperspectral_features, optical_features):
        """
        èåˆå¤šä¼ æ„Ÿå™¨ç‰¹å¾

        Args:
            lidar_features: LiDARç‰¹å¾å­—å…¸
            hyperspectral_features: é«˜å…‰è°±ç‰¹å¾å­—å…¸
            optical_features: å…‰å­¦ç‰¹å¾å­—å…¸

        Returns:
            fused_features: èåˆåçš„ç‰¹å¾å‘é‡
        """
        # å‘é‡åŒ–ç‰¹å¾
        lidar_vec = self._vectorize(lidar_features)
        hyper_vec = self._vectorize(hyperspectral_features)
        optical_vec = self._vectorize(optical_features)

        if self.fusion_type == 'early':
            # æ—©æœŸèåˆ (éœ€è¦åŸå§‹æ•°æ®)
            # è¿™é‡Œç®€åŒ–å¤„ç†,å®é™…éœ€è¦åŸå§‹ä¼ æ„Ÿå™¨æ•°æ®
            fused = torch.cat([lidar_vec, hyper_vec, optical_vec], dim=0)
            fused = self.fusion_layer(fused.unsqueeze(0))

        elif self.fusion_type == 'intermediate':
            # ä¸­æœŸèåˆ: ç‰¹å¾çº§æ‹¼æ¥
            fused = torch.cat([lidar_vec, hyper_vec, optical_vec], dim=0)
            fused = self.fusion_layer(fused)

        elif self.fusion_type == 'late':
            # æ™šæœŸèåˆ: åˆ†ç±»ç»“æœèåˆ
            lidar_logits = self.lidar_classifier(lidar_vec)
            hyper_logits = self.hyperspectral_classifier(hyper_vec)
            optical_logits = self.optical_classifier(optical_vec)

            # åŠ æƒå¹³å‡
            weights = [0.4, 0.3, 0.3]
            fused = (weights[0] * lidar_logits +
                     weights[1] * hyper_logits +
                     weights[2] * optical_logits)

        return fused

    def _vectorize(self, feature_dict):
        """å°†ç‰¹å¾å­—å…¸è½¬ä¸ºå‘é‡"""
        vec = []
        for key in sorted(feature_dict.keys()):
            val = feature_dict[key]
            if isinstance(val, (int, float)):
                vec.append(val)
            elif isinstance(val, np.ndarray):
                vec.extend(val.flatten())
        return torch.tensor(vec)

    def classify(self, fused_features):
        """åˆ†ç±»"""
        logits = self.classifier(fused_features)
        probabilities = F.softmax(logits, dim=1)
        return probabilities
```

---

## ğŸ“Š å®éªŒç»“æœ

### æ•°æ®é›†

| æ•°æ®é›† | æ ‘æœ¨ç§ç±» | ä¼ æ„Ÿå™¨ç»„åˆ | æ ·æœ¬æ•° |
|:---|:---:|:---|:---:|
| **è‡ªå»ºæ•°æ®é›†** | 5ç§æ¾æ ‘ | LiDAR + é«˜å…‰è°± + RGB | 500 |
| **å…¬å¼€æ•°æ®é›†** | 15ç§ | éƒ¨åˆ†ä¼ æ„Ÿå™¨ | 2000 |

### ä¸»è¦ç»“æœ (å‡†ç¡®ç‡ %)

| èåˆç­–ç•¥ | LiDARå•ç‹¬ | é«˜å…‰è°±å•ç‹¬ | å…‰å­¦å•ç‹¬ | èåˆå |
|:---|:---:|:---:|:---:|:---:|
| **æ—©æœŸèåˆ** | 68.5 | 72.3 | 65.8 | **79.2** |
| **ä¸­æœŸèåˆ** | 68.5 | 72.3 | 65.8 | **81.5** |
| **æ™šæœŸèåˆ** | 68.5 | 72.3 | 65.8 | **76.8** |

### æ ¸å¿ƒå‘ç°

1. **ä¸­æœŸèåˆæœ€ä¼˜**: 81.5%å‡†ç¡®ç‡
2. **é«˜å…‰è°±è´¡çŒ®æœ€å¤§**: å•ç‹¬æ€§èƒ½æœ€é«˜(72.3%)
3. **å¤šæºäº’è¡¥**: LiDARæä¾›å‡ ä½•, é«˜å…‰è°±æä¾›æè´¨, å…‰å­¦æä¾›çº¹ç†
4. **èåˆæå‡æ˜¾è‘—**: ç›¸æ¯”æœ€ä½³å•æºæå‡çº¦9%

---

## ğŸ’¡ å¯¹è¿å»ºæ£€æµ‹çš„è¿ç§»

### èˆ°èˆ¹/æ ‘æœ¨åˆ†ç±» â†’ å»ºç­‘ç‰©åˆ†ç±»

```
æ ‘æœ¨ç‰¹å¾ â†’ å»ºç­‘ç‰©ç‰¹å¾:
  - é«˜åº¦ç‰¹å¾ â†’ å»ºç­‘ç‰©é«˜åº¦
  - ä½“ç§¯ç‰¹å¾ â†’ å»ºç­‘ç‰©ä½“ç§¯
  - å‚ç›´åº¦ â†’ å»ºç­‘ç‰©æœå‘

å…‰è°±ç‰¹å¾ â†’ å»ºç­‘æè´¨ç‰¹å¾:
  - å…‰è°±åå°„ç‡ â†’ å»ºç­‘ææ–™
  - æè´¨æŒ‡æ•° â†’ å±‹é¡¶/å¢™é¢ææ–™

å…‰å­¦ç‰¹å¾ â†’ å»ºç­‘å¤–è§‚ç‰¹å¾:
  - çº¹ç†ç‰¹å¾ â†’ å¢™é¢çº¹ç†
  - å½¢çŠ¶ç‰¹å¾ â†’ å»ºç­‘è½®å»“
```

### è¿å»ºæ£€æµ‹å¤šæ¨¡æ€ç³»ç»Ÿ

```python
class BuildingMultiModalDetector:
    """
    å¤šæ¨¡æ€è¿å»ºæ£€æµ‹å™¨

    åŸºäº[4-10]çš„å¤šä¼ æ„Ÿå™¨èåˆæ–¹æ³•
    """
    def __init__(self):
        # ç‰¹å¾æå–å™¨
        self.lidar_extractor = LiDARFeatureExtractor()
        self.hyperspectral_extractor = HyperspectralFeatureExtractor()
        self.optical_extractor = OpticalFeatureExtractor()

        # å¤šæ¨¡æ€èåˆ ([4-10]ä¸­æœŸèåˆ)
        self.fusion = MultiSensorFusion(
            fusion_type='intermediate',
            num_classes=3  # æ­£å¸¸/æ–°å¢/æ‹†é™¤
        )

    def detect(self, lidar_data, hyperspectral_data, optical_data):
        """
        å¤šæ¨¡æ€è¿å»ºæ£€æµ‹

        Args:
            lidar_data: LiDARç‚¹äº‘
            hyperspectral_data: é«˜å…‰è°±å›¾åƒ
            optical_data: RGBå›¾åƒ

        Returns:
            detection_results: {
                'building_type': å»ºç­‘ç±»å‹,
                'confidence': ç½®ä¿¡åº¦,
                'material': æè´¨ä¿¡æ¯,
                '3d_model': 3Dé‡å»ºç»“æœ
            }
        """
        # 1. æå–ç‰¹å¾
        lidar_feat = self.lidar_extractor.extract_features(lidar_data)
        hyper_feat = self.hyperspectral_extractor.extract_features(hyperspectral_data)
        optical_feat = self.optical_extractor.extract_features(optical_data)

        # 2. å¤šæ¨¡æ€èåˆ
        fused_features = self.fusion.fuse(lidar_feat, hyper_feat, optical_feat)

        # 3. åˆ†ç±»
        probabilities = self.fusion.classify(fused_features)

        # 4. åå¤„ç†
        results = {
            'building_type': self._map_to_building_type(probabilities),
            'confidence': probabilities.max(),
            'material': self._infer_material(hyper_feat),
            '3d_model': self._reconstruct_3d(lidar_data, lidar_feat)
        }

        return results

    def _map_to_building_type(self, probabilities):
        """å°†åˆ†ç±»ç»“æœæ˜ å°„åˆ°å»ºç­‘ç±»å‹"""
        class_names = ['æ­£å¸¸å»ºç­‘', 'æ–°å¢å»ºç­‘', 'è¿å»ºæ‹†é™¤']
        idx = probabilities.argmax().item()
        return {
            'type': class_names[idx],
            'all_probs': {
                'æ­£å¸¸å»ºç­‘': probabilities[0].item(),
                'æ–°å¢å»ºç­‘': probabilities[1].item(),
                'è¿å»ºæ‹†é™¤': probabilities[2].item()
            }
        }

    def _infer_material(self, hyperspectral_features):
        """ä»é«˜å…‰è°±æ¨æ–­å»ºç­‘æè´¨"""
        # ç®€åŒ–: æ ¹æ®å…‰è°±ç‰¹å¾æ¨æ–­
        if hyperspectral_features.get('ndvi', 0) > 0.6:
            return 'vegetation'  # æ¤è¢«è¦†ç›–
        elif hyperspectral_features.get('spectral_angle', 0) < 0.5:
            return 'metal'  # é‡‘å±
        else:
            return 'concrete'  # æ··å‡åœŸ/ç –çŸ³

    def _reconstruct_3d(self, point_cloud, features):
        """3Dé‡å»º"""
        # ç®€åŒ–: ä½¿ç”¨å‡¸åŒ…é‡å»º
        from scipy.spatial import ConvexHull
        hull = ConvexHull(point_cloud)
        return {
            'volume': hull.volume,
            'surface_area': hull.area,
            'vertices': hull.vertices
        }
```

---

## ğŸ’¡ å¯å¤ç”¨ä»£ç ç»„ä»¶

### ç»„ä»¶1: å®Œæ•´çš„å¤šæ¨¡æ€æ£€æµ‹ç³»ç»Ÿ

```python
import torch
import torch.nn as nn
import numpy as np

class MultiModalViolationDetector(nn.Module):
    """
    å¤šæ¨¡æ€è¿å»ºæ£€æµ‹ç³»ç»Ÿ

    åŸºäº[4-10]å¤šä¼ æ„Ÿå™¨èåˆæ–¹æ³•
    """
    def __init__(self):
        super().__init__()

        # ç‰¹å¾æå–å™¨
        self.lidar_encoder = LiDARFeatureExtractor()
        self.hyperspectral_encoder = HyperspectralFeatureExtractor()
        self.optical_encoder = OpticalFeatureExtractor()

        # å¤šæ¨¡æ€èåˆ ([4-10]ä¸­æœŸèåˆ)
        self.fusion = MultiSensorFusion(
            fusion_type='intermediate',
            num_classes=3  # æ­£å¸¸/æ–°å¢/æ‹†é™¤
        )

    def forward(self, lidar_data, hyperspectral_data, optical_data):
        """
        å¤šæ¨¡æ€æ£€æµ‹

        Args:
            lidar_data: (N, 3) LiDARç‚¹äº‘
            hyperspectral_data: (H, W, C) é«˜å…‰è°±å›¾åƒ
            optical_data: (H, W, 3) RGBå›¾åƒ

        Returns:
            results: æ£€æµ‹ç»“æœ
        """
        # æå–ç‰¹å¾
        lidar_feat = self.lidar_encoder.extract_features(lidar_data)
        hyper_feat = self.hyperspectral_encoder.extract_features(hyperspectral_data)
        optical_feat = self.optical_encoder.extract_features(optical_data)

        # èåˆ
        fused = self.fusion.fuse(lidar_feat, hyper_feat, optical_feat)

        # åˆ†ç±»
        probs = self.fusion.classify(fused)

        return probs
```

### ç»„ä»¶2: é€‚é…è¿å»ºæ£€æµ‹çš„ç‰¹å¾ä¿®æ”¹

```python
class BuildingMultiModalExtractor:
    """
    å»ºç­‘ç‰©å¤šæ¨¡æ€ç‰¹å¾æå–å™¨ (ä¿®æ”¹è‡ª[4-10])
    """
    def __init__(self):
        # LiDAR: æå–å»ºç­‘å‡ ä½•ç‰¹å¾
        self.lidar_extractor = LiDARFeatureExtractor()

        # é«˜å…‰è°±: æ”¹ä¸ºæå–å»ºç­‘æè´¨ç‰¹å¾
        self.hyperspectral_extractor = HyperspectralFeatureExtractor()

        # å…‰å­¦: æå–å»ºç­‘å¤–è§‚ç‰¹å¾
        self.optical_extractor = OpticalFeatureExtractor()

    def extract_building_features(self, lidar_data, hyperspectral_data,
                                   optical_data):
        """
        æå–å»ºç­‘ç‰¹å¾

        æ”¹è¿›[4-10]æ–¹æ³•,ä¸“é—¨é’ˆå¯¹å»ºç­‘ç‰©
        """
        # 1. LiDARå‡ ä½•ç‰¹å¾
        lidar_features = self.lidar_extractor.extract_features(lidar_data)

        # 2. é«˜å…‰è°±æè´¨ç‰¹å¾ (æ”¹è¿›)
        spectral_features = self.hyperspectral_extractor.extract_features(hyperspectral_data)
        # æ·»åŠ å»ºç­‘ç›¸å…³ç‰¹å¾
        spectral_features['building_material'] = self._infer_building_material(
            spectral_features
        )

        # 3. å…‰å­¦å¤–è§‚ç‰¹å¾ (æ”¹è¿›)
        optical_features = self.optical_extractor.extract_features(optical_data)
        # æ·»åŠ å»ºç­‘ç›¸å…³ç‰¹å¾
        optical_features['roof_shape'] = self._classify_roof_shape(
            optical_data
        )
        optical_features['wall_pattern'] = self._detect_wall_pattern(
            optical_data
        )

        # 4. èåˆ
        features = self._combine_features(
            lidar_features, spectral_features, optical_features
        )

        return features

    def _infer_building_material(self, spectral_feat):
        """æ¨æ–­å»ºç­‘æè´¨"""
        ndvi = spectral_feat.get('ndvi', 0)
        red_edge = spectral_feat.get('red_edge', 0)

        if ndvi > 0.6:
            return 'vegetation_covered'
        elif red_edge > 0.3:
            return 'metal_roof'
        else:
            return 'concrete_brick'

    def _classify_roof_shape(self, image):
        """åˆ†ç±»å±‹é¡¶å½¢çŠ¶"""
        # ç®€åŒ–: é€šè¿‡è¾¹ç¼˜æ£€æµ‹åˆ†æå±‹é¡¶å½¢çŠ¶
        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
        edges = cv2.Canny(gray, 50, 150)

        # æ£€æµ‹ç›´çº¿
        lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=100,
                              minLineLength=30, maxLineGap=10)

        if len(lines) > 10:
            # æ£€æµ‹åˆ°å¤§é‡ç›´çº¿ â†’ å¹³é¡¶
            return 'flat'
        else:
            return 'pitched'

    def _detect_wall_pattern(self, image):
        """æ£€æµ‹å¢™é¢çº¹ç†æ¨¡å¼"""
        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
        glcm = self._compute_glcm(gray)

        # åˆ†æçº¹ç†å¤æ‚åº¦
        texture_complexity = glcm[0, 0]  # å¯¹æ¯”åº¦

        if texture_complexity > 0.1:
            return 'textured'
        else:
            return 'smooth'

    def _compute_glcm(self, gray):
        """è®¡ç®—ç°åº¦å…±ç”ŸçŸ©é˜µ"""
        glcm = cv2.calcHist([gray], [0], None, False)
        glcm = glcm.astype(np.float32) / (glcm.sum() + 1e-6)
        return glcm

    def _combine_features(self, lidar_feat, spectral_feat, optical_feat):
        """ç»„åˆç‰¹å¾"""
        combined = []

        # LiDARç‰¹å¾
        combined.extend([
            lidar_feat['height_max'],
            lidar_feat['volume'],
            lidar_feat['verticality']
        ])

        # å…‰è°±ç‰¹å¾
        combined.extend([
            spectral_feat['ndvi'],
            spectral_feat['red_edge']
        ])

        # å…‰å­¦ç‰¹å¾
        combined.extend([
            optical_feat['color_l'],
            optical_feat['glcm_contrast']
        ])

        return torch.tensor(combined)
```

---

## ğŸ“– å…³é”®æ¦‚å¿µä¸æœ¯è¯­

| æœ¯è¯­ | è‹±æ–‡ | è§£é‡Š |
|:---|:---|:---|
| **å¤šä¼ æ„Ÿå™¨èåˆ** | Multi-Sensor Fusion | æ•´åˆå¤šä¸ªä¼ æ„Ÿå™¨æ•°æ® |
| **LiDAR** | Light Detection and Ranging | æ¿€å…‰é›·è¾¾ |
| **é«˜å…‰è°±** | Hyperspectral | å¤šæ³¢æ®µå…‰è°±æˆåƒ |
| **NDVI** | Normalized Difference Vegetation Index | å½’ä¸€åŒ–æ¤è¢«æŒ‡æ•° |
| **çº¢è¾¹æ•ˆåº”** | Red Edge | æ¤è¢«åœ¨çº¢å…‰åå°„ç‡å˜åŒ– |
| **GLCM** | Gray Level Co-occurrence Matrix | ç°åº¦å…±ç”ŸçŸ©é˜µ |
| | | | |
| **æ—©æœŸèåˆ** | Early Fusion | æ•°æ®çº§èåˆ |
| **ä¸­æœŸèåˆ** | Intermediate Fusion | ç‰¹å¾çº§èåˆ |
| **æ™šæœŸèåˆ** | Late Fusion | å†³ç­–çº§èåˆ |

---

## âœ… å¤ä¹ æ£€æŸ¥æ¸…å•

- [ ] ç†è§£å¤šä¼ æ„Ÿå™¨æ•°æ®çš„ç‰¹ç‚¹
- [ ] æŒæ¡LiDARã€é«˜å…‰è°±ã€å…‰å­¦ç‰¹å¾çš„æå–æ–¹æ³•
- [ ] äº†è§£ä¸‰ç§èåˆç­–ç•¥åŠå…¶ä¼˜ç¼ºç‚¹
- [ ] ç†è§£ä¸­æœŸèåˆæœ€ä¼˜çš„åŸç†
- [ ] èƒ½å°†æ–¹æ³•è¿ç§»åˆ°è¿å»ºæ£€æµ‹å¤šæ¨¡æ€åˆ†æ

---

## ğŸ¤” æ€è€ƒé—®é¢˜

1. **ä¸ºä»€ä¹ˆä¸­æœŸèåˆæ•ˆæœæœ€å¥½ï¼Ÿ**
   - æç¤º: ç‰¹å¾çº§èåˆä¿ç•™å„æ¨¡æ€ä¼˜åŠ¿

2. **å¦‚ä½•å¤„ç†ä¼ æ„Ÿå™¨é—´çš„é…å‡†é—®é¢˜ï¼Ÿ**
   - æç¤º: å‡ ä½•å˜æ¢ã€ICPç®—æ³•

3. **é«˜å…‰è°±æ•°æ®å¦‚ä½•è·å–ï¼Ÿ**
   - æç¤º: å«æ˜Ÿ/æ— äººæœºæ­è½½ã€ä¸“ç”¨ä¼ æ„Ÿå™¨

4. **å¦‚ä½•é’ˆå¯¹å»ºç­‘ç‰©ä¼˜åŒ–ç‰¹å¾ï¼Ÿ**
   - æç¤º: å»ºç­‘ç‰©ç‰¹æœ‰çš„å‡ ä½•/æè´¨ç‰¹å¾

---

## ğŸ”— ç›¸å…³è®ºæ–‡æ¨è

### å¿…è¯»
1. **LEVIR-CD** - é¥æ„Ÿå˜åŒ–æ£€æµ‹æ•°æ®é›†
2. **WHU Building** - å»ºç­‘ç‰©æå–æ•°æ®é›†
3. **ISPRS Journal** - æ‘„å½±æµ‹é‡ä¸é¥æ„Ÿé¡¶åˆŠ

### æ‰©å±•é˜…è¯»
1. **å¤šæ¨¡æ€èåˆç»¼è¿°**
2. **é«˜å…‰è°±å›¾åƒåˆ†æ**
3. **æ·±åº¦å­¦ä¹ åœ¨é¥æ„Ÿä¸­çš„åº”ç”¨

---

**ç¬”è®°åˆ›å»ºæ—¶é—´**: 2026å¹´2æœˆ7æ—¥
**çŠ¶æ€**: å·²å®Œæˆç²¾è¯» âœ…
**ä¸‹ä¸€æ­¥**: ç»“åˆ[4-29]çº¿ç‰¹å¾åŒ¹é…,è®¾è®¡å®Œæ•´çš„è¿å»ºæ£€æµ‹ç³»ç»Ÿ
