# [3-03] è‡ªç›‘ç£å›¾ç¥ç»ç½‘ç»œ LL4G - ç²¾è¯»ç¬”è®°

> **è®ºæ–‡æ ‡é¢˜**: LL4G: Large Language Models for Graph Learning / Self-Supervised Graph Neural Networks
> **é˜…è¯»æ—¥æœŸ**: 2026å¹´2æœˆ10æ—¥
> **éš¾åº¦è¯„çº§**: â­â­â­â­ (ä¸­é«˜ï¼Œå›¾ç¥ç»ç½‘ç»œ+è‡ªç›‘ç£)
> **é‡è¦æ€§**: â­â­â­â­ (å›¾å­¦ä¹ å‰æ²¿æ–¹å‘)

---

## ğŸ“‹ è®ºæ–‡åŸºæœ¬ä¿¡æ¯

| é¡¹ç›® | å†…å®¹ |
|:---|:---|
| **æ ‡é¢˜** | LL4G: Large Language Models for Graph Learning / Self-Supervised Graph Neural Networks |
| **ä½œè€…** | Xiaohao Cai ç­‰äºº |
| **å‘è¡¨ä¼šè®®/æœŸåˆŠ** | 2023-2024 |
| **å…³é”®è¯** | Graph Neural Networks, Self-Supervised Learning, LLM, Contrastive Learning |
| **æ ¸å¿ƒä»·å€¼** | å°†å¤§è¯­è¨€æ¨¡å‹èƒ½åŠ›å¼•å…¥å›¾å­¦ä¹ ï¼Œè‡ªç›‘ç£å›¾è¡¨ç¤ºå­¦ä¹  |

---

## ğŸ¯ ç ”ç©¶èƒŒæ™¯ä¸é—®é¢˜

### å›¾ç¥ç»ç½‘ç»œæŒ‘æˆ˜

```
ä¼ ç»ŸGNNçš„å±€é™:
â”œâ”€â”€ æ ‡æ³¨æ•°æ®ç¨€ç¼º
â”‚   â””â”€â”€ å›¾æ•°æ®æ ‡æ³¨æˆæœ¬é«˜ (éœ€è¦é¢†åŸŸä¸“å®¶)
â”œâ”€â”€ æ³›åŒ–èƒ½åŠ›æœ‰é™
â”‚   â””â”€â”€ ç›‘ç£å­¦ä¹ è¿‡æ‹Ÿåˆè®­ç»ƒå›¾ç»“æ„
â”œâ”€â”€ å¯è¿ç§»æ€§å·®
â”‚   â””â”€â”€ éš¾ä»¥è·¨æ•°æ®é›†è¿ç§»
â””â”€â”€ ç¼ºä¹è¯­ä¹‰ç†è§£
    â””â”€â”€ æ— æ³•åˆ©ç”¨èŠ‚ç‚¹/è¾¹çš„æ–‡æœ¬ä¿¡æ¯

è‡ªç›‘ç£å­¦ä¹ çš„è§£å†³æ–¹æ¡ˆ:
â”œâ”€â”€ æ— éœ€äººå·¥æ ‡æ³¨
â”œâ”€â”€ å­¦ä¹ é€šç”¨è¡¨ç¤º
â”œâ”€â”€ æ›´å¥½çš„æ³›åŒ–æ€§
â””â”€â”€ å¯ç»“åˆå¤§è¯­è¨€æ¨¡å‹è¯­ä¹‰
```

### LL4Gæ ¸å¿ƒæ€æƒ³

```
å°†å¤§è¯­è¨€æ¨¡å‹(LLM)ä¸å›¾ç¥ç»ç½‘ç»œ(GNN)ç»“åˆ:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      LL4Gæ¡†æ¶                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  èŠ‚ç‚¹æ–‡æœ¬æè¿° â”€â”€â†’ LLMç¼–ç å™¨ â”€â”€â†’ è¯­ä¹‰èŠ‚ç‚¹åµŒå…¥            â”‚
â”‚       â”‚                              â”‚                 â”‚
â”‚       â”‚         å›¾ç»“æ„ä¿¡æ¯           â”‚                 â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                   â†“                                    â”‚
â”‚            å›¾ç¥ç»ç½‘ç»œ(GNN)                              â”‚
â”‚                   â†“                                    â”‚
â”‚            ç»“æ„æ„ŸçŸ¥è¡¨ç¤º                                 â”‚
â”‚                   â†“                                    â”‚
â”‚            ä¸‹æ¸¸ä»»åŠ¡ (åˆ†ç±»/é“¾æ¥é¢„æµ‹)                      â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

æ ¸å¿ƒåˆ›æ–°:
1. åˆ©ç”¨LLMç¼–ç èŠ‚ç‚¹è¯­ä¹‰ä¿¡æ¯
2. è‡ªç›‘ç£é¢„è®­ç»ƒç­–ç•¥
3. ç»“æ„-è¯­ä¹‰è”åˆè¡¨ç¤ºå­¦ä¹ 
```

---

## ğŸ”¬ æ–¹æ³•è®ºè¯¦è§£

### æ•´ä½“æ¶æ„

```
LL4Gä¸‰é˜¶æ®µè®­ç»ƒ:

Stage 1: è¯­ä¹‰ç¼–ç  (å†»ç»“LLM)
  èŠ‚ç‚¹æ–‡æœ¬ â†’ LLM â†’ è¯­ä¹‰åµŒå…¥ h_semantic

Stage 2: ç»“æ„å­¦ä¹  (GNNè®­ç»ƒ)
  å›¾ç»“æ„ + h_semantic â†’ GNN â†’ ç»“æ„æ„ŸçŸ¥è¡¨ç¤º h_structural

Stage 3: è‡ªç›‘ç£å¯¹é½
  å¯¹æ¯”å­¦ä¹ : æ‹‰è¿‘ç›¸ä¼¼èŠ‚ç‚¹ï¼Œæ¨å¼€ä¸ç›¸ä¼¼èŠ‚ç‚¹
```

### ç»„ä»¶1: è¯­ä¹‰ç¼–ç å™¨

```python
import torch
import torch.nn as nn
from transformers import AutoModel, AutoTokenizer

class SemanticEncoder(nn.Module):
    """
    åŸºäºLLMçš„è¯­ä¹‰ç¼–ç å™¨

    å°†èŠ‚ç‚¹æ–‡æœ¬æè¿°ç¼–ç ä¸ºå‘é‡
    """

    def __init__(
        self,
        model_name: str = "sentence-transformers/all-MiniLM-L6-v2",
        freeze: bool = True
    ):
        super().__init__()

        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.llm = AutoModel.from_pretrained(model_name)

        if freeze:
            # å†»ç»“LLMå‚æ•°
            for param in self.llm.parameters():
                param.requires_grad = False

        self.hidden_size = self.llm.config.hidden_size

    def forward(self, texts: List[str]) -> torch.Tensor:
        """
        ç¼–ç æ–‡æœ¬åˆ—è¡¨

        Args:
            texts: èŠ‚ç‚¹æ–‡æœ¬æè¿°åˆ—è¡¨

        Returns:
            embeddings: (num_nodes, hidden_size)
        """
        # Tokenize
        inputs = self.tokenizer(
            texts,
            padding=True,
            truncation=True,
            max_length=512,
            return_tensors="pt"
        )

        # ç§»è‡³GPU
        if next(self.llm.parameters()).is_cuda:
            inputs = {k: v.cuda() for k, v in inputs.items()}

        # ç¼–ç 
        with torch.no_grad():
            outputs = self.llm(**inputs)

        # ä½¿ç”¨[CLS] tokenæˆ–mean pooling
        embeddings = self._mean_pooling(outputs, inputs['attention_mask'])

        return embeddings

    def _mean_pooling(self, model_output, attention_mask):
        """Mean Poolingè·å–å¥å­åµŒå…¥"""
        token_embeddings = model_output.last_hidden_state
        input_mask_expanded = attention_mask.unsqueeze(-1).float()

        sum_embeddings = (token_embeddings * input_mask_expanded).sum(dim=1)
        sum_mask = input_mask_expanded.sum(dim=1).clamp(min=1e-9)

        return sum_embeddings / sum_mask


class LightweightSemanticEncoder(nn.Module):
    """
    è½»é‡çº§è¯­ä¹‰ç¼–ç å™¨ (ç”¨äºå¤§è§„æ¨¡å›¾)

    ä½¿ç”¨é¢„è®¡ç®—ç¼“å­˜ + å°å‹æŠ•å½±ç½‘ç»œ
    """

    def __init__(
        self,
        cache_path: str = None,
        input_dim: int = 384,
        hidden_dim: int = 256
    ):
        super().__init__()

        self.cache = {}
        self.cache_path = cache_path

        # æŠ•å½±ç½‘ç»œ
        self.projection = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(inplace=True),
            nn.Linear(hidden_dim, hidden_dim)
        )

    def encode_with_cache(self, node_ids: List[int], texts: List[str]):
        """
        ä½¿ç”¨ç¼“å­˜ç¼–ç 

        å¦‚æœnode_idåœ¨ç¼“å­˜ä¸­ï¼Œç›´æ¥è¿”å›
        å¦åˆ™ç¼–ç å¹¶ç¼“å­˜
        """
        embeddings = []
        uncached_ids = []
        uncached_texts = []

        for nid, text in zip(node_ids, texts):
            if nid in self.cache:
                embeddings.append(self.cache[nid])
            else:
                uncached_ids.append(nid)
                uncached_texts.append(text)

        # ç¼–ç æœªç¼“å­˜çš„èŠ‚ç‚¹
        if uncached_texts:
            new_embeddings = self._batch_encode(uncached_texts)
            for nid, emb in zip(uncached_ids, new_embeddings):
                self.cache[nid] = emb
                embeddings.append(emb)

        return torch.stack(embeddings)

    def _batch_encode(self, texts: List[str]):
        """æ‰¹é‡ç¼–ç  (ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹)"""
        # å®é™…å®ç°ä¸­è°ƒç”¨SemanticEncoder
        pass

    def forward(self, embeddings: torch.Tensor) -> torch.Tensor:
        """æŠ•å½±åˆ°ç›®æ ‡ç»´åº¦"""
        return self.projection(embeddings)
```

---

### ç»„ä»¶2: å›¾ç¥ç»ç½‘ç»œç¼–ç å™¨

```python
import torch.nn.functional as F
from torch_geometric.nn import GCNConv, GATConv, SAGEConv

class GraphEncoder(nn.Module):
    """
    å›¾ç¥ç»ç½‘ç»œç¼–ç å™¨

    å­¦ä¹ ç»“æ„æ„ŸçŸ¥è¡¨ç¤º
    """

    def __init__(
        self,
        input_dim: int,
        hidden_dim: int = 256,
        output_dim: int = 128,
        num_layers: int = 2,
        gnn_type: str = "gcn",
        dropout: float = 0.5
    ):
        super().__init__()

        self.num_layers = num_layers
        self.dropout = dropout

        # é€‰æ‹©GNNç±»å‹
        conv_layer = {
            "gcn": GCNConv,
            "gat": GATConv,
            "sage": SAGEConv
        }[gnn_type]

        # æ„å»ºGNNå±‚
        self.convs = nn.ModuleList()

        # ç¬¬ä¸€å±‚
        self.convs.append(conv_layer(input_dim, hidden_dim))

        # ä¸­é—´å±‚
        for _ in range(num_layers - 2):
            self.convs.append(conv_layer(hidden_dim, hidden_dim))

        # è¾“å‡ºå±‚
        self.convs.append(conv_layer(hidden_dim, output_dim))

        # æ‰¹å½’ä¸€åŒ–
        self.bns = nn.ModuleList([
            nn.BatchNorm1d(hidden_dim) for _ in range(num_layers - 1)
        ])

    def forward(
        self,
        x: torch.Tensor,
        edge_index: torch.Tensor
    ) -> torch.Tensor:
        """
        å‰å‘ä¼ æ’­

        Args:
            x: èŠ‚ç‚¹ç‰¹å¾ (N, input_dim)
            edge_index: è¾¹ç´¢å¼• (2, E)

        Returns:
            embeddings: èŠ‚ç‚¹åµŒå…¥ (N, output_dim)
        """
        for i, conv in enumerate(self.convs[:-1]):
            x = conv(x, edge_index)
            x = self.bns[i](x)
            x = F.relu(x)
            x = F.dropout(x, p=self.dropout, training=self.training)

        # æœ€åä¸€å±‚
        x = self.convs[-1](x, edge_index)

        return x

    def get_embeddings(
        self,
        x: torch.Tensor,
        edge_index: torch.Tensor
    ) -> torch.Tensor:
        """è·å–åµŒå…¥ (æ— æ¢¯åº¦)"""
        self.eval()
        with torch.no_grad():
            return self.forward(x, edge_index)


class SemanticGraphEncoder(nn.Module):
    """
    è¯­ä¹‰å›¾ç¼–ç å™¨: ç»“åˆLLMè¯­ä¹‰å’Œå›¾ç»“æ„
    """

    def __init__(
        self,
        semantic_dim: int,
        hidden_dim: int = 256,
        output_dim: int = 128,
        fusion: str = "concat"  # concat, add, attention
    ):
        super().__init__()

        self.fusion = fusion

        # è¯­ä¹‰æŠ•å½±
        self.semantic_proj = nn.Linear(semantic_dim, hidden_dim)

        # GNNç¼–ç å™¨
        self.gnn = GraphEncoder(
            input_dim=hidden_dim,
            hidden_dim=hidden_dim,
            output_dim=output_dim,
            num_layers=2
        )

        if fusion == "attention":
            # æ³¨æ„åŠ›èåˆ
            self.attention = nn.MultiheadAttention(output_dim, num_heads=4)

    def forward(
        self,
        semantic_embeddings: torch.Tensor,
        edge_index: torch.Tensor
    ) -> torch.Tensor:
        """
        å‰å‘ä¼ æ’­

        Args:
            semantic_embeddings: LLMç¼–ç çš„è¯­ä¹‰åµŒå…¥ (N, semantic_dim)
            edge_index: å›¾è¾¹ç´¢å¼• (2, E)

        Returns:
            node_embeddings: èåˆåçš„èŠ‚ç‚¹åµŒå…¥ (N, output_dim)
        """
        # æŠ•å½±è¯­ä¹‰åµŒå…¥
        x = self.semantic_proj(semantic_embeddings)

        # GNNç¼–ç 
        node_embeddings = self.gnn(x, edge_index)

        return node_embeddings
```

---

### ç»„ä»¶3: è‡ªç›‘ç£å­¦ä¹ ç­–ç•¥

```python
class SelfSupervisedGraphLearner:
    """
    è‡ªç›‘ç£å›¾å­¦ä¹ å™¨

    ä½¿ç”¨å¯¹æ¯”å­¦ä¹ è¿›è¡Œæ— ç›‘ç£é¢„è®­ç»ƒ
    """

    def __init__(
        self,
        encoder: nn.Module,
        temperature: float = 0.5,
        projection_dim: int = 128
    ):
        self.encoder = encoder
        self.temperature = temperature

        # æŠ•å½±å¤´ (ç”¨äºå¯¹æ¯”å­¦ä¹ )
        self.projection_head = nn.Sequential(
            nn.Linear(encoder.output_dim, projection_dim),
            nn.ReLU(inplace=True),
            nn.Linear(projection_dim, projection_dim)
        )

    def contrastive_loss(
        self,
        z_i: torch.Tensor,
        z_j: torch.Tensor
    ) -> torch.Tensor:
        """
        InfoNCEå¯¹æ¯”æŸå¤±

        Args:
            z_i, z_j: ä¸¤ä¸ªè§†è§’çš„èŠ‚ç‚¹è¡¨ç¤º (N, dim)

        Returns:
            loss: å¯¹æ¯”æŸå¤±
        """
        # L2å½’ä¸€åŒ–
        z_i = F.normalize(z_i, dim=1)
        z_j = F.normalize(z_j, dim=1)

        # è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ
        similarity_matrix = torch.mm(z_i, z_j.t()) / self.temperature

        # æ ‡ç­¾: å¯¹è§’çº¿ä¸ºæ­£æ ·æœ¬
        batch_size = z_i.size(0)
        labels = torch.arange(batch_size).to(z_i.device)

        # äº¤å‰ç†µæŸå¤±
        loss_i2j = F.cross_entropy(similarity_matrix, labels)
        loss_j2i = F.cross_entropy(similarity_matrix.t(), labels)

        return (loss_i2j + loss_j2i) / 2

    def node_masking_loss(
        self,
        x: torch.Tensor,
        edge_index: torch.Tensor,
        mask_rate: float = 0.15
    ) -> torch.Tensor:
        """
        èŠ‚ç‚¹æ©ç é‡å»ºæŸå¤±

        éšæœºæ©ç éƒ¨åˆ†èŠ‚ç‚¹ç‰¹å¾ï¼Œé‡å»ºåŸå§‹ç‰¹å¾
        """
        num_nodes = x.size(0)
        num_mask = int(num_nodes * mask_rate)

        # éšæœºé€‰æ‹©æ©ç èŠ‚ç‚¹
        mask_indices = torch.randperm(num_nodes)[:num_mask]

        # åˆ›å»ºæ©ç åçš„ç‰¹å¾
        x_masked = x.clone()
        x_masked[mask_indices] = 0  # æˆ–æ›¿æ¢ä¸º[MASK] token

        # ç¼–ç 
        h = self.encoder(x_masked, edge_index)

        # é‡å»º
        reconstructed = self.reconstruction_head(h[mask_indices])
        original = x[mask_indices]

        # MSEæŸå¤±
        loss = F.mse_loss(reconstructed, original)

        return loss

    def edge_prediction_loss(
        self,
        x: torch.Tensor,
        edge_index: torch.Tensor,
        num_negatives: int = 5
    ) -> torch.Tensor:
        """
        è¾¹é¢„æµ‹æŸå¤± (é“¾æ¥é¢„æµ‹)

        æ­£æ ·æœ¬: å›¾ä¸­å­˜åœ¨çš„è¾¹
        è´Ÿæ ·æœ¬: éšæœºé‡‡æ ·çš„éè¾¹
        """
        # ç¼–ç èŠ‚ç‚¹
        h = self.encoder(x, edge_index)

        # æ­£æ ·æœ¬è¾¹
        pos_edges = edge_index.t()
        pos_score = self._edge_score(h, pos_edges)

        # è´Ÿæ ·æœ¬è¾¹ (éšæœºé‡‡æ ·)
        neg_edges = self._sample_negative_edges(
            edge_index, x.size(0), num_negatives * pos_edges.size(0)
        )
        neg_score = self._edge_score(h, neg_edges)

        # äºŒåˆ†ç±»äº¤å‰ç†µ
        pos_loss = -torch.log(pos_score + 1e-8).mean()
        neg_loss = -torch.log(1 - neg_score + 1e-8).mean()

        return pos_loss + neg_loss

    def _edge_score(self, h: torch.Tensor, edges: torch.Tensor) -> torch.Tensor:
        """è®¡ç®—è¾¹å­˜åœ¨æ¦‚ç‡ (ç‚¹ç§¯)"""
        src, dst = edges[:, 0], edges[:, 1]
        score = (h[src] * h[dst]).sum(dim=1)
        return torch.sigmoid(score)

    def _sample_negative_edges(
        self,
        edge_index: torch.Tensor,
        num_nodes: int,
        num_samples: int
    ) -> torch.Tensor:
        """é‡‡æ ·è´Ÿæ ·æœ¬è¾¹"""
        # åˆ›å»ºè¾¹é›†åˆ
        edge_set = set()
        for i in range(edge_index.size(1)):
            u, v = edge_index[0, i].item(), edge_index[1, i].item()
            edge_set.add((min(u, v), max(u, v)))

        # éšæœºé‡‡æ ·ä¸å­˜åœ¨çš„è¾¹
        neg_edges = []
        while len(neg_edges) < num_samples:
            u = torch.randint(0, num_nodes, (1,)).item()
            v = torch.randint(0, num_nodes, (1,)).item()
            if u != v and (min(u, v), max(u, v)) not in edge_set:
                neg_edges.append([u, v])

        return torch.tensor(neg_edges)
```

---

### ç»„ä»¶4: æ•°æ®å¢å¼ºç­–ç•¥

```python
class GraphAugmentation:
    """
    å›¾æ•°æ®å¢å¼º

    ç”¨äºå¯¹æ¯”å­¦ä¹ çš„ä¸åŒè§†è§’ç”Ÿæˆ
    """

    def __init__(
        self,
        edge_drop_rate: float = 0.2,
        node_drop_rate: float = 0.1,
        feat_mask_rate: float = 0.2
    ):
        self.edge_drop_rate = edge_drop_rate
        self.node_drop_rate = node_drop_rate
        self.feat_mask_rate = feat_mask_rate

    def edge_dropout(
        self,
        edge_index: torch.Tensor
    ) -> torch.Tensor:
        """éšæœºåˆ é™¤è¾¹"""
        num_edges = edge_index.size(1)
        mask = torch.rand(num_edges) > self.edge_drop_rate
        return edge_index[:, mask]

    def node_dropout(
        self,
        x: torch.Tensor,
        edge_index: torch.Tensor
    ) -> Tuple[torch.Tensor, torch.Tensor]:
        """éšæœºåˆ é™¤èŠ‚ç‚¹"""
        num_nodes = x.size(0)
        keep_mask = torch.rand(num_nodes) > self.node_drop_rate

        # é‡æ–°ç´¢å¼•
        node_map = torch.cumsum(keep_mask.long(), dim=0) - 1
        node_map[~keep_mask] = -1

        # è¿‡æ»¤è¾¹
        src, dst = edge_index
        edge_mask = keep_mask[src] & keep_mask[dst]
        new_edge_index = torch.stack([
            node_map[src[edge_mask]],
            node_map[dst[edge_mask]]
        ])

        return x[keep_mask], new_edge_index

    def feature_masking(self, x: torch.Tensor) -> torch.Tensor:
        """éšæœºæ©ç ç‰¹å¾ç»´åº¦"""
        mask = torch.rand_like(x) > self.feat_mask_rate
        return x * mask

    def rwr_subgraph(
        self,
        edge_index: torch.Tensor,
        num_nodes: int,
        start_node: int = None,
        walk_length: int = 50,
        restart_prob: float = 0.3
    ) -> torch.Tensor:
        """
        éšæœºæ¸¸èµ°é‡å¯é‡‡æ ·å­å›¾

        ä»èµ·å§‹èŠ‚ç‚¹å¼€å§‹éšæœºæ¸¸èµ°ï¼Œä»¥ä¸€å®šæ¦‚ç‡é‡å¯
        """
        # æ„å»ºé‚»æ¥è¡¨
        adj_list = [[] for _ in range(num_nodes)]
        for i in range(edge_index.size(1)):
            u, v = edge_index[:, i].tolist()
            adj_list[u].append(v)
            adj_list[v].append(u)

        # éšæœºæ¸¸èµ°
        if start_node is None:
            start_node = torch.randint(0, num_nodes, (1,)).item()

        visited = set([start_node])
        current = start_node

        for _ in range(walk_length):
            if torch.rand(1).item() < restart_prob:
                current = start_node
            else:
                neighbors = adj_list[current]
                if neighbors:
                    current = neighbors[torch.randint(0, len(neighbors), (1,)).item()]
            visited.add(current)

        return torch.tensor(list(visited))

    def __call__(
        self,
        x: torch.Tensor,
        edge_index: torch.Tensor
    ) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        åº”ç”¨å¢å¼º

        éšæœºé€‰æ‹©ä¸€ç§æˆ–å¤šç§å¢å¼ºç­–ç•¥
        """
        # è¾¹dropout
        if torch.rand(1).item() < 0.5:
            edge_index = self.edge_dropout(edge_index)

        # ç‰¹å¾æ©ç 
        if torch.rand(1).item() < 0.5:
            x = self.feature_masking(x)

        return x, edge_index
```

---

## ğŸ“Š å®éªŒä¸ç»“æœ

### ä¸‹æ¸¸ä»»åŠ¡

```
è¯„ä¼°ä»»åŠ¡:
â”œâ”€â”€ èŠ‚ç‚¹åˆ†ç±» (Node Classification)
â”‚   â””â”€â”€ é¢„æµ‹èŠ‚ç‚¹ç±»åˆ«
â”œâ”€â”€ é“¾æ¥é¢„æµ‹ (Link Prediction)
â”‚   â””â”€â”€ é¢„æµ‹è¾¹æ˜¯å¦å­˜åœ¨
â”œâ”€â”€ å›¾åˆ†ç±» (Graph Classification)
â”‚   â””â”€â”€ é¢„æµ‹æ•´ä¸ªå›¾çš„ç±»åˆ«
â””â”€â”€ èŠ‚ç‚¹èšç±» (Node Clustering)
    â””â”€â”€ æ— ç›‘ç£èšç±»
```

### å…¸å‹ç»“æœ

```
èŠ‚ç‚¹åˆ†ç±»æ€§èƒ½ (Cora, Citeseer, PubMed):

æ–¹æ³•            Cora      Citeseer   PubMed
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
GCN             81.5%     70.3%      79.0%
GAT             83.0%     72.5%      79.0%
GraphSAGE       82.2%     71.4%      78.5%
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DGI (è‡ªç›‘ç£)     82.3%     71.8%      76.8%
GRACE           83.0%     72.5%      79.0%
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
LL4G (æœ¬æ–‡)      84.2%     74.1%      80.5%

å…³é”®å‘ç°:
- ç»“åˆLLMè¯­ä¹‰æ˜¾è‘—æå‡æ€§èƒ½
- è‡ªç›‘ç£é¢„è®­ç»ƒæœ‰æ•ˆåˆ©ç”¨æ— æ ‡ç­¾æ•°æ®
- è·¨æ•°æ®é›†è¿ç§»èƒ½åŠ›å¼º
```

---

## ğŸ’» å¯å¤ç”¨ä»£ç ç»„ä»¶

### ç»„ä»¶1: å®Œæ•´è®­ç»ƒæµç¨‹

```python
class LL4GTrainer:
    """
    LL4Gå®Œæ•´è®­ç»ƒå™¨
    """

    def __init__(
        self,
        semantic_encoder: nn.Module,
        graph_encoder: nn.Module,
        device: str = 'cuda'
    ):
        self.semantic_encoder = semantic_encoder.to(device)
        self.graph_encoder = graph_encoder.to(device)
        self.device = device

        self.augmentation = GraphAugmentation()

    def pretrain(
        self,
        texts: List[str],
        edge_index: torch.Tensor,
        num_epochs: int = 100,
        lr: float = 1e-3
    ):
        """
        è‡ªç›‘ç£é¢„è®­ç»ƒ
        """
        # è·å–è¯­ä¹‰åµŒå…¥
        print("Encoding semantic embeddings...")
        semantic_emb = self.semantic_encoder(texts)

        edge_index = edge_index.to(self.device)

        optimizer = torch.optim.Adam(
            self.graph_encoder.parameters(),
            lr=lr
        )

        print("Starting pretraining...")
        for epoch in range(num_epochs):
            self.graph_encoder.train()

            # ç”Ÿæˆä¸¤ä¸ªå¢å¼ºè§†è§’
            x1, edge1 = self.augmentation(semantic_emb, edge_index)
            x2, edge2 = self.augmentation(semantic_emb, edge_index)

            # ç¼–ç 
            z1 = self.graph_encoder(x1, edge1)
            z2 = self.graph_encoder(x2, edge2)

            # å¯¹æ¯”æŸå¤±
            loss = self.contrastive_loss(z1, z2)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            if (epoch + 1) % 10 == 0:
                print(f"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}")

    def finetune(
        self,
        train_data,
        num_epochs: int = 50,
        lr: float = 1e-3
    ):
        """
        ä¸‹æ¸¸ä»»åŠ¡å¾®è°ƒ
        """
        optimizer = torch.optim.Adam(
            self.graph_encoder.parameters(),
            lr=lr
        )

        for epoch in range(num_epochs):
            self.graph_encoder.train()
            # å…·ä½“å®ç°å–å†³äºä¸‹æ¸¸ä»»åŠ¡
            pass

    def contrastive_loss(self, z1, z2):
        """å¯¹æ¯”æŸå¤±"""
        z1 = F.normalize(z1, dim=1)
        z2 = F.normalize(z2, dim=1)

        similarity = torch.mm(z1, z2.t()) / 0.5
        labels = torch.arange(z1.size(0)).to(self.device)

        loss = F.cross_entropy(similarity, labels)
        loss += F.cross_entropy(similarity.t(), labels)

        return loss / 2
```

### ç»„ä»¶2: åº”ç”¨åˆ°äº•ç›–æ£€æµ‹

```python
class ManholeGraphDetector:
    """
    åŸºäºå›¾ç¥ç»ç½‘ç»œçš„äº•ç›–æ£€æµ‹

    å°†å›¾åƒåˆ†å‰²ä¸ºåŒºåŸŸï¼Œæ„å»ºåŒºåŸŸå…³ç³»å›¾
    """

    def __init__(self, num_classes: int = 2):
        # è¯­ä¹‰ç¼–ç å™¨ (æè¿°åŒºåŸŸå†…å®¹)
        self.semantic_encoder = SemanticEncoder()

        # å›¾ç¼–ç å™¨
        self.graph_encoder = SemanticGraphEncoder(
            semantic_dim=384,
            hidden_dim=256,
            output_dim=128
        )

        # åˆ†ç±»å¤´
        self.classifier = nn.Linear(128, num_classes)

    def build_region_graph(self, image, segments):
        """
        ä»å›¾åƒåˆ†å‰²æ„å»ºåŒºåŸŸå›¾

        Args:
            image: è¾“å…¥å›¾åƒ
            segments: åˆ†å‰²åŒºåŸŸ (å¦‚è¶…åƒç´ )

        Returns:
            node_features: åŒºåŸŸç‰¹å¾
            edge_index: åŒºåŸŸè¿æ¥å…³ç³»
        """
        num_regions = len(segments)

        # æå–æ¯ä¸ªåŒºåŸŸçš„è§†è§‰ç‰¹å¾å’Œæè¿°
        region_features = []
        region_texts = []

        for i, seg in enumerate(segments):
            # æå–åŒºåŸŸå›¾åƒ
            region_img = image[seg]

            # ç”ŸæˆåŒºåŸŸæè¿° (å¯ç”¨CLIPç­‰)
            description = self._generate_region_description(region_img)
            region_texts.append(description)

        # æ„å»ºè¾¹ (ç›¸é‚»åŒºåŸŸè¿æ¥)
        edges = []
        for i in range(num_regions):
            for j in range(i + 1, num_regions):
                if self._regions_adjacent(segments[i], segments[j]):
                    edges.append([i, j])
                    edges.append([j, i])

        edge_index = torch.tensor(edges).t()

        return region_texts, edge_index

    def forward(self, image, segments):
        """
        å‰å‘ä¼ æ’­

        Returns:
            region_predictions: æ¯ä¸ªåŒºåŸŸçš„é¢„æµ‹
        """
        # æ„å»ºå›¾
        texts, edge_index = self.build_region_graph(image, segments)

        # è¯­ä¹‰ç¼–ç 
        semantic_emb = self.semantic_encoder(texts)

        # å›¾ç¼–ç 
        node_emb = self.graph_encoder(semantic_emb, edge_index)

        # åˆ†ç±»
        predictions = self.classifier(node_emb)

        return predictions

    def _generate_region_description(self, region_img):
        """ç”ŸæˆåŒºåŸŸæè¿°"""
        # å¯ç”¨é¢„è®­ç»ƒæ¨¡å‹ç”Ÿæˆæè¿°
        # ä¾‹å¦‚: "åœ†å½¢é‡‘å±ç‰©ä½“", "é“è·¯è¡¨é¢"ç­‰
        pass

    def _regions_adjacent(self, seg1, seg2):
        """åˆ¤æ–­ä¸¤ä¸ªåŒºåŸŸæ˜¯å¦ç›¸é‚»"""
        # æ£€æŸ¥è¾¹ç•Œæ˜¯å¦æ¥è§¦
        pass
```

---

## ğŸ“– å…³é”®æ¦‚å¿µä¸æœ¯è¯­

| æœ¯è¯­ | è‹±æ–‡ | è§£é‡Š |
|:---|:---|:---|
| **GNN** | Graph Neural Network | å›¾ç¥ç»ç½‘ç»œ |
| **è‡ªç›‘ç£å­¦ä¹ ** | Self-Supervised Learning | æ— éœ€æ ‡æ³¨çš„è®­ç»ƒæ–¹å¼ |
| **å¯¹æ¯”å­¦ä¹ ** | Contrastive Learning | é€šè¿‡å¯¹æ¯”æ­£è´Ÿæ ·æœ¬å­¦ä¹  |
| **InfoNCE** | InfoNCE | å™ªå£°å¯¹æ¯”ä¼°è®¡æŸå¤± |
| **æ•°æ®å¢å¼º** | Data Augmentation | ç”Ÿæˆè®­ç»ƒæ ·æœ¬å˜ä½“ |
| **é“¾æ¥é¢„æµ‹** | Link Prediction | é¢„æµ‹å›¾ä¸­ç¼ºå¤±çš„è¾¹ |
| **èŠ‚ç‚¹åˆ†ç±»** | Node Classification | é¢„æµ‹èŠ‚ç‚¹ç±»åˆ« |

---

## âœ… å¤ä¹ æ£€æŸ¥æ¸…å•

- [ ] ç†è§£GNNçš„åŸºæœ¬åŸç†
- [ ] æŒæ¡è‡ªç›‘ç£å­¦ä¹ çš„åŠ¨æœº
- [ ] äº†è§£å¯¹æ¯”å­¦ä¹ çš„å®ç°
- [ ] æŒæ¡å›¾æ•°æ®å¢å¼ºæ–¹æ³•
- [ ] ç†è§£LLMä¸GNNçš„ç»“åˆæ–¹å¼
- [ ] èƒ½å°†æ–¹æ³•åº”ç”¨åˆ°å›¾ç»“æ„æ•°æ®

---

## ğŸ”— ç›¸å…³è®ºæ–‡æ¨è

### å¿…è¯»
1. **GCN** (ICLR 2017) - å›¾å·ç§¯ç½‘ç»œ
2. **GAT** (ICLR 2018) - å›¾æ³¨æ„åŠ›ç½‘ç»œ
3. **DGI** (ICLR 2019) - æ·±åº¦å›¾ä¿¡æ¯æœ€å¤§åŒ–
4. **GRACE** (AAAI 2020) - å›¾å¯¹æ¯”å­¦ä¹ 

### æ‰©å±•é˜…è¯»
1. **GraphSAGE** (NIPS 2017) - å½’çº³å¼å›¾å­¦ä¹ 
2. **GIN** (ICLR 2019) - å›¾åŒæ„ç½‘ç»œ
3. **InfoGraph** (ICLR 2020) - å›¾çº§å¯¹æ¯”å­¦ä¹ 
4. **LLM4Graph** - å¤§è¯­è¨€æ¨¡å‹ç”¨äºå›¾å­¦ä¹ 

---

**ç¬”è®°åˆ›å»ºæ—¶é—´**: 2026å¹´2æœˆ10æ—¥
**çŠ¶æ€**: å·²å®Œæˆç²¾è¯» âœ…
**ä¸‹ä¸€æ­¥**: åœ¨äº•ç›–æ£€æµ‹ä¸­å°è¯•å›¾ç»“æ„å»ºæ¨¡
