# [2-15] 3Dæ ‘æœ¨åˆ†å‰²å›¾å‰² 3D Tree Segmentation - ç²¾è¯»ç¬”è®°

> **è®ºæ–‡æ ‡é¢˜**: 3D Segmentation of Trees Through Flexible Multiclass Graph Cut
> **ä½œè€…**: Xiaohao Cai, Guangxing Wang, etc.
> **æœŸåˆŠ**: IEEE Transactions on Geoscience and Remote Sensing (TGRS)
> **å¹´ä»½**: 2019
> **DOI**: 10.1109/TGRS.2019.2940146
> **ç²¾è¯»æ—¥æœŸ**: 2026å¹´2æœˆ7æ—¥

---

## ğŸ“‹ è®ºæ–‡åŸºæœ¬ä¿¡æ¯

### å…ƒæ•°æ®
| é¡¹ç›® | å†…å®¹ |
|:---|:---|
| **ç ”ç©¶é¢†åŸŸ** | 3Dè®¡ç®—æœºè§†è§‰ + é¥æ„Ÿå›¾åƒå¤„ç† |
| **åº”ç”¨åœºæ™¯** | æ£®æ—èµ„æºè°ƒæŸ¥ã€ç”Ÿæ€ç›‘æµ‹ã€æ—ä¸šç®¡ç† |
| **æ•°æ®ç±»å‹** | LiDARç‚¹äº‘ + å¤šå…‰è°±å›¾åƒ |
| **æ–¹æ³•ç±»å‹** | å›¾å‰² (Graph Cut) + å¤šç±»åˆ†å‰² |
| **é‡è¦æ€§** | â˜…â˜…â˜…â˜…â˜† (3Dè§†è§‰ä¸é¥æ„Ÿäº¤å‰é¢†åŸŸçš„ä»£è¡¨æ€§å·¥ä½œ) |

### å…³é”®è¯
- **3D Segmentation** - ä¸‰ç»´åˆ†å‰²
- **Graph Cut** - å›¾å‰²ç®—æ³•
- **Multiclass** - å¤šç±»åˆ«
- **LiDAR** - æ¿€å…‰é›·è¾¾
- **Tree Segmentation** - æ ‘æœ¨åˆ†å‰²
- **Forest Inventory** - æ£®æ—èµ„æºæ¸…æŸ¥

---

## ğŸ¯ ç ”ç©¶èƒŒæ™¯ä¸åŠ¨æœº

### 1.1 é—®é¢˜å®šä¹‰

**æ ¸å¿ƒé—®é¢˜**: å¦‚ä½•ä»å¤§è§„æ¨¡3Dç‚¹äº‘æ•°æ®ä¸­ç²¾ç¡®åˆ†å‰²å•æ ªæ ‘æœ¨ï¼Ÿ

**ç ”ç©¶æŒ‘æˆ˜**:
```
æŒ‘æˆ˜1: æ ‘æœ¨å½¢æ€å¤æ‚æ€§
â”œâ”€â”€ æ ‘å† å½¢æ€å¤šæ ·ï¼ˆé˜”å¶ã€é’ˆå¶ã€æ··äº¤ï¼‰
â”œâ”€â”€ æ ‘æäº¤é”™é‡å 
â””â”€â”€ æ ‘æœ¨å¯†åº¦ä¸å‡

æŒ‘æˆ˜2: æ•°æ®è·å–é™åˆ¶
â”œâ”€â”€ LiDARç‚¹äº‘ç¨€ç–
â”œâ”€â”€ å¤šå…‰è°±åˆ†è¾¨ç‡æœ‰é™
â””â”€â”€ æ•°æ®é…å‡†å›°éš¾

æŒ‘æˆ˜3: åˆ†å‰²ç²¾åº¦è¦æ±‚
â”œâ”€â”€ éœ€è¦åŒºåˆ†ç›¸é‚»æ ‘æœ¨
â”œâ”€â”€ éœ€è¦è¯†åˆ«æ ‘å¹²ä¸æ ‘å† 
â””â”€â”€ éœ€è¦å¤„ç†é®æŒ¡æƒ…å†µ
```

### 1.2 åº”ç”¨ä»·å€¼

| åº”ç”¨é¢†åŸŸ | å…·ä½“ç”¨é€” |
|:---|:---|
| **æ£®æ—èµ„æºè°ƒæŸ¥** | æ ‘æœ¨è®¡æ•°ã€è“„ç§¯é‡ä¼°ç®—ã€ç”Ÿé•¿ç›‘æµ‹ |
| **ç”Ÿæ€å­¦ç ”ç©¶** | ç¢³æ±‡ä¼°ç®—ã€ç”Ÿç‰©å¤šæ ·æ€§åˆ†æã€ç—…è™«å®³ç›‘æµ‹ |
| **åŸå¸‚ç»¿åŒ–** | è¡Œé“æ ‘ç®¡ç†ã€ç»¿åœ°è§„åˆ’ã€æ ‘æœ¨å¥åº·è¯„ä¼° |
| **æ—ä¸šç®¡ç†** | é‡‡ä¼è§„åˆ’ã€æ£®æ—é˜²ç«ã€å¯æŒç»­ç»è¥ |

### 1.3 ç°æœ‰æ–¹æ³•å±€é™

**ä¼ ç»Ÿæ–¹æ³•**:
- âœ— åŸºäºè§„åˆ™çš„æ–¹æ³•ï¼šéš¾ä»¥é€‚åº”å¤æ‚åœºæ™¯
- âœ— 2Då›¾åƒæ–¹æ³•ï¼šæ— æ³•å‡†ç¡®è·å–3Dä¿¡æ¯
- âœ— ç®€å•èšç±»ï¼šå®¹æ˜“äº§ç”Ÿè¿‡åˆ†å‰²æˆ–æ¬ åˆ†å‰²

**æœ¬æ–‡åˆ›æ–°**:
- âœ“ æå‡º**çµæ´»å¤šç±»å›¾å‰²**æ¡†æ¶
- âœ“ ç»“åˆ**LiDAR + å¤šå…‰è°±**å¤šæ¨¡æ€æ•°æ®
- âœ“ å¼•å…¥**è‡ªé€‚åº”èƒ½é‡å‡½æ•°**è®¾è®¡
- âœ“ å®ç°**å•æ ªæ ‘æœ¨çº§åˆ«**çš„ç²¾ç¡®åˆ†å‰²

---

## ğŸ”¬ æ ¸å¿ƒæ–¹æ³•è®º

### 2.1 æ•´ä½“æ¡†æ¶

```
è¾“å…¥æ•°æ®
    â”œâ”€â”€ LiDARç‚¹äº‘æ•°æ®
    â”‚   â”œâ”€â”€ 3Dåæ ‡ (x, y, z)
    â”‚   â”œâ”€â”€ å¼ºåº¦ä¿¡æ¯
    â”‚   â””â”€â”€ å›æ³¢æ¬¡æ•°
    â”‚
    â””â”€â”€ å¤šå…‰è°±å›¾åƒ
        â”œâ”€â”€ RGBæ³¢æ®µ
        â”œâ”€â”€ è¿‘çº¢å¤–æ³¢æ®µ
        â””â”€â”€ çº¢è¾¹æ³¢æ®µ
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         é¢„å¤„ç†é˜¶æ®µ                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. ç‚¹äº‘æ»¤æ³¢ä¸å»å™ª                      â”‚
â”‚ 2. åœ°é¢ç‚¹åˆ†ç¦» (CSFæ»¤æ³¢å™¨)              â”‚
â”‚ 3. æ•°æ®é…å‡† (LiDAR-å¤šå…‰è°±)            â”‚
â”‚ 4. ç‰¹å¾æå–                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       Graph Construction               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ èŠ‚ç‚¹: æ¯ä¸ªç‚¹äº‘ä½œä¸ºå›¾èŠ‚ç‚¹              â”‚
â”‚ â€¢ è¾¹: Kè¿‘é‚»è¿æ¥                        â”‚
â”‚ â€¢ è¾¹æƒé‡: ç‰¹å¾ç›¸ä¼¼åº¦ + ç©ºé—´è·ç¦»        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Energy Function Design              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  E(L) = E_data(L) + Î» E_smooth(L)      â”‚
â”‚                                      â”‚
â”‚  â€¢ Data Term: èŠ‚ç‚¹åˆ†é…ä»£ä»·             â”‚
â”‚  â€¢ Smoothness Term: é‚»åŸŸä¸€è‡´æ€§         â”‚
â”‚  â€¢ Î»: å¹³è¡¡å‚æ•°                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Optimization                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Max-Flow / Min-Cutç®—æ³•               â”‚
â”‚ â€¢ Î±-Expansionå¤šæ ‡å·ä¼˜åŒ–                â”‚
â”‚ â€¢ æ”¶æ•›æ¡ä»¶æ£€éªŒ                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Post-processing                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. å°åŒºåŸŸç§»é™¤                          â”‚
â”‚ 2. è¾¹ç•Œå¹³æ»‘                            â”‚
â”‚ 3. æ ‘æœ¨å®ä¾‹åˆ†å‰²                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
       è¾“å‡ºç»“æœ
    â”œâ”€â”€ å•æ ªæ ‘æœ¨åˆ†å‰²
    â”œâ”€â”€ æ ‘å† è¾¹ç•Œ
    â””â”€â”€ æ ‘å¹²ä½ç½®
```

### 2.2 Graph Cut åŸºç¡€ç†è®º

#### 2.2.1 å›¾å‰²é—®é¢˜å®šä¹‰

**åŸºæœ¬æ¦‚å¿µ**:
```
G = (V, E, W)
â”œâ”€â”€ V: é¡¶ç‚¹é›†åˆ (ç‚¹äº‘æ•°æ®ç‚¹)
â”œâ”€â”€ E: è¾¹é›†åˆ (é‚»åŸŸå…³ç³»)
â””â”€â”€ W: è¾¹æƒé‡ (ç›¸ä¼¼åº¦åº¦é‡)

æ ‡æ³¨ L: V â†’ {0, 1, ..., K}
â”œâ”€â”€ K: ç±»åˆ«æ•° (åŒ…æ‹¬èƒŒæ™¯)
â””â”€â”€ ç›®æ ‡: æ‰¾åˆ°æœ€ä¼˜æ ‡æ³¨ L*
```

#### 2.2.2 èƒ½é‡å‡½æ•°è®¾è®¡

**æ ‡å‡†èƒ½é‡å‡½æ•°**:
```
E(L) = E_data(L) + E_smooth(L)

æ•°æ®é¡¹ (Data Term):
E_data(L) = Î£ D_p(L_p)
â”œâ”€â”€ D_p(Â·): èŠ‚ç‚¹påˆ†é…åˆ°å„ç±»åˆ«çš„ä»£ä»·
â”œâ”€â”€ åŸºäºç‰¹å¾ç›¸ä¼¼åº¦
â””â”€â”€ åŸºäºå…ˆéªŒçŸ¥è¯†

å¹³æ»‘é¡¹ (Smoothness Term):
E_smooth(L) = Î£ V_{p,q}(L_p, L_q)
â”œâ”€â”€ V_{p,q}: é‚»åŸŸèŠ‚ç‚¹æ ‡æ³¨ä¸ä¸€è‡´çš„æƒ©ç½š
â”œâ”€â”€ åŸºäºè¾¹ç•Œç‰¹å¾
â””â”€â”€ é¼“åŠ±é‚»åŸŸä¸€è‡´æ€§
```

**æœ¬æ–‡æ”¹è¿›çš„èƒ½é‡å‡½æ•°**:
```
E(L) = E_data(L) + Î»_s E_smooth(L) + Î»_c E_constraint(L)

æ–°å¢çº¦æŸé¡¹:
E_constraint(L) = Î£ C_p(L_p)
â”œâ”€â”€ æ ‘æœ¨å‡ ä½•å…ˆéªŒ
â”œâ”€â”€ é«˜åº¦çº¦æŸ
â””â”€â”€ å½¢çŠ¶æ­£åˆ™åŒ–
```

### 2.3 ç‰¹å¾å·¥ç¨‹

#### 2.3.1 å‡ ä½•ç‰¹å¾

```python
å‡ ä½•ç‰¹å¾æå–:
â”œâ”€â”€ 3Dåæ ‡ç‰¹å¾
â”‚   â”œâ”€â”€ å½’ä¸€åŒ–é«˜åº¦ h' = (h - h_min) / (h_max - h_min)
â”‚   â”œâ”€â”€ ç›¸å¯¹åœ°é¢é«˜åº¦
â”‚   â””â”€â”€ å±€éƒ¨é«˜åº¦å·®
â”‚
â”œâ”€â”€ å±€éƒ¨å‡ ä½•ç‰¹å¾
â”‚   â”œâ”€â”€ æ³•å‘é‡ä¼°è®¡ (PCAåˆ†æ)
â”‚   â”œâ”€â”€ æ›²ç‡è®¡ç®—
â”‚   â”œâ”€â”€ ç‚¹å¯†åº¦
â”‚   â””â”€â”€ é‚»åŸŸç‚¹åˆ†å¸ƒ
â”‚
â””â”€â”€ å…¨å±€å‡ ä½•ç‰¹å¾
    â”œâ”€â”€ åˆ°æ ‘å¹²ä¸­å¿ƒè·ç¦»
    â”œâ”€â”€ å‚ç›´æŠ•å½±
    â””â”€â”€ ç©ºé—´ä½ç½®å…³ç³»
```

#### 2.3.2 å…‰è°±ç‰¹å¾

```python
å…‰è°±ç‰¹å¾æå–:
â”œâ”€â”€ å¤šå…‰è°±æ³¢æ®µ
â”‚   â”œâ”€â”€ RGBæ³¢æ®µ (R, G, B)
â”‚   â”œâ”€â”€ è¿‘çº¢å¤– (NIR)
â”‚   â””â”€â”€ çº¢è¾¹ (Red Edge)
â”‚
â”œâ”€â”€ æ¤è¢«æŒ‡æ•°
â”‚   â”œâ”€â”€ NDVI = (NIR - R) / (NIR + R)
â”‚   â”œâ”€â”€ EVI (å¢å¼ºæ¤è¢«æŒ‡æ•°)
â”‚   â””â”€â”€ LAI (å¶é¢ç§¯æŒ‡æ•°ä¼°è®¡)
â”‚
â””â”€â”€ çº¹ç†ç‰¹å¾
    â”œâ”€â”€ GLCMç‰¹å¾
    â”œâ”€â”€ å±€éƒ¨äºŒå€¼æ¨¡å¼
    â””â”€â”€ å°æ³¢ç³»æ•°
```

#### 2.3.3 LiDARç‰¹å¾

```python
LiDARç‰¹å¾æå–:
â”œâ”€â”€ å¼ºåº¦ç‰¹å¾
â”‚   â”œâ”€â”€ å›æ³¢å¼ºåº¦
â”‚   â”œâ”€â”€ å¼ºåº¦æ¢¯åº¦
â”‚   â””â”€â”€ å¼ºåº¦ç»Ÿè®¡é‡
â”‚
â”œâ”€â”€ å›æ³¢ç‰¹å¾
â”‚   â”œâ”€â”€ é¦–æ¬¡å›æ³¢æ ‡è®°
â”‚   â”œâ”€â”€ æœ«æ¬¡å›æ³¢æ ‡è®°
â”‚   â””â”€â”€ å›æ³¢æ¬¡æ•°
â”‚
â””â”€â”€ ç‚¹äº‘å¯†åº¦ç‰¹å¾
    â”œâ”€â”€ å±€éƒ¨ç‚¹å¯†åº¦
    â”œâ”€â”€ ç‚¹äº‘åˆ†å¸ƒæ–¹å·®
    â””â”€â”€ ç©ºéš™ç‡
```

### 2.4 å¤šç±»Graph Cutç®—æ³•

#### 2.4.1 Î±-Expansionç®—æ³•

**ç®—æ³•æµç¨‹**:
```
åˆå§‹åŒ–: éšæœºæˆ–åŸºäºç®€å•è§„åˆ™åˆå§‹åŒ–æ ‡æ³¨ L^0

è¿­ä»£ä¼˜åŒ–:
For Î± = 1 to K:
    1. å›ºå®šå…¶ä»–æ ‡ç­¾ï¼Œåªè€ƒè™‘å½“å‰æ ‡ç­¾Î±
    2. æ„å»ºäºŒå€¼å›¾å‰²é—®é¢˜:
       - èŠ‚ç‚¹p âˆˆ V
       - æºç‚¹s (æ ‡ç­¾Î±)
       - æ±‡ç‚¹t (ä¿æŒåŸæ ‡ç­¾)
    3. è®¡ç®—è¾¹æƒé‡:
       - t-links: èŠ‚ç‚¹åˆ°æº/æ±‡çš„ä»£ä»·
       - n-links: èŠ‚ç‚¹é—´é‚»åŸŸä»£ä»·
    4. æ±‚è§£æœ€å¤§æµ/æœ€å°å‰²
    5. æ›´æ–°æ ‡æ³¨

æ”¶æ•›æ¡ä»¶:
- èƒ½é‡ä¸å†ä¸‹é™
- æˆ–è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°
```

#### 2.4.2 è‡ªé€‚åº”æƒé‡ç­–ç•¥

**æ•°æ®é¡¹æƒé‡è‡ªé€‚åº”**:
```
w_p(â„“) = -log P(â„“ | f_p)

å…¶ä¸­:
â”œâ”€â”€ â„“: æ ‡ç­¾
â”œâ”€â”€ f_p: èŠ‚ç‚¹pçš„ç‰¹å¾å‘é‡
â””â”€â”€ P(â„“ | f_p): åŸºäºç‰¹å¾çš„ä¼¼ç„¶
    â”œâ”€â”€ é«˜æ–¯æ··åˆæ¨¡å‹ (GMM)
    â”œâ”€â”€ éšæœºæ£®æ— (RF)
    â””â”€â”€ æˆ–å…¶ä»–åˆ†ç±»å™¨
```

**å¹³æ»‘é¡¹æƒé‡è‡ªé€‚åº”**:
```
V_{p,q}(â„“_p, â„“_q) =
    Î» Ã— exp(-||f_p - f_q||Â² / ÏƒÂ²) Ã—
    [â„“_p â‰  â„“_q]

è‡ªé€‚åº”å‚æ•°:
â”œâ”€â”€ Î»: æ ¹æ®å±€éƒ¨ç‰¹å¾å·®è°ƒæ•´
â”œâ”€â”€ Ïƒ: ç‰¹å¾å°ºåº¦å‚æ•°
â””â”€â”€ [â„“_p â‰  â„“_q]: ç¤ºæ€§å‡½æ•°
```

### 2.5 çº¦æŸé¡¹è®¾è®¡

#### 2.5.1 å‡ ä½•çº¦æŸ

```python
# æ ‘æœ¨é«˜åº¦çº¦æŸ
def height_constraint(point_p, label_tree):
    """ç¡®ä¿æ ‘æœ¨åˆ†å‰²åœ¨åˆç†é«˜åº¦èŒƒå›´"""
    if label_tree == BACKGROUND:
        return 0
    else:
        z_p = point_p.height
        z_min = tree_height_range[label_tree].min
        z_max = tree_height_range[label_tree].max

        if z_p < z_min or z_p > z_max:
            return LARGE_PENALTY  # ä¸åˆç†é«˜åº¦
        else:
            return 0

# æ ‘å¹²çº¦æŸ
def trunk_constraint(point_p, label_tree):
    """æ ‘å¹²åŒºåŸŸåº”è¯¥è¿ç»­ä¸”å‚ç›´"""
    if is_trunk_region(point_p):
        # æœŸæœ›å±äºåŒä¸€æ£µæ ‘
        expected_label = dominant_tree_label[neighborhood]
        if label_tree != expected_label:
            return TRUNK_PENALTY
    return 0
```

#### 2.5.2 å…‰è°±çº¦æŸ

```python
# æ¤è¢«æŒ‡æ•°çº¦æŸ
def vegetation_index_constraint(point_p, label_tree):
    """åˆ©ç”¨NDVIçº¦æŸåˆ†å‰²"""
    ndvi = calculate_ndvi(point_p.spectral)

    if label_tree == VEGETATION:
        if ndvi < NDVI_THRESHOLD:
            return NON_VEGETATION_PENALTY
    elif label_tree == BACKGROUND:
        if ndvi > NDVI_THRESHOLD:
            return VEGETATION_PENALTY

    return 0
```

---

## ğŸ§ª å®éªŒè®¾è®¡

### 3.1 æ•°æ®é›†

#### 3.1.1 æ•°æ®æ¥æº

| æ•°æ®ç±»å‹ | ä¼ æ„Ÿå™¨ | å‚æ•° |
|:---|:---|:---|
| **LiDAR** | ALS (æœºè½½æ¿€å…‰é›·è¾¾) | ç‚¹å¯†åº¦: 20-50 pts/mÂ² |
| **å¤šå…‰è°±** | èˆªç©ºå¤šå…‰è°±ç›¸æœº | åˆ†è¾¨ç‡: 0.5m GSD |
| **éªŒè¯æ•°æ®** | äººå·¥å®åœ°æµ‹é‡ | æ ‘æœ¨ä½ç½®ã€æ ‘ç§ã€èƒ¸å¾„ |

#### 3.1.2 æ•°æ®ç‰¹ç‚¹

```
ç ”ç©¶åŒºåŸŸ:
â”œâ”€â”€ æ£®æ—ç±»å‹
â”‚   â”œâ”€â”€ é’ˆå¶æ—
â”‚   â”œâ”€â”€ é˜”å¶æ—
â”‚   â””â”€â”€ æ··äº¤æ—
â”‚
â”œâ”€â”€ åœ°å½¢ç‰¹å¾
â”‚   â”œâ”€â”€ å¹³å¦åœ°åŒº
â”‚   â””â”€â”€ ä¸˜é™µåœ°åŒº
â”‚
â””â”€â”€ æ ‘æœ¨å¯†åº¦
    â”œâ”€â”€ ç¨€ç– ( < 100æ ª/ha)
    â”œâ”€â”€ ä¸­ç­‰ (100-300æ ª/ha)
    â””â”€â”€ å¯†é›† ( > 300æ ª/ha)
```

### 3.2 è¯„ä¼°æŒ‡æ ‡

#### 3.2.1 åˆ†å‰²è´¨é‡æŒ‡æ ‡

```python
# åƒç´ çº§æŒ‡æ ‡
def pixel_level_metrics(pred, gt):
    """è®¡ç®—åƒç´ çº§åˆ†å‰²ç²¾åº¦"""
    TP = np.sum((pred == 1) & (gt == 1))
    TN = np.sum((pred == 0) & (gt == 0))
    FP = np.sum((pred == 1) & (gt == 0))
    FN = np.sum((pred == 0) & (gt == 1))

    metrics = {
        'Accuracy': (TP + TN) / (TP + TN + FP + FN),
        'Precision': TP / (TP + FP) if (TP + FP) > 0 else 0,
        'Recall': TP / (TP + FN) if (TP + FN) > 0 else 0,
        'F1-Score': 2 * TP / (2 * TP + FP + FN),
        'IoU': TP / (TP + FP + FN)
    }

    return metrics

# å®ä¾‹çº§æŒ‡æ ‡
def instance_level_metrics(pred_trees, gt_trees):
    """è®¡ç®—å•æ ªæ ‘æœ¨æ£€æµ‹ç²¾åº¦"""
    # åŒ¹é…é¢„æµ‹æ ‘æœ¨ä¸çœŸå®æ ‘æœ¨
    matched = match_trees(pred_trees, gt_trees, IoU_threshold=0.5)

    metrics = {
        'Detection Rate': len(matched) / len(gt_trees),
        'False Positive Rate': (len(pred_trees) - len(matched)) / len(gt_trees),
        'Mean IoU': np.mean([m.IoU for m in matched])
    }

    return metrics
```

#### 3.2.2 åº”ç”¨è¯„ä¼°æŒ‡æ ‡

```python
# æ—ä¸šåº”ç”¨æŒ‡æ ‡
def forestry_metrics(predictions, ground_truth):
    """æ—ä¸šåº”ç”¨ç‰¹å®šè¯„ä¼°"""
    metrics = {
        # æ ‘æœ¨è®¡æ•°è¯¯å·®
        'Count Error': (pred_count - gt_count) / gt_count,

        # æ ‘å† é¢ç§¯è¯¯å·®
        'Canopy Area Error': mean_absolute_percentage_error(
            pred_canopy_area, gt_canopy_area
        ),

        # æ ‘é«˜è¯¯å·®
        'Height Error': mean_absolute_error(
            pred_tree_height, gt_tree_height
        ),

        # èƒ¸å¾„ä¼°è®¡è¯¯å·®
        'DBH Error': mean_absolute_error(
            pred_dbh, gt_dbh
        )
    }

    return metrics
```

### 3.3 å¯¹æ¯”æ–¹æ³•

| æ–¹æ³• | ç±»å‹ | ç‰¹ç‚¹ |
|:---|:---|:---|
| **Watershed** | ä¼ ç»Ÿå›¾åƒåˆ†å‰² | åŸºäºåˆ†æ°´å²­ç®—æ³•ï¼Œæ˜“è¿‡åˆ†å‰² |
| **Mean Shift** | èšç±»æ–¹æ³• | å¯†åº¦é©±åŠ¨ï¼Œå‚æ•°æ•æ„Ÿ |
| **Region Growing** | åŒºåŸŸç”Ÿé•¿ | ä¾èµ–ç§å­ç‚¹é€‰æ‹© |
| **PointNet++** | æ·±åº¦å­¦ä¹  | éœ€è¦å¤§é‡æ ‡æ³¨æ•°æ® |
| **æœ¬æ–‡æ–¹æ³•** | Graph Cut | èƒ½é‡ä¼˜åŒ–ï¼Œç»“åˆå…ˆéªŒ |

### 3.4 æ¶ˆèå®éªŒ

```python
æ¶ˆèå®éªŒè®¾è®¡:
â”œâ”€â”€ ç‰¹å¾ç»„åˆ
â”‚   â”œâ”€â”€ åªæœ‰å‡ ä½•ç‰¹å¾
â”‚   â”œâ”€â”€ å‡ ä½• + å…‰è°±
â”‚   â”œâ”€â”€ å‡ ä½• + LiDAR
â”‚   â””â”€â”€ å…¨éƒ¨ç‰¹å¾
â”‚
â”œâ”€â”€ èƒ½é‡å‡½æ•°ç»„ä»¶
â”‚   â”œâ”€â”€ åªæœ‰æ•°æ®é¡¹
â”‚   â”œâ”€â”€ æ•°æ® + å¹³æ»‘é¡¹
â”‚   â””â”€â”€ å…¨éƒ¨ï¼ˆå«çº¦æŸï¼‰
â”‚
â””â”€â”€ ä¼˜åŒ–ç®—æ³•
    â”œâ”€â”€ æ ‡å‡†Graph Cut
    â”œâ”€â”€ Î±-Expansion
    â””â”€â”€ Î±-Î²-Swap
```

---

## ğŸ“Š å®éªŒç»“æœ

### 4.1 ä¸»å®éªŒç»“æœ

#### 4.1.1 åˆ†å‰²ç²¾åº¦

| æ–¹æ³• | Accuracy | Precision | Recall | F1-Score | IoU |
|:---|:---:|:---:|:---:|:---:|:---:|
| Watershed | 0.82 | 0.76 | 0.71 | 0.73 | 0.61 |
| Mean Shift | 0.85 | 0.79 | 0.74 | 0.76 | 0.64 |
| Region Growing | 0.87 | 0.81 | 0.78 | 0.79 | 0.68 |
| PointNet++ | 0.91 | 0.86 | 0.83 | 0.84 | 0.75 |
| **æœ¬æ–‡æ–¹æ³•** | **0.94** | **0.89** | **0.87** | **0.88** | **0.81** |

**å…³é”®å‘ç°**:
- âœ“ æœ¬æ–‡æ–¹æ³•åœ¨æ‰€æœ‰æŒ‡æ ‡ä¸Šæœ€ä¼˜
- âœ“ ç›¸æ¯”ä¼ ç»Ÿæ–¹æ³•æå‡ 8-15%
- âœ“ ç›¸æ¯”æ·±åº¦å­¦ä¹ æ–¹æ³•ï¼Œæ— éœ€å¤§é‡è®­ç»ƒæ•°æ®
- âœ“ åœ¨å¯†é›†æ—åŒºä¼˜åŠ¿æ›´æ˜æ˜¾

#### 4.1.2 å®ä¾‹çº§æ£€æµ‹

| æ ‘æœ¨å¯†åº¦ | æ£€æµ‹ç‡ | è¯¯æ£€ç‡ | å¹³å‡IoU |
|:---|:---:|:---:|:---:|
| ç¨€ç– | 96% | 3% | 0.87 |
| ä¸­ç­‰ | 92% | 5% | 0.83 |
| å¯†é›† | 88% | 8% | 0.78 |

### 4.2 æ¶ˆèå®éªŒç»“æœ

#### 4.2.1 ç‰¹å¾è´¡çŒ®

```python
ç‰¹å¾é‡è¦æ€§åˆ†æ:
â”œâ”€â”€ åŸºçº¿ (åªæœ‰3Dåæ ‡)     â†’ F1: 0.76
â”œâ”€â”€ + æ³•å‘é‡ & æ›²ç‡       â†’ F1: 0.79 (+3%)
â”œâ”€â”€ + å…‰è°±ç‰¹å¾ (NDVI)    â†’ F1: 0.83 (+4%)
â”œâ”€â”€ + LiDARå¼ºåº¦          â†’ F1: 0.85 (+2%)
â””â”€â”€ + çº¦æŸé¡¹             â†’ F1: 0.88 (+3%)

ç»“è®º: å¤šæ¨¡æ€ç‰¹å¾æ˜¾è‘—æå‡åˆ†å‰²ç²¾åº¦
```

#### 4.2.2 èƒ½é‡å‡½æ•°ç»„ä»¶

```
èƒ½é‡é¡¹è´¡çŒ®:
â”œâ”€â”€ æ•°æ®é¡¹              â†’ F1: 0.72 (åŸºçº¿)
â”œâ”€â”€ + å¹³æ»‘é¡¹ (Î»=0.5)    â†’ F1: 0.81 (+9%)
â”œâ”€â”€ + å¹³æ»‘é¡¹ (Î»=1.0)    â†’ F1: 0.85 (+4%)
â””â”€â”€ + çº¦æŸé¡¹            â†’ F1: 0.88 (+3%)

ç»“è®º:
1. å¹³æ»‘é¡¹å¯¹ç»“æœå½±å“æœ€å¤§
2. çº¦æŸé¡¹è¿›ä¸€æ­¥ä¼˜åŒ–è¾¹ç•Œ
3. Î»=1.0ä¸ºæœ€ä¼˜å¹³è¡¡å‚æ•°
```

### 4.3 å¯è§†åŒ–ç»“æœ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          å¯è§†åŒ–ç»“æœç¤ºä¾‹                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                         â”‚
â”‚  [è¾“å…¥LiDAR] â†’ [åˆ†å‰²ç»“æœ] â†’ [3Dé‡å»º]    â”‚
â”‚                                         â”‚
â”‚  â€¢ ä¸åŒé¢œè‰²è¡¨ç¤ºä¸åŒæ ‘æœ¨                   â”‚
â”‚  â€¢ æ¸…æ™°çš„æ ‘å† è¾¹ç•Œ                         â”‚
â”‚  â€¢ å‡†ç¡®çš„æ ‘å¹²ä½ç½®                         â”‚
â”‚  â€¢ ç›¸é‚»æ ‘æœ¨æ­£ç¡®åˆ†ç¦»                       â”‚
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.4 è®¡ç®—æ•ˆç‡

| æ•°æ®è§„æ¨¡ | ç‚¹äº‘æ•°é‡ | é¢„å¤„ç† | Graph Cut | åå¤„ç† | æ€»æ—¶é—´ |
|:---|:---:|:---:|:---:|:---:|:---:|
| å°è§„æ¨¡ | 10ä¸‡ | 2s | 8s | 1s | 11s |
| ä¸­è§„æ¨¡ | 50ä¸‡ | 8s | 35s | 3s | 46s |
| å¤§è§„æ¨¡ | 200ä¸‡ | 25s | 120s | 8s | 153s |

**ç»“è®º**: å¯¹äºå…¸å‹çš„æ£®æ—åŒºå—(50ä¸‡ç‚¹)ï¼Œå¤„ç†æ—¶é—´<1åˆ†é’Ÿï¼Œæ»¡è¶³å®ç”¨éœ€æ±‚

---

## ğŸ’¡ æ ¸å¿ƒåˆ›æ–°ç‚¹

### 5.1 æ–¹æ³•åˆ›æ–°

#### åˆ›æ–°ç‚¹1: çµæ´»å¤šç±»Graph Cutæ¡†æ¶

**ä¼ ç»ŸGraph Cuté™åˆ¶**:
```
ä¼ ç»Ÿæ–¹æ³•:
â”œâ”€â”€ ä¸»è¦å¤„ç†äºŒå€¼åˆ†å‰² (å‰æ™¯/èƒŒæ™¯)
â”œâ”€â”€ å¤šç±»åˆ†å‰²éœ€è¦å¤šæ¬¡äºŒå€¼åŒ–
â””â”€â”€ ç±»åˆ«é—´ç¼ºä¹å…¨å±€ä¸€è‡´æ€§
```

**æœ¬æ–‡æ”¹è¿›**:
```
çµæ´»å¤šç±»æ¡†æ¶:
â”œâ”€â”€ ç›´æ¥å¤„ç†Kç±»é—®é¢˜ (K > 2)
â”œâ”€â”€ Î±-Expansionä¿è¯å…¨å±€æœ€ä¼˜
â”œâ”€â”€ ç±»åˆ«é—´å¹³è¡¡ä¼˜åŒ–
â””â”€â”€ è‡ªé€‚åº”èƒ½é‡å‡½æ•°
```

#### åˆ›æ–°ç‚¹2: å¤šæ¨¡æ€ç‰¹å¾èåˆ

```python
å¤šæ¨¡æ€èåˆç­–ç•¥:
â”œâ”€â”€ æ—©æœŸèåˆ (Early Fusion)
â”‚   â””â”€â”€ ç‰¹å¾çº§è”: [å‡ ä½• | å…‰è°± | LiDAR]
â”‚
â”œâ”€â”€ ä¸­æœŸèåˆ (Intermediate Fusion)
â”‚   â”œâ”€â”€ åˆ†æ”¯ç½‘ç»œåˆ†åˆ«æå–
â”‚   â””â”€â”€ ç‰¹å¾å±‚æ³¨æ„åŠ›èåˆ
â”‚
â””â”€â”€ æœ¬æ–‡æ–¹æ³•: è‡ªé€‚åº”æƒé‡èåˆ
    â”œâ”€â”€ å­¦ä¹ å„ç±»ç‰¹å¾é‡è¦æ€§
    â”œâ”€â”€ åŠ¨æ€è°ƒæ•´èåˆæƒé‡
    â””â”€â”€ åœºæ™¯è‡ªé€‚åº”
```

#### åˆ›æ–°ç‚¹3: é¢†åŸŸçŸ¥è¯†çº¦æŸ

```python
æ—ä¸šçŸ¥è¯†èå…¥:
â”œâ”€â”€ å‡ ä½•çº¦æŸ
â”‚   â”œâ”€â”€ æ ‘æœ¨é«˜åº¦èŒƒå›´
â”‚   â”œâ”€â”€ æ ‘å† å½¢çŠ¶å…ˆéªŒ
â”‚   â””â”€â”€ å‚ç›´è¿ç»­æ€§
â”‚
â”œâ”€â”€ ç”Ÿç†çº¦æŸ
â”‚   â”œâ”€â”€ NDVIæ¤è¢«æŒ‡æ•°
â”‚   â”œâ”€â”€ å…‰è°±åå°„ç‰¹æ€§
â”‚   â””â”€â”€ å­£èŠ‚å˜åŒ–è§„å¾‹
â”‚
â””â”€â”€ æ—å­¦çº¦æŸ
    â”œâ”€â”€ æ ‘æœ¨é—´è·
    â”œâ”€â”€ æ—åˆ†å¯†åº¦
    â””â”€â”€ æ ‘ç§åˆ†å¸ƒæ¨¡å¼
```

### 5.2 åº”ç”¨åˆ›æ–°

#### åº”ç”¨åˆ›æ–°1: å•æ ªæ ‘æœ¨çº§åˆ«åˆ†å‰²

**æ„ä¹‰**:
- ä¼ ç»Ÿæ–¹æ³•: æ—åˆ†çº§åˆ« (æ•´ä¸ªæ—åŒº)
- æœ¬æ–‡æ–¹æ³•: å•æœ¨çº§åˆ« (æ¯æ£µæ ‘)
- åº”ç”¨ä»·å€¼: ç²¾å‡†æ—ä¸šç®¡ç†

#### åº”ç”¨åˆ›æ–°2: å¤§è§„æ¨¡æ•°æ®å¤„ç†

**ç‰¹ç‚¹**:
- å¤„ç†>ç™¾ä¸‡ç‚¹äº‘è§„æ¨¡
- è®¡ç®—æ•ˆç‡å®ç”¨åŒ–
- é€‚åˆä¸šåŠ¡éƒ¨ç½²

---

## ğŸ”— ä¸å…¶ä»–å·¥ä½œçš„å…³ç³»

### 6.1 Xiaohao Caiç ”ç©¶è°±ç³»ä¸­çš„ä½ç½®

```
ç ”ç©¶è„‰ç»œ:
[2-15] 3Dæ ‘æœ¨åˆ†å‰² (2019) â† æœ¬ç¯‡
    â”œâ”€â”€ ç»§æ‰¿: [2-16] 3Dæ ‘æœ¨æç»˜ (2018)
    â”‚   â””â”€â”€ ä»2Dåˆ°3Dçš„æ‹“å±•
    â”‚
    â”œâ”€â”€ å‘å±•: [2-14] 3Dç”Ÿé•¿è½¨è¿¹ (2020)
    â”‚   â””â”€â”€ ä»é™æ€åˆ†å‰²åˆ°åŠ¨æ€é‡å»º
    â”‚
    â””â”€â”€ èåˆ: [2-12] ç‚¹äº‘ç¥ç»è¡¨ç¤º (2022)
        â””â”€â”€ ä»ä¼ ç»Ÿæ–¹æ³•åˆ°ç¥ç»ç½‘ç»œ
```

### 6.2 æ–¹æ³•è®ºæ¼”è¿›

```
2010-2013: å˜åˆ†æ³•åŸºç¡€
    â†“
2013-2016: å›¾åƒåˆ†å‰²åº”ç”¨
    â†“
2016-2019: 3Dè§†è§‰æ¢ç´¢ â† [2-15] åœ¨æ­¤é˜¶æ®µ
    â”œâ”€â”€ ä»2Då›¾åƒ â†’ 3Dç‚¹äº‘
    â”œâ”€â”€ ä»é€šç”¨åˆ†å‰² â†’ ä¸“ä¸šåº”ç”¨
    â””â”€â”€ ä»ä¼ ç»Ÿæ–¹æ³• â†’ æ·±åº¦å­¦ä¹ 
    â†“
2019-2022: æ–¹æ³•èåˆåˆ›æ–°
```

### 6.3 ä¸å…¶ä»–æ ¸å¿ƒè®ºæ–‡çš„å…³ç³»

| è®ºæ–‡ | ä¸æœ¬ç¯‡å…³ç³» |
|:---|:---|
| [1-04] å˜åˆ†æ³•åŸºç¡€ | èƒ½é‡å‡½æ•°è®¾è®¡çš„ç†è®ºåŸºç¡€ |
| [2-01] å‡¸ä¼˜åŒ–åˆ†å‰² | å›¾å‰²ä¼˜åŒ–çš„æ•°å­¦åŸºç¡€ |
| [2-12] ç‚¹äº‘ç¥ç»è¡¨ç¤º | æœ¬ç¯‡çš„ç¥ç»ç½‘ç»œæ¼”è¿›ç‰ˆ |
| [4-10] å¤šä¼ æ„Ÿå™¨æ ‘ç§åˆ†ç±» | åŒæœŸé¥æ„Ÿåº”ç”¨å·¥ä½œ |

---

## ğŸ“– å¯å¤ç”¨ç»„ä»¶åº“

### 7.1 Graph Cutæ ¸å¿ƒä»£ç æ¨¡æ¿

```python
import numpy as np
import maxflow  # PyMaxflowåº“

class MultiClassGraphCut:
    """
    å¤šç±»Graph Cutåˆ†å‰²å™¨
    åŸºäºÎ±-Expansionç®—æ³•
    """

    def __init__(self, num_classes, lambda_smooth=1.0):
        """
        å‚æ•°:
            num_classes: ç±»åˆ«æ•° (åŒ…æ‹¬èƒŒæ™¯)
            lambda_smooth: å¹³æ»‘é¡¹æƒé‡
        """
        self.num_classes = num_classes
        self.lambda_smooth = lambda_smooth

    def build_graph(self, points, features, k_neighbors=10):
        """
        æ„å»ºå›¾ç»“æ„

        å‚æ•°:
            points: (N, 3) ç‚¹äº‘åæ ‡
            features: (N, D) ç‰¹å¾å‘é‡
            k_neighbors: Kè¿‘é‚»æ•°

        è¿”å›:
            graph: å›¾ç»“æ„
            edges: è¾¹åˆ—è¡¨
        """
        N = points.shape[0]

        # ä½¿ç”¨KDæ ‘æŸ¥æ‰¾Kè¿‘é‚»
        from sklearn.neighbors import NearestNeighbors
        nbrs = NearestNeighbors(n_neighbors=k_neighbors).fit(points)
        distances, indices = nbrs.kneighbors(points)

        # æ„å»ºè¾¹åˆ—è¡¨
        edges = []
        edge_weights = []

        for i in range(N):
            for j, dist in zip(indices[i], distances[i]):
                if i != j:  # æ’é™¤è‡ªå·±
                    edges.append((i, j))
                    # è®¡ç®—è¾¹æƒé‡: ç‰¹å¾ç›¸ä¼¼åº¦
                    feat_dist = np.linalg.norm(features[i] - features[j])
                    weight = np.exp(-feat_dist**2 / (2 * 0.1**2))
                    edge_weights.append(weight)

        return edges, edge_weights

    def compute_data_cost(self, features, labels_prior=None):
        """
        è®¡ç®—æ•°æ®é¡¹ä»£ä»·

        å‚æ•°:
            features: (N, D) ç‰¹å¾å‘é‡
            labels_prior: å…ˆéªŒæ ‡æ³¨ (å¯é€‰)

        è¿”å›:
            data_cost: (N, K) æ¯ä¸ªç‚¹åˆ†é…åˆ°æ¯ä¸ªç±»åˆ«çš„ä»£ä»·
        """
        N = features.shape[0]
        K = self.num_classes

        data_cost = np.zeros((N, K))

        if labels_prior is not None:
            # åŸºäºå…ˆéªŒæ ‡æ³¨è®­ç»ƒç®€å•åˆ†ç±»å™¨
            from sklearn.ensemble import RandomForestClassifier
            clf = RandomForestClassifier(n_estimators=50)
            clf.fit(features[labels_prior >= 0],
                   labels_prior[labels_prior >= 0])

            # é¢„æµ‹æ¦‚ç‡ä½œä¸ºè´Ÿå¯¹æ•°ä¼¼ç„¶
            probs = clf.predict_proba(features)
            for k in range(K):
                # ä»£ä»· = -log(æ¦‚ç‡)
                data_cost[:, k] = -np.log(probs[:, k] + 1e-10)
        else:
            # ä½¿ç”¨ç®€å•çš„ç‰¹å¾è·ç¦»
            for k in range(K):
                # å‡è®¾æ¯ç±»çš„ç‰¹å¾ä¸­å¿ƒå·²çŸ¥
                # ä»£ä»· = ç‰¹å¾åˆ°ç±»ä¸­å¿ƒçš„è·ç¦»
                pass

        return data_cost

    def alpha_expansion(self, edges, edge_weights, data_cost, current_labels, alpha):
        """
        Î±-Expansionæ­¥éª¤: å°†éƒ¨åˆ†èŠ‚ç‚¹æ ‡ç­¾æ›¿æ¢ä¸ºÎ±

        å‚æ•°:
            edges: è¾¹åˆ—è¡¨
            edge_weights: è¾¹æƒé‡
            data_cost: æ•°æ®é¡¹ä»£ä»·
            current_labels: å½“å‰æ ‡æ³¨
            alpha: å½“å‰è€ƒè™‘çš„æ ‡ç­¾

        è¿”å›:
            new_labels: æ›´æ–°åçš„æ ‡æ³¨
        """
        N = len(current_labels)

        # åˆ›å»ºå›¾
        g = maxflow.Graph[float]()
        nodeids = g.add_grid_nodes((N,))

        # æ·»åŠ æºç‚¹å’Œæ±‡ç‚¹
        g.add_grid_tedges(nodeids, np.inf, np.inf)

        # æ·»åŠ t-links: èŠ‚ç‚¹åˆ°æº/æ±‡çš„è¾¹
        for i in range(N):
            # å¦‚æœå½“å‰æ ‡ç­¾æ˜¯Î±ï¼Œä¿æŒÎ±çš„ä»£ä»·ä¸º0
            if current_labels[i] == alpha:
                g.add_tedge(i, 0, np.inf)
            else:
                # ä»å½“å‰æ ‡ç­¾åˆ‡æ¢åˆ°Î±çš„ä»£ä»·
                cost_switch = data_cost[i, alpha] - data_cost[i, current_labels[i]]
                g.add_tedge(i, max(0, cost_switch), max(0, -cost_switch))

        # æ·»åŠ n-links: èŠ‚ç‚¹é—´çš„è¾¹
        for (i, j), weight in zip(edges, edge_weights):
            # å¹³æ»‘é¡¹ä»£ä»·
            if current_labels[i] != current_labels[j]:
                # å¦‚æœæ ‡ç­¾ä¸åŒï¼Œå¯èƒ½äº§ç”Ÿä»£ä»·
                smooth_cost = self.lambda_smooth * weight
                g.add_edge(i, j, smooth_cost, smooth_cost)

        # æœ€å¤§æµ/æœ€å°å‰²
        g.maxflow()

        # æ ¹æ®å‰²ç»“æœæ›´æ–°æ ‡ç­¾
        new_labels = current_labels.copy()
        for i in range(N):
            if g.get_segment(i) == 0:
                new_labels[i] = alpha

        return new_labels

    def segment(self, points, features, labels_prior=None, max_iter=10):
        """
        æ‰§è¡Œå¤šç±»åˆ†å‰²

        å‚æ•°:
            points: (N, 3) ç‚¹äº‘åæ ‡
            features: (N, D) ç‰¹å¾å‘é‡
            labels_prior: å…ˆéªŒæ ‡æ³¨ (å¯é€‰)
            max_iter: æœ€å¤§è¿­ä»£æ¬¡æ•°

        è¿”å›:
            labels: (N,) åˆ†å‰²æ ‡ç­¾
        """
        N = points.shape[0]

        # 1. æ„å»ºå›¾
        edges, edge_weights = self.build_graph(points, features)

        # 2. è®¡ç®—æ•°æ®ä»£ä»·
        data_cost = self.compute_data_cost(features, labels_prior)

        # 3. åˆå§‹åŒ–æ ‡æ³¨
        if labels_prior is not None:
            labels = labels_prior.copy()
        else:
            # åŸºäºç‰¹å¾èšç±»åˆå§‹åŒ–
            from sklearn.cluster import KMeans
            kmeans = KMeans(n_clusters=self.num_classes)
            labels = kmeans.fit_predict(features)

        # 4. Î±-Expansionè¿­ä»£
        for iteration in range(max_iter):
            prev_labels = labels.copy()
            prev_energy = self.compute_energy(
                labels, edges, edge_weights, data_cost
            )

            # å°è¯•æ¯ä¸ªÎ±å€¼
            for alpha in range(self.num_classes):
                labels = self.alpha_expansion(
                    edges, edge_weights, data_cost, labels, alpha
                )

            # æ£€æŸ¥æ”¶æ•›
            current_energy = self.compute_energy(
                labels, edges, edge_weights, data_cost
            )

            if abs(current_energy - prev_energy) < 1e-6:
                print(f"Converged at iteration {iteration}")
                break

        return labels

    def compute_energy(self, labels, edges, edge_weights, data_cost):
        """è®¡ç®—å½“å‰æ ‡æ³¨çš„èƒ½é‡"""
        energy = 0.0

        # æ•°æ®é¡¹
        for i, label in enumerate(labels):
            energy += data_cost[i, label]

        # å¹³æ»‘é¡¹
        for (i, j), weight in zip(edges, edge_weights):
            if labels[i] != labels[j]:
                energy += self.lambda_smooth * weight

        return energy


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
    N = 10000
    points = np.random.rand(N, 3) * 100
    features = np.random.rand(N, 10)  # å‡ ä½•+å…‰è°±ç‰¹å¾

    # åˆ›å»ºåˆ†å‰²å™¨
    segmenter = MultiClassGraphCut(num_classes=5, lambda_smooth=1.0)

    # æ‰§è¡Œåˆ†å‰²
    labels = segmenter.segment(points, features)

    print(f"åˆ†å‰²ç»“æœ: {labels.shape}")
    print(f"ç±»åˆ«åˆ†å¸ƒ: {np.bincount(labels)}")
```

### 7.2 ç‰¹å¾æå–æ¨¡æ¿

```python
import numpy as np
from sklearn.neighbors import NearestNeighbors
from sklearn.decomposition import PCA

class TreeFeatureExtractor:
    """æ ‘æœ¨ç‚¹äº‘ç‰¹å¾æå–å™¨"""

    def __init__(self, k_neighbors=20):
        self.k = k_neighbors

    def extract_geometric_features(self, points):
        """
        æå–å‡ ä½•ç‰¹å¾

        å‚æ•°:
            points: (N, 3) ç‚¹äº‘åæ ‡

        è¿”å›:
            features: (N, D_geo) å‡ ä½•ç‰¹å¾
        """
        N = points.shape[0]
        features = []

        # 1. é«˜åº¦ç‰¹å¾
        z_coords = points[:, 2]
        z_min, z_max = z_coords.min(), z_coords.max()
        height_normalized = (z_coords - z_min) / (z_max - z_min + 1e-6)
        features.append(height_normalized.reshape(-1, 1))

        # 2. æ³•å‘é‡å’Œæ›²ç‡ (ä½¿ç”¨PCA)
        nbrs = NearestNeighbors(n_neighbors=self.k).fit(points)
        normals = []
        curvatures = []

        for i in range(N):
            # æ‰¾åˆ°Kè¿‘é‚»
            _, indices = nbrs.kneighbors([points[i]])
            neighborhood = points[indices[0]]

            # PCAåˆ†æ
            pca = PCA(n_components=3)
            pca.fit(neighborhood)

            # æ³•å‘é‡ = æœ€å°ç‰¹å¾å€¼å¯¹åº”çš„ç‰¹å¾å‘é‡
            normal = pca.components_[-1]
            normals.append(normal)

            # æ›²ç‡ = æœ€å°ç‰¹å¾å€¼ / ç‰¹å¾å€¼ä¹‹å’Œ
            curvature = pca.explained_variance_[-1] / pca.explained_variance_.sum()
            curvatures.append(curvature)

        features.append(np.array(normals))  # (N, 3)
        features.append(np.array(curvatures).reshape(-1, 1))  # (N, 1)

        # 3. ç‚¹å¯†åº¦
        densities = []
        for i in range(N):
            # è®¡ç®—å±€éƒ¨ç‚¹å¯†åº¦
            _, indices = nbrs.kneighbors([points[i]])
            density = self.k / (np.max(points[indices[0]], axis=0) -
                                np.min(points[indices[0]], axis=0)).prod()
            densities.append(density)

        features.append(np.array(densities).reshape(-1, 1))  # (N, 1)

        return np.hstack(features)

    def extract_spectral_features(self, spectral_data):
        """
        æå–å…‰è°±ç‰¹å¾

        å‚æ•°:
            spectral_data: (N, C) å…‰è°±æ³¢æ®µ
                - é€šå¸¸åŒ…å«: R, G, B, NIR, Red Edgeç­‰

        è¿”å›:
            features: (N, D_spec) å…‰è°±ç‰¹å¾
        """
        features = []

        # 1. åŸå§‹å…‰è°±æ³¢æ®µ
        features.append(spectral_data)

        # 2. NDVI (å½’ä¸€åŒ–æ¤è¢«æŒ‡æ•°)
        # NDVI = (NIR - R) / (NIR + R)
        if spectral_data.shape[1] >= 4:
            # å‡è®¾ç¬¬3ä¸ªé€šé“æ˜¯NIRï¼Œç¬¬0ä¸ªæ˜¯R
            R = spectral_data[:, 0]
            NIR = spectral_data[:, 3]
            NDVI = (NIR - R) / (NIR + R + 1e-6)
            features.append(NDVI.reshape(-1, 1))

        # 3. EVI (å¢å¼ºæ¤è¢«æŒ‡æ•°)
        # EVI = 2.5 * (NIR - R) / (NIR + 6*R - 7.5*B + 1)
        if spectral_data.shape[1] >= 4:
            B = spectral_data[:, 2]
            EVI = 2.5 * (NIR - R) / (NIR + 6*R - 7.5*B + 1 + 1e-6)
            features.append(EVI.reshape(-1, 1))

        return np.hstack(features)

    def extract_lidar_features(self, lidar_data):
        """
        æå–LiDARç‰¹å¾

        å‚æ•°:
            lidar_data: dict
                - intensity: (N,) å›æ³¢å¼ºåº¦
                - return_num: (N,) å›æ³¢æ¬¡æ•°
                - num_returns: (N,) æ€»å›æ³¢æ¬¡æ•°

        è¿”å›:
            features: (N, D_lidar) LiDARç‰¹å¾
        """
        features = []

        # 1. å¼ºåº¦ç‰¹å¾
        intensity = lidar_data['intensity']
        features.append(intensity.reshape(-1, 1))

        # 2. å›æ³¢æ¯”ç‡
        return_ratio = lidar_data['return_num'] / lidar_data['num_returns']
        features.append(return_ratio.reshape(-1, 1))

        # 3. é¦–æ¬¡å›æ³¢æ ‡è®°
        is_first_return = (lidar_data['return_num'] == 1).astype(float)
        features.append(is_first_return.reshape(-1, 1))

        # 4. æœ«æ¬¡å›æ³¢æ ‡è®°
        is_last_return = (lidar_data['return_num'] == lidar_data['num_returns']).astype(float)
        features.append(is_last_return.reshape(-1, 1))

        return np.hstack(features)

    def extract_all_features(self, points, spectral_data, lidar_data):
        """
        æå–æ‰€æœ‰ç‰¹å¾

        è¿”å›:
            all_features: (N, D_all) å®Œæ•´ç‰¹å¾å‘é‡
        """
        geo_feat = self.extract_geometric_features(points)
        spec_feat = self.extract_spectral_features(spectral_data)
        lidar_feat = self.extract_lidar_features(lidar_data)

        all_features = np.hstack([geo_feat, spec_feat, lidar_feat])

        return all_features
```

### 7.3 è¯„ä¼°æŒ‡æ ‡ä»£ç 

```python
import numpy as np
from sklearn.metrics import confusion_matrix

def compute_iou(pred, gt, num_classes):
    """
    è®¡ç®—IoU (Intersection over Union)

    å‚æ•°:
        pred: (H, W) é¢„æµ‹æ ‡ç­¾
        gt: (H, W) çœŸå®æ ‡ç­¾
        num_classes: ç±»åˆ«æ•°

    è¿”å›:
        iou_per_class: æ¯ä¸ªç±»åˆ«çš„IoU
        miou: å¹³å‡IoU
    """
    iou_per_class = []

    for cls in range(num_classes):
        # True Positives, False Positives, False Negatives
        tp = np.sum((pred == cls) & (gt == cls))
        fp = np.sum((pred == cls) & (gt != cls))
        fn = np.sum((pred != cls) & (gt == cls))

        # IoU = TP / (TP + FP + FN)
        iou = tp / (tp + fp + fn + 1e-6)
        iou_per_class.append(iou)

    miou = np.mean(iou_per_class)

    return iou_per_class, miou

def compute_detection_metrics(pred_instances, gt_instances, iou_threshold=0.5):
    """
    è®¡ç®—å®ä¾‹çº§æ£€æµ‹æŒ‡æ ‡

    å‚æ•°:
        pred_instances: é¢„æµ‹çš„å®ä¾‹åˆ—è¡¨
        gt_instances: çœŸå®çš„å®ä¾‹åˆ—è¡¨
        iou_threshold: IoUé˜ˆå€¼

    è¿”å›:
        metrics: æ£€æµ‹æŒ‡æ ‡å­—å…¸
    """
    # åŒ¹é…é¢„æµ‹å’ŒçœŸå®å®ä¾‹
    matched_pred = []
    matched_gt = []

    for i, pred_inst in enumerate(pred_instances):
        for j, gt_inst in enumerate(gt_instances):
            # è®¡ç®—IoU
            intersection = np.sum((pred_inst > 0) & (gt_inst > 0))
            union = np.sum((pred_inst > 0) | (gt_inst > 0))
            iou = intersection / (union + 1e-6)

            if iou >= iou_threshold:
                matched_pred.append(i)
                matched_gt.append(j)
                break

    # è®¡ç®—æŒ‡æ ‡
    num_pred = len(pred_instances)
    num_gt = len(gt_instances)
    num_matched = len(matched_pred)

    metrics = {
        'Detection Rate': num_matched / num_gt if num_gt > 0 else 0,
        'Precision': num_matched / num_pred if num_pred > 0 else 0,
        'Recall': num_matched / num_gt if num_gt > 0 else 0,
        'F1': 2 * num_matched / (num_pred + num_gt) if (num_pred + num_gt) > 0 else 0,
        'False Positives': num_pred - num_matched,
        'False Negatives': num_gt - num_matched
    }

    return metrics

def compute_forestry_metrics(pred_trees, gt_trees):
    """
    è®¡ç®—æ—ä¸šåº”ç”¨æŒ‡æ ‡

    å‚æ•°:
        pred_trees: é¢„æµ‹æ ‘æœ¨ä¿¡æ¯åˆ—è¡¨
        gt_trees: çœŸå®æ ‘æœ¨ä¿¡æ¯åˆ—è¡¨

    è¿”å›:
        metrics: æ—ä¸šæŒ‡æ ‡å­—å…¸
    """
    # æ ‘æœ¨è®¡æ•°è¯¯å·®
    count_error = (len(pred_trees) - len(gt_trees)) / len(gt_trees)

    # æ ‘å† é¢ç§¯è¯¯å·®
    pred_areas = [tree['canopy_area'] for tree in pred_trees]
    gt_areas = [tree['canopy_area'] for tree in gt_trees]

    # åŒ¹é…æ ‘æœ¨åè®¡ç®—
    # (ç®€åŒ–: å‡è®¾å·²ç»åŒ¹é…)
    area_mae = np.mean([abs(p - g) for p, g in zip(pred_areas, gt_areas)])
    area_mape = np.mean([abs(p - g) / (g + 1e-6) for p, g in zip(pred_areas, gt_areas)])

    # æ ‘é«˜è¯¯å·®
    pred_heights = [tree['height'] for tree in pred_trees]
    gt_heights = [tree['height'] for tree in gt_trees]

    height_mae = np.mean([abs(p - g) for p, g in zip(pred_heights, gt_heights)])
    height_mape = np.mean([abs(p - g) / (g + 1e-6) for p, g in zip(pred_heights, gt_heights)])

    metrics = {
        'Count Error': count_error,
        'Canopy Area MAE': area_mae,
        'Canopy Area MAPE': area_mape,
        'Height MAE': height_mae,
        'Height MAPE': height_mape
    }

    return metrics
```

---

## ğŸ¯ å­¦ä¹ è¦ç‚¹ä¸å¯ç¤º

### 8.1 æ–¹æ³•è®ºå±‚é¢

#### è¦ç‚¹1: å›¾å‰²ç®—æ³•çš„çµæ´»åº”ç”¨

**å…³é”®ç†è§£**:
```
Graph Cuté€‚ç”¨åœºæ™¯:
âœ“ éœ€è¦å…¨å±€æœ€ä¼˜è§£
âœ“ èƒ½é‡å‡½æ•°å¯å®šä¹‰
âœ“ æ•°æ®é‡ä¸­ç­‰è§„æ¨¡
âœ“ æ ‡æ³¨æ•°æ®æœ‰é™

Graph Cutä¼˜åŠ¿:
âœ“ æ•°å­¦ç†è®ºå®Œå¤‡
âœ“ å…¨å±€æœ€ä¼˜ä¿è¯
âœ“ å¯èå…¥å…ˆéªŒçŸ¥è¯†
âœ“ å¯è§£é‡Šæ€§å¼º
```

#### è¦ç‚¹2: å¤šæ¨¡æ€ç‰¹å¾èåˆç­–ç•¥

```
èåˆå±‚æ¬¡é€‰æ‹©:
â”œâ”€â”€ æ—©æœŸèåˆ: ç®€å•ç›´æ¥ï¼Œä½†ç‰¹å¾ç»´åº¦é«˜
â”œâ”€â”€ ä¸­æœŸèåˆ: å¹³è¡¡æ€§èƒ½ä¸å¤æ‚åº¦
â””â”€â”€ æ™šæœŸèåˆ: çµæ´»ï¼Œä½†å¯èƒ½ä¸¢å¤±ä¿¡æ¯

æœ¬æ–‡ç­–ç•¥: ç‰¹å¾å±‚è‡ªé€‚åº”èåˆ
â”œâ”€â”€ æ ¹æ®åœºæ™¯è°ƒæ•´æƒé‡
â”œâ”€â”€ æ ¹æ®æ•°æ®è´¨é‡é€‰æ‹©
â””â”€â”€ æ ¹æ®ä»»åŠ¡ç›®æ ‡ä¼˜åŒ–
```

#### è¦ç‚¹3: é¢†åŸŸçŸ¥è¯†çš„é‡è¦æ€§

```
é¢†åŸŸçŸ¥è¯†èå…¥:
â”œâ”€â”€ æå‡æ–¹æ³•é²æ£’æ€§
â”œâ”€â”€ å‡å°‘å¯¹æ•°æ®ä¾èµ–
â”œâ”€â”€ æé«˜ç»“æœå¯è§£é‡Šæ€§
â””â”€â”€ å¢å¼ºå®é™…åº”ç”¨ä»·å€¼

æ—ä¸šçŸ¥è¯†åº”ç”¨:
â”œâ”€â”€ æ ‘æœ¨ç”Ÿé•¿è§„å¾‹
â”œâ”€â”€ æ—åˆ†ç»“æ„ç‰¹å¾
â”œâ”€â”€ æ¤è¢«å…‰è°±ç‰¹æ€§
â””â”€â”€ åœ°å½¢å½±å“è§„å¾‹
```

### 8.2 åº”ç”¨å±‚é¢

#### åº”ç”¨1: ç²¾å‡†æ—ä¸š

```
ç²¾å‡†æ—ä¸šéœ€æ±‚:
â”œâ”€â”€ å•æœ¨çº§åˆ«ç®¡ç†
â”œâ”€â”€ ç²¾å‡†èµ„æºä¼°ç®—
â”œâ”€â”€ ä¸ªæ€§åŒ–ä¿æŠ¤æ–¹æ¡ˆ
â””â”€â”€ å¯æŒç»­ç»è¥å†³ç­–

æœ¬æ–‡æ–¹æ³•è´¡çŒ®:
â”œâ”€â”€ å®ç°å•æœ¨åˆ†å‰²
â”œâ”€â”€ è‡ªåŠ¨åŒ–å¤„ç†
â”œâ”€â”€ é«˜ç²¾åº¦æµ‹é‡
â””â”€â”€ å¯è§„æ¨¡åŒ–åº”ç”¨
```

#### åº”ç”¨2: ç”Ÿæ€ç›‘æµ‹

```
ç”Ÿæ€ç›‘æµ‹åº”ç”¨:
â”œâ”€â”€ æ£®æ—ç¢³æ±‡ä¼°ç®—
â”œâ”€â”€ ç”Ÿç‰©é‡ç›‘æµ‹
â”œâ”€â”€ æ ‘ç§è¯†åˆ«
â””â”€â”€ ç—…è™«å®³æ£€æµ‹

æŠ€æœ¯è·¯å¾„:
åˆ†å‰² â†’ å•æœ¨æå– â†’ ç‰¹å¾è®¡ç®— â†’ ç”Ÿæ€å‚æ•°åæ¼”
```

### 8.3 ç ”ç©¶èŒƒå¼å¯ç¤º

#### å¯ç¤º1: ä»é€šç”¨åˆ°ä¸“ç”¨

```
ç ”ç©¶è·¯å¾„:
é€šç”¨åˆ†å‰²æ–¹æ³• (å›¾å‰²)
    â†“
é¢†åŸŸçŸ¥è¯†èå…¥ (æ—ä¸šå…ˆéªŒ)
    â†“
ä¸“ä¸šæ–¹æ³•è®¾è®¡ (æœ¬æ–‡)
    â†“
å®é™…åº”ç”¨è½åœ°
```

#### å¯ç¤º2: æ–¹æ³•èåˆåˆ›æ–°

```
åˆ›æ–°æ¥æº:
â”œâ”€â”€ ä¼ ç»Ÿæ–¹æ³• + æ·±åº¦å­¦ä¹ 
â”œâ”€â”€ é€šç”¨ç®—æ³• + é¢†åŸŸçŸ¥è¯†
â”œâ”€â”€ å•ä¸€æ¨¡æ€ + å¤šæ¨¡æ€èåˆ
â””â”€â”€ ç¦»çº¿å¤„ç† + åœ¨çº¿æ›´æ–°
```

---

## ğŸ“ ä¸ªäººæ€è€ƒä¸æ‰©å±•

### 9.1 ä¼˜åŠ¿åˆ†æ

| ä¼˜åŠ¿ | è¯´æ˜ |
|:---|:---|
| **ç†è®ºåŸºç¡€æ‰å®** | åŸºäºèƒ½é‡æœ€å°åŒ–ï¼Œæ•°å­¦å®Œå¤‡ |
| **å®é™…åº”ç”¨å¯¼å‘** | è§£å†³æ—ä¸šå®é™…é—®é¢˜ |
| **å¤šæ¨¡æ€èåˆ** | å……åˆ†åˆ©ç”¨å¤šæºæ•°æ® |
| **å¯è§£é‡Šæ€§å¼º** | æ¯ä¸ªç»„ä»¶éƒ½æœ‰æ˜ç¡®æ„ä¹‰ |
| **æ— éœ€å¤§é‡æ ‡æ³¨** | ä¼ ç»Ÿæ–¹æ³•ä¼˜åŠ¿ |

### 9.2 å±€é™æ€§åˆ†æ

| å±€é™ | æ”¹è¿›æ–¹å‘ |
|:---|:---|
| **å‚æ•°æ•æ„Ÿæ€§** | è‡ªé€‚åº”å‚æ•°å­¦ä¹  |
| **è®¡ç®—å¤æ‚åº¦** | å¹¶è¡ŒåŒ–ã€åˆ†å±‚ä¼˜åŒ– |
| **å¯¹é®æŒ¡æ•æ„Ÿ** | å¼•å…¥æ—¶åºä¿¡æ¯ |
| **æ³›åŒ–èƒ½åŠ›** | è·¨åœºæ™¯è¿ç§»å­¦ä¹  |

### 9.3 ç°ä»£æ‰©å±•æ–¹å‘

#### æ–¹å‘1: æ·±åº¦å­¦ä¹ èåˆ

```
ç»“åˆæ·±åº¦å­¦ä¹ :
â”œâ”€â”€ Graph Cut + CNN
â”‚   â”œâ”€â”€ CNNæå–ç‰¹å¾
â”‚   â””â”€â”€ Graph Cutä¼˜åŒ–è¾¹ç•Œ
â”‚
â”œâ”€â”€ Graph Cut + GNN
â”‚   â”œâ”€â”€ GNNå­¦ä¹ è¾¹æƒé‡
â”‚   â””â”€â”€ ä¿æŒå›¾å‰²ä¼˜åŒ–æ¡†æ¶
â”‚
â””â”€â”€ ç«¯åˆ°ç«¯å¯å¾®åˆ†å›¾å‰²
    â”œâ”€â”€ å­¦ä¹ èƒ½é‡å‡½æ•°
    â””â”€â”€ ä¿æŒä¼˜åŒ–ç†è®º
```

#### æ–¹å‘2: æ—¶åºä¿¡æ¯åˆ©ç”¨

```
åŠ¨æ€åˆ†å‰²:
â”œâ”€â”€ å¤šæ—¶ç›¸æ•°æ®
â”‚   â”œâ”€â”€ ç”Ÿé•¿ç›‘æµ‹
â”‚   â””â”€â”€ å˜åŒ–æ£€æµ‹
â”‚
â”œâ”€â”€ æ—¶åºä¸€è‡´æ€§çº¦æŸ
â”‚   â””â”€â”€ æ—¶é—´å¹³æ»‘
â”‚
â””â”€â”€ ç”Ÿé•¿è½¨è¿¹é¢„æµ‹
    â””â”€â”€ [2-14] å·¥ä½œçš„å»¶ä¼¸
```

#### æ–¹å‘3: è¿å»ºæ£€æµ‹åº”ç”¨

```
è¿ç§»åˆ°è¿å»ºæ£€æµ‹:
â”œâ”€â”€ ç›¸ä¼¼ç‚¹:
â”‚   â”œâ”€â”€ 3Dåˆ†å‰²éœ€æ±‚
â”‚   â”œâ”€â”€ LiDARæ•°æ®
â”‚   â””â”€â”€ é¥æ„Ÿåº”ç”¨
â”‚
â”œâ”€â”€ æ”¹è¿›ç‚¹:
â”‚   â”œâ”€â”€ æ ‘æœ¨ â†’ å»ºç­‘ç‰©
â”‚   â”œâ”€â”€ è‡ªç„¶å½¢æ€ â†’ è§„åˆ™å‡ ä½•
â”‚   â””â”€â”€ æ¤è¢«æŒ‡æ•° â†’ å»ºç­‘ç‰¹å¾
â”‚
â””â”€â”€ å…·ä½“æ–¹æ¡ˆ:
    â”œâ”€â”€ å±‹é¡¶å¹³é¢ç‰¹å¾
    â”œâ”€â”€ å‚ç›´å¢™é¢æ£€æµ‹
    â”œâ”€â”€ è§„åˆ™å‡ ä½•çº¦æŸ
    â””â”€â”€ æ—¶åºå˜åŒ–åˆ†æ
```

### 9.4 ä»£ç å®ç°æ”¹è¿›

```python
# ç°ä»£åŒ–æ”¹è¿›å»ºè®®

# 1. ä½¿ç”¨æ·±åº¦å­¦ä¹ æå–ç‰¹å¾
class DeepFeatureExtractor:
    """æ·±åº¦å­¦ä¹ ç‰¹å¾æå–"""
    def __init__(self, model_path):
        import torch
        self.model = torch.load(model_path)
        self.model.eval()

    def extract(self, points):
        """æå–æ·±åº¦ç‰¹å¾"""
        with torch.no_grad():
            features = self.model(points)
        return features.numpy()

# 2. å¯å¾®åˆ†çš„Graph Cut
class DifferentiableGraphCut:
    """å¯å¾®åˆ†å›¾å‰² (ç”¨äºç«¯åˆ°ç«¯è®­ç»ƒ)"""
    def __init__(self):
        # å¯å­¦ä¹ çš„å‚æ•°
        self.lambda_smooth = nn.Parameter(torch.tensor(1.0))

    def forward(self, features):
        """å‰å‘ä¼ æ’­"""
        # æ„å»ºå›¾
        # è®¡ç®—èƒ½é‡
        # æ±‚è§£å›¾å‰²
        # è¿”å›ç»“æœ
        pass

# 3. å¹¶è¡ŒåŒ–åŠ é€Ÿ
class ParallelGraphCut:
    """å¹¶è¡ŒåŒ–å›¾å‰²"""
    def __init__(self, num_workers=4):
        self.num_workers = num_workers

    def segment_parallel(self, data_chunks):
        """å¹¶è¡Œåˆ†å‰²å¤šä¸ªæ•°æ®å—"""
        from multiprocessing import Pool

        with Pool(self.num_workers) as pool:
            results = pool.map(self._segment_single, data_chunks)

        return results

    def _segment_single(self, data):
        """å•ä¸ªæ•°æ®å—åˆ†å‰²"""
        # æ ‡å‡†å›¾å‰²æµç¨‹
        pass
```

---

## ğŸ”— ç›¸å…³è®ºæ–‡æ¨è

### å‰ç½®é˜…è¯»

1. **[1-04] å˜åˆ†æ³•åŸºç¡€ Mumford-Shahä¸ROF**
   - ç†è§£èƒ½é‡å‡½æ•°ç†è®º

2. **[2-01] å‡¸ä¼˜åŒ–åˆ†å‰² Convex Mumford-Shah**
   - ç†è§£å›¾ä¼˜åŒ–çš„æ•°å­¦åŸºç¡€

### åç»­é˜…è¯»

1. **[2-14] 3Dç”Ÿé•¿è½¨è¿¹é‡å»º**
   - ä»é™æ€åˆ†å‰²åˆ°åŠ¨æ€è½¨è¿¹

2. **[2-12] ç‚¹äº‘ç¥ç»è¡¨ç¤º Neural Varifolds**
   - ä»ä¼ ç»Ÿæ–¹æ³•åˆ°ç¥ç»ç½‘ç»œ

3. **[4-10] å¤šä¼ æ„Ÿå™¨æ ‘ç§åˆ†ç±»**
   - åŒæœŸé¥æ„Ÿåº”ç”¨å·¥ä½œ

---

## âœ… ç²¾è¯»æ£€æŸ¥æ¸…å•

### ç†è§£ç¨‹åº¦è‡ªè¯„

- [ ] **æ–¹æ³•ç†è§£**: èƒ½ç‹¬ç«‹è§£é‡ŠGraph CutåŸç†
- [ ] **å…¬å¼æ¨å¯¼**: èƒ½æ¨å¯¼èƒ½é‡å‡½æ•°å’Œä¼˜åŒ–è¿‡ç¨‹
- [ ] **ä»£ç å®ç°**: èƒ½å®ç°ç®€åŒ–ç‰ˆç®—æ³•
- [ ] **å®éªŒè®¾è®¡**: èƒ½è®¾è®¡ç±»ä¼¼ç ”ç©¶çš„å®éªŒæ–¹æ¡ˆ
- [ ] **åº”ç”¨è¿ç§»**: èƒ½æƒ³åˆ°è‡³å°‘2ä¸ªåº”ç”¨åœºæ™¯

### å…³é”®é—®é¢˜

1. **ä¸ºä»€ä¹ˆé€‰æ‹©Graph Cutè€Œä¸æ˜¯æ·±åº¦å­¦ä¹ ï¼Ÿ**
   - æ ‡æ³¨æ•°æ®æœ‰é™
   - éœ€è¦å¯è§£é‡Šæ€§
   - å¯ä»¥èå…¥é¢†åŸŸçŸ¥è¯†

2. **å¤šæ¨¡æ€ç‰¹å¾å¦‚ä½•èåˆï¼Ÿ**
   - ç‰¹å¾å±‚çº§è”
   - è‡ªé€‚åº”æƒé‡
   - çº¦æŸé¡¹ç»Ÿä¸€

3. **å¦‚ä½•åº”ç”¨åˆ°è‡ªå·±çš„ç ”ç©¶ï¼Ÿ**
   - è¿å»ºæ£€æµ‹: æ ‘æœ¨â†’å»ºç­‘ç‰©
   - ç‰¹å¾è°ƒæ•´: æ¤è¢«æŒ‡æ•°â†’å»ºç­‘ç‰¹å¾
   - çº¦æŸä¿®æ”¹: è‡ªç„¶è§„å¾‹â†’å»ºç­‘è§„èŒƒ

---

## ğŸ“š å‚è€ƒèµ„æº

### ä»£ç åº“

- **PyMaxflow**: Pythonæœ€å¤§æµåº“
- **OpenCV**: å›¾åƒå¤„ç†åŸºç¡€
- **scikit-learn**: ç‰¹å¾æå–å·¥å…·
- **Point Cloud Library**: ç‚¹äº‘å¤„ç†

### ç›¸å…³æ•™ç¨‹

- Graph Cut Tutorial: `https://vision.cs.duke.edu/software/GraphCut/`
- LiDAR Processing Guide: ASPRS LiDAR Data Format
- Forest Inventory: FAO National Forest Inventory

---

**ç²¾è¯»å®Œæˆæ—¶é—´**: 2026å¹´2æœˆ7æ—¥
**é¢„è®¡åç»­è·Ÿè¿›**: [2-14] 3Dç”Ÿé•¿è½¨è¿¹é‡å»º
**åº”ç”¨æ–¹å‘**: è¿å»ºæ£€æµ‹æ–¹æ³•æ”¹è¿›

---

*æœ¬ç²¾è¯»ç¬”è®°åŸºäºXiaohao Caiç­‰äººçš„IEEE TGRS 2019è®ºæ–‡*
*é‡ç‚¹å…³æ³¨: Graph Cutæ–¹æ³•ã€å¤šæ¨¡æ€èåˆã€æ—ä¸šåº”ç”¨*
