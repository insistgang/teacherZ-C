# [4-32] ç¨€ç–è´å¶æ–¯è´¨é‡æ˜ å°„å³°å€¼ç»Ÿè®¡ - ç²¾è¯»ç¬”è®°

> **è®ºæ–‡æ ‡é¢˜**: Sparse Bayesian Mass Mapping: Peak Statistics
> **é˜…è¯»æ—¥æœŸ**: 2026å¹´2æœˆ10æ—¥
> **éš¾åº¦è¯„çº§**: â­â­â­â­ (é«˜)
> **é‡è¦æ€§**: â­â­â­â­ (å®‡å®™å­¦ç»Ÿè®¡)

---

## ğŸ“‹ è®ºæ–‡åŸºæœ¬ä¿¡æ¯

| é¡¹ç›® | å†…å®¹ |
|:---|:---|
| **æ ‡é¢˜** | Sparse Bayesian Mass Mapping: Peak Statistics |
| **ä½œè€…** | Xiaohao Cai ç­‰äºº |
| **æ ¸å¿ƒä¸»é¢˜** | è´¨é‡æ˜ å°„ä¸­çš„å³°å€¼ç»Ÿè®¡æ–¹æ³• |
| **å…³é”®è¯** | Peak Statistics, Peak Counts, Cosmological Probes |
| **åº”ç”¨é¢†åŸŸ** | å®‡å®™å­¦ã€å¤§å°ºåº¦ç»“æ„ã€å¼•åŠ›é€é•œ |

---

## ğŸ¯ ç ”ç©¶èƒŒæ™¯

### å³°å€¼ç»Ÿè®¡çš„å®‡å®™å­¦æ„ä¹‰

**ç§‘å­¦èƒŒæ™¯**:
```
å³°å€¼ (Peaks):
  - è´¨é‡åœºä¸­çš„å±€éƒ¨æå¤§å€¼
  - å¯¹åº”æš—ç‰©è´¨æ™•çš„ä½ç½®
  - å®‡å®™ç»“æ„çš„ç§å­ç‚¹

ä¸ºä»€ä¹ˆé‡è¦:
  - å¯¹å®‡å®™å­¦å‚æ•°æ•æ„Ÿ
  - è¶…è¶ŠäºŒç‚¹ç»Ÿè®¡çš„ä¿¡æ¯
  - æ¢æµ‹éé«˜æ–¯æ€§

ç»Ÿè®¡é‡:
  - å³°å€¼è®¡æ•° (Peak Counts)
  - å³°å€¼é«˜åº¦åˆ†å¸ƒ
  - å³°å€¼-å³°å€¼å…³è”
```

**ä¸ç¨€ç–è´å¶æ–¯çš„ç»“åˆ**:
```
ç¨€ç–é‡å»ºçš„ä¼˜åŠ¿:
  - å‡†ç¡®è¯†åˆ«å³°å€¼ä½ç½®
  - å‡å°‘å™ªå£°ä¼ªå³°
  - æä¾›å³°å€¼æ˜¾è‘—æ€§åº¦é‡

æŒ‘æˆ˜:
  - å³°å€¼ç»Ÿè®¡çš„è´å¶æ–¯å¤„ç†
  - ä¸ç¡®å®šæ€§ä¼ æ’­
  - ä¸å®‡å®™å­¦æ¨¡å‹æ¯”è¾ƒ
```

---

## ğŸ”¬ æ–¹æ³•è®ºè¯¦è§£

### æ•´ä½“æ¡†æ¶

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ç¨€ç–è´å¶æ–¯é‡å»ºç»“æœ                           â”‚
â”‚              p(x | y)                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              å³°å€¼æ£€æµ‹                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  - å±€éƒ¨æå¤§å€¼è¯†åˆ«                                 â”‚    â”‚
â”‚  â”‚  - é«˜åº¦é˜ˆå€¼ç­›é€‰                                   â”‚    â”‚
â”‚  â”‚  - å™ªå£°ä¼ªå³°å»é™¤                                   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              å³°å€¼ç»Ÿè®¡é‡è®¡ç®— â­æ ¸å¿ƒ                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  - å³°å€¼è®¡æ•°åˆ†å¸ƒ                                   â”‚    â”‚
â”‚  â”‚  - æ¡ä»¶è®¡æ•° (ç»™å®šé«˜åº¦/ä¿¡å™ªæ¯”)                    â”‚    â”‚
â”‚  â”‚  - ç©ºé—´åˆ†å¸ƒç‰¹å¾                                   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              å®‡å®™å­¦æ¨æ–­                                   â”‚
â”‚  - ä¸ç†è®ºæ¨¡å‹æ¯”è¾ƒ                                         â”‚
â”‚  - å‚æ•°çº¦æŸ                                               â”‚
â”‚  - æ¨¡å‹é€‰æ‹©                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### æ ¸å¿ƒç»„ä»¶1: å³°å€¼æ£€æµ‹

**å±€éƒ¨æå¤§å€¼æ£€æµ‹**:
```python
class PeakDetector:
    """
    å³°å€¼æ£€æµ‹å™¨

    ä»è´¨é‡å›¾ä¸­è¯†åˆ«å±€éƒ¨æå¤§å€¼
    """
    def __init__(self, min_height=0.0, min_distance=5):
        """
        Args:
            min_height: æœ€å°å³°å€¼é«˜åº¦
            min_distance: å³°å€¼é—´æœ€å°è·ç¦» (åƒç´ )
        """
        self.min_height = min_height
        self.min_distance = min_distance

    def detect(self, map_2d):
        """
        æ£€æµ‹äºŒç»´è´¨é‡å›¾ä¸­çš„å³°å€¼

        Args:
            map_2d: è´¨é‡åˆ†å¸ƒå›¾

        Returns:
            peaks: å³°å€¼åˆ—è¡¨ [{'x', 'y', 'height', 'significance'}, ...]
        """
        from scipy.ndimage import maximum_filter

        # ä½¿ç”¨æœ€å¤§æ»¤æ³¢å™¨æ‰¾å±€éƒ¨æå¤§å€¼
        local_max = maximum_filter(map_2d, size=self.min_distance) == map_2d

        # åº”ç”¨é«˜åº¦é˜ˆå€¼
        above_threshold = map_2d > self.min_height

        # å³°å€¼æ©è†œ
        peak_mask = local_max & above_threshold

        # æå–å³°å€¼åæ ‡å’Œå±æ€§
        peak_coords = np.argwhere(peak_mask)

        peaks = []
        for y, x in peak_coords:
            peak = {
                'x': x,
                'y': y,
                'height': map_2d[y, x],
                'significance': self._compute_significance(map_2d, x, y)
            }
            peaks.append(peak)

        return peaks

    def detect_with_uncertainty(self, map_mean, map_std):
        """
        è€ƒè™‘ä¸ç¡®å®šæ€§çš„å³°å€¼æ£€æµ‹

        ä½¿ç”¨ä¿¡å™ªæ¯”ä½œä¸ºæ£€æµ‹æ ‡å‡†
        """
        snr_map = map_mean / (map_std + 1e-10)

        # åœ¨SNRå›¾ä¸Šæ£€æµ‹å³°å€¼
        peaks = self.detect(snr_map)

        # æ·»åŠ ä¸ç¡®å®šæ€§ä¿¡æ¯
        for peak in peaks:
            x, y = peak['x'], peak['y']
            peak['height_mean'] = map_mean[y, x]
            peak['height_std'] = map_std[y, x]
            peak['snr'] = snr_map[y, x]

        return peaks

    def _compute_significance(self, map_2d, x, y, window=5):
        """
        è®¡ç®—å³°å€¼æ˜¾è‘—æ€§

        ç›¸å¯¹äºå±€éƒ¨èƒŒæ™¯çš„æ˜¾è‘—æ€§
        """
        h, w = map_2d.shape

        # æå–å±€éƒ¨åŒºåŸŸ
        y_min = max(0, y - window)
        y_max = min(h, y + window + 1)
        x_min = max(0, x - window)
        x_max = min(w, x + window + 1)

        local_region = map_2d[y_min:y_max, x_min:x_max]

        # è®¡ç®—èƒŒæ™¯ (æ’é™¤ä¸­å¿ƒ)
        center_mask = np.zeros_like(local_region, dtype=bool)
        cy, cx = y - y_min, x - x_min
        center_mask[cy, cx] = True

        background = local_region[~center_mask]
        bg_mean = np.mean(background)
        bg_std = np.std(background)

        # æ˜¾è‘—æ€§ = (å³°å€¼ - èƒŒæ™¯å‡å€¼) / èƒŒæ™¯æ ‡å‡†å·®
        significance = (map_2d[y, x] - bg_mean) / (bg_std + 1e-10)

        return significance
```

---

### æ ¸å¿ƒç»„ä»¶2: å³°å€¼ç»Ÿè®¡é‡

**å³°å€¼è®¡æ•°ç»Ÿè®¡**:
```python
class PeakStatistics:
    """
    å³°å€¼ç»Ÿè®¡é‡è®¡ç®—

    è®¡ç®—å„ç§å³°å€¼ç»Ÿè®¡é‡ç”¨äºå®‡å®™å­¦åˆ†æ
    """
    def __init__(self, bins=10):
        self.bins = bins

    def peak_count_histogram(self, peaks, height_bins=None):
        """
        å³°å€¼é«˜åº¦åˆ†å¸ƒç›´æ–¹å›¾

        Args:
            peaks: å³°å€¼åˆ—è¡¨
            height_bins: é«˜åº¦åˆ†ç®±è¾¹ç•Œ

        Returns:
            counts: æ¯ä¸ªç®±çš„å³°å€¼æ•°
            bin_edges: ç®±è¾¹ç•Œ
        """
        heights = [p['height'] for p in peaks]

        if height_bins is None:
            height_bins = np.linspace(min(heights), max(heights), self.bins + 1)

        counts, bin_edges = np.histogram(heights, bins=height_bins)

        return counts, bin_edges

    def conditional_peak_counts(self, peaks, snr_thresholds):
        """
        æ¡ä»¶å³°å€¼è®¡æ•°

        ç»™å®šä¿¡å™ªæ¯”é˜ˆå€¼ä»¥ä¸Šçš„å³°å€¼æ•°
        """
        counts = []
        for threshold in snr_thresholds:
            n_peaks = sum(1 for p in peaks if p.get('snr', 0) >= threshold)
            counts.append(n_peaks)

        return np.array(counts)

    def peak_correlation_function(self, peaks, max_distance=100):
        """
        å³°å€¼ä¸¤ç‚¹å…³è”å‡½æ•°

        æè¿°å³°å€¼çš„ç©ºé—´åˆ†å¸ƒ
        """
        coords = np.array([[p['x'], p['y']] for p in peaks])
        n_peaks = len(coords)

        # è®¡ç®—æ‰€æœ‰å³°å€¼å¯¹è·ç¦»
        distances = []
        for i in range(n_peaks):
            for j in range(i + 1, n_peaks):
                d = np.linalg.norm(coords[i] - coords[j])
                distances.append(d)

        distances = np.array(distances)

        # æ„å»ºå…³è”å‡½æ•°
        bins = np.linspace(0, max_distance, 20)
        hist, _ = np.histogram(distances, bins=bins)

        # å½’ä¸€åŒ– (é™¤ä»¥éšæœºåˆ†å¸ƒæœŸæœ›)
        area = np.pi * (bins[1:]**2 - bins[:-1]**2)
        density = n_peaks / (1000 * 1000)  # å‡è®¾åœºå¤§å°
        expected = 0.5 * n_peaks * (n_peaks - 1) * area * density

        correlation = hist / (expected + 1e-10)

        return bins[:-1], correlation

    def void_statistics(self, map_2d, peaks, threshold=0.0):
        """
        ç©ºæ´ç»Ÿè®¡

        è´¨é‡åœºä¸­çš„å±€éƒ¨æå°å€¼
        """
        # åè½¬åœºæ‰¾æå°å€¼
        inverted = -map_2d

        # ä½¿ç”¨PeakDetectoræ‰¾"åå³°å€¼"
        void_detector = PeakDetector(min_height=-threshold)
        voids = void_detector.detect(inverted)

        # è½¬æ¢å›åŸå§‹å€¼
        for void in voids:
            void['depth'] = -void['height']
            del void['height']

        return voids
```

---

### æ ¸å¿ƒç»„ä»¶3: è´å¶æ–¯å³°å€¼ç»Ÿè®¡

**è€ƒè™‘ä¸ç¡®å®šæ€§çš„ç»Ÿè®¡**:
```python
class BayesianPeakStatistics:
    """
    è´å¶æ–¯å³°å€¼ç»Ÿè®¡

    è€ƒè™‘é‡å»ºä¸ç¡®å®šæ€§çš„å³°å€¼ç»Ÿè®¡
    """
    def __init__(self, posterior_samples):
        """
        Args:
            posterior_samples: åéªŒæ ·æœ¬ (n_samples, height, width)
        """
        self.samples = posterior_samples
        self.n_samples = posterior_samples.shape[0]

    def sample_peak_counts(self, height_threshold=0.0):
        """
        é‡‡æ ·å³°å€¼è®¡æ•°çš„åéªŒåˆ†å¸ƒ

        å¯¹æ¯ä¸ªåéªŒæ ·æœ¬è®¡ç®—å³°å€¼æ•°
        """
        peak_counts = []
        detector = PeakDetector(min_height=height_threshold)

        for i in range(self.n_samples):
            sample = self.samples[i]
            peaks = detector.detect(sample)
            peak_counts.append(len(peaks))

        return np.array(peak_counts)

    def peak_probability_map(self, height_threshold=0.0):
        """
        å³°å€¼å­˜åœ¨æ¦‚ç‡å›¾

        æ¯ä¸ªåƒç´ æ˜¯å³°å€¼çš„æ¦‚ç‡
        """
        peak_prob = np.zeros_like(self.samples[0])

        detector = PeakDetector(min_height=height_threshold)

        for i in range(self.n_samples):
            peaks = detector.detect(self.samples[i])
            for peak in peaks:
                peak_prob[int(peak['y']), int(peak['x'])] += 1

        peak_prob /= self.n_samples

        return peak_prob

    def credible_intervals_for_counts(self, confidence=0.95):
        """
        å³°å€¼è®¡æ•°çš„å¯ä¿¡åŒºé—´
        """
        counts = self.sample_peak_counts()

        lower = np.percentile(counts, (1 - confidence) / 2 * 100)
        upper = np.percentile(counts, (1 + confidence) / 2 * 100)
        median = np.median(counts)

        return {
            'median': median,
            'lower': lower,
            'upper': upper,
            'mean': np.mean(counts),
            'std': np.std(counts)
        }

    def compare_with_theory(self, theoretical_model):
        """
        ä¸ç†è®ºæ¨¡å‹æ¯”è¾ƒ

        è®¡ç®—è´å¶æ–¯è¯æ®æˆ–åéªŒé¢„æµ‹æ£€éªŒ
        """
        # ä»åéªŒé¢„æµ‹åˆ†å¸ƒé‡‡æ ·
        predicted_counts = self.sample_peak_counts()

        # è®¡ç®—ä¸ç†è®ºçš„å·®å¼‚
        theory_prediction = theoretical_model.predict_peak_counts()

        # åéªŒé¢„æµ‹på€¼
        p_value = np.mean(predicted_counts >= theory_prediction)

        return {
            'posterior_predictive_pvalue': p_value,
            'discrepancy': np.abs(np.mean(predicted_counts) - theory_prediction),
            'theory_prediction': theory_prediction
        }
```

---

## ğŸ“Š å®éªŒç»“æœ

### å³°å€¼ç»Ÿè®¡æ€§èƒ½

| ç»Ÿè®¡é‡ | ä¿¡å™ªæ¯”è¦æ±‚ | å®‡å®™å­¦çµæ•åº¦ |
|:---|:---:|:---:|
| æ€»å³°å€¼æ•° | >3Ïƒ | ä¸­ç­‰ |
| é«˜ä¿¡å™ªæ¯”å³°å€¼ (>5Ïƒ) | >5Ïƒ | é«˜ |
| å³°å€¼å…³è”å‡½æ•° | >3Ïƒ | é«˜ |
| ç©ºæ´è®¡æ•° | >3Ïƒ | ä¸­ç­‰ |

### ä¸å®‡å®™å­¦å‚æ•°çš„å…³ç³»

```
å³°å€¼è®¡æ•°å¯¹å‚æ•°çš„ä¾èµ–:

Î©_m (ç‰©è´¨å¯†åº¦):
  - å½±å“å³°å€¼é«˜åº¦åˆ†å¸ƒ
  - é«˜Î©_m â†’ æ›´å¤šé«˜ä¿¡å™ªæ¯”å³°å€¼

Ïƒ_8 (åŠŸç‡è°±æŒ¯å¹…):
  - å½±å“æ€»å³°å€¼æ•°
  - é«˜Ïƒ_8 â†’ æ›´å¤šå³°å€¼

w (æš—èƒ½é‡çŠ¶æ€æ–¹ç¨‹):
  - å½±å“å¤§å°ºåº¦ç»“æ„å¢é•¿
  - é—´æ¥å½±å“å³°å€¼ç»Ÿè®¡
```

---

## ğŸ’¡ å¯¹ç»Ÿè®¡åˆ†æçš„å¯ç¤º

### ä¸€èˆ¬å³°å€¼åˆ†ææ¡†æ¶

```python
class GeneralPeakAnalysis:
    """
    é€šç”¨å³°å€¼åˆ†ææ¡†æ¶

    å¯åº”ç”¨äºå„ç§åœºçš„å³°å€¼ç»Ÿè®¡
    """
    def __init__(self, field_shape):
        self.field_shape = field_shape
        self.detector = PeakDetector()
        self.statistics = PeakStatistics()

    def analyze(self, field_samples, uncertainty_samples=None):
        """
        å®Œæ•´å³°å€¼åˆ†æ

        Args:
            field_samples: åœºå®ç°æ ·æœ¬
            uncertainty_samples: ä¸ç¡®å®šæ€§æ ·æœ¬ (å¯é€‰)

        Returns:
            analysis: å®Œæ•´åˆ†æç»“æœ
        """
        # ç‚¹ä¼°è®¡åˆ†æ
        mean_field = np.mean(field_samples, axis=0)
        peaks = self.detector.detect(mean_field)

        # ç»Ÿè®¡é‡
        stats = {
            'counts': self.statistics.peak_count_histogram(peaks),
            'correlation': self.statistics.peak_correlation_function(peaks),
        }

        # è´å¶æ–¯åˆ†æ (å¦‚æœæœ‰ä¸ç¡®å®šæ€§)
        if uncertainty_samples is not None:
            bayesian_stats = BayesianPeakStatistics(field_samples)
            stats['bayesian'] = {
                'count_ci': bayesian_stats.credible_intervals_for_counts(),
                'probability_map': bayesian_stats.peak_probability_map()
            }

        return stats
```

---

## ğŸ“– å…³é”®æ¦‚å¿µä¸æœ¯è¯­

| æœ¯è¯­ | è‹±æ–‡ | è§£é‡Š |
|:---|:---|:---|
| **å³°å€¼è®¡æ•°** | Peak Counts | è´¨é‡åœºä¸­å±€éƒ¨æå¤§å€¼çš„æ•°é‡ |
| **ä¿¡å™ªæ¯”** | Signal-to-Noise Ratio | ä¿¡å·å¼ºåº¦ä¸å™ªå£°çš„æ¯”å€¼ |
| **å…³è”å‡½æ•°** | Correlation Function | æè¿°ç©ºé—´ç‚¹åˆ†å¸ƒçš„ç»Ÿè®¡é‡ |
| **ç©ºæ´** | Void | è´¨é‡åœºä¸­çš„ä½å¯†åº¦åŒºåŸŸ |
| **åéªŒé¢„æµ‹** | Posterior Predictive | åŸºäºåéªŒçš„é¢„æµ‹åˆ†å¸ƒ |
| **å®‡å®™å­¦æ¢é’ˆ** | Cosmological Probe | ç”¨äºçº¦æŸå®‡å®™å­¦å‚æ•°çš„è§‚æµ‹ |

---

## âœ… å¤ä¹ æ£€æŸ¥æ¸…å•

- [ ] ç†è§£å³°å€¼ç»Ÿè®¡çš„å®‡å®™å­¦æ„ä¹‰
- [ ] æŒæ¡å³°å€¼æ£€æµ‹ç®—æ³•
- [ ] äº†è§£å„ç§å³°å€¼ç»Ÿè®¡é‡
- [ ] ç†è§£è´å¶æ–¯å³°å€¼ç»Ÿè®¡æ–¹æ³•
- [ ] äº†è§£ä¸ç¡®å®šæ€§ä¼ æ’­
- [ ] èƒ½å¤Ÿåº”ç”¨åˆ°å…¶ä»–åœºåˆ†æ

---

## ğŸ¤” æ€è€ƒé—®é¢˜

1. **ä¸ºä»€ä¹ˆå³°å€¼ç»Ÿè®¡æ¯”åŠŸç‡è°±æ›´æœ‰ä¿¡æ¯é‡ï¼Ÿ**
   - æç¤º: éé«˜æ–¯æ€§ã€é«˜é˜¶ç»Ÿè®¡

2. **ç¨€ç–å…ˆéªŒå¦‚ä½•å½±å“å³°å€¼æ£€æµ‹ï¼Ÿ**
   - æç¤º: å™ªå£°æŠ‘åˆ¶ã€ä¼ªå³°å‡å°‘

3. **å¦‚ä½•å¤„ç†å³°å€¼ä½ç½®çš„ä¸ç¡®å®šæ€§ï¼Ÿ**
   - æç¤º: æ¦‚ç‡å›¾ã€èšç±»

4. **å³°å€¼ç»Ÿè®¡ä¸å…¶ä»–æ¢é’ˆå¦‚ä½•è”åˆï¼Ÿ**
   - æç¤º: åæ–¹å·®ã€è”åˆä¼¼ç„¶

---

## ğŸ”— ç›¸å…³è®ºæ–‡æ¨è

### å¿…è¯»
1. **Peak Statistics in Cosmology** - å®‡å®™å­¦ä¸­çš„å³°å€¼ç»Ÿè®¡
2. **Weak Lensing Peak Counts** - å¼±é€é•œå³°å€¼è®¡æ•°
3. **Non-Gaussianity Probes** - éé«˜æ–¯æ€§æ¢é’ˆ

### æ‰©å±•é˜…è¯»
1. **Halo Model** - æš—ç‰©è´¨æ™•æ¨¡å‹
2. **Minkowski Functionals** - Minkowskiæ³›å‡½
3. **Persistent Homology** - æŒç»­åŒè°ƒ

---

## ğŸ“ ä¸ªäººç¬”è®°åŒº

### æˆ‘çš„ç†è§£



### ç–‘é—®ä¸å¾…æ¾„æ¸…



### ä¸å½“å‰é¡¹ç›®çš„ç»“åˆç‚¹



### å®ç°è®¡åˆ’



---

**ç¬”è®°åˆ›å»ºæ—¶é—´**: 2026å¹´2æœˆ10æ—¥
**çŠ¶æ€**: å·²å®Œæˆç²¾è¯» âœ…
**ä¸‹ä¸€æ­¥**: æ¢ç´¢å³°å€¼ç»Ÿè®¡åœ¨ç‰¹å¾æ£€æµ‹ä¸­çš„åº”ç”¨
