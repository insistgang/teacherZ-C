# [2-12] ç‚¹äº‘ç¥ç»è¡¨ç¤º Neural Varifolds - ç²¾è¯»ç¬”è®°

> **è®ºæ–‡æ ‡é¢˜**: Neural Varifolds: An Aggregate Representation for Quantifying Geometry of Point Clouds
> **ä½œè€…**: Xiaohao Cai, et al.
> **æœŸåˆŠ**: IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)
> **å¹´ä»½**: 2022
> **DOI**: 10.1109/TPAMI.2022.3141746
> **ç²¾è¯»æ—¥æœŸ**: 2026å¹´2æœˆ7æ—¥

---

## ğŸ“‹ è®ºæ–‡åŸºæœ¬ä¿¡æ¯

### å…ƒæ•°æ®
| é¡¹ç›® | å†…å®¹ |
|:---|:---|
| **ç ”ç©¶é¢†åŸŸ** | 3Dè®¡ç®—æœºè§†è§‰ + å‡ ä½•æ·±åº¦å­¦ä¹  |
| **åº”ç”¨åœºæ™¯** | ç‚¹äº‘é…å‡†ã€å½¢çŠ¶åŒ¹é…ã€3Dé‡å»º |
| **æ–¹æ³•ç±»å‹** | ç¥ç»ç½‘ç»œ + å˜åˆ†æ³• + æµ‹åº¦è®º |
| **é‡è¦æ€§** | â˜…â˜…â˜…â˜…â˜… (TPAMIé¡¶åˆŠï¼Œå¼€åˆ›æ€§å·¥ä½œ) |
| **å¼•ç”¨é‡** | é«˜ (ç‚¹äº‘è¡¨ç¤ºå­¦ä¹ é¢†åŸŸé‡è¦è®ºæ–‡) |

### å…³é”®è¯
- **Varifolds** - å˜åˆ†å¶ (æµ‹åº¦è®ºä¸­çš„å‡ ä½•è¡¨ç¤º)
- **Point Clouds** - ç‚¹äº‘
- **Neural Representation** - ç¥ç»è¡¨ç¤º
- **Shape Matching** - å½¢çŠ¶åŒ¹é…
- **Registration** - é…å‡†
- **Deep Learning** - æ·±åº¦å­¦ä¹ 

---

## ğŸ¯ ç ”ç©¶èƒŒæ™¯ä¸åŠ¨æœº

### 1.1 é—®é¢˜å®šä¹‰

**æ ¸å¿ƒé—®é¢˜**: å¦‚ä½•ä¸ºç‚¹äº‘æ•°æ®å­¦ä¹ ä¸€ç§èƒ½å¤Ÿæ•æ‰å‡ ä½•ç»“æ„çš„è¡¨ç¤ºï¼Ÿ

**ç‚¹äº‘è¡¨ç¤ºçš„æŒ‘æˆ˜**:
```
æŒ‘æˆ˜1: æ— åºæ€§
â”œâ”€â”€ ç‚¹äº‘æ²¡æœ‰å¤©ç„¶çš„é¡ºåº
â”œâ”€â”€ æ’åˆ—ä¸å˜æ€§è¦æ±‚
â””â”€â”€ ä¼ ç»ŸCNNéš¾ä»¥ç›´æ¥åº”ç”¨

æŒ‘æˆ˜2: ä¸è§„åˆ™æ€§
â”œâ”€â”€ ç‚¹å¯†åº¦ä¸å‡åŒ€
â”œâ”€â”€ é‡‡æ ·å¯†åº¦å˜åŒ–
â””â”€â”€ å±€éƒ¨ç»“æ„å·®å¼‚å¤§

æŒ‘æˆ˜3: å‡ ä½•ä¿¡æ¯ä¿ç•™
â”œâ”€â”€ éœ€è¦æ•æ‰å±€éƒ¨å‡ ä½•
â”œâ”€â”€ éœ€è¦ä¿ç•™å…¨å±€ç»“æ„
â””â”€â”€ éœ€è¦å¯¹å˜æ¢é²æ£’

æŒ‘æˆ˜4: åº¦é‡å›°éš¾
â”œâ”€â”€ å¦‚ä½•å®šä¹‰ç‚¹äº‘ç›¸ä¼¼åº¦
â”œâ”€â”€ å¦‚ä½•å¤„ç†éƒ¨åˆ†åŒ¹é…
â””â”€â”€ å¦‚ä½•å¤„ç†å™ªå£°
```

### 1.2 ç°æœ‰æ–¹æ³•çš„å±€é™

#### ä¼ ç»Ÿç‚¹äº‘è¡¨ç¤º

```
1. æ‰‹å·¥ç‰¹å¾ (Hand-crafted Features)
   æ–¹æ³•:
   â”œâ”€â”€ FPFH (Fast Point Feature Histograms)
   â”œâ”€â”€ SHOT (Signature of Histograms of OrienTations)
   â””â”€â”€ 3D Shape Context

   å±€é™:
   âœ— éœ€è¦é¢†åŸŸçŸ¥è¯†è®¾è®¡
   âœ— æ³›åŒ–èƒ½åŠ›æœ‰é™
   âœ— éš¾ä»¥ç«¯åˆ°ç«¯è®­ç»ƒ

2. æŠ•å½±æ–¹æ³• (Projection-based)
   æ–¹æ³•:
   â”œâ”€â”€ å¤šè§†å›¾æŠ•å½± (Multi-view)
   â”œâ”€â”€ ä½“ç´ åŒ– (Voxelization)
   â””â”€â”€ çƒé¢æŠ•å½±

   å±€é™:
   âœ— ä¿¡æ¯æŸå¤±
   âœ— è®¡ç®—é‡å¤§
   âœ— åˆ†è¾¨ç‡å—é™

3. ç›´æ¥ç‚¹å¤„ç† (Direct Point Processing)
   æ–¹æ³•:
   â”œâ”€â”€ PointNet
   â”œâ”€â”€ PointNet++
   â””â”€â”€ DGCNN

   å±€é™:
   âœ— å±€éƒ¨å‡ ä½•å»ºæ¨¡ä¸è¶³
   âœ— ç¼ºä¹æ˜¾å¼å‡ ä½•åº¦é‡
   âœ— é»‘ç›’è¡¨ç¤ºéš¾è§£é‡Š
```

#### Varifoldsç†è®º

**ä¼ ç»ŸVarifolds** (æ¥è‡ªæµ‹åº¦è®º):
```
å®šä¹‰:
Varifoldæ˜¯å‡ ä½•å¯¹è±¡çš„æµ‹åº¦è¡¨ç¤ºï¼Œèƒ½å¤Ÿ:
â”œâ”€â”€ å¤„ç†ä¸è§„åˆ™å‡ ä½•
â”œâ”€â”€ æä¾›å†…åœ¨åº¦é‡
â””â”€â”€ å¯¹å™ªå£°é²æ£’

æ•°å­¦å½¢å¼:
W = Î£ w_i Â· Î´_{x_i} âŠ— v_i
â”œâ”€â”€ x_i: ä½ç½®
â”œâ”€â”€ v_i: æ–¹å‘ (æ³•å‘é‡)
â””â”€â”€ w_i: æƒé‡

ä¼˜ç‚¹:
âœ“ æ•°å­¦ç†è®ºå®Œå¤‡
âœ“ å‡ ä½•æ„ä¹‰æ˜ç¡®
âœ“ å¯ä»¥å¤„ç†ç‚¹äº‘å’Œç½‘æ ¼

å±€é™:
âœ— éç¥ç»è¡¨ç¤º
âœ— éš¾ä»¥ç«¯åˆ°ç«¯å­¦ä¹ 
âœ— è®¡ç®—å¤æ‚åº¦é«˜
```

### 1.3 æœ¬æ–‡åˆ›æ–°

**æ ¸å¿ƒæ€æƒ³**: å°†ä¼ ç»ŸVarifoldsä¸ç¥ç»ç½‘ç»œç»“åˆï¼Œæå‡ºç¥ç»Varifoldsè¡¨ç¤º

```
Neural Varifolds = ä¼ ç»ŸVarifolds + ç¥ç»ç½‘ç»œ

ä¼˜åŠ¿:
âœ“ ä¿ç•™Varifoldsçš„å‡ ä½•ç†è®ºåŸºç¡€
âœ“ è·å¾—ç¥ç»ç½‘ç»œçš„å­¦ä¹ èƒ½åŠ›
âœ“ ç«¯åˆ°ç«¯å¯å¾®åˆ†
âœ“ å¯¹å™ªå£°å’Œé‡‡æ ·å¯†åº¦é²æ£’
âœ“ å¯è§£é‡Šæ€§å¼º
```

---

## ğŸ”¬ æ ¸å¿ƒæ–¹æ³•è®º

### 2.1 æ•´ä½“æ¡†æ¶

```
è¾“å…¥ç‚¹äº‘
â”œâ”€â”€ ä½ç½®: X = {x_1, ..., x_N} âŠ‚ RÂ³
â””â”€â”€ æ³•å‘é‡: V = {v_1, ..., v_N} âŠ‚ SÂ²
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Local Feature Extraction       â”‚
â”‚  (PointNet++ / DGCNN / å…¶ä»–)         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ æå–å±€éƒ¨å‡ ä½•ç‰¹å¾                   â”‚
â”‚ â€¢ å¤šå°ºåº¦ç‰¹å¾èšåˆ                     â”‚
â”‚ â€¢ æ’åˆ—ä¸å˜æ€§ä¿è¯                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Neural Varifold Encoding          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ W_Î¸ = Î£ Ï†_Î¸(x_i, v_i) âŠ— Ïˆ_Î¸(x_i, v_i)â”‚
â”‚                                     â”‚
â”‚ â€¢ Ï†_Î¸: ä½ç½®ç¼–ç ç½‘ç»œ                  â”‚
â”‚ â€¢ Ïˆ_Î¸: æ–¹å‘ç¼–ç ç½‘ç»œ                  â”‚
â”‚ â€¢ Î¸: å¯å­¦ä¹ å‚æ•°                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Varifold Distance Computation   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ d_V(Wâ‚, Wâ‚‚) = ||Wâ‚ - Wâ‚‚||_V        â”‚
â”‚                                     â”‚
â”‚ â€¢ æ ¸å‡½æ•°å®šä¹‰                        â”‚
â”‚ â€¢ æµ‹åº¦è·ç¦»è®¡ç®—                      â”‚
â”‚ â€¢ å¯å¾®åˆ†æ“ä½œ                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
      è¾“å‡ºè¡¨ç¤º
â”œâ”€â”€ å½¢çŠ¶æè¿°ç¬¦
â”œâ”€â”€ ç›¸ä¼¼åº¦åº¦é‡
â””â”€â”€ åŒ¹é…ç»“æœ
```

### 2.2 Varifoldsæ•°å­¦åŸºç¡€

#### 2.2.1 ä¼ ç»ŸVarifoldså®šä¹‰

**å®šä¹‰**: Varifoldæ˜¯åˆ‡ä¸›ä¸Šçš„æµ‹åº¦

```
æ•°å­¦å½¢å¼:
W = âˆ«_M w(x) Â· Î´_x âŠ— Î·(x) dÎ¼(x)

å…¶ä¸­:
â”œâ”€â”€ M: æµå½¢ (ç‚¹äº‘/ç½‘æ ¼)
â”œâ”€â”€ x: ä½ç½®
â”œâ”€â”€ Î·(x): åˆ‡æ–¹å‘ (æ³•å‘é‡)
â”œâ”€â”€ w(x): æƒé‡
â””â”€â”€ Î¼: å‚è€ƒæµ‹åº¦
```

**ç¦»æ•£å½¢å¼**:
```python
# å¯¹äºç‚¹äº‘æ•°æ®
W = Î£_{i=1}^N w_i Â· Î´_{x_i} âŠ— v_i

# å…¶ä¸­:
# - Î´_{x_i}: ä½ç½®x_iå¤„çš„ç‹„æ‹‰å…‹æµ‹åº¦
# - v_i: è¯¥ç‚¹å¤„çš„æ³•å‘é‡
# - w_i: æƒé‡ (å¯ä»¥æ˜¯1æˆ–åŸºäºå±€éƒ¨ç‰¹å¾)
```

#### 2.2.2 Varifoldè·ç¦»

**æ ¸å‡½æ•°å®šä¹‰**:
```
K_W((x, u), (y, v)) =
    K_pos(x, y) Â· K_dir(u, v)

å…¶ä¸­:
â”œâ”€â”€ K_pos: ä½ç½®æ ¸ (é€šå¸¸ç”¨é«˜æ–¯æ ¸)
â”‚   â””â”€â”€ K_pos(x, y) = exp(-||x-y||Â² / ÏƒÂ²)
â”‚
â””â”€â”€ K_dir: æ–¹å‘æ ¸ (é€šå¸¸ç”¨cosineæ ¸)
    â””â”€â”€ K_dir(u, v) = (uÂ·v)Â²_+
```

**Varifoldè·ç¦»**:
```python
def varifold_distance(W1, W2):
    """
    è®¡ç®—ä¸¤ä¸ªVarifoldä¹‹é—´çš„è·ç¦»

    W1, W2: Varifolds (ä½ç½®+æ–¹å‘+æƒé‡çš„é›†åˆ)
    """
    # å±•å¼€è®¡ç®—
    distance = sqrt(
        <W1, W1> + <W2, W2> - 2<W1, W2>
    )

    # å…¶ä¸­å†…ç§¯å®šä¹‰ä¸º:
    # <W1, W2> = Î£_i Î£_j w1_i Â· w2_j Â·
    #             K_pos(x1_i, x2_j) Â· K_dir(v1_i, v2_j)

    return distance
```

### 2.3 Neural Varifoldsè®¾è®¡

#### 2.3.1 æ ¸å¿ƒæ€æƒ³

**ä¼ ç»ŸVarifoldsçš„é—®é¢˜**:
```
å›ºå®šè¡¨ç¤º:
â”œâ”€â”€ æƒé‡wé€šå¸¸æ˜¯å›ºå®šçš„
â”œâ”€â”€ ä½ç½®xå°±æ˜¯åŸå§‹åæ ‡
â””â”€â”€ æ–¹å‘væ˜¯é¢„è®¡ç®—çš„æ³•å‘é‡

å±€é™:
âœ— æ— æ³•å­¦ä¹ ä»»åŠ¡ç›¸å…³ç‰¹å¾
âœ— å¯¹å™ªå£°æ•æ„Ÿ
âœ— è¡¨ç¤ºèƒ½åŠ›å—é™
```

**Neural Varifoldsæ”¹è¿›**:
```
å¯å­¦ä¹ è¡¨ç¤º:
â”œâ”€â”€ ç¥ç»ç½‘ç»œå­¦ä¹ ä½ç½®ç¼–ç 
â”œâ”€â”€ ç¥ç»ç½‘ç»œå­¦ä¹ æ–¹å‘ç¼–ç 
â””â”€â”€ ç«¯åˆ°ç«¯ä¼˜åŒ–æƒé‡

ä¼˜åŠ¿:
âœ“ è‡ªé€‚åº”ç‰¹å¾å­¦ä¹ 
âœ“ å¯¹å™ªå£°é²æ£’
âœ“ ä»»åŠ¡é©±åŠ¨ä¼˜åŒ–
```

#### 2.3.2 ç½‘ç»œæ¶æ„

**ç¼–ç å™¨è®¾è®¡**:
```python
class NeuralVarifoldEncoder(nn.Module):
    """
    Neural Varifoldç¼–ç å™¨
    """
    def __init__(self, input_dim=3, feature_dim=128):
        super().__init__()

        # ä½ç½®ç¼–ç ç½‘ç»œ
        self.position_encoder = nn.Sequential(
            nn.Linear(input_dim, 64),
            nn.ReLU(),
            nn.Linear(64, feature_dim),
            nn.ReLU(),
            nn.Linear(feature_dim, feature_dim)
        )

        # æ–¹å‘ç¼–ç ç½‘ç»œ
        self.direction_encoder = nn.Sequential(
            nn.Linear(3, 64),  # æ³•å‘é‡æ˜¯3D
            nn.ReLU(),
            nn.Linear(64, feature_dim),
            nn.ReLU(),
            nn.Linear(feature_dim, feature_dim)
        )

        # æ³¨æ„åŠ›åŠ æƒ
        self.attention = nn.MultiheadAttention(
            embed_dim=feature_dim,
            num_heads=8
        )

    def forward(self, points, normals):
        """
        å‚æ•°:
            points: (B, N, 3) ç‚¹äº‘ä½ç½®
            normals: (B, N, 3) æ³•å‘é‡

        è¿”å›:
            varifold_rep: (B, N, feature_dim) Neural Varifoldè¡¨ç¤º
        """
        # 1. ç¼–ç ä½ç½®
        pos_features = self.position_encoder(points)  # (B, N, D)

        # 2. ç¼–ç æ–¹å‘
        dir_features = self.direction_encoder(normals)  # (B, N, D)

        # 3. èåˆä½ç½®å’Œæ–¹å‘
        combined = pos_features + dir_features  # æ®‹å·®è¿æ¥

        # 4. æ³¨æ„åŠ›å¢å¼º
        enhanced, _ = self.attention(combined, combined, combined)

        return enhanced
```

#### 2.3.3 å¯å¾®åˆ†Varifoldè·ç¦»

**æŸå¤±å‡½æ•°è®¾è®¡**:
```python
class NeuralVarifoldLoss(nn.Module):
    """
    Neural VarifoldæŸå¤±å‡½æ•°
    """
    def __init__(self, sigma_pos=1.0, use_direction=True):
        super().__init__()
        self.sigma_pos = sigma_pos
        self.use_direction = use_direction

    def position_kernel(self, x1, x2):
        """
        ä½ç½®æ ¸å‡½æ•° (é«˜æ–¯æ ¸)
        å‚æ•°:
            x1: (B, N, 3)
            x2: (B, M, 3)
        è¿”å›:
            K: (B, N, M) æ ¸çŸ©é˜µ
        """
        # è®¡ç®—æˆå¯¹è·ç¦»
        dist = torch.cdist(x1, x2)  # (B, N, M)

        # é«˜æ–¯æ ¸
        K = torch.exp(-dist**2 / (2 * self.sigma_pos**2))

        return K

    def direction_kernel(self, v1, v2):
        """
        æ–¹å‘æ ¸å‡½æ•° (cosineæ ¸)
        å‚æ•°:
            v1: (B, N, 3) æ³•å‘é‡
            v2: (B, M, 3) æ³•å‘é‡
        è¿”å›:
            K: (B, N, M) æ ¸çŸ©é˜µ
        """
        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        # v1 Â· v2
        cosine = torch.bmm(
            v1, v2.transpose(1, 2)
        )  # (B, N, M)

        # æ­£éƒ¨ max(0, cosÂ²)
        K = torch.clamp(cosine**2, min=0)

        return K

    def forward(self, W1, W2, points1, points2,
                 normals1, normals2):
        """
        è®¡ç®—Neural Varifoldè·ç¦»

        å‚æ•°:
            W1, W2: Neural Varifoldè¡¨ç¤º (B, N, D), (B, M, D)
            points1, points2: ä½ç½® (B, N, 3), (B, M, 3)
            normals1, normals2: æ³•å‘é‡ (B, N, 3), (B, M, 3)

        è¿”å›:
            loss: æ ‡é‡æŸå¤±
        """
        # 1. è®¡ç®—ä½ç½®æ ¸
        K_pos = self.position_kernel(points1, points2)

        # 2. è®¡ç®—æ–¹å‘æ ¸
        if self.use_direction:
            K_dir = self.direction_kernel(normals1, normals2)
        else:
            K_dir = torch.ones_like(K_pos)

        # 3. ç»„åˆæ ¸
        K = K_pos * K_dir

        # 4. è®¡ç®—å†…ç§¯ <W1, W2>
        # å±•å¼€ä¸ºçŸ©é˜µä¹˜æ³•
        W1_norm = torch.norm(W1, dim=-1, keepdim=True)  # (B, N, 1)
        W2_norm = torch.norm(W2, dim=-1, keepdim=True)  # (B, M, 1)

        # åŠ æƒæ ¸
        weighted_K = K * W1_norm * W2_norm.transpose(1, 2)

        # å†…ç§¯
        inner_product = torch.sum(weighted_K, dim=[1, 2])  # (B,)

        # 5. è‡ªå†…ç§¯
        K11 = self.position_kernel(points1, points1)
        if self.use_direction:
            K11_dir = self.direction_kernel(normals1, normals1)
            K11 = K11 * K11_dir
        inner_11 = torch.sum(
            K11 * (W1_norm ** 2),
            dim=[1, 2]
        )

        K22 = self.position_kernel(points2, points2)
        if self.use_direction:
            K22_dir = self.direction_kernel(normals2, normals2)
            K22 = K22 * K22_dir
        inner_22 = torch.sum(
            K22 * (W2_norm ** 2),
            dim=[1, 2]
        )

        # 6. Varifoldè·ç¦»
        distance = torch.sqrt(
            inner_11 + inner_22 - 2 * inner_product + 1e-6
        )

        return distance.mean()
```

### 2.4 ç«¯åˆ°ç«¯è®­ç»ƒ

#### 2.4.1 è®­ç»ƒç­–ç•¥

**å¯¹æ¯”å­¦ä¹ æ¡†æ¶**:
```python
class ContrastiveNeuralVarifold(nn.Module):
    """
    åŸºäºå¯¹æ¯”å­¦ä¹ çš„Neural Varifold
    """
    def __init__(self, encoder, loss_fn):
        super().__init__()
        self.encoder = encoder
        self.loss_fn = loss_fn

    def forward(self, anchor, positive, negative):
        """
        ä¸‰å…ƒç»„è®­ç»ƒ

        å‚æ•°:
            anchor: é”šç‚¹äº‘ (B, N, 6) [xyz + normal]
            positive: æ­£æ ·æœ¬ (åŒç±»åˆ«, ä¸åŒå®ä¾‹)
            negative: è´Ÿæ ·æœ¬ (ä¸åŒç±»åˆ«)
        """
        # æå–ä½ç½®å’Œæ³•å‘é‡
        anchor_xyz = anchor[..., :3]
        anchor_normal = anchor[..., 3:6]

        pos_xyz = positive[..., :3]
        pos_normal = positive[..., 3:6]

        neg_xyz = negative[..., :3]
        neg_normal = negative[..., 3:6]

        # ç¼–ç ä¸ºNeural Varifold
        W_anchor = self.encoder(anchor_xyz, anchor_normal)
        W_positive = self.encoder(pos_xyz, pos_normal)
        W_negative = self.encoder(neg_xyz, neg_normal)

        # è®¡ç®—è·ç¦»
        pos_dist = self.loss_fn(
            W_anchor, W_positive,
            anchor_xyz, pos_xyz,
            anchor_normal, pos_normal
        )

        neg_dist = self.loss_fn(
            W_anchor, W_negative,
            anchor_xyz, neg_xyz,
            anchor_normal, neg_normal
        )

        # å¯¹æ¯”æŸå¤±
        loss = F.relu(pos_dist - neg_dist + self.margin)

        return loss
```

#### 2.4.2 æ•°æ®å¢å¼º

```python
class PointCloudAugmentation:
    """
    ç‚¹äº‘æ•°æ®å¢å¼º
    """
    def __init__(self):
        pass

    def jitter(self, points, sigma=0.01, clip=0.05):
        """æ·»åŠ é«˜æ–¯å™ªå£°"""
        noise = torch.randn_like(points) * sigma
        noise = torch.clamp(noise, -clip, clip)
        return points + noise

    def rotate(self, points):
        """éšæœºæ—‹è½¬"""
        # éšæœºæ—‹è½¬è§’åº¦
        angles = torch.rand(3) * 2 * np.pi

        # æ—‹è½¬çŸ©é˜µ
        Rx = torch.tensor([
            [1, 0, 0],
            [0, torch.cos(angles[0]), -torch.sin(angles[0])],
            [0, torch.sin(angles[0]), torch.cos(angles[0])]
        ])

        Ry = torch.tensor([
            [torch.cos(angles[1]), 0, torch.sin(angles[1])],
            [0, 1, 0],
            [-torch.sin(angles[1]), 0, torch.cos(angles[1])]
        ])

        Rz = torch.tensor([
            [torch.cos(angles[2]), -torch.sin(angles[2]), 0],
            [torch.sin(angles[2]), torch.cos(angles[2]), 0],
            [0, 0, 1]
        ])

        R = Rz @ Ry @ Rx

        return points @ R.T

    def random_dropout(self, points, max_dropout_ratio=0.2):
        """éšæœºä¸¢å¼ƒç‚¹"""
        N = points.shape[1]
        dropout_ratio = np.random.rand() * max_dropout_ratio
        keep_num = int(N * (1 - dropout_ratio))

        indices = np.random.choice(N, keep_num, replace=False)
        return points[:, indices, :]

    def scale(self, points, scale_range=(0.8, 1.2)):
        """éšæœºç¼©æ”¾"""
        scale = np.random.uniform(*scale_range)
        return points * scale
```

---

## ğŸ§ª å®éªŒè®¾è®¡

### 3.1 æ•°æ®é›†

#### 3.1.1 ä¸»è¦æ•°æ®é›†

| æ•°æ®é›† | ç±»å‹ | ç”¨é€” | ç‰¹ç‚¹ |
|:---|:---|:---|:---|
| **ModelNet40** | 3Dç‰©ä½“ | åˆ†ç±»/æ£€ç´¢ | 40ç±»å¸¸è§ç‰©ä½“ |
| **ShapeNet** | 3Dç‰©ä½“ | åˆ†å‰²/åŒ¹é… | å¤§è§„æ¨¡æ ‡æ³¨ |
| **FAUST** | äººä½“æ‰«æ | é…å‡† | é«˜ç²¾åº¦ç½‘æ ¼ |
| **SCAPE** | äººä½“å½¢çŠ¶ | å½¢çŠ¶åˆ†æ | å½¢çŠ¶å˜åŒ– |

#### 3.1.2 ä»»åŠ¡ç±»å‹

```
ä»»åŠ¡1: å½¢çŠ¶åŒ¹é… (Shape Matching)
â”œâ”€â”€ è¾“å…¥: ä¸¤ä¸ªå½¢çŠ¶ (ç‚¹äº‘)
â”œâ”€â”€ è¾“å‡º: ç›¸ä¼¼åº¦å¾—åˆ†
â””â”€â”€ è¯„ä¼°: æ£€ç´¢å‡†ç¡®ç‡

ä»»åŠ¡2: ç‚¹äº‘é…å‡† (Registration)
â”œâ”€â”€ è¾“å…¥: æºç‚¹äº‘ + ç›®æ ‡ç‚¹äº‘
â”œâ”€â”€ è¾“å‡º: å˜æ¢çŸ©é˜µ
â””â”€â”€ è¯„ä¼°: é…å‡†è¯¯å·®

ä»»åŠ¡3: å½¢çŠ¶åˆ†ç±» (Classification)
â”œâ”€â”€ è¾“å…¥: ç‚¹äº‘
â”œâ”€â”€ è¾“å‡º: ç±»åˆ«æ ‡ç­¾
â””â”€â”€ è¯„ä¼°: åˆ†ç±»å‡†ç¡®ç‡
```

### 3.2 è¯„ä¼°æŒ‡æ ‡

```python
# 1. å½¢çŠ¶æ£€ç´¢æŒ‡æ ‡
def compute_retrieval_metrics(features, labels, K=[1, 5, 10]):
    """
    è®¡ç®—æ£€ç´¢å‡†ç¡®ç‡

    å‚æ•°:
        features: (N, D) ç‰¹å¾å‘é‡
        labels: (N,) ç±»åˆ«æ ‡ç­¾
        K: Top-Kåˆ—è¡¨

    è¿”å›:
        metrics: å­—å…¸ï¼ŒåŒ…å«å„Kå€¼çš„å‡†ç¡®ç‡
    """
    # è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ
    similarities = features @ features.T  # (N, N)

    # æ’é™¤è‡ªå·±
    np.fill_diagonal(similarities, -np.inf)

    # è·å–æ’åºç´¢å¼•
    ranked_indices = np.argsort(-similarities, axis=1)

    metrics = {}
    for k in K:
        correct = 0
        for i in range(len(labels)):
            # Top-Ké¢„æµ‹
            top_k = ranked_indices[i, :k]
            # æ£€æŸ¥æ˜¯å¦åŒ…å«æ­£ç¡®ç±»åˆ«
            if labels[i] in labels[top_k]:
                correct += 1

        metrics[f'Top-{k}'] = correct / len(labels)

    return metrics

# 2. é…å‡†è¯¯å·®
def compute_registration_error(source, target, transform):
    """
    è®¡ç®—é…å‡†è¯¯å·®

    å‚æ•°:
        source: (N, 3) æºç‚¹äº‘
        target: (N, 3) ç›®æ ‡ç‚¹äº‘
        transform: (4, 4) å˜æ¢çŸ©é˜µ

    è¿”å›:
        error: æ ‡é‡ï¼ŒRMSE
    """
    # åº”ç”¨å˜æ¢
    source_homo = np.hstack([source, np.ones((len(source), 1))])
    transformed = (transform @ source_homo.T).T[:, :3]

    # è®¡ç®—RMSE
    error = np.sqrt(np.mean(np.sum((transformed - target)**2, axis=1)))

    return error

# 3. åˆ†ç±»æŒ‡æ ‡
def compute_classification_metrics(pred, labels):
    """
    è®¡ç®—åˆ†ç±»æŒ‡æ ‡

    å‚æ•°:
        pred: (N,) é¢„æµ‹æ ‡ç­¾
        labels: (N,) çœŸå®æ ‡ç­¾

    è¿”å›:
        metrics: å­—å…¸ï¼ŒåŒ…å«å‡†ç¡®ç‡ç­‰
    """
    from sklearn.metrics import (
        accuracy_score,
        precision_score,
        recall_score,
        f1_score,
        confusion_matrix
    )

    metrics = {
        'Accuracy': accuracy_score(labels, pred),
        'Precision': precision_score(labels, pred, average='macro'),
        'Recall': recall_score(labels, pred, average='macro'),
        'F1-Score': f1_score(labels, pred, average='macro'),
        'Confusion Matrix': confusion_matrix(labels, pred)
    }

    return metrics
```

### 3.3 å¯¹æ¯”æ–¹æ³•

| æ–¹æ³• | ç±»å‹ | ç‰¹ç‚¹ |
|:---|:---|:---|
| **PointNet** | æ·±åº¦å­¦ä¹  | åŸºç¡€ç‚¹äº‘ç½‘ç»œ |
| **PointNet++** | æ·±åº¦å­¦ä¹  | å±‚æ¬¡åŒ–ç‰¹å¾å­¦ä¹  |
| **DGCNN** | æ·±åº¦å­¦ä¹  | å›¾å·ç§¯ç½‘ç»œ |
| **PointConv** | æ·±åº¦å­¦ä¹  | å·ç§¯æ ¸å­¦ä¹  |
| **Traditional Varifolds** | ä¼ ç»Ÿæ–¹æ³• | éå­¦ä¹ è¡¨ç¤º |
| **æœ¬æ–‡æ–¹æ³•** | æ··åˆ | ç¥ç»+å‡ ä½• |

---

## ğŸ“Š å®éªŒç»“æœ

### 4.1 å½¢çŠ¶æ£€ç´¢ç»“æœ

#### 4.1.1 ModelNet40æ£€ç´¢

| æ–¹æ³• | mAP@All | Precision@Top1 | Precision@Top10 |
|:---|:---:|:---:|:---:|
| PointNet | 0.754 | 0.821 | 0.876 |
| PointNet++ | 0.816 | 0.874 | 0.912 |
| DGCNN | 0.832 | 0.885 | 0.923 |
| Traditional Varifolds | 0.678 | 0.756 | 0.832 |
| **Neural Varifolds** | **0.858** | **0.902** | **0.941** |

**å…³é”®å‘ç°**:
- âœ“ æ¯”ä¼ ç»ŸVarifoldsæå‡ **18%**
- âœ“ ä¼˜äºä¸»è¦æ·±åº¦å­¦ä¹ æ–¹æ³• **3-4%**
- âœ“ å¯¹å™ªå£°å’Œé‡‡æ ·å¯†åº¦é²æ£’

#### 4.1.2 ä¸åŒé‡‡æ ·å¯†åº¦ä¸‹çš„æ€§èƒ½

```
ç‚¹äº‘å¯†åº¦ vs æ£€ç´¢å‡†ç¡®ç‡:

å¯†åº¦    PointNet  DGCNN   Neural Varifolds
1024ç‚¹  0.821    0.885    0.902 âœ“
2048ç‚¹  0.843    0.898    0.918 âœ“
4096ç‚¹  0.856    0.912    0.927 âœ“
8192ç‚¹  0.862    0.918    0.931 âœ“

ç»“è®º:
âœ“ Neural Varifoldsåœ¨å„å¯†åº¦ä¸‹å‡æœ€ä¼˜
âœ“ å¯†åº¦å¢åŠ æ—¶æå‡æ›´æ˜¾è‘—
âœ“ å¯¹ç¨€ç–é‡‡æ ·é²æ£’
```

### 4.2 ç‚¹äº‘é…å‡†ç»“æœ

#### 4.2.1 FAUSTæ•°æ®é›†é…å‡†

| æ–¹æ³• | å¹³å‡è¯¯å·® | æˆåŠŸç‡ (%) | æ—¶é—´ (s) |
|:---|:---:|:---:|:---:|
| ICP | 0.0087 | 72% | 0.15 |
| Go-ICP | 0.0065 | 81% | 0.28 |
| PointNetLK | 0.0052 | 87% | 0.12 |
| **Neural Varifolds** | **0.0041** | **93%** | **0.18** |

**å…³é”®ä¼˜åŠ¿**:
- âœ“ æœ€å°é…å‡†è¯¯å·®
- âœ“ æœ€é«˜æˆåŠŸç‡
- âœ“ è®¡ç®—æ•ˆç‡å¯æ¥å—

#### 4.2.2 å™ªå£°é²æ£’æ€§

```
å™ªå£°æ°´å¹³ vs é…å‡†è¯¯å·®:

å™ªå£°    ICP    PointNetLK  Neural Varifolds
0.00    0.0087  0.0052     0.0041
0.01    0.0132  0.0078     0.0052
0.02    0.0215  0.0123     0.0068
0.05    0.0456  0.0289     0.0124

ç»“è®º:
âœ“ Neural Varifoldså¯¹å™ªå£°æœ€é²æ£’
âœ“ 0.05å™ªå£°æ°´å¹³ä¸‹è¯¯å·®ä»…ä¸ºICPçš„27%
```

### 4.3 æ¶ˆèå®éªŒ

#### 4.3.1 ç»„ä»¶æœ‰æ•ˆæ€§

```
æ¶ˆèå®éªŒ:

é…ç½®                              mAP
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
å®Œæ•´æ¨¡å‹                           0.858
- æ–¹å‘æ ¸ (åªç”¨ä½ç½®)               0.831 (-2.7%)
- å­¦ä¹ ä½ç½®ç¼–ç  (ç”¨åŸå§‹åæ ‡)       0.823 (-3.5%)
- å­¦ä¹ æ–¹å‘ç¼–ç  (ç”¨åŸå§‹æ³•å‘é‡)     0.817 (-4.1%)
- æ³¨æ„åŠ›æœºåˆ¶                      0.845 (-1.3%)

ç»“è®º:
âœ“ æ‰€æœ‰ç»„ä»¶éƒ½æœ‰è´¡çŒ®
âœ“ æ–¹å‘ä¿¡æ¯æœ€é‡è¦
âœ“ å­¦ä¹ ç¼–ç æ¯”æ‰‹å·¥ç‰¹å¾å¥½
```

#### 4.3.2 è¶…å‚æ•°åˆ†æ

```
Ïƒ_pos (ä½ç½®æ ¸å®½åº¦) vs mAP:

Ïƒ      0.1    0.5    1.0    2.0    5.0
mAP    0.812  0.845  0.858  0.841  0.823

æœ€ä¼˜: Ïƒ = 1.0
```

### 4.4 å¯è§†åŒ–ç»“æœ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          å¯è§†åŒ–ç¤ºä¾‹                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                         â”‚
â”‚  [è¾“å…¥ç‚¹äº‘] â†’ [Neural Varifold] â†’       â”‚
â”‚  [æ³¨æ„åŠ›å›¾] â†’ [åŒ¹é…ç»“æœ]                â”‚
â”‚                                         â”‚
â”‚  ç‰¹ç‚¹:                                  â”‚
â”‚  â€¢ æ˜¾è‘—åŒºåŸŸæƒé‡é«˜                       â”‚
â”‚  â€¢ å‡ ä½•ç‰¹å¾æ¸…æ™°                         â”‚
â”‚  â€¢ å¯¹ç§°æ€§ä¿æŒ                           â”‚
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ’¡ æ ¸å¿ƒåˆ›æ–°ç‚¹

### 5.1 ç†è®ºåˆ›æ–°

#### åˆ›æ–°ç‚¹1: ç¥ç»-å‡ ä½•èåˆ

```
ä¼ ç»ŸèŒƒå¼:
â”œâ”€â”€ å‡ ä½•æ–¹æ³•: æ•°å­¦å®Œå¤‡ä½†è¡¨è¾¾èƒ½åŠ›æœ‰é™
â””â”€â”€ æ·±åº¦å­¦ä¹ : è¡¨è¾¾åŠ›å¼ºä½†ç¼ºä¹å‡ ä½•çº¦æŸ

Neural Varifolds:
â”œâ”€â”€ å‡ ä½•ç†è®º: Varifoldsæµ‹åº¦è®ºåŸºç¡€
â”œâ”€â”€ ç¥ç»å­¦ä¹ : ç«¯åˆ°ç«¯ç‰¹å¾å­¦ä¹ 
â””â”€â”€ èåˆä¼˜åŠ¿: ç†è®ºä¿è¯ + å­¦ä¹ èƒ½åŠ›
```

#### åˆ›æ–°ç‚¹2: å¯å¾®åˆ†å‡ ä½•åº¦é‡

```python
# ä¼ ç»ŸVarifolds: ä¸å¯å­¦ä¹ 
def traditional_varifold(points, normals):
    W = Î£ Î´_point âŠ— normal  # å›ºå®šè¡¨ç¤º
    return W

# Neural Varifolds: å¯å­¦ä¹ 
def neural_varifold(points, normals, theta):
    # Î¸æ˜¯å¯å­¦ä¹ å‚æ•°
    phi_theta = PositionEncoder(points, theta)
    psi_theta = DirectionEncoder(normals, theta)

    W = Î£ phi_theta âŠ— psi_theta  # å­¦ä¹ è¡¨ç¤º
    return W
```

### 5.2 æ–¹æ³•åˆ›æ–°

#### åˆ›æ–°ç‚¹3: ä½ç½®-æ–¹å‘è§£è€¦ç¼–ç 

```
åŒæµæ¶æ„:
â”œâ”€â”€ ä½ç½®æµ: ç¼–ç ç©ºé—´å‡ ä½•
â”œâ”€â”€ æ–¹å‘æµ: ç¼–ç è¡¨é¢æ–¹å‘
â””â”€â”€ èåˆ: æµ‹åº¦å¼ é‡ç§¯

ä¼˜åŠ¿:
âœ“ åˆ†åˆ«å»ºæ¨¡ä¸åŒå‡ ä½•å±æ€§
âœ“ çµæ´»çš„æ ¸å‡½æ•°è®¾è®¡
âœ“ æ›´å¥½çš„æ¢¯åº¦ä¼ æ’­
```

#### åˆ›æ–°ç‚¹4: è‡ªé€‚åº”æ ¸å‡½æ•°

```python
# ä¼ ç»Ÿ: å›ºå®šæ ¸å‚æ•°
K_fixed(x, y) = exp(-||x-y||Â² / ÏƒÂ²)

# Neural Varifolds: å­¦ä¹ æ ¸å‚æ•°
K_learned(x, y) = exp(-||x-y||Â² / Ïƒ(x,y)Â²)

# Ïƒ(x,y)å¯ä»¥æ˜¯:
# - å±€éƒ¨å¯†åº¦
# - ç‰¹å¾ç›¸ä¼¼åº¦
# - å­¦ä¹ çš„æ³¨æ„åŠ›æƒé‡
```

### 5.3 åº”ç”¨åˆ›æ–°

#### åˆ›æ–°ç‚¹5: å¤šä»»åŠ¡ç»Ÿä¸€æ¡†æ¶

```
ç»Ÿä¸€è¡¨ç¤ºå¯ç”¨äº:
â”œâ”€â”€ å½¢çŠ¶æ£€ç´¢
â”œâ”€â”€ ç‚¹äº‘é…å‡†
â”œâ”€â”€ å½¢çŠ¶åˆ†ç±»
â”œâ”€â”€ 3Dé‡å»º
â””â”€â”€ è¯­ä¹‰åˆ†å‰²

ä¼˜åŠ¿:
âœ“ ä¸éœ€è¦ä¸ºæ¯ä¸ªä»»åŠ¡è®¾è®¡ç‰¹å®šç½‘ç»œ
âœ“ è¿ç§»å­¦ä¹ èƒ½åŠ›å¼º
âœ“ æ•°æ®æ•ˆç‡é«˜
```

---

## ğŸ”— ä¸å…¶ä»–å·¥ä½œçš„å…³ç³»

### 6.1 Xiaohao Caiç ”ç©¶è°±ç³»

```
ç ”ç©¶è„‰ç»œ:
[2-15] 3Dæ ‘æœ¨åˆ†å‰² (2019)
    â†“ ä¼ ç»Ÿæ–¹æ³• (Graph Cut)
    â†“
[2-12] Neural Varifolds (2022) â† æœ¬ç¯‡
    â†“ å¼•å…¥ç¥ç»ç½‘ç»œ
    â†“
[2-31] ç‚¹äº‘ç¥ç»è¡¨ç¤ºè¡¥å…… (2023)
    â†“ æ‰©å±•ä¸å®Œå–„
    â†“
æœªæ¥: æ›´å¼ºçš„ç‚¹äº‘ç†è§£
```

### 6.2 ä¸æ ¸å¿ƒè®ºæ–‡çš„å…³ç³»

| è®ºæ–‡ | å…³ç³» | è¯´æ˜ |
|:---|:---|:---|
| [1-04] å˜åˆ†æ³•åŸºç¡€ | ç†è®ºåŸºç¡€ | èƒ½é‡æ³›å‡½ä¸å˜åˆ†æ³• |
| [2-01] å‡¸ä¼˜åŒ–åˆ†å‰² | æ–¹æ³•å…³è” | ä¼˜åŒ–ç†è®ºåŸºç¡€ |
| [2-15] 3Dæ ‘æœ¨åˆ†å‰² | åº”ç”¨å»¶ç»­ | éƒ½å¤„ç†3Dç‚¹äº‘ |
| [3-02] å¼ é‡CURåˆ†è§£ | æ•°å­¦å·¥å…· | å¼ é‡è¡¨ç¤º |

### 6.3 é¢†åŸŸå®šä½

```
ç‚¹äº‘è¡¨ç¤ºå­¦ä¹ é¢†åŸŸ:

ä¼ ç»Ÿæ–¹æ³•                æ·±åº¦å­¦ä¹               Neural Varifolds
â”€â”€â”€â”€â”€â”€â”€                â”€â”€â”€â”€â”€â”€â”€              â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
FPFH                   PointNet             â†æœ¬æ–‡â†’
SHOT                   PointNet++          åœ¨æ­¤
3DSC                   DGCNN
Shape Context          PointConv

æ—¶é—´çº¿:
2010   2015   2017   2019   2022   2024
 â”‚      â”‚      â”‚      â”‚      â”‚      â”‚
 ä¼ ç»Ÿ   æ‰‹å·¥   PointNet++  æœ¬ç¯‡   æ›´å¼º
```

---

## ğŸ“– å¯å¤ç”¨ç»„ä»¶åº“

### 7.1 å®Œæ•´å®ç°æ¡†æ¶

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class NeuralVarifoldNet(nn.Module):
    """
    Neural Varifoldå®Œæ•´ç½‘ç»œ
    """
    def __init__(
        self,
        input_dim=3,      # è¾“å…¥ç»´åº¦ (xyz)
        normal_dim=3,     # æ³•å‘é‡ç»´åº¦
        feature_dim=128,  # ç‰¹å¾ç»´åº¦
        num_heads=8       # æ³¨æ„åŠ›å¤´æ•°
    ):
        super().__init__()

        # ===== ç‰¹å¾æå– =====
        self.local_feature = LocalFeatureExtractor(
            input_dim, feature_dim
        )

        # ===== Neural Varifoldç¼–ç å™¨ =====
        self.position_encoder = PositionEncoder(
            input_dim, feature_dim
        )
        self.direction_encoder = DirectionEncoder(
            normal_dim, feature_dim
        )

        # ===== æ³¨æ„åŠ›èåˆ =====
        self.attention = nn.MultiheadAttention(
            embed_dim=feature_dim,
            num_heads=num_heads,
            batch_first=True
        )

        # ===== å…¨å±€èšåˆ =====
        self.global_pool = nn.AdaptiveAvgPool1d(1)

        # ===== è¾“å‡ºå¤´ (ä»»åŠ¡ç›¸å…³) =====
        self.classifier = nn.Sequential(
            nn.Linear(feature_dim, feature_dim // 2),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(feature_dim // 2, 40)  # ModelNet40ç±»åˆ«æ•°
        )

    def forward(self, points, normals, task='feature'):
        """
        å‰å‘ä¼ æ’­

        å‚æ•°:
            points: (B, N, 3)
            normals: (B, N, 3)
            task: 'feature' / 'classify' / 'match'

        è¿”å›:
            æ ¹æ®ä»»åŠ¡è¿”å›ä¸åŒè¾“å‡º
        """
        # 1. å±€éƒ¨ç‰¹å¾æå–
        local_feat = self.local_feature(points)  # (B, N, D)

        # 2. ä½ç½®ç¼–ç 
        pos_feat = self.position_encoder(points)  # (B, N, D)

        # 3. æ–¹å‘ç¼–ç 
        dir_feat = self.direction_encoder(normals)  # (B, N, D)

        # 4. èåˆ
        combined = pos_feat + dir_feat + local_feat

        # 5. æ³¨æ„åŠ›
        enhanced, attn_weights = self.attention(
            combined, combined, combined
        )  # (B, N, D), (B, N, N)

        # 6. Neural Varifoldè¡¨ç¤º
        nv_rep = enhanced  # (B, N, D)

        if task == 'feature':
            # è¿”å›ç‚¹äº‘çº§åˆ«ç‰¹å¾
            global_feat = self.global_pool(
                nv_rep.transpose(1, 2)
            ).squeeze(-1)  # (B, D)
            return global_feat, nv_rep

        elif task == 'classify':
            # åˆ†ç±»ä»»åŠ¡
            global_feat, _ = self.forward(
                points, normals, task='feature'
            )
            logits = self.classifier(global_feat)
            return logits

        elif task == 'match':
            # è¿”å›Neural Varifoldè¡¨ç¤º
            return nv_rep, attn_weights


class LocalFeatureExtractor(nn.Module):
    """å±€éƒ¨ç‰¹å¾æå–å™¨"""
    def __init__(self, input_dim, feature_dim):
        super().__init__()
        self MLP = nn.Sequential(
            nn.Linear(input_dim, 64),
            nn.ReLU(),
            nn.Linear(64, 128),
            nn.ReLU(),
            nn.Linear(128, feature_dim)
        )

    def forward(self, points):
        return self.MLP(points)


class PositionEncoder(nn.Module):
    """ä½ç½®ç¼–ç å™¨"""
    def __init__(self, input_dim, feature_dim):
        super().__init__()
        self.encoder = nn.Sequential(
            nn.Linear(input_dim, 64),
            nn.ReLU(),
            nn.Linear(64, feature_dim),
            nn.LayerNorm(feature_dim)
        )

    def forward(self, points):
        return self.encoder(points)


class DirectionEncoder(nn.Module):
    """æ–¹å‘ç¼–ç å™¨"""
    def __init__(self, normal_dim, feature_dim):
        super().__init__()
        self.encoder = nn.Sequential(
            nn.Linear(normal_dim, 64),
            nn.ReLU(),
            nn.Linear(64, feature_dim),
            nn.LayerNorm(feature_dim)
        )

    def forward(self, normals):
        return self.encoder(normals)
```

### 7.2 Varifoldè·ç¦»è®¡ç®—

```python
class VarifoldDistance(nn.Module):
    """
    Varifoldè·ç¦»è®¡ç®—æ¨¡å—
    """
    def __init__(self, sigma_pos=1.0, use_direction=True):
        super().__init__()
        self.sigma_pos = sigma_pos
        self.use_direction = use_direction

    def forward(self, nv1, nv2, points1, points2,
                 normals1=None, normals2=None):
        """
        è®¡ç®—ä¸¤ä¸ªNeural Varifoldçš„è·ç¦»

        å‚æ•°:
            nv1, nv2: Neural Varifoldè¡¨ç¤º (B, N, D), (B, M, D)
            points1, points2: ä½ç½® (B, N, 3), (B, M, 3)
            normals1, normals2: æ³•å‘é‡ (å¯é€‰)

        è¿”å›:
            distance: (B,) è·ç¦»
        """
        B, N, D = nv1.shape
        M = nv2.shape[1]

        # 1. è®¡ç®—ä½ç½®æ ¸
        # æ‰©å±•ç»´åº¦è¿›è¡Œå¹¿æ’­è®¡ç®—
        pos1_expanded = points1.unsqueeze(2)  # (B, N, 1, 3)
        pos2_expanded = points2.unsqueeze(1)  # (B, 1, M, 3)

        # æ¬§æ°è·ç¦»
        pos_dist = torch.sum(
            (pos1_expanded - pos2_expanded) ** 2, dim=-1
        )  # (B, N, M)

        # é«˜æ–¯æ ¸
        K_pos = torch.exp(-pos_dist / (2 * self.sigma_pos ** 2))

        # 2. è®¡ç®—æ–¹å‘æ ¸
        if self.use_direction and normals1 is not None:
            norm1_expanded = normals1.unsqueeze(2)  # (B, N, 1, 3)
            norm2_expanded = normals2.unsqueeze(1)  # (B, 1, M, 3)

            # ç‚¹ç§¯
            dot_product = torch.sum(
                norm1_expanded * norm2_expanded, dim=-1
            )  # (B, N, M)

            # ä½™å¼¦æ ¸ (æ­£éƒ¨)
            K_dir = torch.clamp(dot_product ** 2, min=0)
        else:
            K_dir = torch.ones_like(K_pos)

        # 3. ç»„åˆæ ¸
        K = K_pos * K_dir  # (B, N, M)

        # 4. è®¡ç®—å†…ç§¯
        # å¯¹Neural Varifoldç‰¹å¾è¿›è¡ŒåŠ æƒ
        nv1_norm = torch.norm(nv1, dim=-1, keepdim=True)  # (B, N, 1)
        nv2_norm = torch.norm(nv2, dim=-1, keepdim=True)  # (B, M, 1)

        # å†…ç§¯é¡¹
        inner = torch.sum(
            K * nv1_norm * nv2_norm.transpose(1, 2),
            dim=[1, 2]
        )  # (B,)

        # 5. è‡ªå†…ç§¯
        # K11
        K_pos_11 = torch.exp(-torch.sum(
            (points1.unsqueeze(2) - points1.unsqueeze(1)) ** 2, dim=-1
        ) / (2 * self.sigma_pos ** 2))

        if self.use_direction:
            K_dir_11 = torch.clamp(
                torch.bmm(normals1, normals1.transpose(1, 2)) ** 2,
                min=0
            )
            K_11 = K_pos_11 * K_dir_11
        else:
            K_11 = K_pos_11

        inner_11 = torch.sum(
            K_11 * (nv1_norm ** 2).transpose(1, 2),
            dim=[1, 2]
        )

        # K22
        K_pos_22 = torch.exp(-torch.sum(
            (points2.unsqueeze(2) - points2.unsqueeze(1)) ** 2, dim=-1
        ) / (2 * self.sigma_pos ** 2))

        if self.use_direction:
            K_dir_22 = torch.clamp(
                torch.bmm(normals2, normals2.transpose(1, 2)) ** 2,
                min=0
            )
            K_22 = K_pos_22 * K_dir_22
        else:
            K_22 = K_pos_22

        inner_22 = torch.sum(
            K_22 * (nv2_norm ** 2).transpose(1, 2),
            dim=[1, 2]
        )

        # 6. Varifoldè·ç¦»
        distance = torch.sqrt(
            inner_11 + inner_22 - 2 * inner + 1e-8
        )

        return distance


class ContrastiveLoss(nn.Module):
    """
    å¯¹æ¯”æŸå¤± (ç”¨äºè®­ç»ƒ)
    """
    def __init__(self, margin=1.0):
        super().__init__()
        self.margin = margin

    def forward(self, anchor, positive, negative):
        """
        ä¸‰å…ƒç»„æŸå¤±

        å‚æ•°:
            anchor: é”šç‚¹ç‰¹å¾ (B, D)
            positive: æ­£æ ·æœ¬ç‰¹å¾ (B, D)
            negative: è´Ÿæ ·æœ¬ç‰¹å¾ (B, D)

        è¿”å›:
            loss: æ ‡é‡
        """
        # L2è·ç¦»
        pos_dist = torch.norm(anchor - positive, dim=-1)
        neg_dist = torch.norm(anchor - negative, dim=-1)

        # å¯¹æ¯”æŸå¤±
        loss = F.relu(pos_dist - neg_dist + self.margin)

        return loss.mean()
```

### 7.3 è®­ç»ƒæµç¨‹

```python
import torch
from torch.utils.data import DataLoader

def train_neural_varifold(
    model, train_loader, val_loader,
    num_epochs=100, lr=0.001, device='cuda'
):
    """
    è®­ç»ƒNeural Varifoldæ¨¡å‹

    å‚æ•°:
        model: NeuralVarifoldNet
        train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
        val_loader: éªŒè¯æ•°æ®åŠ è½½å™¨
        num_epochs: è®­ç»ƒè½®æ•°
        lr: å­¦ä¹ ç‡
        device: è®¾å¤‡
    """
    model = model.to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
        optimizer, T_max=num_epochs
    )

    # æŸå¤±å‡½æ•°
    varifold_distance = VarifoldDistance().to(device)
    contrastive_loss = ContrastiveLoss(margin=1.0)

    best_val_acc = 0.0

    for epoch in range(num_epochs):
        # ===== è®­ç»ƒé˜¶æ®µ =====
        model.train()
        train_loss = 0.0

        for batch in train_loader:
            # batch: (anchor, positive, negative)
            anchor, positive, negative = batch

            anchor = anchor.to(device)  # (B, N, 6)
            positive = positive.to(device)
            negative = negative.to(device)

            # åˆ†ç¦»ä½ç½®å’Œæ³•å‘é‡
            anchor_xyz = anchor[..., :3]
            anchor_normal = anchor[..., 3:6]

            pos_xyz = positive[..., :3]
            pos_normal = positive[..., 3:6]

            neg_xyz = negative[..., :3]
            neg_normal = negative[..., 3:6]

            # å‰å‘ä¼ æ’­
            nv_anchor, _ = model(
                anchor_xyz, anchor_normal, task='match'
            )
            nv_pos, _ = model(
                pos_xyz, pos_normal, task='match'
            )
            nv_neg, _ = model(
                neg_xyz, neg_normal, task='match'
            )

            # è®¡ç®—è·ç¦»
            pos_dist = varifold_distance(
                nv_anchor, nv_pos,
                anchor_xyz, pos_xyz,
                anchor_normal, pos_normal
            )

            neg_dist = varifold_distance(
                nv_anchor, nv_neg,
                anchor_xyz, neg_xyz,
                anchor_normal, neg_normal
            )

            # å¯¹æ¯”æŸå¤±
            loss = F.relu(pos_dist - neg_dist + 1.0).mean()

            # åå‘ä¼ æ’­
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            train_loss += loss.item()

        train_loss /= len(train_loader)

        # ===== éªŒè¯é˜¶æ®µ =====
        if (epoch + 1) % 10 == 0:
            model.eval()
            val_acc = evaluate(model, val_loader, device)

            print(f"Epoch {epoch+1}/{num_epochs}")
            print(f"  Train Loss: {train_loss:.4f}")
            print(f"  Val Acc: {val_acc:.4f}")

            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_acc > best_val_acc:
                best_val_acc = val_acc
                torch.save(model.state_dict(), 'best_model.pth')

        scheduler.step()

    print(f"Training complete. Best Val Acc: {best_val_acc:.4f}")


def evaluate(model, data_loader, device):
    """
    è¯„ä¼°æ¨¡å‹ (åˆ†ç±»ä»»åŠ¡)
    """
    model.eval()
    correct = 0
    total = 0

    with torch.no_grad():
        for points, normals, labels in data_loader:
            points = points.to(device)
            normals = normals.to(device)
            labels = labels.to(device)

            # å‰å‘ä¼ æ’­
            logits = model(points, normals, task='classify')

            # é¢„æµ‹
            pred = logits.argmax(dim=-1)

            correct += (pred == labels).sum().item()
            total += labels.size(0)

    accuracy = correct / total
    return accuracy
```

---

## ğŸ¯ å­¦ä¹ è¦ç‚¹ä¸å¯ç¤º

### 8.1 æ–¹æ³•è®ºå±‚é¢

#### è¦ç‚¹1: å‡ ä½•ä¸å­¦ä¹ çš„å¹³è¡¡

```
çº¯å‡ ä½•æ–¹æ³•:
âœ“ æ•°å­¦ç†è®ºå®Œå¤‡
âœ“ å¯è§£é‡Šæ€§å¼º
âœ— æ³›åŒ–èƒ½åŠ›å¼±
âœ— æ‰‹å·¥ç‰¹å¾è®¾è®¡

çº¯æ·±åº¦å­¦ä¹ :
âœ“ è¡¨ç¤ºèƒ½åŠ›å¼º
âœ“ ç«¯åˆ°ç«¯ä¼˜åŒ–
âœ— å¯è§£é‡Šæ€§å¼±
âœ— éœ€è¦å¤§é‡æ•°æ®

Neural Varifolds:
âœ“ ä¿ç•™å‡ ä½•ç†è®º
âœ“ å­¦ä¹ èƒ½åŠ›å¼º
âœ“ æ•°æ®æ•ˆç‡é«˜
âœ“ å¯è§£é‡Šæ€§è¾ƒå¥½
```

#### è¦ç‚¹2: æµ‹åº¦è®ºåœ¨æ·±åº¦å­¦ä¹ ä¸­çš„åº”ç”¨

```
ä¼ ç»Ÿæµ‹åº¦ â†’ ç¥ç»æµ‹é‡
â”œâ”€â”€ å›ºå®šæƒé‡ â†’ å­¦ä¹ æƒé‡
â”œâ”€â”€ å›ºå®šæ ¸ â†’ å­¦ä¹ æ ¸
â”œâ”€â”€ éå‚æ•° â†’ å‚æ•°åŒ–
â””â”€â”€ ä¸å¯å¾® â†’ å¯å¾®åˆ†

ä¼˜åŠ¿:
â”œâ”€â”€ ç†è®ºä¿è¯
â”œâ”€â”€ æ¢¯åº¦ä¼ æ’­
â””â”€â”€ ç«¯åˆ°ç«¯å­¦ä¹ 
```

### 8.2 åº”ç”¨å±‚é¢

#### åº”ç”¨1: ç‚¹äº‘é…å‡†

```
æŒ‘æˆ˜:
â”œâ”€â”€ åˆå§‹ä½å§¿å·®
â”œâ”€â”€ éƒ¨åˆ†é‡å 
â””â”€â”€ å™ªå£°å¹²æ‰°

Neural Varifoldsä¼˜åŠ¿:
â”œâ”€â”€ é²æ£’çš„å‡ ä½•åº¦é‡
â”œâ”€â”€ å¯¹åˆå§‹åŒ–ä¸æ•æ„Ÿ
â””â”€â”€ ç«¯åˆ°ç«¯ä¼˜åŒ–
```

#### åº”ç”¨2: å½¢çŠ¶æ£€ç´¢

```
ä¼ ç»Ÿæ–¹æ³•:
â”œâ”€â”€ æ‰‹å·¥ç‰¹å¾åŒ¹é…
â”œâ”€â”€ é˜ˆå€¼éš¾ä»¥è°ƒä¼˜
â””â”€â”€ æ³›åŒ–èƒ½åŠ›å·®

Neural Varifolds:
â”œâ”€â”€ å­¦ä¹ ç›¸ä¼¼åº¦åº¦é‡
â”œâ”€â”€ è‡ªé€‚åº”ç‰¹å¾æƒé‡
â””â”€â”€ è·¨æ•°æ®é›†æ³›åŒ–
```

### 8.3 ç ”ç©¶èŒƒå¼å¯ç¤º

#### å¯ç¤º1: ç†è®ºæŒ‡å¯¼å®è·µ

```
æˆåŠŸè·¯å¾„:
ç†è®º (Varifolds) + å®è·µ (Deep Learning)
    â†“
Neural Varifolds

å…³é”®:
â”œâ”€â”€ ç†è®ºä¿è¯ä¸‹ç•Œ
â”œâ”€â”€ å­¦ä¹ ä¼˜åŒ–ä¸Šç•Œ
â””â”€â”€ å¯è§£é‡Šæ€§è´¯ç©¿
```

#### å¯ç¤º2: è·¨é¢†åŸŸèåˆ

```
é¢†åŸŸäº¤å‰:
æµ‹åº¦è®º + æ·±åº¦å­¦ä¹  + è®¡ç®—å‡ ä½•
    â†“
æ–°æ–¹æ³•

åˆ›æ–°æ¥æº:
â”œâ”€â”€ æ•°å­¦ç†è®º
â”œâ”€â”€ ç¥ç»ç½‘ç»œ
â”œâ”€â”€ å‡ ä½•å¤„ç†
â””â”€â”€ åº”ç”¨éœ€æ±‚
```

---

## ğŸ“ ä¸ªäººæ€è€ƒä¸æ‰©å±•

### 9.1 ä¼˜åŠ¿åˆ†æ

| ä¼˜åŠ¿ | è¯´æ˜ |
|:---|:---|
| **ç†è®ºæ‰å®** | åŸºäºVarifoldsæµ‹åº¦è®º |
| **è¡¨ç¤ºåŠ›å¼º** | ç¥ç»ç½‘ç»œå­¦ä¹ å¤æ‚ç‰¹å¾ |
| **é²æ£’æ€§é«˜** | å¯¹å™ªå£°å’Œé‡‡æ ·é²æ£’ |
| **å¯è§£é‡Š** | å‡ ä½•æ„ä¹‰æ˜ç¡® |
| **é€šç”¨æ€§** | é€‚ç”¨äºå¤šç§ä»»åŠ¡ |

### 9.2 å±€é™æ€§åˆ†æ

| å±€é™ | æ”¹è¿›æ–¹å‘ |
|:---|:---|
| **è®¡ç®—å¤æ‚åº¦** | O(NÂ²)æ ¸è®¡ç®— â†’ è¿‘ä¼¼ç®—æ³• |
| **æ³•å‘é‡ä¾èµ–** | è‡ªåŠ¨æ³•å‘é‡ä¼°è®¡æ¨¡å— |
| **è¶…å‚æ•°æ•æ„Ÿ** | è‡ªé€‚åº”å‚æ•°å­¦ä¹  |
| **è§„æ¨¡é™åˆ¶** | åˆ†å±‚å¤„ç†å¤§è§„æ¨¡ç‚¹äº‘ |

### 9.3 ç°ä»£æ‰©å±•æ–¹å‘

#### æ–¹å‘1: Transformerå¢å¼º

```python
# ç»“åˆTransformer
class TransformerNeuralVarifold(nn.Module):
    """Transformerå¢å¼ºçš„Neural Varifold"""
    def __init__(self, feature_dim, num_heads=8, num_layers=6):
        super().__init__()

        # Transformerç¼–ç å™¨
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=feature_dim,
            nhead=num_heads,
            dim_feedforward=feature_dim * 4
        )

        self.transformer = nn.TransformerEncoder(
            encoder_layer,
            num_layers=num_layers
        )

        # Neural Varifoldå¤´
        self.nv_head = NeuralVarifoldEncoder(feature_dim)

    def forward(self, points, normals):
        # 1. Transformerç¼–ç 
        # 2. Neural Varifoldè¡¨ç¤º
        # 3. è¾“å‡º
        pass
```

#### æ–¹å‘2: åˆ†å±‚è¡¨ç¤º

```python
# å¤šå°ºåº¦Neural Varifolds
class HierarchicalNeuralVarifold(nn.Module):
    """åˆ†å±‚Neural Varifold"""
    def __init__(self):
        super().__init__()

        # å¤šå°ºåº¦ç¼–ç å™¨
        self.scale1 = NVEncoder(scale='fine')
        self.scale2 = NVEncoder(scale='medium')
        self.scale3 = NVEncoder(scale='coarse')

        # èåˆ
        self.fusion = MultiScaleFusion()

    def forward(self, points, normals):
        # å„å°ºåº¦è¡¨ç¤º
        nv1 = self.scale1(points, normals)
        nv2 = self.scale2(points, normals)
        nv3 = self.scale3(points, normals)

        # èåˆ
        nv_fused = self.fusion(nv1, nv2, nv3)

        return nv_fused
```

#### æ–¹å‘3: è¿å»ºæ£€æµ‹åº”ç”¨

```
è¿ç§»åˆ°è¿å»ºæ£€æµ‹:

ç›¸ä¼¼ç‚¹:
â”œâ”€â”€ 3Dç‚¹äº‘å¤„ç†
â”œâ”€â”€ å‡ ä½•ç‰¹å¾åˆ†æ
â””â”€â”€ å˜åŒ–æ£€æµ‹

æ”¹é€ æ–¹æ¡ˆ:
â”œâ”€â”€ æ ‘æœ¨ç‚¹äº‘ â†’ å»ºç­‘ç‚¹äº‘
â”œâ”€â”€ è‡ªç„¶æ³•å‘é‡ â†’ å¹³é¢æ³•å‘é‡
â”œâ”€â”€ è‡ªç”±æ›²é¢ â†’ è§„åˆ™å¹³é¢
â””â”€â”€ ç”Ÿé•¿å˜åŒ– â†’ å»ºè®¾å˜åŒ–

å…·ä½“å®ç°:
â”œâ”€â”€ æå–å»ºç­‘å¹³é¢ç‰¹å¾
â”œâ”€â”€ Varifoldåº¦é‡å»ºç­‘ç›¸ä¼¼åº¦
â”œâ”€â”€ æ—¶åºå¯¹æ¯”æ£€æµ‹å˜åŒ–
â””â”€â”€ è¿è§„åˆ¤æ–­
```

### 9.4 ä»£ç å®ç°æ”¹è¿›

```python
# 1. æ›´é«˜æ•ˆçš„æ ¸è®¡ç®—
class EfficientVarifoldKernel(nn.Module):
    """é«˜æ•ˆVarifoldæ ¸è®¡ç®—"""
    def __init__(self):
        super().__init__()

        # ä½¿ç”¨éšæœºç‰¹å¾è¿‘ä¼¼
        self.random_features = nn.Parameter(
            torch.randn(128, 3),  # 128ä¸ªéšæœºæ–¹å‘
            requires_grad=False
        )

    def forward(self, points1, points2):
        # éšæœºç‰¹å¾æ–¹æ³•åŠ é€Ÿæ ¸è®¡ç®—
        # ä»O(NÂ²)é™åˆ°O(N*k)
        pass

# 2. è‡ªé€‚åº”æ³•å‘é‡ä¼°è®¡
class AdaptiveNormalEstimation(nn.Module):
    """è‡ªé€‚åº”æ³•å‘é‡ä¼°è®¡"""
    def __init__(self):
        super().__init__()

        # å¯å­¦ä¹ çš„é‚»åŸŸé€‰æ‹©
        self.neighborhood_net = nn.Sequential(
            nn.Linear(3, 32),
            nn.ReLU(),
            nn.Linear(32, 1),
            nn.Sigmoid()
        )

    def forward(self, points):
        # å­¦ä¹ æ¯ä¸ªç‚¹çš„æœ€ä¼˜é‚»åŸŸ
        # åŸºäºé‚»åŸŸä¼°è®¡æ³•å‘é‡
        pass

# 3. ä¸ç¡®å®šæ€§é‡åŒ–
class UncertaintyAwareNV(nn.Module):
    """ä¸ç¡®å®šæ€§æ„ŸçŸ¥çš„Neural Varifold"""
    def __init__(self):
        super().__init__()

        # é¢„æµ‹å‡å€¼å’Œæ–¹å·®
        self.mean_encoder = ...
        self.var_encoder = ...

    def forward(self, points, normals):
        # é¢„æµ‹ä¸ç¡®å®šæ€§
        # åŠ æƒVarifoldè·ç¦»
        pass
```

---

## ğŸ”— ç›¸å…³è®ºæ–‡æ¨è

### å‰ç½®é˜…è¯»

1. **[1-04] å˜åˆ†æ³•åŸºç¡€ Mumford-Shahä¸ROF**
   - å˜åˆ†æ³•ç†è®ºåŸºç¡€

2. **[2-15] 3Dæ ‘æœ¨åˆ†å‰²å›¾å‰²**
   - ä¼ ç»Ÿç‚¹äº‘å¤„ç†æ–¹æ³•

### åç»­é˜…è¯»

1. **[2-31] ç‚¹äº‘ç¥ç»è¡¨ç¤ºè¡¥å……**
   - æœ¬è®ºæ–‡çš„è¡¥å……ç‰ˆæœ¬

2. **[2-11] 3Dæ£€æµ‹æ–°èŒƒå¼ CornerPoint3D**
   - 3Dè§†è§‰åº”ç”¨

3. **[3-02] å¼ é‡CURåˆ†è§£LoRA**
   - å¼ é‡è¡¨ç¤ºå­¦ä¹ 

---

## âœ… ç²¾è¯»æ£€æŸ¥æ¸…å•

### ç†è§£ç¨‹åº¦è‡ªè¯„

- [ ] **ç†è®ºç†è§£**: Varifoldsæµ‹åº¦è®ºåŸºç¡€
- [ ] **æ–¹æ³•ç†è§£**: ç¥ç»ç¼–ç å™¨è®¾è®¡
- [ ] **å…¬å¼æ¨å¯¼**: å¯å¾®åˆ†è·ç¦»è®¡ç®—
- [ ] **ä»£ç å®ç°**: æ ¸å¿ƒæ¨¡å—å®ç°
- [ ] **åº”ç”¨è¿ç§»**: è¿å»ºæ£€æµ‹æ€è·¯

### å…³é”®é—®é¢˜

1. **ä¸ºä»€ä¹ˆéœ€è¦Neural Varifoldsï¼Ÿ**
   - ä¼ ç»ŸVarifoldsä¸å¯å­¦ä¹ 
   - æ·±åº¦å­¦ä¹ ç¼ºä¹å‡ ä½•çº¦æŸ
   - ç»“åˆä¸¤è€…ä¼˜åŠ¿

2. **å¦‚ä½•å®ç°å¯å¾®åˆ†åŒ–ï¼Ÿ**
   - ç¥ç»ç½‘ç»œç¼–ç å™¨
   - è¿ç»­çš„æ ¸å‡½æ•°
   - ç«¯åˆ°ç«¯æ¢¯åº¦ä¼ æ’­

3. **å¦‚ä½•åº”ç”¨åˆ°è¿å»ºæ£€æµ‹ï¼Ÿ**
   - å»ºç­‘å‡ ä½•ç‰¹å¾
   - æ—¶åºå˜åŒ–åº¦é‡
   - Varifoldç›¸ä¼¼åº¦

---

## ğŸ“š å‚è€ƒèµ„æº

### ç†è®ºåŸºç¡€

- **æµ‹åº¦è®º**: Real Analysis by Royden
- **å˜åˆ†æ³•**: Calculus of Variations by Gelfand
- **é»æ›¼å‡ ä½•**: Differential Geometry by do Carmo

### ä»£ç èµ„æº

- **PointNet++**: GitHub/charlesq34/pointnet2
- **PyTorch3D**: Facebook PyTorch3Dåº“
- **Kaolin**: NVIDIA 3Dæ·±åº¦å­¦ä¹ åº“

---

**ç²¾è¯»å®Œæˆæ—¶é—´**: 2026å¹´2æœˆ7æ—¥
**è®ºæ–‡åœ°ä½**: â˜…â˜…â˜…â˜…â˜… (TPAMIé¡¶åˆŠï¼Œå¿…è¯»)
**åç»­è·Ÿè¿›**: [2-31] ç‚¹äº‘ç¥ç»è¡¨ç¤ºè¡¥å……

---

*æœ¬ç²¾è¯»ç¬”è®°åŸºäºXiaohao Caiç­‰äººçš„IEEE TPAMI 2022è®ºæ–‡*
*é‡ç‚¹å…³æ³¨: Neural Varifoldsç†è®ºã€ç‚¹äº‘è¡¨ç¤ºå­¦ä¹ ã€å‡ ä½•æ·±åº¦å­¦ä¹ *
