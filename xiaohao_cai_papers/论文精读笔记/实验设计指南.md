# 实验设计指南

> **创建日期**: 2026年2月9日
> **范围**: 计算机视觉与机器学习实验设计
> **基于**: Xiaohao Cai师门83篇论文的实验设计规范

---

## 目录

1. [实验设计原则](#实验设计原则)
2. [数据集选择](#数据集选择)
3. [评估指标](#评估指标)
4. [对比实验设计](#对比实验设计)
5. [消融实验设计](#消融实验设计)
6. [统计分析方法](#统计分析方法)
7. [实验报告模板](#实验报告模板)

---

## 实验设计原则

### 核心原则

```
可复现性 → 公平对比 → 全面评估 → 充分消融
```

### 实验设计流程

```
研究问题 → 假设提出 → 实验设计 → 数据收集 → 实验执行 → 结果分析 → 结论
```

### 实验类型矩阵

| 实验类型 | 目的 | 设计要点 |
|----------|------|----------|
| **主要实验** | 验证方法有效性 | 标准数据集+SOTA对比 |
| **消融实验** | 分析各组件贡献 | 单变量控制 |
| **泛化实验** | 验证跨域能力 | 多数据集测试 |
| **效率实验** | 评估计算开销 | 时间/空间/参数量 |
| **鲁棒性实验** | 测试抗干扰能力 | 噪声/扰动测试 |

---

## 数据集选择

### 分割任务数据集

| 数据集 | 类型 | 图像数 | 类别数 | 特点 | 适用场景 |
|--------|------|--------|--------|------|----------|
| **BSDS500** | 自然图像 | 500 | - | 边缘标注 | 通用分割 |
| **PASCAL VOC** | 自然图像 | 10k+ | 20 | 物体分割 | 语义分割 |
| **ISIC 2018** | 医学图像 | 2000+ | 2 | 皮肤病变 | 医学分割 |
| **BRATS** | 医学图像 | 300+ | 3 | 脑肿瘤 | 3D医学分割 |
| **Synapse** | 医学图像 | 1000+ | 8 | 多器官CT | 多器官分割 |
| **COCO** | 自然图像 | 120k+ | 80 | 实例分割 | 实例分割 |

### 点云数据集

| 数据集 | 点云数 | 类别数 | 任务 | 特点 |
|--------|--------|--------|------|------|
| **ModelNet40** | 12311 | 40 | 分类 | CAD模型 |
| **ShapeNet** | 51135 | 55 | 分类/检索 | 多样物体 |
| **FAUST** | 100 | 10 | 形状匹配 | 人体扫描 |
| **ScanNet** | 1500+ | 20 | 语义分割 | 室内场景 |
| **KITTI** | - | - | 检测 | 自动驾驶 |

### 小样本学习数据集

| 数据集 | 基类 | 新类 | 样本数 | 特点 |
|--------|------|------|--------|------|
| **miniImageNet** | 64 | 16 | 100 | 标准基准 |
| **tieredImageNet** | 351 | 97 | 1000+ | 大规模 |
| **CUB-200** | 150 | 50 | - | 细粒度 |

### 数据集划分标准

```python
数据集划分规范 = {
    "通用划分": {
        "训练集": "70%",
        "验证集": "15%",
        "测试集": "15%"
    },
    "医学图像": {
        "训练集": "60%",
        "验证集": "20%",
        "测试集": "20%",
        "注意": "患者级别划分,避免数据泄露"
    },
    "小样本学习": {
        "基类(训练)": "70%",
        "新类(测试)": "30%"
    }
}
```

---

## 评估指标

### 分割指标

```python
class SegmentationMetrics:
    """分割评估指标"""

    @staticmethod
    def iou(pred, target):
        """交并比"""
        intersection = (pred & target).sum()
        union = (pred | target).sum()
        return intersection / (union + 1e-8)

    @staticmethod
    def dice(pred, target):
        """Dice系数"""
        intersection = (pred & target).sum()
        return (2. * intersection) / (pred.sum() + target.sum() + 1e-8)

    @staticmethod
    def hausdorff_distance(pred, target, percentile=95):
        """Hausdorff距离 (HD95)"""
        from scipy.spatial.distance import directed_hausdorff

        # 获取边界点
        pred_points = np.argwhere(pred)
        target_points = np.argwhere(target)

        # 计算双向Hausdorff距离
        d1 = directed_hausdorff(pred_points, target_points)[0]
        d2 = directed_hausdorff(target_points, pred_points)[0]

        # 返回最大值的百分位
        return max(d1, d2)

    @staticmethod
    def average_surface_distance(pred, target):
        """平均表面距离(ASD)"""
        from scipy.spatial.distance import cdist

        pred_points = np.argwhere(pred)
        target_points = np.argwhere(target)

        # 计算距离矩阵
        distances = cdist(pred_points, target_points)

        # 双向平均距离
        d1 = distances.min(axis=1).mean()
        d2 = distances.min(axis=0).mean()

        return (d1 + d2) / 2

    @staticmethod
    def pixel_accuracy(pred, target):
        """像素准确率"""
        correct = (pred == target).sum()
        total = pred.numel()
        return correct / total
```

### 检测指标

```python
class DetectionMetrics:
    """检测评估指标"""

    @staticmethod
    def ap(precisions, recalls):
        """平均精度"""
        # 计算PR曲线下的面积
        return np.trapz(precisions, recalls)

    @staticmethod
    def mean_ap(aps):
        """mAP"""
        return np.mean(aps)

    @staticmethod
    def precision_recall(pred_boxes, gt_boxes, iou_threshold=0.5):
        """精确率和召回率"""
        tp, fp, fn = 0, 0, 0

        for pred, gt in zip(pred_boxes, gt_boxes):
            if len(pred) == 0 and len(gt) == 0:
                continue
            elif len(pred) == 0:
                fn += len(gt)
            elif len(gt) == 0:
                fp += len(pred)
            else:
                # 计算IoU矩阵
                iou_matrix = compute_iou_matrix(pred, gt)

                # 匹配
                matched = iou_matrix.max(axis=1) > iou_threshold
                tp += matched.sum()
                fp += (~matched).sum()
                fn += max(0, len(gt) - matched.sum())

        precision = tp / (tp + fp + 1e-8)
        recall = tp / (tp + fn + 1e-8)

        return precision, recall
```

### 生成质量指标

```python
class GenerationMetrics:
    """生成质量评估指标"""

    @staticmethod
    def fid(real_images, generated_images, model):
        """Fréchet Inception Distance"""
        import scipy.linalg

        # 提取特征
        real_feat = model.extract_features(real_images)
        gen_feat = model.extract_features(generated_images)

        # 计算均值和协方差
        mu1, sigma1 = real_feat.mean(axis=0), np.cov(real_feat, rowvar=False)
        mu2, sigma2 = gen_feat.mean(axis=0), np.cov(gen_feat, rowvar=False)

        # 计算FID
        ssdiff = np.sum((mu1 - mu2)**2)
        covmean = scipy.linalg.sqrtm(sigma1.dot(sigma2))

        if np.iscomplexobj(covmean):
            covmean = covmean.real

        fid = ssdiff + np.trace(sigma1 + sigma2 - 2 * covmean)
        return fid

    @staticmethod
    def inception_score(images, model):
        """Inception Score"""
        # 计算条件边缘分布的KL散度
        preds = model.predict(images)

        # 计算IS
        kl = preds * (np.log(preds) - np.log(np.mean(preds, axis=0)))
        kl = np.mean(np.sum(kl, axis=1))
        is_score = np.exp(kl)

        return is_score
```

### 效率指标

```python
class EfficiencyMetrics:
    """效率评估指标"""

    @staticmethod
    def count_parameters(model):
        """统计参数量"""
        total = sum(p.numel() for p in model.parameters())
        trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)
        return {
            "total": total,
            "trainable": trainable,
            "percentage": trainable / total * 100
        }

    @staticmethod
    def count_flops(model, input_shape):
        """计算FLOPs"""
        from thop import profile

        input_tensor = torch.randn(input_shape)
        flops, params = profile(model, inputs=(input_tensor,))
        return flops

    @staticmethod
    def measure_inference_time(model, input_tensor, iterations=100):
        """测量推理时间"""
        # 预热
        for _ in range(10):
            _ = model(input_tensor)

        # 计时
        torch.cuda.synchronize() if torch.cuda.is_available() else None
        start = time.time()

        for _ in range(iterations):
            _ = model(input_tensor)

        torch.cuda.synchronize() if torch.cuda.is_available() else None
        end = time.time()

        avg_time = (end - start) / iterations
        fps = 1 / avg_time

        return {"avg_time": avg_time, "fps": fps}
```

---

## 对比实验设计

### 对比方法选择矩阵

| 方法类型 | 代表方法 | 选择标准 |
|----------|----------|----------|
| **传统方法** | Graph Cuts, Random Walker | 验证理论优势 |
| **经典深度学习** | U-Net, DeepLab | 验证架构改进 |
| **最新SOTA** | SAM, SegFormer | 验证前沿竞争 |
| **领域专用** | 医学/3D专用方法 | 验证领域适应 |

### 对比实验表格模板

```markdown
| 方法 | Backbone | IoU↑ | Dice↑ | HD95↓ | ASD↓ | 参数量 | FLOPs |
|------|----------|------|-------|-------|-------|--------|-------|
| Graph Cuts | - | 65.2 | 78.5 | 12.3 | 3.2 | - | - |
| U-Net | ResNet50 | 78.5 | 85.2 | 8.7 | 2.1 | 31M | 152G |
| DeepLabV3+ | ResNet101 | 81.2 | 87.6 | 7.5 | 1.8 | 58M | 287G |
| **Ours** | Swin-B | **83.7** | **89.3** | **6.8** | **1.5** | 88M | 198G |
```

### 公平对比原则

```python
公平对比检查清单 = {
    "数据集": "使用相同的训练/验证/测试划分",
    "预处理": "使用相同的数据增强和归一化",
    "训练设置": "相同的学习率、批次大小、优化器",
    "评估协议": "使用标准评估指标和数据划分",
    "硬件": "报告使用的硬件配置",
    "随机种子": "固定随机种子确保可复现",
    "重复次数": "至少3次实验报告均值和标准差"
}
```

---

## 消融实验设计

### 单变量消融

| 变量 | 设置1 | 设置2 | 设置3 | 目的 |
|------|-------|-------|-------|------|
| 主干网络 | ResNet-50 | ResNet-101 | Swin-T | 验证架构影响 |
| 损失函数 | CE | Dice | CE+Dice | 验证损失设计 |
| 注意力 | 无 | Self | Cross | 验证注意力作用 |
| 跳跃连接 | 无 | 普通 | Attention | 验证跳跃连接 |

### 递进消融

```python
递进消融实验设计 = {
    "基线": "基础U-Net",
    "基线+模块A": "验证模块A的贡献",
    "基线+模块A+模块B": "验证模块B的额外贡献",
    "基线+模块A+模块B+模块C": "验证模块C的额外贡献",
    "完整模型": "所有模块的组合效果"
}
```

### 消融实验报告

```markdown
| 配置 | IoU | Δ | Dice | Δ |
|------|-----|---|------|---|
| 基线 | 78.5 | - | 85.2 | - |
| + 注意力 | 80.3 | +1.8 | 86.7 | +1.5 |
| + 深层监督 | 81.7 | +1.4 | 87.9 | +1.2 |
| + 损失加权 | 82.4 | +0.7 | 88.4 | +0.5 |
| **完整模型** | **83.7** | **+1.3** | **89.3** | **+0.9** |
```

---

## 统计分析方法

### 显著性检验

```python
from scipy.stats import ttest_ind, mannwhitneyu

def statistical_test(method1_scores, method2_scores, test_type='ttest'):
    """
    统计显著性检验

    Args:
        method1_scores: 方法1的得分列表
        method2_scores: 方法2的得分列表
        test_type: 'ttest' 或 'mannwhitney'

    Returns:
        statistic: 统计量
        p_value: p值
    """
    if test_type == 'ttest':
        statistic, p_value = ttest_ind(method1_scores, method2_scores)
    elif test_type == 'mannwhitney':
        statistic, p_value = mannwhitneyu(
            method1_scores, method2_scores, alternative='two-sided'
        )

    return statistic, p_value

# 使用示例
scores_ours = [83.2, 83.5, 83.8, 83.1, 83.6]
_scores_baseline = [81.5, 81.8, 81.2, 81.6, 81.4]

stat, p_value = statistical_test(scores_ours, scores_baseline)

print(f"Statistic: {stat:.4f}")
print(f"P-value: {p_value:.4f}")
print(f"Significant: {'Yes' if p_value < 0.05 else 'No'}")
```

### 置信区间计算

```python
import numpy as np
from scipy.stats import t

def confidence_interval(data, confidence=0.95):
    """
    计算置信区间

    Args:
        data: 数据列表
        confidence: 置信水平

    Returns:
        (mean, lower, upper): 均值和置信区间
    """
    data = np.array(data)
    n = len(data)
    mean = np.mean(data)
    std_err = np.std(data, ddof=1) / np.sqrt(n)

    # t分布临界值
    t_critical = t.ppf((1 + confidence) / 2, n - 1)

    margin = t_critical * std_err

    return mean, mean - margin, mean + margin

# 使用示例
scores = [83.2, 83.5, 83.8, 83.1, 83.6]
mean, lower, upper = confidence_interval(scores)

print(f"Mean: {mean:.2f}")
print(f"95% CI: [{lower:.2f}, {upper:.2f}]")
```

---

## 实验报告模板

### 实验报告结构

```markdown
# 实验: [实验名称]

## 1. 实验目的
- [ ] 验证什么假设
- [ ] 评估什么指标

## 2. 实验设置
### 2.1 数据集
- 数据集名称
- 训练/验证/测试划分
- 数据增强策略

### 2.2 实现细节
- 框架: PyTorch 2.0
- 硬件: 4× NVIDIA A100
- 超参数配置

### 2.3 评估指标
- 主要指标
- 次要指标

## 3. 主要结果
### 3.1 对比实验
[表格]

### 3.2 消融实验
[表格]

## 4. 分析与讨论
### 4.1 性能分析
### 4.2 失败案例分析
### 4.3 可视化结果

## 5. 结论
```

### 结果可视化规范

```python
import matplotlib.pyplot as plt
import seaborn as sns

def plot_comparison(results_dict):
    """
    绘制方法对比图

    Args:
        results_dict: {method_name: {'mean': x, 'std': y}}
    """
    methods = list(results_dict.keys())
    means = [results_dict[m]['mean'] for m in methods]
    stds = [results_dict[m]['std'] for m in methods]

    # 设置风格
    sns.set_style("whitegrid")
    plt.figure(figsize=(10, 6))

    # 绘制柱状图
    bars = plt.bar(methods, means, yerr=stds, capsize=5,
                    color='steelblue', alpha=0.8)

    # 标注数值
    for bar, mean in zip(bars, means):
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + bar.get_y(),
                 f'{mean:.1f}', ha='center', va='bottom')

    plt.ylabel('Score', fontsize=12)
    plt.title('Method Comparison', fontsize=14)
    plt.ylim(0, 100)
    plt.tight_layout()
    plt.savefig('comparison.png', dpi=300)
```

---

## 附录

### 常用数据集下载命令

```bash
# BSDS500
wget https://github.com/afcarl/benchmark/releases/download/v1.0/BSDS500.zip

# PASCAL VOC
wget http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar

# ISIC 2018
# 从官网申请下载: https://challenge.isic-archive.com/

# ModelNet40
wget https://shapenet.cs.stanford.edu/media/modelnet40_ply_hdf5_2048.zip

# miniImageNet
wget https://github.com/boyu-ai/Hands-on-Meta-Learning/raw/master/miniimagenet.zip
```

### 评估代码库

```python
# 推荐评估库
评估库推荐 = {
    "分割": "segmentation_models_pytorch",
    "检测": "pycocotools",
    "点云": "MinkowskiEngine, torch-points3d",
    "生成": "pytorch-fid, inception_score",
    "统计": "scipy, statsmodels"
}
```

---

*文档创建时间: 2026年2月9日*
*基于: Xiaohao Cai 师门论文实验设计规范*
