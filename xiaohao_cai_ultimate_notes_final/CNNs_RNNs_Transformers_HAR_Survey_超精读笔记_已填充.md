# CNNsã€RNNsä¸Transformeråœ¨äººä½“åŠ¨ä½œè¯†åˆ«ä¸­çš„ç»¼åˆç»¼è¿°

> **è¶…ç²¾è¯»ç¬”è®°** | 5-Agentè¾©è®ºåˆ†æç³»ç»Ÿ
> åˆ†ææ—¶é—´ï¼š2026-02-16
> ä½œè€…ï¼šKhaled Alomar, Halil Ibrahim Aysel, Xiaohao Cai
> æ¥æºï¼šUniversity of Southampton (2024)

---

## ğŸ“„ è®ºæ–‡å…ƒä¿¡æ¯

| å±æ€§ | ä¿¡æ¯ |
|------|------|
| **æ ‡é¢˜** | CNNs, RNNs and Transformers in Human Action Recognition: A Survey and a Hybrid Model |
| **ä½œè€…** | Khaled Alomar, Halil Ibrahim Aysel, Xiaohao Cai |
| **å¹´ä»½** | 2024 |
| **arXiv ID** | 2407.06162 |
| **æœºæ„** | University of Southampton |
| **é¢†åŸŸ** | è®¡ç®—æœºè§†è§‰ã€æ·±åº¦å­¦ä¹ ã€ç»¼è¿° |
| **ç±»å‹** | ç»¼è¿°è®ºæ–‡ + æ–¹æ³•è®ºæ–‡ |

### ğŸ“ æ‘˜è¦ç¿»è¯‘

æœ¬æ–‡ç³»ç»Ÿç»¼è¿°äº†å·ç§¯ç¥ç»ç½‘ç»œ(CNN)ã€å¾ªç¯ç¥ç»ç½‘ç»œ(RNN)å’ŒTransformeråœ¨äººä½“åŠ¨ä½œè¯†åˆ«(HAR)ä¸­çš„åº”ç”¨ä¸å‘å±•ã€‚é¦–å…ˆæ¢³ç†äº†ä¸‰ç±»æ¶æ„çš„æ•°å­¦åŸºç¡€å’Œæ¼”è¿›å†ç¨‹ï¼Œç„¶åæå‡ºäº†CNN-ViTæ··åˆæ¶æ„ï¼šä½¿ç”¨TimeDistributed 2D-CNNæå–ç©ºé—´ç‰¹å¾ï¼ŒVision Transformerå»ºæ¨¡æ—¶åºä¾èµ–ã€‚å®éªŒè¡¨æ˜æ··åˆæ¶æ„åœ¨KTHæ•°æ®é›†ä¸Šè¾¾åˆ°97.89%å‡†ç¡®ç‡ï¼Œä¼˜äºçº¯CNNæˆ–çº¯ViTæ–¹æ³•ã€‚æœ¬æ–‡ä¸ºHARé¢†åŸŸçš„ç ”ç©¶è€…æä¾›äº†å…¨é¢çš„æŠ€æœ¯å‚è€ƒå’Œå®ç”¨çš„æ··åˆæ–¹æ¡ˆã€‚

**å…³é”®è¯**: åŠ¨ä½œè¯†åˆ«ã€CNNã€RNNã€Transformerã€æ··åˆæ¶æ„ã€ç»¼è¿°

---

## ğŸ¯ ä¸€å¥è¯æ€»ç»“

æœ¬æ–‡å…¨é¢ç»¼è¿°HARé¢†åŸŸçš„ä¸‰ç±»æ·±åº¦å­¦ä¹ æ–¹æ³•ï¼Œå¹¶æå‡ºå®ç”¨çš„CNN-ViTæ··åˆæ¶æ„å®ç°æ›´ä¼˜æ€§èƒ½ã€‚

---

## ğŸ”‘ æ ¸å¿ƒåˆ›æ–°ç‚¹

1. **å…¨é¢ç»¼è¿°**ï¼šç³»ç»Ÿæ¢³ç†CNNã€RNNã€Transformerä¸‰ç±»æ¶æ„
2. **æ··åˆæ¶æ„**ï¼šCNNç©ºé—´ç‰¹å¾ + ViTæ—¶åºå»ºæ¨¡
3. **æ•°å­¦åŸºç¡€**ï¼šæä¾›ä¸‰ç±»æ¶æ„çš„ç»Ÿä¸€æ•°å­¦è¡¨è¿°
4. **å®éªŒéªŒè¯**ï¼šæ··åˆæ¶æ„åœ¨KTHä¸Šè¾¾åˆ°97.89%

---

## ğŸ“Š èƒŒæ™¯ä¸åŠ¨æœº

### HARé—®é¢˜çš„æ•°å­¦å½¢å¼åŒ–

```
å®šä¹‰:
- è§†é¢‘åºåˆ—: V = {f_1, f_2, ..., f_T}, f_t âˆˆ R^(HÃ—WÃ—C)
- åŠ¨ä½œæ ‡ç­¾: y âˆˆ Y, Y = {a_1, a_2, ..., a_K}

ç›®æ ‡: å­¦ä¹ æ˜ å°„å‡½æ•° f: V* â†’ Y
```

### ç©ºé—´-æ—¶åºåˆ†è§£

```
ç©ºé—´ç‰¹å¾: S_t = g_s(f_t), g_s: R^(HÃ—WÃ—C) â†’ R^d_s
æ—¶åºç‰¹å¾: T = g_t({S_1, ..., S_T}), g_t: (R^d_s)^T â†’ R^d_t
åˆ†ç±»: y = g_c(T), g_c: R^d_t â†’ Y
```

### ä¸‰ç±»æ¶æ„å¯¹æ¯”

| ç»´åº¦ | CNN | RNN | ViT |
|-----|-----|-----|-----|
| å±€éƒ¨ç‰¹å¾ | âœ“ | âœ— | âœ— |
| å…¨å±€ä¾èµ– | âœ— | âœ“ | âœ“ |
| å‚æ•°æ•ˆç‡ | âœ“ | â–³ | âœ— |
| é•¿åºåˆ—å»ºæ¨¡ | âœ— | âœ“ | âœ“ |
| è¿ç§»å­¦ä¹  | âœ“ | âœ— | â–³ |

---

## ğŸ’¡ æ–¹æ³•è¯¦è§£ï¼ˆå«å…¬å¼æ¨å¯¼ï¼‰

### 3.1 CNNçš„æ•°å­¦è¡¨è¾¾

**2Då·ç§¯**ï¼š

```
Y[i,j] = Î£_m Î£_n X[i+m, j+n] Â· K[m,n]
```

**3Då·ç§¯**ï¼š

```
Y[i,j,k] = Î£_m Î£_n Î£_p X[i+m, j+n, k+p] Â· K[m,n,p]
```

### 3.2 RNNçš„æ•°å­¦è¡¨è¾¾

**Vanilla RNN**ï¼š

```
h_t = tanh(W_h h_{t-1} + W_x x_t + b)
```

**LSTM**ï¼š

```
f_t = Ïƒ(W_f h_{t-1} + U_f x_t + b_f)  # é—å¿˜é—¨
i_t = Ïƒ(W_i h_{t-1} + U_i x_t + b_i)  # è¾“å…¥é—¨
o_t = Ïƒ(W_o h_{t-1} + U_o x_t + b_o)  # è¾“å‡ºé—¨
cÌƒ_t = tanh(W_c h_{t-1} + U_c x_t + b_c)  # å€™é€‰å€¼
c_t = f_t âŠ™ c_{t-1} + i_t âŠ™ cÌƒ_t  # ç»†èƒçŠ¶æ€
h_t = o_t âŠ™ tanh(c_t)  # éšè—çŠ¶æ€
```

### 3.3 Transformerçš„æ•°å­¦è¡¨è¾¾

**è‡ªæ³¨æ„åŠ›**ï¼š

```
Q = X W_Q, K = X W_K, V = X W_V
Attention(Q,K,V) = softmax(QK^T / âˆšd_k) V
```

**å¤šå¤´æ³¨æ„åŠ›**ï¼š

```
MultiHead(Q,K,V) = Concat(head_1, ..., head_h) W_O
```

**ä½ç½®ç¼–ç **ï¼š

```
PE_{(pos, 2i)} = sin(pos/10000^(2i/d))
PE_{(pos, 2i+1)} = cos(pos/10000^(2i/d))
```

### 3.4 CNN-ViTæ··åˆæ¶æ„

```
ç©ºé—´ç»„ä»¶(2D-CNN):
z_i = p_Î¸(X_i), i = 1, ..., N

æ—¶é—´ç»„ä»¶(ViT):
è¾“å…¥: Z = {z_1, ..., z_N}
ä½ç½®ç¼–ç : Z'_i = z_i + PE(i)

è‡ªæ³¨æ„åŠ›: A(Q,K,V) = softmax(QK^T/âˆšd_k)V
è¾“å‡º: z = Agg(Z')

åˆ†ç±»: y = Softmax(W_c z + b_c)
```

---

## ğŸ§ª å®éªŒä¸ç»“æœ

### KTHæ•°æ®é›†ç»“æœ

| æ¨¡å‹ | 12å¸§ | 18å¸§ | 24å¸§ |
|-----|------|------|------|
| CNN | 94.35% | 93.91% | 93.49% |
| ViT | 92.44% | 92.82% | 93.69% |
| Hybrid | 94.12% | 94.56% | 95.78% |
| **Hybrid(pre)** | **96.34%** | **97.13%** | **97.89%** |

**å…³é”®å‘ç°**ï¼š
- CNN: é•¿åºåˆ—æ€§èƒ½ä¸‹é™
- ViT: é•¿åºåˆ—æ€§èƒ½æå‡
- Hybrid: å§‹ç»ˆæœ€ä¼˜ï¼Œé¢„è®­ç»ƒæå‡æ˜¾è‘—

### ä¸SOTAå¯¹æ¯”

| æ–¹æ³• | KTHå‡†ç¡®ç‡ |
|-----|----------|
| Sahoo et al. (2020) | 97.67% |
| Jaouedi et al. (2020) | 96.30% |
| Basha et al. (2022) | 96.53% |
| **Hybrid(pre)** | **97.89%** |

---

## ğŸ“ˆ æŠ€æœ¯æ¼”è¿›è„‰ç»œ

```
ç¬¬ä¸€ä»£: CNNç‰¹å¾ + æ‰‹å·¥æ—¶åºç‰¹å¾
  â†“ æ‰‹å·¥ç‰¹å¾æå–
ç¬¬äºŒä»£: CNN + RNN/LSTM
  â†“ RNNæ—¶åºå»ºæ¨¡
ç¬¬ä¸‰ä»£: Two-Stream CNN
  â†“ RGB + å…‰æµåŒè·¯
ç¬¬å››ä»£: 3D CNN (C3D, I3D)
  â†“ ç›´æ¥3Då·ç§¯
ç¬¬äº”ä»£: CNN + Transformer
  â†“ æ··åˆæ¶æ„ (æœ¬æ–‡)
```

---

## ğŸ”— ä¸Šä¸‹æ¸¸å…³ç³»

### ä¸Šæ¸¸ä¾èµ–

- **2D-CNN**ï¼šResNet, MobileNetç­‰backbone
- **Transformer**ï¼šViTæ¶æ„è®¾è®¡
- **æ³¨æ„åŠ›æœºåˆ¶**ï¼šè‡ªæ³¨æ„åŠ›ç†è®º

### ä¸‹æ¸¸å½±å“

- ä¸ºHARé¢†åŸŸæä¾›æ··åˆæ¶æ„æ€è·¯
- ä¿ƒè¿›CNNå’ŒTransformerçš„èåˆç ”ç©¶

---

## âš™ï¸ å¯å¤ç°æ€§åˆ†æ

### æ··åˆæ¶æ„å‚æ•°

| ç»„ä»¶ | å‚æ•° | å€¼ |
|-----|------|-----|
| CNN backbone | - | MobileNet/VGG/ResNet |
| ViT heads | - | 8 |
| ViT layers | - | 1 |
| ä¼˜åŒ–å™¨ | - | Adam |
| å­¦ä¹ ç‡ | - | 1e-4 |

### æ–¹æ³•è®ºå¯¹æ¯”çŸ©é˜µ

| ç»´åº¦ | CNN | RNN | ViT | Hybrid |
|-----|-----|-----|-----|--------|
| å±€éƒ¨ç‰¹å¾ | âœ“ | âœ— | âœ— | âœ“ |
| å…¨å±€ä¾èµ– | âœ— | âœ“ | âœ“ | âœ“ |
| å‚æ•°æ•ˆç‡ | âœ“ | â–³ | âœ— | â–³ |
| è®­ç»ƒé€Ÿåº¦ | âœ“ | âœ— | âœ— | â–³ |
| é•¿åºåˆ—å»ºæ¨¡ | âœ— | âœ“ | âœ“ | âœ“ |
| è¿ç§»å­¦ä¹  | âœ“ | âœ— | â–³ | âœ“ |

---

## ğŸ“š å…³é”®å‚è€ƒæ–‡çŒ®

1. Simonyan & Zisserman. "Two-Stream Convolutional Networks for Action Recognition." NIPS 2014.
2. Vaswani et al. "Attention Is All You Need." NeurIPS 2017.
3. Dosovitskiy et al. "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale." ICLR 2021.

---

## ğŸ’» ä»£ç å®ç°è¦ç‚¹

```python
import tensorflow as tf
from tensorflow.keras import layers, models

class CNNViTHybrid(tf.keras.Model):
    def __init__(self, cnn_backbone='mobilenet_v2', num_frames=12, num_classes=6):
        super().__init__()
        self.num_frames = num_frames

        # CNNç»„ä»¶(ç©ºé—´ç‰¹å¾æå–)
        if cnn_backbone == 'mobilenet_v2':
            base_cnn = tf.keras.applications.MobileNetV2(
                include_top=False,
                weights='imagenet',
                input_shape=(224, 224, 3),
                pooling='avg'
            )
        self.cnn = layers.TimeDistributed(base_cnn, name='spatial_cnn')

        # ViTç»„ä»¶(æ—¶åºå»ºæ¨¡)
        self.vit = self.build_vit_block(num_frames, 1280)

        # åˆ†ç±»å™¨
        self.classifier = layers.Dense(num_classes, activation='softmax')

    def build_vit_block(self, seq_len, dim):
        """æ„å»ºViTå—"""
        inputs = layers.Input(shape=(seq_len, dim))

        # ä½ç½®ç¼–ç 
        positions = layers.Embedding(input_dim=seq_len, output_dim=dim)(tf.range(seq_len))
        x = layers.Add()([inputs, positions])

        # å¤šå¤´è‡ªæ³¨æ„åŠ›
        attn_output = layers.MultiHeadAttention(
            num_heads=8, key_dim=dim//8
        )(x, x)
        x = layers.Add()([x, attn_output])
        x = layers.LayerNormalization()(x)

        # å‰é¦ˆç½‘ç»œ
        ffn = layers.Dense(dim*4, activation='gelu')(x)
        ffn = layers.Dense(dim)(ffn)
        x = layers.Add()([x, ffn])
        x = layers.LayerNormalization()(x)

        # å…¨å±€å¹³å‡æ± åŒ–
        x = layers.GlobalAveragePooling1D()(x)

        return models.Model(inputs, x)

    def call(self, inputs, training=False):
        # CNNç‰¹å¾æå–
        cnn_features = self.cnn(inputs)  # (batch, frames, dim)

        # ViTæ—¶åºå»ºæ¨¡
        aggregated = self.vit(cnn_features)

        # åˆ†ç±»
        outputs = self.classifier(aggregated)

        return outputs
```

---

## ğŸŒŸ åº”ç”¨ä¸å½±å“

### åº”ç”¨ä»·å€¼

1. **å­¦æœ¯ä»·å€¼**
   - ç³»ç»Ÿæ€§æ¢³ç†HARæŠ€æœ¯æ¼”è¿›
   - æä¾›ä¸‰ç±»æ¶æ„çš„ç»Ÿä¸€æ¡†æ¶
   - æå‡ºå®ç”¨çš„æ··åˆæ–¹æ¡ˆ

2. **å·¥ç¨‹ä»·å€¼**
   - æ˜“äºå®ç°çš„æ··åˆæ¶æ„
   - å¯å¤ç”¨çš„ä»£ç æ¡†æ¶
   - å¹³è¡¡æ€§èƒ½ä¸å¤æ‚åº¦

### é€‚ç”¨åœºæ™¯

- **æ™ºèƒ½ç›‘æ§**ï¼šå®æ—¶è§†é¢‘åˆ†æ
- **ä½“è‚²åˆ†æ**ï¼šåŠ¨ä½œè¯†åˆ«ä¸è¯„ä¼°
- **äººæœºäº¤äº’**ï¼šæ‰‹åŠ¿/å§¿æ€è¯†åˆ«

---

## â“ æœªè§£é—®é¢˜ä¸å±•æœ›

### ç»¼è¿°çš„å±€é™æ€§

1. **æ•°æ®é›†å•ä¸€**ï¼šä»…KTHæ•°æ®é›†éªŒè¯
2. **ç†è®ºåˆ†æä¸è¶³**ï¼šç¼ºå°‘æ³›åŒ–ç•Œåˆ†æ
3. **è®¡ç®—æˆæœ¬**ï¼šæœªè¯¦ç»†è®¨è®ºæ¨ç†æˆæœ¬

### æœªæ¥æ–¹å‘

1. **å¤§è§„æ¨¡éªŒè¯**ï¼šåœ¨Kineticsç­‰å¤§æ•°æ®é›†ä¸Šæµ‹è¯•
2. **è‡ªç›‘ç£å­¦ä¹ **ï¼šæ¢ç´¢æ›´å¥½çš„é¢„è®­ç»ƒç­–ç•¥
3. **è½»é‡åŒ–**ï¼šæ¨¡å‹å‹ç¼©ç”¨äºè¾¹ç¼˜è®¾å¤‡
4. **å¯è§£é‡Šæ€§**ï¼šç†è§£æ¨¡å‹å†³ç­–è¿‡ç¨‹

---

## ğŸ“ åˆ†æç¬”è®°

```
ä¸ªäººç†è§£ï¼š

1. æœ¬æ–‡çš„ç»¼è¿°ä»·å€¼ï¼š
   - å…¨é¢è¦†ç›–ä¸‰ç±»ä¸»æµæ¶æ„
   - æ¸…æ™°çš„æ•°å­¦å½¢å¼åŒ–
   - ç³»ç»Ÿçš„æ–¹æ³•è®ºå¯¹æ¯”

2. æ··åˆæ¶æ„çš„è®¾è®¡æ€æƒ³ï¼š
   - CNNæ“…é•¿å±€éƒ¨ç©ºé—´ç‰¹å¾
   - ViTæ“…é•¿å…¨å±€æ—¶åºå»ºæ¨¡
   - ç»“åˆä¸¤è€…ä¼˜åŠ¿

3. å®éªŒäº®ç‚¹ï¼š
   - Hybrid(pre)è¾¾åˆ°97.89%
   - é¢„è®­ç»ƒå¸¦æ¥æ˜¾è‘—æå‡
   - é•¿åºåˆ—è¡¨ç°ç¨³å®š

4. å·¥ç¨‹å®ç”¨æ€§ï¼š
   - æ¶æ„æ¸…æ™°æ˜“å®ç°
   - å¯çµæ´»æ›¿æ¢ç»„ä»¶
   - é€‚åˆå®é™…éƒ¨ç½²

5. æ”¹è¿›æ–¹å‘ï¼š
   - æ·»åŠ æ›´å¤šæ•°æ®é›†éªŒè¯
   - æ¢ç´¢å…¶ä»–æ··åˆæ–¹å¼
   - ç ”ç©¶è½»é‡åŒ–æ–¹æ¡ˆ
```

---

## ç»¼åˆè¯„åˆ†

| ç»´åº¦ | è¯„åˆ† | è¯´æ˜ |
|------|------|------|
| ç»¼è¿°å…¨é¢æ€§ | â˜…â˜…â˜…â˜…â˜… | è¦†ç›–ä¸‰ç±»æ¶æ„æ¼”è¿› |
| æ–¹æ³•åˆ›æ–° | â˜…â˜…â˜…â˜†â˜† | æ··åˆæ¶æ„å®ç”¨ |
| å®éªŒéªŒè¯ | â˜…â˜…â˜…â˜†â˜† | å•ä¸€æ•°æ®é›† |
| å®ç”¨ä»·å€¼ | â˜…â˜…â˜…â˜…â˜† | æ˜“äºå®ç° |
| å†™ä½œè´¨é‡ | â˜…â˜…â˜…â˜…â˜† | ç»“æ„æ¸…æ™° |

**æ€»åˆ†ï¼šâ˜…â˜…â˜…â˜…â˜† (4.0/5.0)**

---

*æœ¬ç¬”è®°ç”±5-Agentè¾©è®ºåˆ†æç³»ç»Ÿç”Ÿæˆï¼Œç»“åˆäº†å¤šæ™ºèƒ½ä½“ç²¾è¯»æŠ¥å‘Šå†…å®¹ã€‚*
