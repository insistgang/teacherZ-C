A Bilevel Formalism for the Peer-Reviewing Problem
Gennaro Auricchioa;*, Ruixiao Zhangb, Jie Zhanga and Xiaohao Caib
aDepartment of Computer Science, University of Bath
bSchool of Electronic and Computer Science, University of Southampton
Abstract.
Due to the large number of submissions that more and
more conferences experience, finding an automatized way to well
distribute the submitted papers among reviewers has become nec-
essary. We model the peer-reviewing matching problem as a bilevel
programming (BP) formulation. Our model consists of a lower-level
problem describing the reviewers’ perspective and an upper-level
problem describing the editors’. Every reviewer is interested in min-
imizing their overall effort, while the editors are interested in finding
an allocation that maximizes the quality of the reviews and follows
the reviewers’ preferences the most. To the best of our knowledge,
the proposed model is the first one that formulates the peer-reviewing
matching problem by considering two objective functions, one to de-
scribe the reviewers’ viewpoint and the other to describe the editors’
viewpoint. We demonstrate that both the upper-level and lower-level
problems are feasible and that our BP model admits a solution under
mild assumptions. After studying the properties of the solutions, we
propose a heuristic to solve our model and compare its performance
with the relevant state-of-the-art methods. Extensive numerical re-
sults show that our approach can find fairer solutions with competi-
tive quality and less effort from the reviewers.1
1
Introduction
The peer-review process is the procedure followed by scientific jour-
nals to establish the novelty and correctness of research papers sub-
mitted for publication [27, 19]. The principle behind this process is
simple. Once the editors of a journal receive a submission, they in-
vite a sufficient number of reviewers to review it and, depending on
the reviewers’ reports, the editors decide whether the paper meets
the criteria for publication or not. To make this process meaningful,
there must be a concordance between the topic of the paper and the
expertise of the reviewers, ensuring both the authors of the paper and
the editors that the reviewers are competent on the topics discussed
in the paper. Although the peer-review procedure has been proven to
be reliable for scientific journals, it shows some flaws when applied
to large conferences. In this case, all authors need to submit their
papers by a specified deadline, after which all the submitted papers
will be allocated to some reviewers by the editors. Since most con-
ferences have only one submission deadline per year, all the papers
are submitted in a few days; consequently, the editors need to handle
a large number of papers at the same time. In particular, the editors
have to determine the allocation hastily since this allocation process
needs to respect the tight schedule of the conference.
∗Corresponding Author. Email: ga647@bath.ac.uk
1 Our code website: https://github.com/Galaxy-ZRX/Bilevel-Review.
Due to the large number of papers the editors usually receive and
the lack of time, the allocation process becomes unaffordable through
classic means. To meet this need for time efficiency, several autom-
atized ways to determine a peer-reviewer allocation have been pro-
posed. As we will detail in the related work below, the vast majority
of the approaches assume that the best peer-reviewing matching is
the minimum/maximum of a suitable objective function. This allows
rephrasing the whole problem as an optimization problem whose ob-
jective encodes an appealing property that the peer-reviewing allo-
cation should have. Albeit every model finds an allocation following
its own criterion, all the models tacitly assume that the editors are
the agents that actively decide the allocation. This is limiting for two
reasons. One is that the efficiency of these methods is bound to how
accurate the computation of the objective function is; the other is that
reviewers are often allowed to interfere in the assignment procedure
by refusing to review some papers or by bidding for them.
To represent the interplays between different agents (i.e., editors
and reviewers), we propose and study a model that phrases the peer-
reviewing allocation problem through a bilevel programming (BP)
formulation. Bilevel optimization has been proven to be a valuable
expedient to describe several allocation problems in a multi-agent
framework, such as the ones concerning resource allocation [32],
traffic engineering [6], genomic problems [4], and Knapsack Prob-
lems [8]. The appeal of BP problems lies in the fact that relating the
solutions of different optimization problems well captures how the
choice of one agent affects the others. For a complete discussion on
the BP problems, we refer the reader to [7].
Related Work. At its core, finding a peer-reviewing matching is
a matching problem for indivisible goods. Matching problems were
first introduced in the first half of the twenty century by Hitchcock
[16] and Kantorovich [20]. Ever since they were introduced, this
class of problems found several different applications, such as sta-
ble marriage [17, 26], workers and job matching [11, 29], resource
allocation [13, 31], and biomedical data analysis [2].
It was observed that the first attempt at modeling the peer-
reviewing process as a matching problem dates back to 2007; and
then an integer linear programming (ILP) model was proposed,
whose solution is an allocation minimizing the possible complaints
of the reviewers. This was done with or without considering the re-
viewers’ expertise [15]. In [14, 24], the authors improved this model
by searching for a fair allocation, i.e., an allocation that equalizes
every reviewers’ payoff as much as possible. In [14], this is accom-
plished by maximizing the minimum of the reviewers’ payoffs, while
in [24], the authors try to implement classic social inequality func-
tions, such as the Gini’s social evaluation function. Another similar
approach is taken in [9], where the authors proposed a new cate-
arXiv:2307.12248v1  [cs.MA]  23 Jul 2023
gory of matching problems, called diverse matching problems. De-
spite the differences of those models, they all share the idea that
the optimal peer-reviewing allocation is characterizable as the mini-
mum/maximum of an objective function over a suitable restricted set
of matching. Moreover, all these routines are able to detect a solution
without gathering data from the reviewers. Indeed, all the objective
functions used by these procedures are assumed to be known a priori
or to be computable through machine learning means using data from
open-access sites, such as Google Scholar. These concepts are also
at the base of the Toronto Paper Matching System (TPMS) [5] – one
of the most credited and used peer-reviewing matching procedures.
Paper Outline. In Section 2, we briefly review the classic ILP
model for the peer-reviewing matching problem. In Section 3, we in-
troduce our BP model for the peer-reviewing matching problem. We
describe and study the upper-level problem (ULp) and lower-level
problem (LLp) of our formulation and give a set of conditions that
ensure the existence of a solution. In Section 4, a heuristic solution is
introduced to our BP model and its performance compared with the
ones obtained by the relevant state-of-the-art. The results show that
our model can find quasi-optimal solutions that are much fairer than
the classic ones. Finally, we conclude in Section 5 and outline some
future research directions. Due to space limit, we report the proofs of
the proposed statements, the discussion on the Secondary Variational
Problem, and additional numerical results in the Appendix.
2
Maximum Edge-weighted Matching formulation
In this section, we recall the ILP model on which the TPMS is based
[5]. Throughout the paper, we denote with Bnm the set of n × m
binary matrices. Given A, B ∈Bnm, we say that A ≤B if ai,j ≤
bi,j, ∀i ∈[n], j ∈[m], where [ℓ] denotes the set containing the first
ℓnatural numbers, i.e., [ℓ] := {1, 2, 3, . . . , ℓ}.
In mathematical terms, peer-reviewing matching can be described
as the solution of a maximum edge-weighted matching problem over
a bipartite graph G. The two sides of the bipartite graph G are com-
posed of the set of papers P = [n] and the set of reviewers R = [m].
The bipartite graph is therefore given by G = ([n] ∪[m], [n] × [m])
and any matrix X ∈Bnm describes a possible papers allocation.
Following the classic conventions, the edge (i, j) is active, i.e.,
Xi,j = 1, if and only if paper i is allocated to reviewer j.
Since the editors have to ensure a certain amount of reviews for
every paper and no reviewer can be overburdened with papers to re-
view, every feasible matching has to comply with some restriction
that bounds the number of active edges connected to every vertex
of the bipartite graph. The linear objective function of the problem
is determined by the edge weight matrix W = {wi,j}(i,j)∈G. The
weight wi,j of the edge (i, j) represents the expected quality of the
review that paper i receives from reviewer j, hence we refer to the
matrix W as the quality matrix. In this framework, the optimal peer-
reviewing matching is characterized as the solution of the maximum
edge-weighted matching problem induced by the quality matrix W
over the bipartite graph G, since it describes the matching maximiz-
ing the overall quality of the reviews. We below detail the constraints
the editors must comply with and how the matrix W is determined.
Problem Constraints.
We have two sets of constraints, one for
each side of the bipartite graph. Their role is to regulate the number
of reviews that every paper receives and to limit the number of re-
views that every reviewer can be asked to perform. In detail, the con-
straints are as follows. (i) The set of constraints that is imposed over
the set of reviewers is P
i∈[n] Xi,j ≤Uj, ∀j ∈[m]. To do so, we
restrict the number of papers the editors can assign to each reviewer.
The value Uj is therefore the maximum number of papers that can
be allocated to reviewer j. (ii) The set of constraints that is imposed
over the set of papers is li ≤P
j∈[m] Xi,j ≤ui, ∀i ∈[n]. To do so,
we bound the editors to assign every paper i to at least li and at most
ui reviewers. (iii) We assume every paper is indivisible, imposed by
the restriction X ∈Bnm. Finally, the optimal peer-reviewing assign-
ment is retrieved by solving the following ILP problem.
Problem 1 Given n, m ∈N, and a quality matrix W, the classic
ILP model for the peer-reviewing assignment is
max
X∈Bnm⟨W, X⟩,
s.t.
li ≤
X
j∈[m]
Xi,j ≤ui,
X
i∈[n]
Xi,j ≤Uj,
where the constraints hold for every i ∈[n] and j ∈[m] and ⟨·, ·⟩is
the scalar product in the Euclidean space.
It is easy to see that, as long as li ≤ui, ∀i ∈[n] and P
i∈[n] li ≤
P
j∈[m] Uj, Problem 1 is well-defined and admits a solution [12].
Quality Matrix W and Its Role.
Determining a meaningful qual-
ity matrix W is of key importance for every allocation method based
on the ILP model described in Problem 1. For this reason, retriev-
ing a quality matrix W that reliably represents the expertise of the
reviewers is still a topic of study and discussion.
One way to retrieve the matrix W is to associate every paper and
reviewer to a set of labels that summarizes the contents and the fields
of expertise, respectively. Since both the contents of the paper and
the fields of expertise are drawn from the same set of topics, it is
possible to represent these labels as vectors over an r dimensional
space, where r is the total number of possible topics. If we denote
with vpi the vector describing the topics of the paper i and with vrj
the expertise vector of reviewer j, we can then compute the quality
of the review performed by reviewer j on paper i as the scalar prod-
uct between vpi and vrj, [28]. This metric does make sense since
the more the vectors are aligned, the higher will be their scalar prod-
uct. Moreover, if all the vectors have only positive entries, all the
scalar products will return a positive value. Since there is no canoni-
cal way to represent papers and reviewers in an r dimensional space,
this method highly depends on what embedding we use to translate
papers and reviewers into vectors. Usually, the embedding is deter-
mined through neural network structures that use data reported from
the reviewer or available from sites on the internet (such as Google
Scholar [5]). Despite the remarkable results obtained by those pro-
cedures, it is a common belief that evaluating the quality of a review
only from the publication records of the reviewer is limiting [5]. In-
deed, these models do not consider other factors that are instead re-
lated to the effort the reviewer would put in reviewing the paper, such
as personal interest, personal conflict, or even time at the disposal.
3
Bilevel Formulation of the Assignment Problem
In this section, we first introduce our BP formulation for the peer-
reviewing matching problem, followed by studying the LLp and ULp
and showing that our model admits a solution under mild conditions.
We then highlight the relationship between our model and the classic
literature. Throughout the paper, we assume that the editor in charge
is just one person.
3.1
Bilevel Programming Model
Given a set of papers P = [n] and a set of reviewers R = [m], we
define our BP peer-reviewing matching problem as follows.
Problem 2 Given li, ui and Uj as in Section 2, we consider the
following problem:
max
Z,X∈Bnm
⟨WE, X⟩+ ⟨Y ∗, X⟩
s.t.
li ≤P
j∈[m] Xi,j ≤ui,
P
i∈[n] Xi,j ≤Uj,
P
i∈[n] Zi,j = Uj + ϕj,
X ≤E −Z + Y ∗,
Y ∗
j ∈argmin
Yj∈Bn
⟨(WR)j, Yj⟩,
P
i∈[n] Yi,j = Uj,
and
0 ≤Yj ≤Zj,
(1)
where E is a n × m matrix whose entries are all equal to 1. We
denote with WE the n × m matrix describing the qualities of all
the possible reviews from the editor’s point of view, with WR the
n × m matrix describing the reviewers’ efforts, and with ϕj ∈N
the number of papers that the reviewers can refuse to review. Finally,
since we assume that every reviewer bids independently, the LLp is a
component-wise minimization, i.e., Y ∗is the matrix whose columns
minimize the function Y:,j →⟨(WR):,j, Y:,j⟩.
In Table 1, we report the variables of our model and their meaning.
Remark 1 It is well-known that every BP problem describes a
Stackelberg game [30, 25], and this is no exception. In our case,
the leader is the editor who proposes Z to the followers, which are
the reviewers. Afterwards, the reviewers report a vector Y according
to their preferences. Every couple (Z, Y ) uniquely defines a maxi-
mum edge-weighted matching problem, whose objective value corre-
sponds to the payoff of the editor2. Notice that the BP formulation
we introduced is also equivalent to the following three-phase pro-
cedure. First, the editor proposes a set of papers, described by the
vector Zj, to every reviewer j. Second, the reviewers select a set Yj
out of the set Zj. The vector Yj represents the papers that reviewer j
would review if asked. Finally, the editor gathers the replies of all the
reviewers and searches for a papers-reviewers allocation that maxi-
mizes the quality and matches the reports given by the reviewers as
much as possible. For this reason, given any feasible triplet to prob-
lem (1), namely (X, Y, Z), we refer to Z as the editor’s proposal,
to Y as the reviewers’ bidding, and to X as the final assignment. A
graphical description of this procedure is also given in Figure 1.
As in the previous model, we assume that the editor aims to max-
imize the quality of the peer-reviewing matching. In our case, how-
ever, both the objective function and the constraints of the problem
depend on the reviewers’ biddings, i.e., the solution of the LLp. The
influence that the LLp has on both the objective function and the set
of feasible matching of the ULp is the way in which we model the
interaction between the reviewers and the editor.
Remark 2 (The effort matrix WR and its role) To describe the re-
viewers’ point of view, we introduce a matrix WR that assigns an
effort value to every reviewer-paper couple. When the number of pa-
pers is small, it is possible to retrieve WR by directly asking the
reviewers. As an alternative, we can build a proxy version of WR
using machine learning. Indeed, there are machine learning methods
2 If the couple (Z, Y ) leads to an unfeasible problem, the payoff is −∞. The
reviewers’ payoff is the total effort of the papers they bid for.
Table 1.
List of variables and parameters used in our BP model.
li
minimal number of reviews needed by paper i
ui
maximal number of reviews needed by paper i
Uj
number of papers that reviewer j bids for and maximum number
of papers that j may review
Zj
vector describing the set of papers proposed to reviewer j
Yj
vector describing the set of papers that reviewer j bids for
Y ∗
j
vector that minimizes reviewer j’s effort
X
final allocation decided by the editor
ϕj
degree of freedom of reviewer j
WE
quality matrix from the editor’s point of view
WR
reviewers’ effort matrix
able to find a complete preference order over a set of papers by only
having a partial declaration of preferences [5]. In previous models
these values were used to enhance the quality matrix WE by refining
the values that are less accurate due to a lack of information about
the reviewer. Instead, in our model, we use the preference order to
describe the criterion used by the reviewer during the bidding phase.
3.2
Lower-Level Problem
We now consider the LLp, which captures the reviewers’ point of
view. We first describe the objective function and the constraints, and
then we show that the LLp has a solution and study its properties.
3.2.1
Reviewer’s Objective Function
Once the reviewers receive the editor’s proposal Z, they have to bid
for part of the papers proposed and report their bidding to the editor.
In the following, we denote with Yj the j-th column of the matrix Y ,
so that Yj = Y:,j. Similarly, (WR)j and Zj denote the j-th column
of the matrices WR and Z, respectively. We model the interests of the
reviewers through a linear objective function that evaluates the effort
required by every reviewer j to review a set of papers Yj. In this
framework, the bidding criterion adopted by reviewer j is captured
by the minimization of the objective function Yj →⟨(WR)j, Yj⟩.
Every entry of the reviewers’ effort vector ((WR)j)i describes how
much effort reviewer j would spend to review paper i. To make the
model meaningful, we assume that each entry of the vector (WR)j
is positive, which means that reviewing is never effortless.
3.2.2
Reviewer’s Constraints
Every reviewer j has to comply with two sets of constraints. Since re-
viewers are anonymous to each other, we assume that the constraints
imposed on one reviewer do not depend on the constraints imposed
on other reviewers. Thus, we describe the constraints only for a fixed
reviewer, namely j. To impose the indivisibility of the reviews, every
Yj is assumed to have binary entries. Finally, the set of constraints
with which the reviewers have to comply is as follows. (i) The consis-
tency constraint, that is Yj ≤Zj, where Zj is the proposal advanced
by the editor; this constraint imposes that every reviewer cannot bid
for a paper that does not belong to the pool that the editor proposed.
(ii) The quantity constraint, that is P
i∈[n] Yi,j = Uj; this constraint
forces every reviewer to bid for Uj papers. Since the review effort is
always non-negative, imposing the quantity constraint is equivalent
to imposing the following constraint P
i∈[n] Yi,j ≥Uj.
L1
L2
L3
L4
L5
R1
R2
R3
R4
R5
R6
R7
(a) The initial complete
bipartite graph.
L1
L2
L3
L4
L5
R1
R2
R3
R4
R5
R6
R7
(b) The graph describing
the proposal Z of the ed-
itor.
L1
L2
L3
L4
L5
R1
R2
R3
R4
R5
R6
R7
(c) The graph describing
the bidding of the review-
ers Y .
L1
L2
L3
L4
L5
R1
R2
R3
R4
R5
R6
R7
(d) The graph on which
the editor solves the final
matching problem.
Figure 1.
An example of the allocation procedure described by our BP problem. In (1a), we have the complete bipartite graph. The left side contains the
papers, while the right side contains the reviewers. Reviewers R6, R4 and R2 have to review at most 1 paper, while the other reviewers have to review at most
2. All reviewers have a degree of freedom ϕj equal to 1. In (1b), we report in blue the editor’s proposal Z done by the editor, while the dotted lines represent the
edges that have not been proposed by the editor. In (1c), we report in red the edges the reviewers’ bidding Y , while the blue dotted lines represent the reviews
that the reviewers have declined. Finally, in (1d), we report the final graph on which the editor has to solve a maximum edge-weighted matching problem.
Uniqueness of the Solution and the Equivalence Result.
To con-
clude, we study the solution of the LLp. As we will see, the set of
conditions needed to ensure the uniqueness of the solution and the
equivalence with the relaxed problem is natural to assume.
Lemma 1 Given two integers 0 < a < b, and let {wk}k=1,...,b
be a set of positive and increasingly ordered real values, i.e., 0 ≤
w1 ≤· · · ≤wa ≤wa+1 ≤· · · ≤wb. If xi ∈[0, 1], ∀i ∈[b] and
Pb
i=1 xi = a, then it holds Pa
i=1 wi ≤Pb
i=1 wixi.
We now prove that the ILP problem in the LLp is equivalent to the
LP problem obtained by relaxing the constraint Yj ∈{0, 1}.
Theorem 1 For any given Z ∈Bmn, the LP problem
Y ∗∈argmin
0≤Y ≤Z
⟨W, Y ⟩,
s.t.
X
i∈[n]
Yi,j = Uj,
(2)
and the ILP problem
bY ∈
argmin
Y ∈Bmn,Y ≤Z
⟨W, Y ⟩,
s.t.
X
i∈[n]
Yi,j = Uj,
(3)
attain the same optimal value, i.e., ⟨W, Y ∗⟩= ⟨W, bY ⟩. Moreover, if
∀j ∈[m], the set {Wi,j : (i, j) s.t. Zij = 1} does not contain two
equal values, then the solution is unique and satisfies bY ∈Bmn, i.e.,
Problems (2) and (3) are equivalent.
Notice that the hypothesis of Theorem 3 is satisfied whenever ev-
ery reviewer has a strict preference order over the set of papers. Fi-
nally, we show that minimizing the component-wise reviewers’ effort
is the same as minimizing the global reviewers’ effort.
Theorem 2 For every given Z, Y is a solution of the LLp if and only
if Y minimizes the function Y →P
i∈[n]
P
j∈[m](WR)i,jYi,j under
the constraints P
i∈[n] Yi,j −Uj ≥0 and Zi,j −Yi,j ≥0.
3.3
Upper-Level Problem
We now consider the ULp, which is the problem that captures the
editor’s point of view. We first describe the role of both the objective
function and the constraints, and then we show that the solution to
the ULp problem always exists under mild assumptions.
3.3.1
The Editor’s Objective Function
In our model, the editor needs to find an allocation that maximizes a
linear objective function, described by the matrix WE and the scalar
product of the variables X and Y . While ⟨WE, X⟩represents the
quality of matching X, the scalar product between X and Y de-
scribes how much the final assignment X meets the reviewers’ bid-
ding Y . We, therefore, define the following quantity.
Definition 1 Given a solution (X, Y, Z) to the BP Problem 2, we
define its Accordance Percentage as AC(X, Y, Z) := ⟨X,Y ⟩
⟨X,X⟩.
By
definition,
we
have
AC(X, Y, Z)
∈
[0, 1]
and
AC(X, Y, Z) = 1 if and only if X ≤Y , i.e. if and only if every
reviewer receives only papers they bid for. If AC(X, Y, Z) = 1
holds, we say that the solution (X, Y, Z) is perfect.
3.3.2
The editor’s constraints
In our model, the editor controls two variables, Z and X. Both Z and
X are n × m binary matrices that are subject to two different sets of
constraints below.
Constraints over Z.
We require the proposal Z to comply with
only one set of constraints, which we call freedom constraint. The
role of these constraints is to determine the number of papers the
editor has to propose to every reviewer. In mathematical terms, this
means that P
i∈[n] Zi,j = Uj + ϕj, ∀j ∈[m], where the constants
ϕj ≥0 are the degrees of freedom. In fact, since the reviewer j has
to bid for Uj papers, the parameter ϕj corresponds to the number of
papers that the reviewer can refuse to review.
Constraints over X.
The final assignment X has to comply with
the constraints as follows. (i) The feasibility constraints, that is,
li ≤P
j∈[m] Xi,j ≤ui, ∀i ∈[n] and P
i∈[n] Xi,j ≤Uj, ∀j ∈[m].
These constraints bound the editor to assign every paper i to a num-
ber of reviewers between li and ui and to assign at most Uj re-
views to every reviewer j. (ii) The consistency constraint, that is
X ≤E −Z + Y ∗, where Y ∗is the solution to the LLp and Z
is the editor’s proposal. This constraint bounds the editor to assign a
paper to a reviewer only if the reviewer has not refused it before.
The Solutions of the ULp
In the previous section, we proved that
the LLp admits a solution, regardless of what the editor proposes. As
the next example shows, the same does not hold for the ULp.
Example 1 Let us consider the case in which we have three papers,
namely p1, p2, and p3, and two reviewers, namely r1 and r2. We
assume every paper needs exactly one review (i.e., li = ui = 1)
and that every reviewer can be asked to review at most 2 papers
(i.e., Uj = 2). Finally, we assume that WR is defined as WR =
11
10
1
3
2
1

. Both reviewers have the same preference order over
the set of papers, i.e., p1 > p2 > p3. It is then easy to see that, if
ϕ1, ϕ2 > 0, no reviewer will give its consensus to review paper p3,
making the ULP, and hence the whole BP problem, unfeasible.
Example 1 points out that allowing the reviewers to review or
refuse too many papers leads to an unsolvable problem in some
pathological cases. In fact, if we ask the second reviewer to review
only one paper, that is U2 = 1, the BP problem described in Example
1 becomes feasible. In general, the editor can ensure the existence of
a solution to Problem 2 by tuning the parameters of the problem.
Theorem 3 If, in addition to the assumptions that make Problem 2
feasible, it holds maxj∈[m] ϕj + 2 maxj∈[m] Uj ≤n, then there
exists a feasible triplet to Problem 1. In particular, under these as-
sumptions, Problem 1 has a solution.
Notice that whenever the number of papers n is large enough, the
hypothesis of Theorem 3 is likely to be satisfied, since both Uj and
ϕj are parameters bounded to the human capacity. For example, if
n = 30, the conditions will hold even if we require every reviewer
to review at most 8 papers while allowing everyone to reject up to 10
papers. Finally, even when the number of papers is small, the editor
can decrease ϕj and Uj in order to make them suitable.
3.4
Fairness and the relation with the ILP model
In Example 1, we showed that when the reviewers share the same
preference order over the set of papers, finding a solution to the BP
formulation might be impossible. In the following, we show that this
phenomenon is also due to an intrinsic fairness property that perfect
solutions to the BP problem possess.
Definition 2 Let X be a matching over the bipartite graph G and
let WR be the reviewers’ effort matrix. Given a vector Φ
:=
(ϕ1, . . . , ϕm) ∈Nm, we say that X is Φ-weakly fair if, ∀j ∈[m],
the set BCj(X) :=

i ∈[n], s.t. Xi,j = 0 & (WR)i,j ≥
minXi,j=1(WR)i,j)
	
, contains at least ϕj elements.
Notice that the set BCj(X) contains all the papers in [n] that re-
quire more effort than the highest effort-requiring paper assigned to
j according to X. Therefore, a solution is Φ-weakly fair if every re-
viewer j is not allocated with its ϕj worst picks. Using the notion of
a perfect solution, we are able to relate Φ-weakly fair solutions of the
classic ILP model to the perfect solutions of the BP model.
Proposition 1 There exists a perfect solution (X, Y, Z) that maxi-
mizes the quality if and only if the ILP problem admits a Φ-weakly
fair solution.
To conclude, we show that our model extends the classic ILP for-
mulation described in Problem 1. In particular, whenever we set
ϕj = 0, ∀j ∈[m], the solution of the LLp is actually determined
by the editor. This allows us to find a bijection between the solutions
of the classic ILP model and the solutions of our BP model.
Proposition 2 Set ϕj
= 0, ∀j ∈[m]. Then, given a solution
(X, Y, Z) of the BP problem, we have that X solves Problem 1. Vice-
versa, if X is a solution to Problem 1, then all the triplets (X, Y, Z)
such that X ⊂Y = Z are perfect solutions to the BP problem.
In Appendix B, we delve further into the relationships between our
BP model and previous models. In particular, we focus on the class
of diverse matching proposed in [9], show how this specific model
is related to a Secondary Variational Problem induced by Problem 1,
and adapt it to our BP model.
4
Numerical Experiments
In this section, we report the results of our numerical experiments.
We first introduce the heuristic we use to solve the model. We then
describe the experimental setting, the implementation details, and
introduce the metrics used to compare the outcomes of our experi-
ments. Finally, we comment on the results we find.
4.1
Greedy Heuristic
Due to the complexity of the BP model described in Problem 2, ap-
proaching the problem through Bilevel solvers is prohibitive. For this
reason, we propose a greedy heuristic that finds a solution by fixing
the editor’s proposal Z. Indeed, once we fix Z, retrieving the review-
ers’ best response is simple since it is the minimum of m independent
LP problems. Once we retrieve the best reply YZ, we obtain the final
allocation by solving the maximum edge-weighted matching prob-
lem induced by Z and Y . For every Z and Y , we denote the related
final allocation with XZ,Y . Given a quality matrix WE, we define
the greedy proposal Zg as the solution to the following ILP problem
Zg = argmax
Z∈Bnm
⟨WE, Z⟩,
X
i∈[n]
Zi,j = Uj + ϕj,
∀j ∈[m].
In particular, the greedy proposal Zg is the editor’s proposal that
maximizes the total quality of the papers proposed. Following the
previous notation, we define the greedy heuristic solution to Problem
2 as (Xg, Yg, Zg) := (XZg,YZg , YZg, Zg). We notice that to build
our heuristic solution, we need to solve at most three ILP problems.
Therefore, complexity-wise, our approach is as costly as any method
based on the resolution of an ILP problem. Moreover, when the set
of reviewers is large and heterogeneous enough, the greedy heuristic
always finds a feasible peer review matching.
Theorem 4 The greedy heuristic always finds a feasible peer review
matching if, for every paper i ∈[n], there are at least L = P
i∈[n] li
reviewers that do not place i among its top K := (maxj∈[m] ϕj +
maxj∈[m] Uj) picks.
Finally, we show that if the accordance percentage of the heuristic
solution is equal to 1, then the quality of the matching Xg lower
bounds the quality of the optimal solution to the BP problem.
Theorem 5 Let (Xg, Yg, Zg) be the triplet found by the greedy
heuristic. If AC(Xg, Yg, Zg) = 1, then, for every optimal solution
(X∗, Y ∗, Z∗) to the BP problem, we have ⟨WE, Xg⟩≤⟨WE, X∗⟩.
4.2
Experimental Framework
We now detail the dataset, the parameters, and the solver we used
during the implementation of our experiments.
Dataset. We use the multi-aspect review assignment evaluation
dataset [22, 21], which is a classic benchmark dataset from UIUC.
The dataset contains the information of 73 papers accepted by SI-
GIR 2007, as well as 189 prospective reviewers who had published
in the main information retrieval conferences. Moreover, the dataset
provides 25 major topics and, for each paper in the set, it provides a
25-dimensional label on that paper based on a set of defined topics.
Similarly, for each of the 189 reviewers, a 25-dimensional expertise
representation is provided. To the best of our knowledge, there is
no available dataset from where we could retrieve the effort matri-
ces needed for our tests. For this reason, we rely on two syntheti-
cally generated datasets as follows. (i) The Aligned dataset, in which
there is a linear dependence between WR and WE. We assume that
(WR)i,j = K −
 (WE)i,j + χ), where K is a constant ensuring
(WR)i,j > 0 and χ ∼N(0, σ). In this case, maximizing the quality
of the assignment and minimizing the total reviewers’ effort have the
same objective function up to a Gaussian noise χ, which describes
the personal preferences the reviewers may have over papers from
the same area. (ii) The Random dataset, in which every entry of WR
is defined as (WR)i,j = χ, where χ is a random variable. In our
test, we consider two possible laws for χ: the Uniform distribution
U[0, 1] and the Exponential distribution Exp(0.5). In this scenario,
the effort needed by any reviewer does not depend on the paper, but
rather on external factors not related to the expected quality of the
review, such as time at disposal and conflict of interest.
Experiment Setting. For every instance in our synthetic dataset,
we use different methods to retrieve feasible peer-reviewer match-
ings. In particular, we consider: (i) The matching obtained by solv-
ing the ILP problem described in Problem 1. We call this so-
lution Pure-Quality solution and denote it with XILP . (ii) The
matching obtained by the greedy heuristic we presented above.
We denote this matching with XBP . (iii) The matching obtained
by considering an ILP problem whose objective function tries
to maximize the Quality and minimize the Reviewers’ Effort at
the same time. Given t, we say that X is a t-tuned solution if
it maximizes ⟨(1 −t)WE + t(−WR), X⟩under the constraints
li ≤P
j∈[m] Xi,j ≤ui and P
i∈[n] Xi,j ≤Uj.3 We use X(t)
ILP
to denote the t-tuned solution.
Finally, we fix the parameters we use in our simulations. We set the
values ui and li respectively to be 3 and 5, ∀i ∈[n]. We assume Uj
does not depend on j ∈[m] and let Uj range in {6, 8}. Similarly, we
assume ϕj does not depend on j ∈[m] and let its value vary in a set
that depends on the value of Uj. We assume the degree of freedom to
be proportional to the value Uj. In particular, we consider ϕj equals
to the 50%, the 75%, and the 100% of Uj, and thus, for Uj = 8, we
have ϕ ∈{4, 6, 8}. In the Aligned case, we let the variance of the
Gaussian noise, namely σ, vary in the set {0.1, 0.3}, since we want
3 We take −WR instead of WR because the LLp is a minimization problem.
X to be only a small influence. Due to the fact that the main goal
of the editor is to retrieve high quality solutions and since there does
not exist a unique best parameter t to retrieve the t-tuned solutions,
we let t range in {0.05, 0.1, 0.15}. In that regard, it is worth noticing
that the best parameter t might change depending on the dimensions
of the problem or on the reviewers’ characteristics. Finally, since all
the effort matrices are randomly generated, we run the experiment
250 times for every set of parameters and report the average of our
results. Due to space limits, we report only the results for the case of
Uj = 8. All the missing results are deferred in Appendix C.
Implementation Details. Our experiments are conducted in the
Red Hat Linux Server with Intel Xeon Gold 6138 CPUs. We use
Julia [3] as the main coding language and solve the ILP problems by
using the JuMP package and HiGHS as an optimization solver [10].
4.3
Comparison Metrics
The metrics we use to evaluate our results are the Quality Percentage
(QP), the Reviewers’Average Effort Ratio (RAER), and the Fair-
ness Ratio (FR), which we detail in the following.
Quality Percentage. Given a peer-reviewing allocation X and
a quality matrix WE, we define the quality of X as Q(X) :=
⟨WE, X⟩. Given a solution XILP of the ILP problem and a match-
ing X found, we define the QP as QP(X) :=
Q(X)
Q(XILP ). Since
XILP does maximize the quality over the set of feasible matchings,
we have that QP(X) ∈[0, 1] for every feasible matching.
Reviewers’ Average Effort Ratio. Given a peer-reviewing allo-
cation X and an effort matrix WR, we define the effort required to
reviewer j from X as ρj(X) := ⟨(WR):,j, X:,j⟩and say that j is
active if ρj(X) > 0. We define the total reviewers’ effort required
by X as E(X) := ⟨WR, X⟩= P
j∈[m] ρj(X). Finally, we define
the average effort required by the active reviewers as Eavg(X) :=
E(X)
nact(X), where nact(X) is the number of active reviewers according
to X. Given two peer-reviewers allocations X and X′, we define the
Reviewers’ Average Effort Ratio as RAER(X, X′) =
Eavg(X)
Eavg(X′).
Fairness Ratio. Given an allocation matrix X, let ρ be the
nact(X)-dimensional vector containing the efforts of all the active
reviewers. To measure how fairly spread the effort induced by X is,
we use the variance of vector ρ, denoted as θ(X) [18]. Given two
peer-reviewers allocations X and Y , we define the Fair Ratio be-
tween X and X′ as FR(X, X′) =
θ(X)
θ(X′).
4.4
Results
In this section, we compare the performance of the three matchings
described in Section 4.2. First, we comment how XBP compares
with XILP and then compare XBP with X(t)
ILP .
The Pure-Quality Solutions Against the Greedy Heuristic. We
first comment on the Aligned case. Notice that, in the Aligned case,
maximizing the quality and minimizing the effort are similar tasks,
thus this represents the best scenario for the ILP model. Nonethe-
less, we observe that our model is able to find solutions whose QP
is consistently larger than 95%, such that (i) the RAER is 10% to
20% lower and (ii) the total effort is more evenly spread. Indeed, we
observe that the FR ranges from 76% to 48%, so that the variance
obtained by the ILP model is 1.3 times the variance obtained by our
model in the best case and more than double in the worst case. We,
therefore, conclude that the personal effort required from every re-
viewer according to the solution of the BP model is lower on average,
spread amongst more reviewers, and, overall, more fairly distributed.
Table 2.
Comparison between XBP and XILP . Quantitative results for different values of ϕ and differently generated effort matrices. Every column repre-
sents a different framework and is characterized by the effort matrix, the random variable used to generate the matrices, and the degree of freedom. For each
framework, we report the averages over 250 instances of the Quality Percentage, the Reviewers’ Average Effort Ratio, the Fairness Ratio, and the Accordance
Percentage of the heuristic solution.
Aligned
Random
U=8
σ = 0.1
σ = 0.3
X ∼U[0, 1]
X ∼Exp(0.5)
ϕ = 4
ϕ = 6
ϕ = 8
ϕ = 4
ϕ = 6
ϕ = 8
ϕ = 4
ϕ = 6
ϕ = 8
ϕ = 4
ϕ = 6
ϕ = 8
QP(XBP )
0.99
0.99
0.99
0.98
0.98
0.97
0.96
0.95
0.93
0.97
0.96
0.94
RAER(XBP , XILP )
0.89
0.89
0.86
0.87
0.87
0.80
0.63
0.53
0.47
0.45
0.35
0.30
FR(XBP , XILP )
0.65
0.75
0.57
0.61
0.61
0.48
0.35
0.24
0.19
0.16
0.09
0.07
AC
0.99
0.99
0.99
0.99
0.99
0.99
0.99
0.99
0.99
0.99
0.99
0.99
Table 3.
Comparison between XBP and X(t)
ILP . Quantitative results for different values of ϕ and differently generated effort matrices. Every column repre-
sents a different framework and is characterized by the effort matrix, the random variable used to generate the matrices, and the degree of freedom. For each
framework, we report the averages over 250 instances of the Quality Percentage, the Reviewers’ Average Effort Ratio, and the Fairness Ratio.
Aligned
Random
U=8
σ = 0.1
σ = 0.3
X ∼U[0, 1]
X ∼Exp(0.5)
ϕ = 4
ϕ = 6
ϕ = 8
ϕ = 4
ϕ = 6
ϕ = 8
ϕ = 4
ϕ = 6
ϕ = 8
ϕ = 4
ϕ = 6
ϕ = 8
t = 0.05
QP(X(t)
ILP )
0.99
0.99
0.99
0.99
0.99
0.99
0.99
0.99
0.99
0.99
0.99
0.99
RAER(XBP , X(t)
ILP )
0.96
0.95
0.95
0.93
0.91
0.89
0.72
0.60
0.53
0.59
0.47
0.39
FR(XBP , X(t)
ILP )
0.77
0.77
0.76
0.70
0.65
0.62
0.43
0.29
0.23
0.26
0.16
0.11
t = 0.1
QP(X(t)
ILP )
0.99
0.99
0.99
0.99
0.99
0.99
0.99
0.99
0.99
0.99
0.98
0.98
RAER(XBP , X(t)
ILP )
0.95
0.95
0.95
0.95
0.93
0.91
0.78
0.66
0.58
0.71
0.57
0.47
FR(XBP , X(t)
ILP )
0.78
0.77
0.77
0.72
0.66
0.63
0.47
0.33
0.25
0.37
0.22
0.15
t = 0.15
QP(X(t)
ILP )
0.99
0.99
0.99
0.99
0.99
0.99
0.98
0.98
0.98
0.98
0.97
0.97
RAER(XBP , X(t)
ILP )
0.96
0.95
0.95
0.96
0.95
0.92
0.88
0.75
0.66
0.86
0.68
0.57
FR(XBP , X(t)
ILP )
0.79
0.77
0.77
0.74
0.69
0.65
0.55
0.38
0.30
0.53
0.32
0.22
We now comment on the Random case, i.e. the case in which there
is no guaranteed relationship between the quality of a matching and
the effort of the agents. For both the uniform and exponential dis-
tribution, we observe that the QP slightly drops between from 94%
to 90%. However, the quality drop comes with a larger drop in the
RAER and an even larger drop in the FR. Indeed, the allocation
found by our heuristic halves the effort required by every reviewer in
most cases, and in some instances, it achieves almost a third of the
effort required by the ILP solution. Similarly, the FR drops between
0.35 and 0.07 hence the variance of the heuristic solution is up to
15 times lower than the one found by the classic ILP model. All the
results of our experiments are reported in Table 2.
The t-tuned Solutions Against the Greedy Heuristic. Fi-
nally, we compare our heuristic to the t-tuned solutions for t =
0.05, 0.1, 0.15. As we observe from the results, taking a convex com-
bination of the effort matrix and the quality matrix leads to solutions
that better balance the quality and the effort. This is clear when we
look at the performance on the aligned dataset: in this case, the QP
of both XBP and X(t)
ILP are comparable for every t. Similarly, the
RAER between XBP and X(t)
ILP , ranges between 90% and 95%,
hence the XBP still requires less effort to the reviewers, but only
marginally. The real difference between the two solutions can be
appreciated when look at their FR. Indeed, our heuristic is capa-
ble of finding a matching that spreads the effort in a more fair way
amongst the reviewers. It is again worth stressing, that the aligned
case represents the best set of conditions for any ILP model, since
maximizing the quality and minimizing the effort do coincide in this
specific framework. This consideration is confirmed by the results we
get for the Random dataset. In this case, the performances of X(t)
ILP
is more in line with the performance of XILP : the loss in RAER
is no longer negligible and the loss in FR increases. Finally, we ob-
serve that using our model has a further advantage over the t-tuned
solutions: our method does not require to find a tuning parameter t to
describe the interplay between the editor’s and the reviewers’ objec-
tive function. The experiment results are listed in the Table 3.
Final Remarks. In every setting considered, we observe that the
variance of our solution is noticeably lower than the one found by
any ILP based model. This is especially interesting since we are able
to retrieve those fairer solutions without altering the objective func-
tion nor by determining a tuning parameter to mix the quality and the
effort matrix. Finally, we notice that our accuracy results are accept-
able since the percentages we found are well above the 83% obtained
by other heuristic approaches, as the one proposed in [1].
5
Conclusion and Future Works
In this paper, we introduced an integer BP model for the peer review
problem. To the best of our knowledge, this is the first model that
finds a peer-reviewing matching using this formalism. We showed
that the LLp and the ULp are well-defined problems and that solution
has a neat burden-free property under mild assumptions. Finally, we
defined a heuristic solution and validated it through numerical tests.
From the results, we observe that the heuristic finds fairer solutions
that require a lower average effort from the reviewers and achieves a
competitive quality without requiring any parameter tuning.
For the future avenue, a first improvement to the model would be to
relax the binary constraints of the allocation and search for a proba-
bilistic allocation rather than a deterministic one. Another interesting
aspect of the peer review problem is determining the expertise of the
reviewers by comparing records from conferences.
Acknowledgements
This project is partially supported by a Leverhulme Trust Research
Project Grant (2021–2024). Jie Zhang is also supported by the EP-
SRC grant (EP/W014912/1).
References
[1]
Faez Ahmed, John P. Dickerson, and Mark Fuge, ‘Diverse Weighted
Bipartite b-Matching’, in Proceedings of the 26th International Joint
Conference on Artificial Intelligence, pp. 35–41, Melbourne, Australia,
(2017). IJCAI.
[2]
Gennaro
Auricchio,
Federico
Bassetti,
Stefano
Gualandi,
and
Marco Veneroni, ‘Computing kantorovich-wasserstein distances on d-
dimensional histograms using (d+1)-partite graphs’, in Advances in
Neural Information Processing Systems, eds., S. Bengio, H. Wallach,
H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, vol-
ume 31, p. 5798–5808, Montereal, Canada, (2018). Curran Associates,
Inc.
[3]
Jeff Bezanson, Alan Edelman, Stefan Karpinski, and Viral B Shah, ‘Ju-
lia: A fresh approach to numerical computing’, SIAM Review, 59(1),
65–98, (2017).
[4]
Anthony P. Burgard, Priti Pharkya, and Costas D. Maranas, ‘Optknock:
a bilevel programming framework for identifying gene knockout strate-
gies for microbial strain optimization’, Biotechnology and bioengineer-
ing, 84(6), 647–657, (2003).
[5]
Laurent Charlin and Richard Zemel, ‘The toronto paper matching sys-
tem: an automated paper-reviewer assignment system’, in Proceedings
of ICML Workshop on Peer Reviewing and Publishing Models, Atlanta,
United States, (2013). ICML.
[6]
Stefano Coniglio, Luca G. Gianoli, Edoardo Amaldi, and Antonio
Capone, ‘Elastic Traffic Engineering Subject to a Fair Bandwidth Al-
location via Bilevel Programming’, IEEE/ACM Transactions on Net-
working, 28(6), 2407–2420, (2020).
[7]
Stephan Dempe, Foundations of bilevel programming, Springer Science
& Business Media, New York, United States, 2002.
[8]
Scott DeNegre, Interdiction and discrete bilevel linear programming,
Ph.D. dissertation, Lehigh University, 2011.
[9]
John P. Dickerson, Karthik Abinav Sankararaman, Aravind Srinivasan,
and Pan Xu, ‘Balancing Relevance and Diversity in Online Bipartite
Matching via Submodularity’, in Proceedings of the Thirty-Third AAAI
Conference on Artificial Intelligence and Thirty-First Innovative Ap-
plications of Artificial Intelligence Conference and Ninth AAAI Sym-
posium on Educational Advances in Artificial Intelligence, pp. 1877–
1884, Palo Alto, United States, (2019). AAAI press.
[10]
Iain Dunning, Joey Huchette, and Miles Lubin, ‘Jump: A modeling lan-
guage for mathematical optimization’, SIAM Review, 59(2), 295–320,
(2017).
[11]
Thomas. E. Easterfield, ‘A Combinatorial Algorithm’, Journal of The
London Mathematical Society, 21, 219–226, (1946).
[12]
Jack Edmonds, ‘Maximum matching and a polyhedron with 0, 1-
vertices’, Journal of research of the National Bureau of Standards B,
69(125-130), 55–56, (1965).
[13]
Daquan Feng, Lu Lu, Yi Yuan-Wu, Geoffrey Ye Li, Gang Feng, and
Shaoqian Li, ‘Device-to-device communications underlaying cellular
networks’, IEEE Transactions on communications, 61(8), 3541–3551,
(2013).
[14]
Naveen Garg, Telikepalli Kavitha, Amit Kumar, Kurt Mehlhorn, and
Julián Mestre, ‘Assigning papers to referees’, Algorithmica, 58(1), 119–
136, (2010).
[15]
Judy Goldsmith and Robert H Sloan, ‘The AI conference paper as-
signment problem’, in Proceedings AAAI Workshop on Preference
Handling for Artificial Intelligence, Vancouver, pp. 53–57, Vancouver,
Canada, (2007). AAAI Workshop.
[16]
Frank L. Hitchcock, ‘The Distribution of a Product from Several
Sources to Numerous Localities’, Journal of Mathematics and Physics,
20(1-4), 224–230, (1941).
[17]
Robert W. Irving, ‘Stable marriage and indifference’, Discrete Applied
Mathematics, 48(3), 261–272, (1994).
[18]
Rajendra K Jain, Dah-Ming W Chiu, William R Hawe, et al., ‘A quan-
titative measure of fairness and discrimination’, Eastern Research Lab-
oratory, 21, 1–37, (1984).
[19]
Siladitya Jana, ‘A history and development of peer-review process’, An-
nals of Library and Information Studies, 66(4), 152–162, (2019).
[20]
Leonid V. Kantorovitch, ‘On the Translocation of Masses’, Manage-
ment Science, 5(1), 1–4, (1958).
[21]
Maryam Karimzadehgan and ChengXiang Zhai, ‘Constrained multi-
aspect expertise matching for committee review assignment’, in Pro-
ceedings of the 18th ACM conference on Information and knowledge
management, pp. 1697–1700, New York, United States, (2009). Asso-
ciation for Computing Machinery.
[22]
Maryam Karimzadehgan, ChengXiang Zhai, and Geneva Belford,
‘Multi-aspect expertise matching for review assignment’, in Proceed-
ings of the 17th ACM conference on Information and knowledge man-
agement, pp. 1113–1122, New York, United States, (2008). Association
for Computing Machinery.
[23]
Henry A Kierstead, ‘An effective version of hall’s theorem’, Proceed-
ings of the American Mathematical Society, 88(1), 124–128, (1983).
[24]
Julien Lesca and Patrice Perny, ‘LP Solvable Models for Multiagent
Fair Allocation Problems.’, in ECAI, volume 2010, pp. 393–398, Lis-
boa, Portugal, (2010). IOS Press.
[25]
Zhi-Quan Luo, Jong-Shi Pang, and Daniel Ralph, Mathematical pro-
grams with equilibrium constraints, Cambridge University Press, 1996.
[26]
David G. McVitie and Leslie B Wilson, ‘The stable marriage problem’,
Communications of the ACM, 14(7), 486–490, (1971).
[27]
Nihar B Shah, ‘Challenges, experiments, and computational solutions
in peer review’, Communications of the ACM, 65(6), 76–87, (2022).
[28]
Kazunari Sugiyama and Min-Yen Kan, ‘Scholarly paper recommenda-
tion via user’s recent research interests’, in Proceedings of the 10th an-
nual joint conference on Digital libraries, pp. 29–38, New York, United
States, (2010). Association for Computing Machinery.
[29]
Robert L. Thorndike, ‘The problem of classification of personnel’, Psy-
chometrika, 15, 215–235, (1950).
[30]
Heinrich Von Stackelberg, The theory of the market economy, William
Hodge, 1952.
[31]
Li Wang, Huaqing Wu, Wei Wang, and Kwang-Cheng Chen, ‘So-
cially enabled wireless networks: resource allocation via bipartite graph
matching’, IEEE Communications Magazine, 53(10), 128–135, (2015).
[32]
Jiuping Xu, Yan Tu, and Ziqiang Zeng, ‘Bilevel optimization of re-
gional water resources allocation problem under fuzzy random environ-
ment’, Journal of Water Resources Planning and Management, 139(3),
246–264, (2013).
Appendix
In this appendix, we report the missing proofs, the additional theo-
retical results, and the additional experimental results of our paper.
Appendix A – Proofs
In this appendix, we report all the proofs of the results stated in the
main body of the paper.
Proof. (Lemma 1) It follows from the following chain of inequalities
b
X
i=1
wixi =
a
X
i=1
wixi +
b
X
i=a+1
wixi
≥
a
X
i=1
wixi + wa
b
X
i=a+1
xi
=
a
X
i=1
wixi + waa −wa
a
X
i=1
xi
=
a
X
i=1
(wixi + wa −waxi)
=
a
X
i=1
((wa −wi)(1 −xi) + wi) ≥
a
X
i=1
wi.
Proof. (Theorem 1) It is easy to see that the problems (2) and (3) are
equivalent to the following Linear Programming problems
∀j ∈[m],
Y ∗
:,j ∈argmin
Y:,j
⟨W:,j, Y:,j⟩,
s.t.
P
i∈[n] Yi,j = Ui,
0 ≤Yi,j ≤Zi,j,
(4)
and the following Integer Linear Programming problems
∀j ∈[m],
bY:,j ∈argmin
Y:,j
⟨W:,j, Y:,j⟩,
s.t.
P
i∈[n] Yi,j = Uj,
Yi,j ≤Zi,j,
Y:,j ∈B1,m,
(5)
respectively. Therefore, to show that ⟨W, Y ∗⟩= ⟨W, bY ⟩, we prove
⟨W:,j, Y ∗
:,j⟩= ⟨W:,j, bY:,j⟩for every j ∈[m]. Without loss of gen-
erality, we only consider the case j = 1. Furthermore, we assume
Zi,1 = 1 for every i ∈[n], this can be done without loss of general-
ity since otherwise, it suffices to restrict the sets of indices.
Since the feasible region of (4) is a superset of the feasible set of
(5), it follows ⟨W:,1, Y ∗
:,1⟩≥⟨W:,1, bY:,1⟩. To conclude the proof, we
show the other inequality. If bY:,1 ∈Bn,1, we conclude the proof,
therefore, we assume bY:,1 /∈Bn,1. Let us now define
S :=
n
i ∈[n] : 0 < bYi,1 < 1
o
(6)
and
K :=
n
i ∈[n] : bYi,1 ∈{0, 1}
o
.
(7)
By assumption, S ̸= ∅and, by construction, we have
U1 =
X
i∈[n]
bYi,1 =
X
i∈S
bYi,1 +
X
i∈K
bYi,1 =:
X
i∈S
bYi,1 + t.
(8)
Since bYi,1 ∈{0, 1}, ∀i ∈K, we get that t is an integer number. Let
us now define b := |S| and let a = U1 −t > 0. From equation (8)
and 0 < bY1,j < 1, we infer that b > a. Now, we increasingly reorder
the elements in {Wi,1 : i ∈S}, so that
Wi1,1 ≤Wi2,1 ≤· · · ≤Wia,1 ≤· · · ≤Wib,1,
(9)
where {i1, · · · , ib} = S. Finally, we define Y as
Y i,1 =









bYi,1,
for i ∈K,
1,
i ∈{i1, i2, · · · , ia},
0,
otherwise.
(10)
A simple computation shows that
X
i∈S
Y i,1 =
ia
X
i=i1
1 = a,
(11)
X
i∈S
Wi,1Y i,1 =
ia
X
i=i1
Wi,1
(12)
≤
ib
X
i=i1
Wi,1 bYi,1 ≤
X
j∈S
Wi,1 bYi,1,
which, in conjunction with relationships (10), (12), and (8), allows
us to conclude
X
i∈[n]
Y i,1 =
X
i∈S
Y i,1 +
X
i∈K
Y i,1
=
X
i∈S
Y i,1 +
X
i∈K
bYi,1 = a + t = U1,
which means that Y is feasible. Moreover,
⟨W:,1, Y :,1⟩
=
X
i∈S
Wi,1Y i,1 +
X
i∈K
Wi,1Y i,1
≤
X
i∈S
Wi,1 bYi,1 +
X
i∈K
Wi,1 bYi,1
(due to (12))
=
⟨W:,1, bY:,1⟩,
(13)
hence ⟨W1:, Y 1:⟩= ⟨W1:, bY1:⟩. The uniqueness result follows from
the uniqueness of the non-decreasing ordering of the values {Wi,1 :
i ∈S}.
Proof. (Theorem 2) First of all, we notice that, since we are consider-
ing a minimization problem, imposing the constraint P
i∈[m] Yi,j =
Uj for every j ∈[m] is equivalent to impose P
i∈[m] Yi,j ≥Uj for
every j ∈[m]. If Y minimizes the effort of the reviewers component-
wise, it also minimizes the total effort of the reviewers. Toward a con-
tradiction, assume that Y minimizes the total effort of the reviewers,
but does not minimize the effort of a reviewer, namely j. From The-
orem 1, there exists a binary vector ˜Yj that minimizes the effort of
reviewer j. Let us now define the matrix ¯Y as it follows: every col-
umn different from the j-th is equal to the respective column of Y ,
while the j-th column is equal to ˜Yj. It is easy to see that ¯Y is still
feasible and that the reviewers’ effort of ¯Y is lower than the effort of
Y , which contradicts the hypothesis.
Proof. (Theorem 3) Since the set of feasible triplets for the BP prob-
lem is discrete, if we show that it is also not empty, we infer that there
exists an optimal solution, which concludes the proof. Since the ILP
problem is feasible, let X be a solution to Problem 1. Since we have
that maxj∈[m] ϕj + 2 maxj∈[m] Uj ≤n, we can find a Z such that
X ≤E −Z. Notice that, if the editor proposes Z, the matching X
is a feasible allocation for the ULp regardless of what the solution
to the LLp Y is. Finally, from Theorem 1, we have that there exists
an optimal Y that solves the LLp. Therefore (Z, Y, X) is a feasible
triplet for the BP problem, which concludes the proof.
Proof. (Proposition 1) Let (X, Y, Z) be a perfect solution, so that
X ≤Y ≤Z holds. Moreover, let us fix Φ := (ϕ1, . . . , ϕm). Since
Z has at least Uj + ϕj non-null entries in every row j ∈[m], and
since X:,j ≤Z:,j we infer that the allocation X is Φ-burden-free,
which proves the first half of the proposition.
We now focus the second half of the proof. Let (X, Y, Z) be a
perfect solution such that X maximizes the quality of the match-
ing. Since X maximizes the quality, then X is a solution of the ILP
defined in Problem 1. Since we have already proven that X is also Φ-
burden-free, this concludes the proof. To prove the other implication,
let X be an optimal and Φ-burden-free solution to Problem 1. Let Tj
be a set that contains ϕj papers that are worse, according to reviewer
j, than the ones j is allocated with by assignment X. Since the solu-
tion is Φ-burden-free, the set Tj exists for every reviewer j ∈[m].
Finally, let us consider a feasible Z such that Z:,j ≥X:,j + Tj. Re-
gardless of the LLp solution Y , it holds X ≤Y , which concludes
the second part of the proof.
Proof. (Proposition 2) First, we prove that every solution to the clas-
sic ILP problem induces at least a solution to the BP problem, and
then we show that also the reverse implication holds. Let us con-
sider X a solution to the classic ILP model in Problem (1) and let
Z be a binary matrix such that X ≤Z and P
i∈[n] Zi,j = Uj
for every j ∈[m]. Since every solution to Problem (1) satisfies
P
i∈[n] Xi,j ≤Uj for every j ∈[m], such Z always exists.
Let us now define the triplet (X, Y, Z), where Y = Z. Since X ≤
Z = Y , we infer that ⟨X, Y ⟩= ⟨X, X⟩, hence AC(X, Y, Z) = 1.
Moreover, since Y = Z is the only feasible matrix of the LLp, it is
also optimal for the LLp. To conclude, notice that X maximizes, by
construction, both the functional ⟨WE, X⟩and ⟨Y, X⟩, therefore it
is optimal for the BP problem. Let us now consider a solution to (2),
namely (X, Y, Z). If X is not a solution to the ILP problem, we can
construct a better solution to the BP problem by using the procedure
described above, which contradicts the optimality of (X, Y, Z).
Proof. (Theorem 4) We prove the Theorem by showing that there
exists at least one feasible matching for the ULp when we fix Z = Zg
and Y = Yg. To do so, we show that there exists a feasible matching
X such that X ≤E −Zg.
Given the bipartite graph G = ([n] × [m], E −Zg), we build the
auxiliary graph G′ as it follows. For every element i ∈[n], we gen-
erate li copies of i, we denote this set of papers with P′. Similarly,
for every j ∈[m], we generate Uj copies of j, we denote this set of
reviewers with R′. The edge set of the bipartite graph, namely E′,
is as it follows,: e′ := (i′, j′) ∈E′ if and only if e = (i, j) ∈E,
where i′ is a copy of i and j′ is a copy of j. To conclude the proof,
it suffice to show that there exists a perfect matching of P′ into R′.
First notice that P′ contains L = P
i∈[n] li elements. This follows
from the Hall’s theorem [23], since, by hypothesis and construction,
every paper in P′ is connected to at least L elements of R′.
Proof. (Theorem 5) It is easy to see that
⟨WE + YZg, XZg⟩≤⟨WE + Y ∗, X∗⟩,
where (X∗, Y ∗, Z∗) is the optimal solution of the BP problem. By
rearranging the terms of the latter inequality, we have
AC(Xg, Yg, Zg) −AC(X∗, Y ∗, Z∗) ≤⟨WE, X∗⟩−⟨WE, Xg⟩.
Since AC(Xg, Yg, Zg) = 1 and AC(X∗, Y ∗, Z∗) ≤1, we infer
that the left-hand side of the equation is positive, hence
0 ≤⟨WE, X∗⟩−⟨WE, Xg⟩
→
⟨WE, Xg⟩≤⟨WE, X∗⟩.
In particular, the quality obtained by the heuristic final assignment
XXg,Y gives a lower bound on the quality attained by the optimal
solution of the BP problem.
Appendix B – The Secondary Variational Problems
In this appendix, we analyze the secondary variational problem
(SVP) related to the peer review matching problem. After studying
the properties of the solution when we add a small regularization
term, we focus on the diversity functional introduced in [1]. In par-
ticular, we show how the diversity function they proposed does not
directly describe the diversity, but rather an SVP induced by the en-
tropy function. This allows us to give a theoretical explanation of the
large Entropy Gain results presented in [1].
Enhancing the solutions Via Second Variational
Problem
Albeit maximizing a linear function has been proven to be a reli-
able way to find a meaningful peer review matching, determining
a matching by only using an ILP model leads towards undesirable
features. First, the solution is often non-unique, which means there
is still room for improving the solution. Second, since the solutions
to LP problems lay in the vertexes of a polytope, the maximizers of
the objective function lack other appealing properties such as fair-
ness, entropy, and diversity. For example, the maximum allocation
described in Example 1 allocates all the best papers to one reviewer
and leaves the other reviewer with the worst one. A classic method to
deal with both these issues is to augment the objective function with
a (usually convex) function as follows
⟨W, X⟩+ λC(X),
(14)
where C is a function that describes the property we are interested
in and λ ∈R is a parameter that scales the effect of the function
C over the optimization problem. In this appendix, we show that for
every problem (14) there does exist a small enough parameter λ for
which the maximizers of the function (14) are the matchings that
maximizes4 the function C over the set of matchings that maximize
the quality ⟨W, X⟩.
Definition 3 Given a matching problem and a convex and bounded
function C over the set of feasible matching, we define the secondary
variational problem induced by C as
max
X∈A Wλ,C(X) = max
X∈A⟨W, X⟩+ λC(X),
(15)
where A is the set of feasible points X and λ ∈R.
4 or minimizes, depending on the sign of λ
Depending on the value of λ the solution Xλ of (15) changes. First
of all, depending on the sign of λ, the problem searches for the max-
imum or the minimum of C. Moreover, as the module of λ grows,
the solution Xλ gets less optimal for the LP problem and approaches
the maximum or minimum of C. For the sake of simplicity, in what
follows, we assume C to be convex and λ to be negative, which is
also the most common scenario.
Proposition 3 Let W = (wi,j)i,j be an edge weight matrix such
that mini,j wi,j > 0 and let C be a convex and bounded function.
Then, there exists ϵ > 0 such that for every λ ∈(0, ϵ) the solution to
max
X∈A⟨W, X⟩−λC(X)
(16)
is a Maximum Edge-weighted Matching with respect to edge weight
matrix W that minimizes C.
Proof. Let ¯
X ∈A be a minimizer of the LP problem
max
X∈A⟨W, X⟩.
Toward a contradiction, assume that ∀λ > 0 there exists a Xλ such
that
⟨W, ¯
X⟩−λC( ¯
X) < ⟨W, Xλ⟩−λC(Xλ).
Let us now consider a sequence, namely λn, such that λn > 0 for
every n and that converges monotonically to 0. Let Xn := Xλn
be the related sequence of solutions. Since A is finite, we have that,
up to a sub-sequence, Xn converges to some element in A, namely
X∗, moreover, starting from a given N, we have Xn = X∗for
every n > N. By assumption, we have that ⟨W, X∗⟩< ⟨W, ¯
X⟩.
Moreover, we have
⟨W, ¯
X⟩−λnC( ¯
X) < ⟨W, X∗⟩−λnC(X∗)
for every n > N. By manipulating the latter relation, we get
0 < ⟨W, ¯
X −X∗⟩< λn(C( ¯
X) −C(X∗))
which is a contradiction, since the left-hand side is positive and the
right-hand side converges to zero since C is bounded.
If the matrix W has integer values, we can bound the value of ϵ.
Proposition 4 If the matrix W has integer entries and C is a
bounded and convex function, we have that ϵ is greater than
1
∆C
where ∆C = maxA C −minA C and A is the set of feasible bi-
nary matrices. In particular, whenever 0 < λ <
1
∆C , the solutions
of (16) are also maximizers of the LP model defined in Problem 1.
Proof. (Proposition 4) Let us consider an optimal solution ¯
X for the
ILP model. Since W has integer values, for any given X ∈A that is
not optimal, we have ⟨W, ¯
X −X⟩≥1, hence we have that if there
exists X ∈A that solves (3) and that does not maximize the quantity
⟨W, X⟩over A, then we have
1 ≤⟨W, ¯
X −X⟩≤λ

C( ¯
X) −C(X)

≤λ∆C
which is not possible whenever ∆C ≤1
λ.
The SVP in the Bilevel Formulation
Due to the nature of the BP problems, we can add a convex penalizing
function to both the ULp and the LLp, which leads us to the following
BP problem.
Problem 3 In the framework described in Section 3, consider the
following problem
max
Z,X∈Bnm
⟨WE, X⟩+ ⟨Y ∗, X⟩+ a0CE(X)
where
li ≤P
j∈[m] Xi,j ≤ui,
P
i∈[n] Xi,j ≤Uj,
P
i∈[n] Zi,j = Uj + ϕj,
and
X ≤E −Z + Y ∗
Y ∗∈argmin
Y ∈Bnm
⟨WR, Y ⟩+ ajCj(Y )
where
P
i∈[n] Yi,j = Uj
and
0 ≤Y ≤Z
(17)
where CE is the penalizer of the ULp, Cj are the penalizers of
the LLp, and {ak}k=0,...,m are parameters that scale the influence
of the respective penalizers. As for the previous model, the LLp
is a component-wise minimization, that is Y ∗is the matrix whose
columns minimize the quantity ⟨(WR):,j, Y:,j⟩+ ajCj(Y:,j).
Some Remarks on the Diversity Function
Finally, we study the diversity function. To the best of our knowl-
edge, diversity was first introduced in the context of peer review
matching in [1]. Given a bipartite graph (A ∪B, A × B), a function
that evaluates the weights of the edges W : A × B →[0, ∞), and a
matching X = {Xi,j}(i,j)∈A×B, the authors define the diversity of
X as
F(X) :=
X
i∈A
X
k∈K
 X
j∈Bk
wi,jXi,j
2
(18)
where wi,j = W(i, j) and B := {Bk}k∈K is a partition of one
of the sides of the bipartite graph, in this case, B. They then use a
greedy heuristic method to minimize F over the set of constraints we
described in Section 2. Through empirical experiments, they show
that the minimizers of (18) are close to the classic optimums from
a utility viewpoint. However, their solution has a way higher level
of entropy.5 Although at first sight, it might look like this model has
nothing to do with the SVP, there exists a deep relation between the
problem considered in [1] and the SVP induced by the following
entropy function
C(X) := −
X
i∈[n]
X
k∈[K]
 X
j∈Bk
wi,jXi,j

log
 X
j∈Bk
wi,jXi,j

.
(19)
Moreover, we also show that the function F defined in (18) is not
related to the classic notion of diversity (as the next example shows)
and propose a correct definition of the diversity function.
Example 2 Let us consider the bipartite graph defined by A =
{L1, L2, L3} and B = {R1, R2, R3} (see Figure 2). Let us set
wi,j = W(Li, Rj) where i, j = 1, 2, 3 and let us assume that
w1,1 = w1,2 = 0.1 and w1,3 = 0.9. Finally, we assume that the
5 For the sake of convenience, the authors of [1] considered the minimization
version of the ILP rather than the maximizing one we presented in the paper.
In this case, the editor aims at minimizing the quantity P
i,j wi,jXi,j.
L1
L2
L3
R1
R2
R3
(a) The initial complete bipartite graph.
L1
L2
L3
R1
R2
R3
(b) The graph describing the proposal Z
of the editor.
L1
L2
L3
R1
R2
R3
(c) The graph describing the bidding of
the reviewers Y .
Figure 2.
The graph described in Example 2. The partition on the right side of the graph is described by the different colors of the circles.
partition over B is B1 := {R1, R2} and B2 = {R3}. Let us as-
sume that every element of A has to be matched to at least two items
of B. It is then easy to see that the optimal allocation (the one that
minimizes the functional in (18)) of L1 is to allocate it to R1 and R2
since (0.1 + 0.1)2 < 0.12 + 0.92. However, this is counterintuitive
since the diversity function should seek allocations that match ele-
ments of A to as many elements of different clusters in B. It is easy
to generalize the example to the case of generic positive weights. Fi-
nally, notice that if all the weights of the graph are the same (say, for
example, equal to 1), the notion of diversity is consistent with what
has been proposed in [1]).
In particular, minimizing the functional (18) does not always lead
to a diverse matching. Motivated by the latter example, we propose
the following definition of the diversity functional.
Definition 4 Given a bipartite graph ([n] ∪[m], [n] × [m]) and a
partition B := {Bk}k∈K over [m], we define the diversity functional
D : Bnm →[0, +∞) as
D(X) =
X
i∈[n]
X
k∈[K]
 X
j∈Bk
Xi,j
2
.
(20)
From now on, we refer to the function F defined in (18) as the
weighted diversity function, while we refer to D defined in (20) as
the diversity function.
A Generalized Class of Weighted Diversity Functions
and the Relation with the Entropy
In this section, we study how the minimization of the weighted di-
versity function F defined in (18) is related to an SVP of the lin-
ear problem minX∈A ⟨W, X⟩induced by the entropy function (19).
This allows us to justify the results found in [1]. We start the discus-
sion by introducing a continuous family of functions that generalizes
the weighted diversity function F.
Definition 5 Given a weight matrix W and a parameter p ≥1, we
define the weighted p-diversity functional as
Fp(X) :=
X
i∈A
X
k∈K
 X
j∈Gk
wi,jXi,j
p
.
Notice that F2 is equal to the weighted diversity functional F,
defined in (18). From the same argument used to prove Proposition
3, we infer the following result.
Proposition 5 Given
any
matching
X,
we
have
that
limp→1 Fp(X) = ⟨W, X⟩. Moreover, the function p →Fp(X) is
continuous and, given any feasible set A, there exists a ¯p ∈(1, +∞)
such that, for every 1 < p < ¯p, every minimizer of Fp over A is a
minimizer of X →F1(X) over A.
In particular, we have that the minimizers of Fp for p ≈1 also
maximize the quality of the matching. This is in line with the results
reported in [1], as we have that, due to the continuity of the function
p →Fp(X), the minimum of F2 has to be not that different from
an element of ˜S1. Let us denote with Sp the set of minimizers of Fp
over S, from Proposition 5, we infer that the set Sp converges to a
set ˜S1 that is a subset of the minimizers of F1. We now show that
this process is related to an SVP and that the set ˜S1 is the subset
of minimizers of F1 that maximizes the entropic penalizing function
introduced in (19). Indeed, we recall that, given a > 0, it holds true
the following approximation formula
a1+ϵ ≈a(1 + ϵ log(a)),
where ϵ > 0 is a small parameter. The latter formula allows us to
approximate F1+ϵ(X) as it follows
F1+ϵ(X) =
X
i∈[n]
X
k∈[K]
 X
j∈Bk
wi,jXi,j
1+ϵ
≈
X
i∈[n]
X
k∈[K]
X
j∈Bk
wi,jXi,j

1 + ϵ log
  X
j∈Bk
wi,jXi,j

= ⟨W, X⟩
+ ϵ
X
i∈[n]
X
k∈[K]
 X
j∈Bk
wi,jXi,j

log
 X
j∈Bk
wi,jXi,j

.
Therefore, the weighted diversity function becomes an SVP for the
entropy of the weights allocated to the partition. From Proposition 3,
we infer the following result.
Proposition 6 Let us consider a quality matrix W such that wi,j >
0 for every i ∈[n] and j ∈[m]. Then, for every p ∈[1, ˜p], there
exists a value ¯p > 1 for which every solution to the follwing problem
min
X∈A Fp(X),
(21)
is a minimizer of F1 that maximizes the entropy function (19).
Once again, this result is in line with the results presented in [1],
where the authors show that minimizing F2 instead of the classi-
cal linear function (F1 according to our notation) leads to solutions
that have a higher entropy while still retaining a high overall qual-
ity. Following this idea, by applying the algorithm to the p-diversity
functional with p ∈(1, 2), we should find a solution that has a bet-
ter efficiency from a matching perspective and that does not alter the
entropy gain described in [1] for the case p = 2.
Appendix C – Additional Experiment Results
In this appendix, we report the missing experimental results.
In Table 4 and 5, we report the results for U = 6. We observe that
the results are in accordance with the ones found in Section 4. For the
sake of conciseness, we comment only on the comparison between
X(t)
ILP and XBP . In this case, we have that
• in the Aligned case the quality and the fairness obtained by XBP
and X(t)
ILP are comparable, even though our heuristic finds slightly
fairer solutions. The main difference, in this case, lies in how the
effort is spread amongst the reviewer: XBP finds solution whose
variance is smaller than any X(t)
ILP .
• In both the random cases, our solution finds solutions whose over-
all effort is much smaller than the one required by the X(t)
ILP .
Again, the solutions found by our heuristic are much more fair
than any t-tuned solution.
Table 4.
Quantitative results for different values of ϕ and differently generated effort matrices. Every column represents a different framework and is charac-
terized by the effort matrix, the random variable used to generate the matrices, and the degree of freedom. For each framework, we report the averages over 250
instances of the QP (Quality Percentage), RAER (Reviewers’ Average Effort Ratio), FR (Fairness Ratio), and the AC (Accordance Percentage).
Alligned
Random
U=6
σ = 0.1
σ = 0.3
X ∼U[0, 1]
X ∼Exp(0.5)
ϕ = 3
ϕ = 4
ϕ = 6
ϕ = 3
ϕ = 4
ϕ = 6
ϕ = 3
ϕ = 4
ϕ = 6
ϕ = 3
ϕ = 4
ϕ = 6
QP(XBP )
0.99
0.98
0.98
0.97
0.97
0.96
0.94
0.93
0.90
0.94
0.93
0.90
RAER(XBP , XILP )
0.93
0.93
0.92
0.88
0.87
0.85
0.66
0.59
0.49
0.48
0.42
0.32
FR(XBP , XILP )
0.71
0.70
0.68
0.64
0.61
0.57
0.42
0.34
0.24
0.22
0.16
0.09
AC
0.95
0.94
0.95
0.94
0.94
0.95
0.96
0.97
0.98
0.96
0.97
0.98
Table 5.
Quantitative results for different values of ϕ and differently generated effort matrices. Every column represents a different framework and is charac-
terized by the effort matrix, the random variable used to generate the matrices, and the degree of freedom. For each framework, we report the averages over 250
instances of the QP (Quality Percentage), the RAER (Reviewers’ Average Effort Ratio), and the FR (Fairness Ratio). We recall that the quality percentage is
computed with respect to the maximum achievable quality, i.e. the one achieved by XILP . The RAER and the FR are instead computed by comparing XBP
and X(t)
ILP .
Alligned
Random
U=6
σ = 0.1
σ = 0.3
X ∼U[0, 1]
X ∼Exp(0.5)
ϕ = 4
ϕ = 6
ϕ = 8
ϕ = 4
ϕ = 6
ϕ = 8
ϕ = 4
ϕ = 6
ϕ = 8
ϕ = 4
ϕ = 6
ϕ = 8
t = 0.05
QP(X(t)
ILP )
0.99
0.99
0.99
0.99
0.99
0.99
0.99
0.99
0.99
0.98
0.97
0.97
RAER(XBP , X(t)
ILP )
0.94
0.95
0.94
0.92
0.90
0.89
0.74
0.66
0.55
0.63
0.55
0.42
FR(XBP , X(t)
ILP )
0.73
0.72
0.69
0.69
0.66
0.62
0.52
0.41
0.28
0.36
0.27
0.16
t = 0.1
QP(X(t)
ILP )
0.99
0.99
0.99
0.99
0.99
0.99
0.99
0.99
0.99
0.97
0.97
0.97
RAER(XBP , X(t)
ILP )
0.95
0.95
0.94
0.93
0.92
0.90
0.82
0.73
0.61
0.77
0.66
0.51
FR(XBP , X(t)
ILP )
0.73
0.72
0.69
0.74
0.70
0.65
0.58
0.47
0.32
0.52
0.40
0.23
t = 0.15
QP(X(t)
ILP )
0.99
0.99
0.99
0.99
0.99
0.99
0.98
0.98
0.98
0.96
0.97
0.95
RAER(XBP , X(t)
ILP )
0.95
0.95
0.94
0.96
0.95
0.93
0.92
0.83
0.69
0.93
0.80
0.62
FR(XBP , X(t)
ILP )
0.75
0.73
0.70
0.78
0.74
0.68
0.68
0.54
0.37
0.75
0.55
0.33
