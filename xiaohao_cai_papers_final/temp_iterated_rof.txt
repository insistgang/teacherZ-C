Multiclass Segmentation by Iterated ROF
Thresholding
Xiaohao Cai and Gabriele Steidl
Department of Mathematics,
University of Kaiserslautern, Kaiserslautern, Germany
{cai,steidl}@mathematik.uni-kl.de
Abstract. Variational models as the Mumford-Shah model and the ac-
tivecontour model havemanyapplications inimage segmentation. Inthis
paper, we propose a new multiclass segmentation model by combining
the Rudin-Osher-Fatemimodel with an iterative thresholding procedure.
We show that our new model for two classes is indeed equivalent to the
Chan-Vese model but with an adapted regularization parameter which
allows to segment classes with similar gray values. We propose an ef-
ﬁcient algorithm and discuss its convergence under certain conditions.
Experiments on cartoon, texture and medical images demonstrate that
our algorithm is not only fast but provides very good segmentation re-
sults in comparison with other state-of-the-art segmentation models in
particular for images containing classes of similar gray values.
1 Introduction
Throughout this paper, letΩ⊂R2 be a bounded, open set andf : ¯Ω→ [0,1] a
given image. In 1989, Mumford and Shah in [23] proposed to solve segmentation
problems by minimizing over (Γ,u) ∈Ω×W 1
2 (Ω\Γ) the energy
EMS(Γ,u): =H1(Γ)+ μ
∫
Ω\Γ
|∇u|2dx+λ
∫
Ω
(u−f)2dx, λ,μ >0,
where H1 denotes the 1D Hausdorﬀ measure. The functionalEMS contains three
terms: the regularity term onΓin terms of its length, the regularity term im-
posing smoothness ofu on areasΩ\Γ, and the data ﬁdelity term. Related ap-
proaches in a spatially discrete setting were proposed in [8,18]. An early attempt
to solve the challenging task of ﬁnding a minimizer of the non-convex, non-
smooth Mumford-Shah functional was done by approximating it by a sequence
of simpler elliptic problems in [3]. Many approaches to simplify the model were
meanwhile proposed in the literature as,e.g., the convex relaxation of the piece-
wise smooth Mumford-Shah functional by functional lifting in [26]. A frequently
applied strategy is to restrict the model to∇u =0o n Ω\Γwhich results in the
piecewise constant Mumford-Shah model
E
PCMS(Γ,u): =H1(Γ)+ λ
∫
Ω
(u−f)2dx. (1)
A. Heyden et al. (Eds.): EMMCVPR 2013, LNCS 8081, pp. 237–250, 2013.
c⃝ Springer-Verlag Berlin Heidelberg 2013
238 X. Cai and G. Steidl
Assuming thatΩ= ⋃K−1
i=0 Ωi with pairwise disjoint setsΩi and u(x): =mi for
x ∈Ωi, i =0 ,...K −1, the above functional can be rewritten as
EPCMS(Ω,m)= 1
2
K−1∑
i=0
Per(Ωi;Ω)+ λ
K−1∑
i=0
∫
Ωi
(mi −f)2 dx, (2)
where Per(Ωi;Ω) denotes the perimeter ofΩi in Ωand m := (mi)K−1
i=0 , Ω:=
(Ωi)K−1
i=0 .F o rK = 2, the piecewise constant Mumford-Shah model is actually
the model of the active contours without edges (Chan-Vese model) [16], i.e.
ECV(Ω1,m 0,m 1)=P e r (Ω1;Ω)+ λ
(∫
Ω1
(m1 −f)2 dx+
∫
Ω\Ω1
(m0 −f)2 dx
)
. (3)
One of the model’s drawbacks is that it can easily get stuck in local minima.
To overcome this drawback, a convex relaxation approach was proposed in [15].
More precisely, it was shown that the global minimizer ofECV(·,m 0,m 1)f o r
ﬁxed m0,m 1 can be found by solving
min
0≤u≤1
∫
Ω
|∇u|+λ
∫
Ω
(
(m0 −f)2 −(m1 −f)2)
u(x)dx, (4)
and settingΩ1 := {x ∈Ω: u(x) >ρ} for anyρ∈(0,1], see also [6,9]. In other
words, (4) is a tight relaxation of the Chan-Vese model with ﬁxedmi, i =0 ,1.
There are many other approaches for two-phase image segmentation based on
the Chan-Vese model and its convex version, see, e.g., [31], [9] and [17].
In [28], Chan and Vese proposed a multiphase segmentation model using level
sets. Convex (non-tight) relaxation approaches for the model with ﬁxedm were
proposed, e.g., in [21,22,25,29,30] and for the full model in [10]. For more details
see also [5].
In [12] a two-stage image segmentation method which ﬁnds the solution of a
convex variant of the Mumford-Shah model in the ﬁrst stage followed byone
thresholding step in the second stage was proposed. The applied functional was
the Rudin-Osher-Fatemi (ROF) functional [27] supplemented by theessential
additional term
∫
|∇u|2 dx.
In this paper, we propose a new multiphase segmentation model based on
iterativelythresholding the minimizer of theoriginal ROF functional. In contrast
to [12] we propose a strategy to update the thresholds and prove its convergence
under certain conditions. There exists a clear relationship of our new model
to the Chan-Vese model (3) which shows that a solution of (3) for a certain
regularization parameter can actually be given by iteratively thresholding the
ROF minimizer. Numerical examples demonstrate that our algorithm is not only
fast but produces also very good results for images whose classes are close to
each other. In particular it outperforms the algorithm in [12].
The paper is organizedas follows: In Section 2, we introduce our segmentation
model and discuss its the properties. We propose an eﬃcient solution algorithm
and provide a convergence analysis in Section 3. Finally, in Section 4, we test
our algorithm on various synthetic and real-world images and compare it with
other state-of-the-art segmentation algorithms.
Multiclass Segmentation by Iterated ROF Thresholding 239
2 Continuous Model
2.1 Notation
We brieﬂy introduce the basic notation and relations which can be found, e.g., in
[2,4]. In the following a ‘set’ is understood as a Lebesgue measurable set inR2,
where we will consider equivalence classes of sets which are equal up to Lebesgue
negligible sets. By|A| we denote the Lebesgue measure of a setA.B yBV (Ω)
we denote thespace of functions of bounded variation , i.e., the Banach space of
functions u : Ω→ R with ﬁnite norm∥u∥BV := ∥u∥L1(Ω) +TV (u), where
TV (u): =s u p
{∫
Ω
u(x)divϕdx: ϕ∈C1
c(Ω,R2),∥ϕ∥∞ ≤1
}
.
The distributional ﬁrst order derivativeDu of u is a vector-valued Radon mea-
sure with total variation|Du| = TV (u). In particular, we have foru ∈W 1
1 (Ω)
that Du = ∇u ∈L1 so that in this caseTV (u)=
∫
Ω|∇u|dx. For a Lebesgue
measurable set A ⊂ Ω,t h eperimeter of A in Ω is deﬁned by Per(A;Ω): =
TV (χA), where χA denotes the characteristic function of A. HenceA is of ﬁnite
perimeter, if its characteristic function has bounded variation. IfA has a C1
boundary, then Per(A;Ω)c o i n c i d e sw i t hH1(∂A∩Ω). We deﬁne the mean off
on A ⊂R2 by
meanf(A): =
{ 1
|A|
∫
A fd x if |A| > 0,
0o t h e r w i s e .
We call (u∗,c∗)a partial minimizer of some objective functionE(u,c)i f
E(u∗,c∗) ≤E(u∗,c) for all feasible c, and
E(u∗,c∗) ≤E(u,c∗) for all feasible u. (5)
In case E is diﬀerentiable on its domain every partial minimizer contained in
the interior of the domain is stationary, see, e.g., [19]. For example we see that a
partial minimizer (Ω∗,m∗) of the piecewise constant Mumford-Shah model (2)
with Ω∗=( Ω∗
i )K−1
i=0 , m∗=( m∗
i)K−1
i=0 has to fulﬁll
m∗
i =m e a nf(Ω∗
i ),i =0 ,...,K −1. (6)
2.2 Model
We start by considering the segmentation intoK = 2 classes. Let
E(Σ,τ): =P e r (Σ;Ω)+ μ
∫
Σ
τ−fd x , μ>0. (7)
Note thatE(∅,τ)=0a n dE(Ω,τ)= μ
∫
Ωτ−fd x.S i n c ef maps into [0,1], the
global minimizer ofE(·,τ)f o rﬁ x e dτ≤0i sΩand forτ≥1i ti s∅. Therefore we
restrict ourselves toτ∈(0,1). We intend to ﬁnd (Σ∗,τ∗) ∈Ω×(0,1) fulﬁlling
E(Σ∗,τ∗) ≤E(Σ,τ∗) ∀Σ⊂Ω, (8)
τ∗= 1
2
(
meanf(Σ∗)+mean f(Ω\Σ∗)
)
.
240 X. Cai and G. Steidl
Remark 1. Note that solving (8) is diﬀerent from minimizing
min
Σ,τ
E(Σ,τ) subject to τ= 1
2
(
meanf(Σ)+mean f(Ω\Σ)
)
. (9)
Consider the 1D example with the functionf(x)= x on Ω=( 0,1) and restrict
the attention to Σ ∈{(0,b),(b,1)}.T h e nτ= 1
4( 1+2b) in (9) and we are
searching forb.N o w
E(Σ,τ)=1+ μ
∫
I
τ−xdx =
{ 1+ 1
4μb if I =( 0,b),
1− 1
4μ(1−b)i fI =( b,1)
which has no minimizer in (0,1). On the other hand, letτ∗= 1
2.T h e ni tc a n
easily be checked that (Σ∗,τ∗) withΣ∗=( 1
2,1) fulﬁlls (8).
The following proposition ensures the existence of a global minimizer ofE(·,τ)
for ﬁxedτ.
Proposition 1. For any ﬁxed τ∈(0,1), a global minimizer Σ of E(·,τ) in (7)
can be found by solving the convex minimization problem
min
u∈BV (Ω),u∈[0,1]
TV (u)+ μ
∫
Ω
(τ−f)udx (10)
and then setting Σ:= {x ∈Ω: u(x) >ρ} for any ρ∈[0,1).
For a proof we refer to Proposition 2.1 in the review paper [14]. This proof uses
the same ideas as in [6,24] where the claim was shown for a.e.ρ∈[0,1]. Based on
the next lemma, cf., [1, Lemma 4i)] and a smoothness argument, an explanation
that the minimizing setΣis unique for ﬁxedτwas given in [14].
Lemma 1. For ﬁxed 0 <τ1 <τ2 < 1,l e t Σi be minimizers of E(·,τi), i =1 ,2.
Then |Σ2\Σ1| =0 is fulﬁlled, i.e., Σ1 ⊇Σ2 up to a negligible set.
The relationship between our model (8) and the Chan-Vese model (3) is ex-
plained in the following proposition.
Proposition 2. (Relation between the Chan-Vese model and (8))
Assume that (Σ∗,τ∗), Σ∗̸∈{ ∅,Ω} is a solution of (8).S e t m∗
0 := meanf(Σ∗)
and m∗
1 := meanf(Ω\Σ∗).L e t O be the set of partial minimizers of the Chan-
Vese model (3) with parameter λ:= μ
2(m∗
1−m∗
0 ) .T h e n
(
Σ∗,m∗
0,m∗
1
)
∈O.
Proof. Since Σ∗̸= ∅is a minimizer ofE(·,τ∗) we conclude
∫
Σ∗ τ∗−fd x< 0
which impliesτ∗< meanf(Σ∗)= m∗
1. Similarly, sinceΣ∗̸= Ω,w es e et h a t
Per(Σ∗;Ω)+ μ
∫
Σ∗
τ∗−fd x≤μ
∫
Ω
τ∗−fd x ,
0 < Per(Σ∗;Ω) ≤μ
∫
Ω\Σ∗
τ∗−fd x
Multiclass Segmentation by Iterated ROF Thresholding 241
and consequentlym∗
0 =m e a nf(Ω\Σ∗) <τ∗. Thereforem∗
0 <m ∗
1.T h es e tΣ∗
is also a minimizer ofE(·,τ∗)+ C with the constantC := λ
∫
Ω(m∗
0 −f)2 dx.
Regarding thatτ∗= m∗
1 +m∗
0
2 we obtain
E(Σ,τ∗)+ C =P e r (Σ;Ω)+ μ
∫
Σ
τ∗−fd x+C
=P e r (Σ;Ω)+ μ
2(m∗
1 −m∗
0)
∫
Σ
(m∗
1 −f)2 −(m∗
0 −f)2 dx
+λ
∫
Ω
(m∗
0 −f)2 dx
=P e r (Σ;Ω)+ λ
( ∫
Σ
(m∗
1 −f)2dx+
∫
Ω\Σ
(m∗
0 −f)2
)
.
By deﬁnition ofm∗
i, i =0 ,1 and (6) we get the assertion. □
Since 0<m ∗
1−m∗
0 ≤1 the parameterλ= μ
2(m∗
1−m∗
0 ) in the Chan-Vese model (3)
is largerthan μand increasesif m∗
1−m∗
0 becomes smaller. Hence, it is adapted to
the diﬀerence betweenm∗
1,m∗
0 and penalizes the data term more if this diﬀerence
becomes smaller.
The following proposition has the important consequence that we can obtain
a minimizer Σ of E(·,τ) by minimizing the ROF functional and subsequent
thresholding of the minimizing function byτ.
Proposition 3. The set {x ∈Ω: u(x) >τ} solves (7) if and only if the function
u ∈BV (Ω) solves the ROF model
min
u∈BV (Ω)
TV (u)+ μ
2
∫
Ω
(
u−f)2 dx. (11)
For the proof see [14, Proposition 2.6].
We generalize (7) and (8) to the multiclass caseK ≥2 by settingΣ:= {Σi}K−1
i=1
and τ:= {τi}K−1
i=1 with 0<τ1 ≤τ2 ≤... ≤τK−1 < 1, and
E(Σ,τ): =
K−1∑
i=1
(
Per(Σi;Ω)+ μ
∫
Σi
τi −fd x
)
,μ > 0. (12)
For ﬁxedτ, we know by Lemma 1 that
Ω⊇Στ1 ⊇Στ2 ⊇···⊇ ΣτK−1 ⊇∅ (13)
and we see that the corresponding wanted segments
Ωi := Σi\Σi+1,i =0 ,...,K −1,Σ 0 := Ω, ΣK := ∅ (14)
are pairwise disjoint and fulﬁll∪K−1
i=0 Ωi = Ω. We aim to ﬁnd an ordered vector
τ∗and a corresponding nested setΣ∗with
τ∗
i = 1
2(m∗
i−1 +m∗
i),m ∗
i := meanf(Ω∗
i ),i =1 ,...,K −1 (15)
which minimizesE(·,τ∗) among all sequences of nested sets.
242 X. Cai and G. Steidl
3 Algorithmic Aspects
Our algorithm alternates the minimization ofE(·,τ)i n( 1 2 )f o rﬁ x e dτwith τ1 ≤
τ2 ≤... ≤τK−1 and the computation ofτas in (15) for ﬁxed sequencesΣ of
nestedsets.ByProposition3the minimizationof E(·,τ)in(12)forﬁxed τcanbe
obtained byK−1 times thresholding the minimizer of the ROF functional. This
is in particular eﬃcient since the minimizer of the ROF functional remains the
same during the whole thresholding process. We call the algorithmthresholded
ROF (T-ROF).
Algorithm (T-ROF)
Initialization: τ(0) =
(
τ(0)
i
)K−1
i=1 with 0<τ(0)
1 < ··· <τ(0)
K−1 < 1.
1. Compute the solutionu of the ROF model (11).
2. For k =0 ,1,..., repeat
2.1. Compute Σ(k) =
(
Σ(k)
i
)K−1
i=1 by Σ(k)
i := {x ∈Ω: u(x) >τ(k)
i }.
2.2. Find Ω(k)
i := Σ(k)
i \Σ(k)
i+1, i =0 ,...,K −1 withΣ(k)
0 := Ωand Σ(k)
K := ∅.
2.3. Compute m(k)
i := meanf(Ω(k)
i ), i =0 ,...,K −1.
2.4. Update τ(k+1)
i := 1
2(m(k)
i−1 +m(k)
i ), i =1 ,...,K −1.
We will prove the convergence of our algorithm under the following assumption:
(A) If Στ,Σ˜τ are the minimizers ofE(·,τ)a n dE(·,˜τ) for any 0<τ< ˜τ< 1
appearing in the algorithm, then
τ≤meanf(Στ\Σ˜τ) ≤˜τ. (16)
The right-hand inequality in (16) is for example fulﬁlled ifΣ˜τis also a minimizer
of Per(Σ;Στ)+ μ
∫
Σ ˜τ−fd x. The left-hand inequality holds ifΣτ\Σ˜τis also a
minimizer of Per(Σ;Ω\Σ˜τ)+ μ
∫
Σ τ−fd x. Using the above assumption we can
prove the following lemma, see [11]:
Lemma 2. Under the assumption (A) our T-ROF algorithm produces sequences
(τ(k))k and (m(k))k with the following properties:
i) 0 ≤m(k)
0 ≤τ(k)
1 ≤m(k)
1 ≤···≤ m(k)
K−2 ≤τ(k)
K−1 ≤m(k)
K−1
ii) Set τ(k)
0 := 0 and τ(k)
K := 1.I f τ(k)
i ≥ τ(k−1)
i and τ(k)
i+1 ≥ τ(k−1)
i+1 ,t h e n
m(k)
i ≥m(k−1)
i , i =0 ,...,K −1 and this also holds true if ≤ is replaced
everywhere by ≥.
To prove the convergence of the sequence (τ(k))k, we deﬁne a sign sequence
ζ(k) =( ζ(k)
i )K−1
i=1 as follows: Ifτ(k)
i ̸= τ(k−1)
i ,
ζ(k)
i :=
{
+1 if τ(k)
i >τ(k−1)
i ,
−1i f τ(k)
i <τ(k−1)
i ,
Multiclass Segmentation by Iterated ROF Thresholding 243
and otherwise
ζ(k)
i :=
{
ζ(k)
j if i =1 ,
ζ(k)
i−1 if i ̸=1 , (17)
where j =m i n{l | τ(k)
l ̸= τ(k−1)
l }.B ysk we denote the number of sign changes
in ζ(k), for example, ifζ(k) =(

 
 
+1,+1,+1,

 
 
−1,−1,

+1 ,

−1) , then sk =3 .
Lemma 3. i) The number of sign changes sk is monotone decreasing in k.
ii) If ζ(k+1)
1 ̸= ζ(k)
1 , then we have the strict decrease sk+1 <s k.
Proof. i) Letsk = N and rewrite (τ(k))k as
(τ(k)
0 ,··· ,τ(k)
l1

 
 
v(k)
1
, ··· ,τ(k)
ij ,··· ,τ(k)
lj

 
 
v(k)
j
, ··· ,τ(k)
iN ,··· ,τ(k)
K
 
 
v(k)
N
),
where v(k)
j contains those successive components of (τ(k))k with the same sign.
1. If #v(k)
j ≥3, we considerζ(k+1)
i∗ with ij ≤i∗−1 ≤i∗ ≤i∗+1 ≤lj, i.e.,
ζ(k)
i∗−1 = ζ(k)
i∗ = ζ(k)
i∗+1.W L O Gl e tζ(k)
i∗ = −1. Then we obtain by Lemma 2 ii) that
m(k)
i∗−1 ≤m(k−1)
i∗−1 and m(k)
i∗ ≤m(k−1)
i∗ . Therefore
τ(k+1)
i∗ = m(k)
i∗−1 +m(k)
i∗
2 ≤m(k−1)
i∗−1 +m(k−1)
i∗
2 = τ(k)
i∗
and consequentlyζ(k+1)
i∗ = −1o rζ(k+1)
ij = ζ(k+1)
ij +1 = ··· = ζ(k+1)
i∗ =1 .T h ec a s e
ζ(k)
i∗ = 1 can be handled in the same way.
2. If there is noj such that #v(k)
j =1 ,w ec o n s i d e rζ(k+1)
lj and ζ(k+1)
ij+1 which are
diﬀerent by deﬁnition. WLOG letζ(k)
lj
= −1a n dζ(k)
ij+1 = +1. Then, from Lemma
2 ii), we have
m(k)
lj−1 ≤m(k−1)
lj−1 ,m (k)
ij+1 ≥m(k−1)
ij+1 .
If m(k)
lj ≤m(k−1)
lj (or m(k)
lj ≥m(k−1)
lj ), then τ(k+1)
lj ≤τ(k)
lj (or τ(k+1)
ij+1 ≥τ(k)
ij+1).
This means thatζ(k+1)
lj ̸= ζ(k)
lj and ζ(k+1)
ij+1 ̸= ζ(k)
ij+1 is not possible at the same
time.
3. Finally, we consider the case #v(k)
j =1f o ra l lj1 ≤j ≤j2,w h e r e#v(k)
j1−1 >
1a n d#v(k)
j2 +1 > 1. We prove that from iteration k → k +1t h es i g n so f
ζ(·)
ij1−1,ζ(·)
j ,...,ζ (·)
j2 ,ζ(·)
ij2 +1 can not change at the same time. WLOG assume that
ζ(k)
ij1
= −1s ot h a tζ(k)
ij =( −1)j−j1 +1 for j1 ≤j ≤j2,a n dζ(k)
ij1−1 = ζ(k)
ij1−2 =+ 1
and ζ(k)
ij2 +1 = ζ(k)
ij2 +2 =( −1)j2−j1.¿ F r o mL e m m a2i i ) ,w ek n o wt h a t
m(k)
ij1−2 ≥m(k−1)
ij1−2, and
{
m(k)
ij2 +1 ≥m(k−1)
ij2 +1 if j2 −j1 is even,
m(k)
ij2 +1 ≤m(k−1)
ij2 +1 if j2 −j1 is odd. (18)
244 X. Cai and G. Steidl
If in ζ(·)
ij1−1, ζ(·)
ij1
, ··· , ζ(·)
ij2
, ζ(·)
ij2 +1 the signs change at the same time, we can
deduce by Lemma 2 ii) that
{
m(k)
ij2 +1 <m (k−1)
ij2 +1 if j2 −j1 is even,
m(k)
ij2 +1 >m (k−1)
ij2 +1 if j2 −j1 is odd,
which contradicts (18).
By parts 1–3, we see thatsk+1 ≤sk for anyk ∈N.
ii) Ifζ(k+1)
1 ̸= ζ(k)
1 ,t h e nv(k)
1 = τ(k)
1 and τ(k)
2 ∈v(k)
2 . By parts 1–3 of the proof
we getsk+1 <s k. This completes the proof. □
Now we can prove the convergence of our T-ROF algorithm with a slight mod-
iﬁcation. We divide the interval [0, 1) inton> 1 disjoint subintervals [i
n, i+1
n ),
and deﬁne a projector Pn :[ 0,1) →{ i
n : i =0 ,...,n −1} by Pn(x): = i
n if
x ∈[i
n, i+1
n ). Clearly,Pn(x1) ≥Pn(x2)i f x1 ≥x2.W ec h o o s en large enough
(say machine precision). Instead ofτ(k) we compute in each step of the T-ROF
algorithm the projection Pn(τ(k)) and continue the algorithm with these pro-
jected thresholds. Clearly, the statements of Lemma 2 and 3 remain true. For
convenience we write againτ(k) for the output of the projected algorithm.
Theorem 1. Under the assumption (A), the sequence (τ(k))k∈N produced by the
projected T-ROF algorithm converges to a vector τ∗.
Proof. We prove the assertion by induction on the number of sign changessk in
some iteration stepk.
Assume thatsk =0 .W L O Gl e tζ(k)
i = +1,i =1 ,...,K −1,i.e., τ(k)
i ≥τ(k−1)
i .
From Lemma 2 ii), we obtainm(k)
i ≥m(k−1)
i and consequently τ(k+1)
i ≥τ(k)
i ,
i =1 ,...,K −1. Therefore sk+1 =0a n dζ(k+1)
i = +1,i =1 ,...,K −1. This
means that each sequence (τ(k)
i )k is monotone increasing. Since the sequences
are moreover bounded in [0, 1], we conclude that (τ(k))k converges.
Assume that (τ(k))k converges ifsk ≤N −1f o rs o m ek ∈N.
We prove that in casesk = N,t h e r ee x i s t sˆk>k such that sˆk ≤N −1.
If there exists ˆk>k such that ζ(ˆk)
1 ̸= ζ(k)
1 ,w eg e tsˆk ≤N −1 directly from
Lemma 3 ii). If ζ(ˆk)
1 = ζ(k)
1 for all ˆk>k ,t h e n(τ(ˆk)
1 )ˆk>k is monotone and
bounded and converges consequently to some thresholdτ∗
1 . This threshold must
be attained in the projected algorithm for somek1 >k . Now we can repeat the
same arguments withk1 instead ofk and ζ(·)
2 instead ofζ(·)
1 to see that (τ(k)
2 )k
converges to a thresholdτ∗
2 which must be attained for somek2 >k 1.M o r e o v e r ,
we haveζ(j)
2 = ζ(j)
1 for allj>k 1. Repeating this procedure up to the ﬁnal index
K −1 we obtain the assertion. □
4 Numerical Results
In this section, we test our method on various images. We actually use the T-
ROF Algorithm with a discrete ROF model, see, e.g. [13], which minimizer is
Multiclass Segmentation by Iterated ROF Thresholding 245
(a) Original Image (b) Corrupted Image (c) T-ROF (Ite. 6) (d) Cai [12]
SA =0 .9913 SA =0 .9878
(e) Li [22] (f) Pock [25] (g) Yuan [29] (h) He [20]
SA =0 .6918 SA =0 .8581 SA =0 .6915 SA =0 .9888
Fig. 1. Segmentation of two-class cartoon image (256×256) with some missing pixel
values
(a) Original image (b) Noisy image (c) T-ROF (Ite. 6) (d) Cai [12]
SA =0 .9845 SA =0 .9816
(e) Li [22] (f) Pock [25] (g) Yuan [29] (h) He [20]
SA =0 .7867 SA =0 .9658 SA =0 .9598 SA =0 .9663
Fig. 2. Segmentation of two-class image (128×128) with close intensities
246 X. Cai and G. Steidl
(a) Original Image (b) T-ROF (Ite. 11) (c) Cai [12]
(d) Li [22] (e) Pock [25] (f) Yuan [29] (g) He [20]
Fig. 3. Four-phase gray and white matter segmentation for a brain MRI image (319×
256)
Fig. 4. Stripe image with 30 stripes (140×240) and its noisy version for the segmen-
tation in Tab. 1
computed numerically by an ADMM algorithm with ﬁxed inner parameter 2.
Speedups by using more sophisticated methods will be considered in a future
paper. The stopping criteria in our T-ROF algorithm foru and τare
(
∥u(i) −
u(i−1)∥2
)
/∥u(i)∥2 ≤ϵu and ∥τ(k) −τ(k−1)∥2 ≤ϵτ, where ϵu and ϵτare ﬁxed to
10−4 and 10−5, respectively. The initialization of (τ(0)
i )K−1
i=1 was computed by
the fuzzy C-means method [7] with 100 iteration steps.
We will compare our method with the recently proposed multiclass segmenta-
tion methods [12,20,22,25,29]. Note that the methods [25,29] work with the ﬁxed
fuzzy C-means codebook and we do not update the codebook. Such update is
however involved in [20]. The default stopping criterion used in [20,22,25] is the
maximum iteration steps; the defaultstopping criterion used in [29] is 10−4 and
Multiclass Segmentation by Iterated ROF Thresholding 247
Table 1. Parameter µ, iteration steps, CPU time in seconds, and SA for example 4
Li [22]
Pock [25]
Yuan [29]
He [20]
Cai [12]
T-ROF
Five phases
µ
 80
 100
 10
 50
 10
 8
Ite.
 100
 100
 87
 100
 41
 84 (4)
Time
 3.87
 6.25
 4.33
 16.75
 1.33
 1.39
SA
 0.9946
 0.9965
 0.9867
 0.9968
 0.9770
 0.9986
Ten phases
µ
 80
 100
 10
 50
 10
 8
Ite.
 100
 100
 102
 100
 41
 84 (5)
Time
 7.71
 15.41
 9.79
 38.52
 2.11
 2.33
SA
 0.8545
 0.9984
 0.9715
 0.9848
 0.8900
 0.9967
Fifteen phases
µ
 80
 100
 10
 50
 10
 8
Ite.
 100
 100
 208
 100
 41
 84 (5)
Time
 11.56
 28.21
 33.21
 63.67
 3.06
 3.74
SA
 0.7715
 0.9993
 0.9730
 0.9904
 0.5280
 0.9933
(a) Original image (b) Noisy image (c) T-ROF (Ite. 6) (d) Cai [12]
SA =0 .9550 SA =0 .9232
(d) Li [22] (e) Pock [25] (f) Yuan [29] (h) He [20]
SA =0 .4420 SA =0 .9485 SA =0 .9557 SA =0 .9637
Fig. 5. Segmentation of three-class image (256 × 256) containing phases with close
intensities
maximum iteration steps 300; the default stopping criterion used in [12] is 10−4.
We choose the regularization parameterμof the ﬁdelity term in all the methods
by judging thesegmentation accuracy (SA) deﬁned as
SA =#correctly classiﬁed pixels
#all pixels .
248 X. Cai and G. Steidl
(a) Original Image (b) Noisy Image (c) T-ROF (Ite. 5) (d) Cai [12]
SA =0 .9798 SA =0 .9688
(e) Li [22] (e) Li [22] (e) Pock [25] (h) Pock [25]
SA =0 .4900 SA =0 .9023 SA =0 .9846 SA =0 .8769
(i) Yuan [29] (j) Yuan [29] (k) He [20] (l) He [20]
SA =0 .9130 SA =0 .8744 SA =0 .6847 SA =0 .9637
Fig. 6. Segmentation of four-class image (256×256) with close gray values
We show the results for two two-class and four multiclass images, where all
computations were done on a MacBook with 2.4 GHz processor and 4GB RAM.
For further examples we refer to [11].
Example 1 is a two-class cartoon image with some missing pixel values. The
segmentation results are shown in Fig. 1. We see that only methods [12,20] and
our method gives good results. Indeeda codebook update is required here.
Example 2 is a two-class image with close intensities generated as follows: We
have added Gaussian noise with mean 0 and variance 10−8 to constant image
with gray value 0.5. The noisy image is obtained by keeping the pixel values
belonging to the white parts of the original image and reducing the pixel values
belonging to the black parts by a factor of 2×10−4. Fig. 2 shows the results of
the various algorithms. Except the method [22], all models produce reasonable
results.
Example 3 is a four-class gray and white matter segmentation for a brain MRI
image from [25]. Fig. 3 gives the results. We can see that, all the methods work
well for this kind of image. Howeverour method with 11τ-value updates is faster
Multiclass Segmentation by Iterated ROF Thresholding 249
than the other methods, e.g., three times faster than the algorithm of Pock et
al. [25] with the assigned parameters.
Example 4 segments the noisy stripe image in Fig. 4 (b), which is generated
by imposing Gaussion noise with mean 0 and variance 10−3 on the clean image
Fig. 4 (a) with 30 stripes. The results for a 5, 10 and 15 class segmentation are
listed in Table 1.
Example 5 is a three-class image with close intensities. The test in image Fig.
5 is generated using the same way as those in Example 2 with Gaussian noise of
mean 0 and variance 10
−2, the scalars used in the black and white parts are 0.1
and 0.6, respectively. For the results of the diﬀerent methods see Fig. 5.
Example 6 showsafour-classimagewithcloseintensities. Fig.6(a)and(b) are
the original image and the noisy image generated by using Gaussian noise with
mean 0 and variance 3×10−2. Figs. 6 (c)–(l) provide two results for each method
using diﬀerent representativeparametersμ, where one parameter is optimalwith
respect to the SA.
References
1. Alter, F., Caselles, V., Chambolle, A.: A characterization of convex calibrable sets
in RN. Mathematische Annalen 332, 329–366 (2005)
2. Ambrosio, L., Fusco, N., Pallara, D.: Functions of Bounded Variation and Free
Discontinuity Problems. Oxford University Press, Oxford (2000)
3. Ambrosio, L., Tortorelli, V.: Approximation of functions depending on jumps by
elliptic functionals viat-convergence. Communications in Pure and Applied Math-
ematics 43, 999–1036 (1990)
4. Attouch, H., Buttazzo, G., Michaille, G.: Variational Analysis in Sobolev and BV
Spaces. SIAM, Philadelphia (2006)
5. Bar, L., Chan, T., Chung, G., Jung, M., Kiryati, N., Mohieddine, R., Sochen, N.,
Vese, L.: Mumford and Shah model and its applications to image segmentation
and image restoration. In: Handbook of Mathematical Imaging, pp. 1095–1157.
Springer (2011)
6. Bellettini, G., Paolini, M., Verdi, C.: Convex approximations of functionals with
curvature. Mat. Appl. 2, 297–306 (1991)
7. Bezdek, J.C., Ehrlich, R., Full, W.: FCM: The fuzzyc-means clustering algorithm.
Computers & Geosciences 10, 191–203 (1984)
8. Blake, A., Zisserman: Visual Reconstruction. MIT Press (1987)
9. Bresson, X., Esedoglu, S., Vandergheynst, P., Thiran, J., Osher, S.: Fast global
minimization of the active contour/snake model. Journal of Mathematical Imaging
and Vision 28, 151–167 (2007)
10. Brown, E., Chan, T., Bresson, X.: Completely convex formulation of the Chan-Vese
image segmentation model. International Journal of Computer Vision 98, 103–121
(2012)
11. Cai, X.: A new multiclass image segmentation model by ROF thresholding.
Preprint University of Kaiserslautern (2013)
12. Cai, X., Chan, R., Zeng, T.: A two-stage image segmentation method using a
convex variant of the Mumford-Shah model and thresholding. SIAM Journal on
Imaging Sciences 6, 368–390 (2013)
250 X. Cai and G. Steidl
13. Chambolle, A.: An algorithm for total variation minimization and applications.
Journal of Mathematical Imaging and Vision 20, 89–97 (2004)
14. Chambolle, A., Caselles, V., Novaga, M., Cremers, D., Pock, T.: An introduction
to total variation for image analysis. HAL Preprint, hal-00437581 (2009)
15. Chan, T.F., Esedoglu, S., Nikolova, M.: Algorithms for ﬁnding global minimizers
of image segmentation and denoising models. SIAM Journal on Applied Mathe-
matics 66, 1632–1648 (2006)
16. Chan, T.F., Vese, L.A.: Active contours without edges. IEEE Transactions on
Image Processing 10, 266–277 (2001)
17. Dong, B., Chien, A., Shen, Z.: Frame based segmentation for medical images.
Commun. Math. Sci. 32, 1724–1739 (2010)
18. Geman, S., Geman, D.: Stochastic relation, Gibbs distributions, and the Baysian
resoration of images. IEEE Transactions on Pattern Analysis and Machine Intelli-
gence 6(6), 721–741 (1984)
19. Gorski, J., Pfeiﬀer, F., Klamroth, K.: Biconvex sets and optimization with bicon-
vex functions - a survey and extensions. Mathematical Methods of Optimization
Research 66, 373–407 (2007)
20. He, Y., Hussaini, M.Y., Ma, J., Shafei, B., Steidl, G.: A new fuzzy c-means method
with total variation regularization for image segmentation of images with noisy and
incomplete data. Pattern Recognition 45, 3463–3471 (2012)
21. Lellmann, J., Schn¨orr, C.: Continuous multiclass labeling approaches and algo-
rithms. SIAM Journal on Imaging Science (to appear)
22. Li, F., Ng, M., Zeng, T., Shen, C.: A multiphase image segmentation method based
on fuzzy region competition. SIAM Journal on Imaging Sciences 3, 277–299 (2010)
23. Mumford, D., Shah, J.: Optimal approximation by piecewise smooth functions and
associated variational problems. Communications on Pure and Applied Mathemat-
ics, 577–685 (1989)
24. Nikolova, M., Esedoglu, S., Chan, T.F.: Algorithms for ﬁnding global minimizers
of image segmentation and denoising models. SIAM Journal on Applied Mathe-
matics 66, 1632–1648 (2006)
25. Pock, T., Chambolle, A., Cremers, D., Bischof, H.: A convex relaxation approach
for computing minimal partitions. In: IEEE Conference on Computer Vision and
Pattern Recognition, pp. 810–817 (2009)
26. Pock, T., Cremers, D., Bischof, H., Chambolle, A.: An algorithm for minimizing
the piecewise smooth Mumford-Shah functional. In: ICCV 2009 (2009)
27. Rudin, L.I., Osher, S., Fatemi, E.: Nonlinear total variation based noise removal
algorithms. Physica D 60, 259–268 (1992)
28. Vese, L., Chan, T.: A multiphase level setframework for image segmentation using
the Mumford and Shah model. International Journal of Computer Vision 50, 271–
293 (2002)
29. Yuan, J., Bae, E., Tai, X.-C., Boykov, Y.: A continuous max-ﬂow approach to Potts
model. In: European Conference on Computer Vision, pp. 379–392 (2010)
30. Zach, C., Gallup, D., Frahm, J., Niethammer, M.: Fast global labeling for real-
time stereo using multiple plane sweeps. In: Vision, Modeling, and Visualization
Workshop (2008)
31. Zhang, Y., Matuszewski, B., Shark, L., Moore, C.: Medical image segmentation
using new hybrid level-set method. In: Fifth International Conference BioMedical
Visualization: Information Visualization in Medical and Biomedical Informatics,
71–76 (2008)
